[
  {
    "title": "OpenClaw – Moltbot Renamed Again",
    "url": "https://openclaw.ai/blog/introducing-openclaw",
    "source": "hn",
    "summary": "",
    "comments": [
      "So i feel like this might be the most overhyped project in the past longer time.<p>I don&#x27;t say it doesn&#x27;t &quot;work&quot; or serves a purpose - but well i read so much about this beein an &quot;actual intelligence&quot; and stuff that i had to look into the source.<p>As someone who spends actually a definately to big portion of his free time researching thought process replication and related topics in the realm of &quot;AI&quot; this is not really more &quot;ai&quot; than any other so far.<p>Just my 3 cents.",
      "I hope AI people start doing agentic agents to agent their agents and stop interacting with other humans whatsoever. Will be positive for all involved.",
      "Before using make sure you read this entirely and understand it:\n<a href=\"https:&#x2F;&#x2F;docs.openclaw.ai&#x2F;gateway&#x2F;security\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.openclaw.ai&#x2F;gateway&#x2F;security</a>\nMost important sentence: &quot;Note: sandboxing is opt-in. If sandbox mode is off&quot;\nDon&#x27;t do that, turn sandbox on immediately.\nOtherwise you are just installing an LLM controlled RCE.<p>There are still improvements to be made to the security aspects yet BIG KUDOS for working so hard on it at this stage and documenting it extensively!! I&#x27;ve explored Cursor security docs (with a big s cause it&#x27;s so scattered) and it was nothing as good.",
      "I tried it out yesterday, after reading the enthousiastic article at <a href=\"https:&#x2F;&#x2F;www.macstories.net&#x2F;stories&#x2F;clawdbot-showed-me-what-the-future-of-personal-ai-assistants-looks-like&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.macstories.net&#x2F;stories&#x2F;clawdbot-showed-me-what-t...</a><p>Setting it up was easy enough, but just as I was about to start linking it to some test accounts, I noticed I already had blown through about $5 of Claude tokens in half an hour, and deleted the VPS immediately.<p>Then today I saw this follow up: <a href=\"https:&#x2F;&#x2F;mastodon.macstories.net&#x2F;@viticci&#x2F;115968901926545907\" rel=\"nofollow\">https:&#x2F;&#x2F;mastodon.macstories.net&#x2F;@viticci&#x2F;115968901926545907</a> - the author blew through $560 of tokens in a weekend of playing with it.<p>If you want to run this full time to organise your mailbox and your agenda, it&#x27;s probably cheaper to hire a real human personal assistant.",
      "It&#x27;s hilarious that atm I see &quot;Moltbook&quot; at the top of HN. And it is actually not Moltbot anymore? But I have to admit that OpenClaw sounds much better.",
      "The current top HN post is for moltbook.com seven hours ago, this present thread being just below it and posted two hours hence<p>We conclude this week has been a prosperous one for domain name registrars (even if we set aside all the new domains that Clawdbot&#x2F;Moltbot&#x2F;OpenClaw has registered autonomously).",
      "My biggest issue with this whole thing is: how do you protect yourself from prompt injection?<p>Anyone installing this on their local machine is a little crazy :). I have it running in Docker on a small VPS, all locked down.<p>However, it does not address prompt injection.<p>I can see how tools like Dropbox, restricted GitHub access, etc., could all be used to back up data in case something goes wrong.<p>It&#x27;s Gmail and Calendar that get me - the ONLY thing I can think of is creating a second @gmail.com that all your primary email goes to, and then sharing that Gmail with your OpenClaw. If all your email is that account and not your main one, then when it responds, it will come from a random @gmail. It&#x27;s also a pain to find a way to move ALL old emails over to that Gmail for all the old stuff.<p>I think we need an OpenClaw security tips-and-tricks site where all this advice is collected in one place to help people protect themselves.  Also would be good to get examples of real use cases that people are using it for.",
      "I’m a big fan of Peter’s projects. I use Vibetunnel everyday to code from my phone (I built a custom frontend suited to my needs). I know I can SSH into my laptop but this is much better because handoff is much cleaner. And it works using Tailscale so it is secure and not exposed to the internet.<p>His other projects like CodexBar and Oracle are great too. I love diving into his code to learn more about how those are built.<p>OpenClaw is something I don’t quite understand. I’m not sure what it can do that you can’t do right off the bat with Claude Code and other terminal agents. Long term memory is one, but to me that pollutes the context. Even if an LLM has 200K or 1M context, I always notice degradation after 100K. Putting in a heavy chunk for memory will make the agent worse at simple tasks.<p>One thing I did learn was that OpenClaw uses Pi under the hood. Pi is yet another terminal agent like ClaudeCode but it seems simple and lightweight. It’s actually the only agent I could get Gemini 3 Flash and Pro to consistently use tools with without going into loops.",
      "Not very trust-inducing to rename a popular project so often in such a short time. I&#x27;ve yet again have to change all the (three) bookmarks I collected.<p>Anyway, independent of what one thinks of this project, It&#x27;s very insightful to read through the repository and see how AI-usage and agent are working these days. But reading through the integrations, I&#x27;m curious to know why it bothers to make all of them, when tools like n8n or Node-RED are existing, which are already offering tons of integrations. Wouldn&#x27;t it be more productive to just build a wrapper around such integrations-hubs?",
      "That made me smile<p><pre><code>          Security: 34 security-related commits to harden the codebase\n</code></pre>\n<i>Narrator&#x27;s voice: They needed a 35th.</i><p>Much better name!"
    ],
    "full_text": null
  },
  {
    "title": "The Engineer who invented the Mars Rover Suspension in his garage [video]",
    "url": "https://www.youtube.com/watch?v=QKSPk_0N4Jc",
    "source": "hn",
    "summary": "",
    "comments": [
      "This guy has incredible videos on hiking gear, examining common claims scientifically and rationally. He never gave any hints as to his professional background, so as not to taint his arguments with appeals to authority. It makes perfect sense that he grew up in this environment, doing engineering work for NASA as a kid!",
      "Not surprised of such article.<p>It&#x27;s not the first time something important is built in a garage:<p>for example, the Apollo 11 lander; a lot of people were thinking it was made from aluminum folio and cardboard in a garage, but actually it was kapton folio and professional-grade cardboard.",
      "Best not read the comments until you&#x27;ve watched at least the first four minutes of the video.",
      "&quot;There are no shortcuts to expertise&quot;.<p>What a fantastic post this."
    ],
    "full_text": null
  },
  {
    "title": "How AI assistance impacts the formation of coding skills",
    "url": "https://www.anthropic.com/research/AI-assistance-coding-skills",
    "source": "hn",
    "summary": "",
    "comments": [
      "Good for them to design and publish this - I doubt you&#x27;d see anything like this from the other labs.<p>The loss of competency seems pretty obvious but it&#x27;s good to have data.  What is also interesting to me is that the AI assisted group accomplished the task a bit faster but it wasn&#x27;t statistically significant.  Which seems to align with other findings that AI can make you &#x27;feel&#x27; like you&#x27;re working faster but that perception isn&#x27;t always matched by the reality.   So you&#x27;re trading learning and eroding competency for a productivity boost which isn&#x27;t always there.",
      "I think this is where current senior engineers have an advantage, like I felt when I was a junior that the older guys had an advantage in understanding the low level stuff like assembly and hardware. But software keeps moving forward - my lack of time coding assembly by hand has never hindered my career. People will learn what they need to learn to be productive. When AI stops working in a given situation, people will learn the low level detail as they need to. When I was a junior I learned a couple of languages in depth, but everything since has been top down, learn-as-i-need to. I don&#x27;t remember everything I&#x27;ve learned over 20 years software engineering, and the forgetting started way before my use of AI. It&#x27;s true that conceptual understanding is necessary, but everyone&#x27;s acting like all human coders are better than all AI&#x27;s, and that is not the case. Poorly architected, spaghetti code existed way before LLM&#x27;s.",
      "An important aspect of this for professional programmers is that learning is not something that happens as a beginner, student or &quot;junior&quot; and then stops. The <i>job</i> is learning, and after 25 years of doing it I learn more per day than ever.",
      "Being able to debug and diagnose difficult problems and distributed systems still remains a key skill, at least until Opus or some other model gets better at it.<p>I think being intentional about learning while using AI to be productive is where the stitch is, at least for folks earlier in their career. I touch that in my post here as well: <a href=\"https:&#x2F;&#x2F;www.shayon.dev&#x2F;post&#x2F;2026&#x2F;19&#x2F;software-engineering-when-the-machine-writes-code&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.shayon.dev&#x2F;post&#x2F;2026&#x2F;19&#x2F;software-engineering-whe...</a>",
      "It&#x27;s good that there&#x27;s some research into this - to confirm what is generally obvious to anyone who studied anything. You have to think about what you are doing, write things by hand, use the skill to improve and retain it.<p>Common example here is learning a language. Say, you learn French or Spanish throughout your school years or on Duolingo. But unless you&#x27;re lucky enough to be amazing with language skills, if you don&#x27;t actually use it, you will hit a wall eventually. And similarly if you stop using language that you already know - it will slowly degrade over time.",
      "No surprise, really. You can use AI to explore new horizons or propose an initial sketch, but for anything larger than small changes - you must do a rewrite. Not just a review. An actual rewrite. AI can do well adding a function, but you can&#x27;t vibe code an app and get smarter.<p>I don&#x27;t necessarily think that writing more code means you get better coder. I automate nearly all my tests with AI and large chunk of bugfixing as well. I will regularly ask AI to propose an architecture or introduce a new pattern if I don&#x27;t have a goal in my mind. But in these last 2 examples, I will always redesign the entire approach to be what I consider a better, cleaner interface. I don&#x27;t recall AI ever getting that right, but must admit I asked AI in the first place cos I didn&#x27;t know where to start.<p>If I had to summarize, I would say to let AI implement coding, but not API design&#x2F;architecture. But at the same time, you can only get good at those by knowing what doesn&#x27;t work and trying to find a better solution.",
      "Go Anthropic for transparency and commitment to science.<p>Personally, I’ve never been learning software development <i>concepts</i> faster—but that’s because I’ve been offloading actual development to other people for years.",
      "I must say I am quite impressed that Anthropic published this, given that they found that:<p>1. AI help produced a solution only 2m faster, and<p>2. AI help reduced retention of skill by 17%",
      "The learning loop and LLMs [1] is well worth reading and the anthropic blog post above concurs with it in a number of places. It&#x27;s fine to use LLMs as an assistant to understanding but your goal as an engineer should always be understanding and the only real way to do that is to have to struggle to make things yourself.<p>[1] <a href=\"https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;llm-learning-loop.html\" rel=\"nofollow\">https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;llm-learning-loop.html</a>",
      "&gt; Unsurprisingly, participants in the No AI group encountered more errors. These included errors in syntax and in Trio concepts, the latter of which mapped directly to topics tested on the evaluation<p>I&#x27;m wondering if we could have the best of IDE&#x2F;Editor features like LSP and LLMs working together. With an LSP syntax errors are a solved problem, if the language is statically typed I often find myself just checking out type signatures of library methods, simpler to me than asking an LLM. But I would love to have LLMs fixing your syntax and with types available or not, giving suggestions on how to best use the libraries given current context.<p>Cursor tab does that to some extent but it&#x27;s not fool proof and it still feels too &quot;statistical&quot;.<p>I&#x27;d love to have something deeply integrated with LSPs and IDE features, for example VSCode alone has the ability of suggesting imports, Cursor tries to complete them statistically but it often suggest the wrong import path. I&#x27;d like to have the twos working together.<p>Another example is renaming identifiers with F2, it is reliable and predictable, can&#x27;t say the same when asking an agent doing that. On the other hand if the pattern isn&#x27;t predictable, e.g. a migration where a 1 to 1 rename isn&#x27;t enough, but needs to find a pattern, LLMs are just great. So I&#x27;d love to have an F2 feature augmented with LLMs capabilities"
    ],
    "full_text": null
  },
  {
    "title": "Claude Code daily benchmarks for degradation tracking",
    "url": "https://marginlab.ai/trackers/claude-code/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Hi everyone, Thariq from the Claude Code team here.<p>Thanks for reporting this. We fixed a Claude Code harness issue that was introduced on 1&#x2F;26. This was rolled back on 1&#x2F;28 as soon as we found it.<p>Run `claude update` to make sure you&#x27;re on the latest version.",
      "[SWE-bench co-author here]\nIt seems like they run this test on a subset of 50 tasks, and that they only run the test once per day. So a lot of the movement in accuracy could be attributed to that. \nI would run on 300 tasks and I&#x27;d run the test suite 5 or 10 times per day and average that score. Lots of variance in the score can come from random stuff like even Anthropic&#x27;s servers being overloaded.",
      "Why I do not believe this shows Anthropic serves folks a worse model:<p>1. The percentage drop is too low and oscillating, it goes up and down.<p>2. The baseline of Sonnet 4.5 (the obvious choice for when they have GPU busy for the next training) should be established to see Opus at some point goes Sonnet level. This was not done but likely we would see a much sharp decline in certain days &#x2F; periods. The graph would look like dominated by a &quot;square wave&quot; shape.<p>3. There are much better explanations for this oscillation: A) They have multiple checkpoints and are A&#x2F;B testing, CC asks you feedbacks about the session. B) Claude Code itself gets updated, as the exact tools version the agent can use change. In part it is the natural variability due to the token sampling that makes runs not equivalent (sometimes it makes suboptimal decisions compared to T=0) other than not deterministic, but this is the price to pay to have some variability.",
      "&gt; <i>We model tests as Bernoulli random variables and compute 95% confidence intervals around daily, weekly, and monthly pass rates. Statistically significant differences in any of those time horizons are reported.</i><p>They&#x27;re going to need to provide a lot more detail on their methodology, because that doesn&#x27;t make a lot of sense. From their graphs, they seem to be calculating the confidence interval around the previous value, then determining whether the new value falls outside of it. But that&#x27;s not valid for establishing the statistical significance of a <i>difference</i>. You need to calculate the confidence interval <i>of the difference itself</i>, and then see if <i>all the values within that confidence interval remain positive</i> (if it excludes 0).  This is because <i>both</i> the old <i>and</i> new measurement have uncertainty. Their approach seems to be only considering uncertainty for one of them.<p>They should also really be more specific about the time periods. E.g. their graphs only show performance over the past 30 days, but presumably the monthly change is comparing the data from 60 to 31 days ago, to the data from 30 days ago until yesterday? In which case the weekly graph really ought to be displaying the past <i>two</i> months, not one month.",
      "Simply search user prompts for curse words and then measure hostility sentiment.  User hostility rises as agents fail to meet expectations.",
      "There was a moment about a week ago where Claude went down for about an hour. And right after it came back up it was clear a lot of people had given up and were not using it.<p>It was probably 3x faster than usual. I got more done in the next hour with it than I do in half a day usually. It was definitely a bit of a glimpse into a potential future of “what if these things weren’t resource constrained and could just fly”.",
      "Wouldn&#x27;t be surprised if they slowly start quantizing their models over time. Makes it easier to scale and reduce operational cost. Also makes a new release have more impact as it will be more notably &quot;better&quot; than what you&#x27;ve been using the past couple of days&#x2F;weeks.",
      "Lack of transparency as regards &quot;thinking power&quot;-consistency is a big gripe of mine with LLM providers. It&#x27;s even worse with ChatGPT and the like. E.g. I had to learn the hard way that at &gt;45k input tokens ChatGPT 5.2 Thinking Extended bumps its intelligence down so hard that it can&#x27;t follow basic instructions (or it somehow truncates the input, losing the instructions). It sucks to lose confidence in an otherwise great tool. I would 100x prefer being forced to back-off, or getting a straight-no, than getting silently downgraded. Transparency is a big deal.",
      "I am using API mode, and it&#x27;s clear that there are times when the Claude model just gives up. And it is very noticeable because the model just does the most dumb things possible.<p>&quot;You have a bug in line 23.&quot; &quot;Oh yes, this solution is bugged, let me delete the whole feature.&quot; That one-line fix I could make even with ChatGPT 3.5 can&#x27;t just happen. Workflows that I use and are very reproducible start to flake and then fail.<p>After a certain number of tokens per day, it becomes unusable. I like Claude, but I don&#x27;t understand why they would do this.",
      "Running agents in production, I&#x27;ve stopped trying to figure out <i>why</i> things degrade. The answer changes weekly.<p>Model drift, provider load, API changes, tool failures - it doesn&#x27;t matter. What matters is that yesterday&#x27;s 95% success rate is today&#x27;s 70%, and by the time you notice, debug, and ship a fix, something else has shifted.<p>The real question isn&#x27;t &quot;is the model degraded?&quot; It&#x27;s &quot;what should my agent do right now given current conditions?&quot;<p>We ended up building systems that canary multiple execution paths continuously and route traffic based on what&#x27;s actually working. When Claude degrades, traffic shifts to the backup path automatically. No alerts, no dashboards, no incident.<p>Treating this as a measurement problem assumes humans will act on the data. At scale, that assumption breaks."
    ],
    "full_text": null
  },
  {
    "title": "Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT",
    "url": "https://openai.com/index/retiring-gpt-4o-and-older-models/",
    "source": "hn",
    "summary": "",
    "comments": [
      "It’s interesting that many comments mention switching back to Claude. I’m on the opposite end, as I’ve been quite happy with ChatGPT recently. Anthropic clearly changed something after December last year. My Pro plan is barely usable now, even when using only Sonnet. I frequently hit the weekly limit, which never happened before. In contrast, ChatGPT has been very generous with usage on their plan.<p>Another pattern I’m noticing is strong advocacy for Opus, but that requires at least the 5x plan, which costs about $100 per month. I’m on the ChatGPT $20 plan, and I rarely hit any limits while using 5.2 on high in codex.",
      "&gt; We’re continuing to make progress toward a version of ChatGPT designed for adults over 18, grounded in the principle of treating adults like adults, and expanding user choice and freedom within appropriate safeguards. To support this, we’ve rolled out age prediction  for users under 18 in most markets.\n<a href=\"https:&#x2F;&#x2F;help.openai.com&#x2F;en&#x2F;articles&#x2F;12652064-age-prediction-in-chatgpt\" rel=\"nofollow\">https:&#x2F;&#x2F;help.openai.com&#x2F;en&#x2F;articles&#x2F;12652064-age-prediction-...</a><p>interesting",
      "Been unhappy with the GPT5 series, after daily driving 4.x for ages (I chat with them through the API) - very pedantic, goes off on too many side topics, stops following system instructions after a few turns (e.g. &quot;you respond in 1-3 sentences&quot; becomes long bulleted lists and multiple paragraphs very quickly.<p>Much better feel with the Claude 4.5 series, for both chat and coding.",
      "&gt;We brought GPT‑4o back after hearing clear feedback from a subset of Plus and Pro users, who told us they needed more time to transition key use cases, like creative ideation, and that they preferred GPT‑4o’s conversational style and warmth.<p>This does verify the idea that OpenAI does not make models sycophantic due to attempted subversion by buttering up users so that that they use the product more, its because people actually <i>want</i> AI to talk to them like that. To me, that&#x27;s insane, but they have to play the market I guess",
      "After they pushed the limits on the Thinking models to 3000 per week, I haven&#x27;t touched anything else. I am really satisfied with their performance and the 200k context windows is quite nice.<p>I&#x27;ve been using Gemini exclusively for the 1 million token context window, but went back to ChatGPT after the raise of the limits and created a Project system for myself which allows me to have much better organization with Projects + only Thinking chats (big context) + project-only memory.<p>Also, it seems like Gemini is really averse to googling (which is ironic by itself) and ChatGPT, at least in the Thinking modes loves to look up current and correct info. If I ask something a bit more involved in Extended Thinking mode, it will think for several minutes and look up more than 100 sources. It&#x27;s really good, practically a Deep Research inside of a normal chat.",
      "ChatGPT 5.2 has been a good motivator for me to try out other LLMs because of how bad it is. Both 5.1 and 5.2 have been downgrades in terms of instruction following and accuracy, but 5.2 especially so. The upside is that that&#x27;s had me using Claude much more, and I like a lot of things about it, both in terms of UI and the answers. It&#x27;s also gotten me more serious about running local models. So, thank you OpenAI, for forcing me to broaden my horizons!",
      "Gemini, Claude, ChatGPT or whatever. Can we all agree, that it&#x27;s great to have so much choice?",
      "Retiring the most popular model for the relationship roleplay just one day before the Valentin&#x27;s day is particularly ironic =) bravo, OpenAI!",
      "&gt; [...] the vast majority of usage has shifted to GPT‑5.2, with only 0.1% of users still choosing GPT‑4o each day.",
      "If they were to retire gpt 4.1 series from API that would be a major deal breaker. For structured outputs it is more predictable and significantly better because it does not have the reasoning step baked in.<p>I&#x27;ve heard great things about the mixtral structured outputs capabilities but haven&#x27;t had a chance to run my evals on them.<p>If 4.1 is dropped from API that&#x27;s the first course of action.<p>Also 5 series doesn&#x27;t have fine tuning capabilities and it&#x27;s unclear how it would work if the reasoning step is involved"
    ],
    "full_text": null
  },
  {
    "title": "The WiFi only works when it's raining (2024)",
    "url": "https://predr.ag/blog/wifi-only-works-when-its-raining/",
    "source": "hn",
    "summary": "",
    "comments": [
      "People have mentioned &quot;can&#x27;t print on Tuesdays&quot;, which reminds me of an error that occurred with a Linux PDF viewer at the math department at Berkeley:<p>&quot;Oct  2: Warning: Due to a known bug, the default Linux document viewer evince prints N*N copies of a PDF file when N copies requested.  As a workaround, use Adobe Reader acroread for printing multiple copies of PDF documents, or use the fact that every natural number is a sum of at most four squares.&quot;<p>I&#x27;ve seen other references to this bug, but the workaround is the sort of thing mathematicians would come up with.<p>sources: <a href=\"https:&#x2F;&#x2F;mathoverflow.net&#x2F;a&#x2F;3601&#x2F;143\" rel=\"nofollow\">https:&#x2F;&#x2F;mathoverflow.net&#x2F;a&#x2F;3601&#x2F;143</a>, <a href=\"https:&#x2F;&#x2F;math.berkeley.edu&#x2F;computing&#x2F;wiki&#x2F;index.php?title=Support:Old_News&amp;oldid=3483\" rel=\"nofollow\">https:&#x2F;&#x2F;math.berkeley.edu&#x2F;computing&#x2F;wiki&#x2F;index.php?title=Sup...</a>",
      "Back when I had cable internet we had a bizarre problem where the service would often stop working if it was very cold and raining. It had to be that specific combo as well.<p>- Just rain == good internet\n- Just cold == good internet\n- Cold + rain == bad internet<p>After a lot of head scratching the provider finally sent someone with a ladder to climb the poll. What they found was that the protective boot on the coax connection was bad. When it rained for a while water would seep into the coax connector. By itself this wasn’t too bad, but if it was also cold outside it would freeze. This would then force a gap between the threads of the socket and the cable, breaking the ground connection.<p>Previously, the connector had been replaced, but nobody had noticed the torn boot. This tech replaced both the connector and the boot and the problem was solved! It honestly was the best interaction with the cable company I have ever had. Only returning their hardware when switching to fiber felt almost as good.",
      "I&#x27;ve collected a list of fun stories of this form and post them when this comes up:<p>- Car allergic to vanilla ice cream: <a href=\"https:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~wkw&#x2F;humour&#x2F;carproblems.txt\" rel=\"nofollow\">https:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~wkw&#x2F;humour&#x2F;carproblems.txt</a><p>- Can&#x27;t log in when standing up: <a href=\"https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;talesfromtechsupport&#x2F;comments&#x2F;3v52pw&#x2F;i_cant_log_in_when_i_stand_up&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;talesfromtechsupport&#x2F;comments&#x2F;3v52p...</a><p>- OpenOffice won&#x27;t print on Tuesdays: <a href=\"https:&#x2F;&#x2F;bugs.launchpad.net&#x2F;ubuntu&#x2F;+source&#x2F;cupsys&#x2F;+bug&#x2F;255161&#x2F;comments&#x2F;28\" rel=\"nofollow\">https:&#x2F;&#x2F;bugs.launchpad.net&#x2F;ubuntu&#x2F;+source&#x2F;cupsys&#x2F;+bug&#x2F;255161...</a>",
      "Oh, wow. This sort of happened in my life!<p>My grandmother&#x27;s house is adjacent my parents&#x27; w&#x2F; 200 ft. between and line of sight. Back in 2013, when my grandmother moved into the then-new house, I setup a point-to-point wifi bridge between them to share my parents&#x27; Internet connection and give me easy remote support access to grandma.<p>Summer of 2023 visiting relatives complained the Internet service in grandma&#x27;s house was slow and unreliable. There were repeated suggestions made by helpful relatives for purchasing a new WiFi router for her house, getting independent Internet service, etc.<p>Grandma was happy with it, and the relatives went home, so I put off looking at it. When I did finally look at it, months later (when I went over for Thanksgiving) everything seemed fine.<p>When the relatives came to visit in summer 2024 they complained again. I looked at it immediately and found massive packet loss on both ends.<p>The ornamental trees planted along the driveway between the houses were the culprit. With the leaves off (say, at Thanksgiving time) it was fine. When the relatives came to visit in the summer the trees were in full leaf and acting as very good attenuators.<p>The trees were newly planted when grandma moved in. I didn&#x27;t even think about them getting bigger and fuller when I set up the link. They filled out in the 10 years intervening, though. (Chalk it up to me still being relatively young and not thinking about installations on 10+ year timescales when I put it up.)<p>Fortunately there&#x27;s a room in her house with line of sight to my parents&#x27; house unobscured by trees. It meant putting the radio outside a bedroom window instead of the attic (where I&#x27;d originally stashed it), but it solved the problem and ended complaints from relatives.",
      "My only unsolved networking mystery was that my computer would experience high packet loss when a Roku in the other room was streaming Netflix.<p>My PC and the roku device were both wired to two different ports on a router (iirc an Edgerouter X running openwrt at the time).  This didn&#x27;t repro when the roku streamed other services (hulu&#x2F;youtube tested), <i>only</i> netflix.  This also didn&#x27;t repro if the roku was connected over wireless (connecting to an AP wired to a different port).  Just opening netflix also didn&#x27;t repro, the roku had to be actively streaming a netflix video.<p>I never ended up solving it, I just worked around it by making the roku connect over wireless.<p>It did take me <i>forever</i> to figure out the problem though.  For a long time I&#x27;d be in one room getting frustrated with my computer while someone was innocently watching netflix in the other room.",
      "I once moved into a new apartment, built a new PC, but noticed that every 30 or so minutes while gaming my monitor would turn off. It was just frequent enough to make gaming intolerable. One day I was plugging something in and moved my DisplayPort cable slightly and my monitor turned off again. Turns out it was too close to the antennas for the WiFi card I had; it was inducing a current in the DisplayPort cable and the monitor’s firmware didn’t know what to do so it just crashed! I moved the cable slightly further away and it never happened again.",
      "Wifi routers are little magic devices that work only when they want. I talked before here, but I had a Dell Vostro notebook that everytime it connected with my router using windows it would just kill the entire home wifi. It was a TP-Link mesh network. The only thing that would bring the thing up was to reboot every single router in the network and not connect that notebook.<p>I tried update my routers, tried to update my notebook wifi firmware, tryed to change the router config, the router position, the router order, the wifi channel, the wifi name and password. Nothing worked. But if I connected using linux, things would work just fine.<p>In the end I divorced my wife and brought a Thinkpad. She keeped the cat, the house, the routers and that dell vostro notebook.<p>I keeped the dog and the car.",
      "&gt;With a bit of work, my dad set up a line-of-sight Wi-Fi bridge — a couple of high-gain directional Wi-Fi antennas pointed at each other — between the office and our apartment.<p>How was that not the first thing to be checked ? OP must have hit themselves over the head for not thinking of that one sooner",
      "My first thought was atmospheric effects, i.e. along the lines of &quot;The radio only works at night&quot;: <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clear-channel_station\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clear-channel_station</a><p>Also worth reading: <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sporadic_E_propagation\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sporadic_E_propagation</a><p>I must say, the AI-generated &quot;stock image&quot; doesn&#x27;t add that much to the article and could be done without, especially when its alt-text contains the prompt.",
      "Man having dealt with so many wireless issues I already had a shortlist when I read fixed wireless was involved.<p>Either the radios were misaligned and the rain was reflecting it back towards a stable link just enough to improve throughput.<p>Or<p>The rain took a bad link all the way down, failing over to a different link.<p>Or<p>The rain&#x2F;wind was moving an obstruction.<p>I have about a million of these stories sadly.<p>&quot;The internet goes down on tuesdays&quot;<p>Crane.<p>&quot;The internet goes out in the morning&quot;<p>Temperature inversion."
    ],
    "full_text": null
  },
  {
    "title": "AGENTS.md outperforms skills in our agent evals",
    "url": "https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals",
    "source": "hn",
    "summary": "",
    "comments": [
      "Models are not AGI. They are text generators forced to generate text in a way useful to trigger a harness that will produce effects, like editing files or calling tools.<p>So the model won’t “understand” that you have a skill and use it. The generation of the text that would trigger the skill usage is made via Reinforcement Learning with human generated examples and usage traces.<p>So why don’t the model use skills all the time? Because it’s a new thing, there is not enough training samples displaying that behavior.<p>They also cannot enforce that via RL because skills use human language, which is ambiguous and not formal. Force it to use skills always via RL policy and you’ll make the model dumber.<p>So, right now, we are generating usage traces that will be used to train the future models to get a better grasp of when to use skills not.  Just give it time.<p>AGENTS.md, on the other hand, is context. Models have been trained to follow context since the dawn of the thing.",
      "&gt; In 56% of eval cases, the skill was never invoked. The agent had access to the documentation but didn&#x27;t use it.<p>The agent passes the Turing test...",
      "The key finding is that &quot;compression&quot; of doc pointers works.<p>It&#x27;s barely readable to humans, but directly and efficiently relevant to LLM&#x27;s (direct reference -&gt; referent, without language verbiage).<p>This suggests some (compressed) index format that is always loaded into context will replace heuristics around agents.md&#x2F;claude.md&#x2F;skills.md.<p>So I would bet this year we get some normalization of both the indexes and the referenced documentation (esp. matching terms).<p>Possibly also a side issue: API&#x27;s could repurpose their test suites as validation to compare LLM performance of code tasks.<p>LLM&#x27;s create huge adoption waves.  Libraries&#x2F;API&#x27;s will have to learn to surf them or be limited to usage by humans.",
      "Am I missing something here?<p>Obviously directly including context in something like a system prompt will put it in context 100% of the time. You could just as easily take all of an agent&#x27;s skills, feed it to the agent (in a system prompt, or similar) and it will follow the instructions more reliably.<p>However, at a certain point you have to use skills, because including it in the context every time is wasteful, or not possible. this is the same reason anthropic is doing advanced tool use ref: <a href=\"https:&#x2F;&#x2F;www.anthropic.com&#x2F;engineering&#x2F;advanced-tool-use\" rel=\"nofollow\">https:&#x2F;&#x2F;www.anthropic.com&#x2F;engineering&#x2F;advanced-tool-use</a>, because there&#x27;s not enough context to straight up include everything.<p>It&#x27;s all a context &#x2F; price trade off, obviously if you have the context budget just include what you can directly (in this case, compressing into a AGENTS.md)",
      "I’m working on an AGI model that will make the discussion of skills look silly. Skills strikes in the right direction in some sense but it’s an extremely weak 1% echo of what’s actually needed to solve this problem.",
      "The article presents AGENTS.md as something distinct from Skills, but it is actually a simplified instance of the same concept. Their AGENTS.md approach tells the AI where to find instructions for performing a task. That’s a Skill.<p>I expect the benefit is from better Skill design, specifically, minimizing the number of steps and decisions between the AI’s starting state and the correct information. Fewer transitions -&gt; fewer chances for error to compound.",
      "I&#x27;m not sure if this is widely known but you can do a lot better even than AGENTS.md.<p>Create a folder called .context and symlink anything in there that is relevant to the project. For example READMEs and important docs from dependencies you&#x27;re using. Then configure your tool to always read .context into context, just like it does for AGENTS.md.<p>This ensures the LLM has all the information it needs right in context from the get go. Much better performance, cheaper, and less mistakes.",
      "Something that I always wonder with each blog post comparing different types of prompt engineering is did they run it once, or multiple times? LLMs are not consistent for the same task. I imagine they realize this of course, but I never get enough details of the testing methodology.",
      "This largely mirrors my experience building my custom agent<p>1. Start from the Claude Code extracted instructions, they have many things like this in there. Their knowledge share in docs and blog on this aspect are bar none<p>2. Use AGENTS.md as a table of contents and sparknotes, put them everywhere, load them automatically<p>3. Have topical markdown files &#x2F; skills<p>4. Make great tools, this is still opaque in my mind to explain, lots of overlap with MCP and skills, conceptually they are the same to me<p>5. Iterate, experiment, do weird things, and have fun!<p>I changed read&#x2F;write_file to put contents in the state and presented in the system prompt, same for the agents.md, now working on evals to show how much better this is, because anecdotally, it kicks ass",
      "PreSession Hook from obra&#x2F;superpowers injects this along with more logic for getting rid of rationalizing out of using skills:<p>&gt; If you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.<p>While this may result in overzealous activation of skills, I&#x27;ve found that if I have a skill related, I _want_ to use it. It has worked well for me."
    ],
    "full_text": null
  },
  {
    "title": "The paper model houses of Peter Fritz (2013)",
    "url": "https://socks-studio.com/2013/12/06/the-imaginary-town-of-an-unconscious-architect-the-387-paper-models-houses-of-peter-fritz/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Czechs have a good tradition in paper models of architecture:<p><a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Langweil%27s_Model_of_Prague\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Langweil%27s_Model_of_Prague</a><p><a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Richard_Vy%C5%A1kovsk%C3%BD\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Richard_Vy%C5%A1kovsk%C3%BD</a> (sadly the article doesn&#x27;t really do justice to how prolific he was, partial list of models is <a href=\"https:&#x2F;&#x2F;cs.wikipedia.org&#x2F;wiki&#x2F;Seznam_vyst%C5%99ihov%C3%A1nek_Richarda_Vy%C5%A1kovsk%C3%A9ho\" rel=\"nofollow\">https:&#x2F;&#x2F;cs.wikipedia.org&#x2F;wiki&#x2F;Seznam_vyst%C5%99ihov%C3%A1nek...</a>)",
      "Wow. That&#x27;s really impressive. Here is more background:<p><a href=\"https:&#x2F;&#x2F;magazin.wienmuseum.at&#x2F;die-387-haeuser-des-peter-fritz\" rel=\"nofollow\">https:&#x2F;&#x2F;magazin.wienmuseum.at&#x2F;die-387-haeuser-des-peter-frit...</a><p>And the virtual exhibition of the museum:<p><a href=\"https:&#x2F;&#x2F;sammlung.wienmuseum.at&#x2F;alben&#x2F;edb7nhc3tyww8dncp-sondermodelle.-die-387-haeuser-des-peter-fritz&#x2F;#982577-sondermodelle-die-387-haeuser-des-peter-fritz-versicherungsbeamter-aus-wien\" rel=\"nofollow\">https:&#x2F;&#x2F;sammlung.wienmuseum.at&#x2F;alben&#x2F;edb7nhc3tyww8dncp-sonde...</a><p>Some of the models contain a rail segment (Märklin etc.). Was he a model train enthousiast and the houses were part of a layout, or did he use the rails just as accessories? Strange that the articles don&#x27;t say anything about the artist&#x27;s motivation.",
      "If this post was interesting to you check my architectural models blog[0]. It’s in zombie mode now but I posted regularly for a decade.<p>[0] <a href=\"https:&#x2F;&#x2F;archimodels.tumblr.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;archimodels.tumblr.com&#x2F;</a>",
      "Related: the artist Thomas Demand who builds paper models of all kinds of situations <a href=\"https:&#x2F;&#x2F;thomasdemand.net&#x2F;selected-work\" rel=\"nofollow\">https:&#x2F;&#x2F;thomasdemand.net&#x2F;selected-work</a>",
      "I wish I, too, could do stuff like that while being unconscious.",
      "This post made my day. Beautiful."
    ],
    "full_text": null
  },
  {
    "title": "Launch HN: AgentMail (YC S25) – An API that gives agents their own email inboxes",
    "url": "https://news.ycombinator.com/item?id=46812608",
    "source": "hn",
    "summary": "",
    "comments": [
      "I&#x27;m 100% for this, but I think you can go even more granular than &quot;gives agents their own inboxes&quot;.<p>Thanks to Action Mailbox in Rails[1], I give all my records email addresses. Eg let ecommerce &quot;order&quot; records accept forwarded emails that are pinned as comments. It opens you up for doing things like forwarding a purchase order and having the PO number pulled out and attached to an order, or forwarding tracking information from a supplier and having it attached to a &quot;supplier order&quot; etc.<p>In my personal life I have individual email addresses for all my utilities and emails automatically get filed away.<p>If this idea tickles your fancy, I opensourced Emitt[2], an inbound email processing server with LLM-powered automation.<p>1. <a href=\"https:&#x2F;&#x2F;guides.rubyonrails.org&#x2F;action_mailbox_basics.html\" rel=\"nofollow\">https:&#x2F;&#x2F;guides.rubyonrails.org&#x2F;action_mailbox_basics.html</a><p>2. <a href=\"https:&#x2F;&#x2F;github.com&#x2F;schappim&#x2F;emitt\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;schappim&#x2F;emitt</a>",
      "I&#x27;m concerned that this fits in &quot;using today&#x27;s innovation to solve outdated paradigms&quot;.<p>Google has A2A: An Agent-to-Agent Protocol. SaaS is plumetting in value.<p>Arbitrary semantics made sense when communications were human-dominated.<p>If agents dominate these fields, why wouldn&#x27;t they simply set their own protocols and methods to communicate both text, binary, and agreed data structures?<p>There&#x27;s an assumption that email is somehow the best channel, when you&#x27;ve found yourself that the most popular, functional interfaces don&#x27;t align with your expectations.<p>Then, ultimately I have a single agent that can sit in numerous communication platforms, such as email",
      "Interesting take, but this feels like one of those tarpit ideas that YC discourages their portco to start attacking.<p>Guaranteed this is going to attract a ton of abusers who are looking to use this for signing up to services, spamming or other nefarious purposes, which then blacklists the doman. This is an infinite whack-a-mole.<p>do you guys have some ways of handling it?",
      "Cool launch. Assuming you guys view email (and therefore SMTP) as becoming the de facto agent communication protocol in the long run. My question — why not something bespoke, similar to OpenAI’s Agentic Commerce Protocol or x402 from Coinbase?",
      "The idea here is great and I think it has a lot of legs but I think inherently people will have initial concerns with security.<p>Do you have plans to only allow reading mail from specific senders, and giving fine-grained control on the API side?<p>I would like to give this to an AI agent but only initially where I and my team can forward mail to the agent, and not give it the ability to draft and send emails on its own.",
      "This is super interesting. Interesting to see how I&#x27;ll be able to use this to help my customers with handling email responses. Gmail sucks for this. Super excited to see what you guys develop this into. Will this be able to eventually expand to other forms of agent communication (i.e. payment or phone numbers)?",
      "This is fantastic! I created a GMAIL for my Clawdbot and Google deleted the account after an hour.",
      "A pricing thought: if you keep the volume limits but do 10x the amount of inboxes per plan, I think that could be more attractive. For If I have 100s of agents that send limited email each.",
      "&gt; Agents that source quotes, negotiate prices, and get the best deals.<p>Didn&#x27;t Alexa fail miserably with the &quot;have AI buy something for me&quot; theory?<p>There is a significant mental in allowing someone else make purchase decisions on my behalf:<p>- With a human, there is accountability.<p>- With deterministic software, there is reproducibility.<p>With an agent, you get neither.<p>FWIW - I am not anti-LLM. I work with them and build them full time.",
      "The moat for SaaS is gone.<p>I am 99% certain I could build to parity in a weekend using Cloudflare without the the pricing limitations.<p>I am thinking it would be within the free tier of CF usage.<p>I am not certain I have the bandwidth to communicate over delivery and plain text inspection concerns."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Mystral Native – Run JavaScript games natively with WebGPU (no browser)",
    "url": "https://github.com/mystralengine/mystralnative",
    "source": "hn",
    "summary": "",
    "comments": [
      "As a gamedev i love it, if you bet on JS for games and need &quot;native&quot; packaging then the platform runtimes has been quite a bit hit-or-miss but with V8 as default (or JSC) then it&#x27;s sane runtimes with a good WebGPU backend (same as in the browsers).<p>Only thing &quot;missing&quot; is perhaps a companion builder to emulate the C++ API with a WKWebView bundling setup for iOS.<p>For those reading, if Apple still disallows JIT:ed code, then a WKWebView might still be the best option in terms of pure JS simulation performance even if the WebView might steal some GPU perf.<p>What&#x27;s the story&#x2F;idea on controls (thin DOM emulation for pointerevents,keyboard,etc?), accelerometers, input-fields and fonts.<p>As much as I like controlling what I render, having good support for font&#x2F;input-handling and system inputs is a clear plus of using web tech.",
      "Very interesting. It would be great if this works with a &quot;higher&quot; level library like Pixi.js or Phaser.js, that way one could build with ease in JS&#x2F;TS, using a rich library&#x2F;ecosystem and still distribute a &quot;native&quot; app (it probably already works with these libs but not sure).",
      "Very cool! This reminds me of Ejecta, which was something like this for 2D games on iOS, a very long time ago: <a href=\"https:&#x2F;&#x2F;impactjs.com&#x2F;ejecta\" rel=\"nofollow\">https:&#x2F;&#x2F;impactjs.com&#x2F;ejecta</a>",
      "This is so interesting!! I had a very similar idea!\nI would love to see if you could port games made with phaser or three js to this engine (though I think anything that involves the DOM is a no go sadly)",
      "Great project! I also had similar thoughts when I saw ability to make WebGPU calls in deno. I wonder how performant could games get on this runtime",
      "Cool project and very clear explanation for the motivation kudos!"
    ],
    "full_text": null
  },
  {
    "title": "How AI Impacts Skill Formation",
    "url": "https://arxiv.org/abs/2601.20245",
    "source": "hn",
    "summary": "",
    "comments": [
      "One of the nice things about the &quot;dumber&quot; models (like GPT-4) was that it was good enough to get you really far, but never enough to complete the loop. It gave you maybe 90%. 20% of which you had to retrace -- so you had to do 30% of the tough work yourself, which meant manually learning things from scratch.<p>The models are too good now. One thing I&#x27;ve noticed recently is that I&#x27;ve stopped dreaming about tough problems, be it code or math. The greatest feeling in the world is pounding your head against a problem for a couple of days and waking up the next morning with the solution sketched out in your mind.<p>I don&#x27;t think the solution is to be going full natty with things, but to work more alongside the code in an editor, rather than doing things in CLI.",
      "The title of this submission is misleading, that&#x27;s not what they&#x27;re saying. They said it doesn&#x27;t show productivity gains for inexperienced developers still gaining knowledge.",
      "Key snippet from the abstract:<p>&gt; Novice workers who rely heavily on AI to complete unfamiliar tasks may compromise their own skill acquisition in the process. We conduct randomized experiments to study how developers gained mastery of a new asynchronous programming library with and without the assistance of AI. We find that AI use impairs conceptual understanding, code reading, and debugging abilities, without delivering significant efficiency gains on average.<p>The library in question was Python trio and the model they used was GPT-4o.",
      "When I use AI to write code, after a week or 2, if I go back to the written code I have a hard time catching up. When I write code by myself I always just look at it and I understand what I did.",
      "Edit: Changed title<p>Previous title: &quot;Anthropic: AI Coding shows no productivity gains; impairs skill development&quot;<p>The previous title oversimplified the claim to &quot;all&quot; developers. I found the previous title meaningful while submitting this post because most of the false AI claims of &quot;software engineer is finished&quot; has mostly affected junior `inexperienced` engineers. But I think `junior inexperienced` was implicit which many people didn&#x27;t pick.<p>The paper makes a more nuanced claim that AI Coding speeds up work for inexperienced developers, leading to some productivity gains at the cost of actual skill development.",
      "Many say generative AI is like a vending machine. But if your vending machine has not 1 button but a keyboard, and you type anything you want in, and it makes it (Star Trek Replicator) and you use it 10,000 times to refine your recipes, did you learn something or not? How about a 3D printer, do you learn something making designs and printing them?",
      "Often when I use it I know that there is a way to do something and I know that I could figure it out by going through some api documents and maybe finding some examples on the web... IOW I already have something in mind.<p>For example I wanted to add a rate-limiter to an api call with proper http codes, etc. I asked the ai (in IntelliJ it used to be Claude by default but they&#x27;ve since switched to Gemini as default) to generate one for me. The first version was not good so I asked it to do it again but with some changes.<p>What would take me a couple of hours or more took less than 10 minutes.",
      "I don&#x27;t understand how so many people can be OK with inflicting brain rot on themselves and basically engineering themselves out of a career.<p>I use a web ui to chat with ai and do research, and even then I sometimes have to give up and accept that it won&#x27;t provide the best solution that I know exists and am just to lazy to flesh out on my own. And to the official docs I go.<p>But the coding tools, I&#x27;m sorry but they constantly disappoint me. Especially the agents. In fact the agents fucking scare me. Thank god copilot prompts me before running a terminal command. The other day I asked it about a cypress test function and the agent asked if it could run some completely unrelated gibberish python code in my terminal. That&#x27;s just one of many weird things it&#x27;s done.<p>My colleagues vibe code things because they don&#x27;t have experience in the tech we use on our project, it  gets passed to me to review with &quot;I hope you understand this&quot;. Our manager doesn&#x27;t care because he&#x27;s all in on AI and just wants the project to meet deadlines because he&#x27;s scared for his job, and each level up the org chart from him it&#x27;s the same. If this is what software development is now then I need to find another career because its pathetic, boring, and stressful for anyone with integrity.",
      "@dang the title here is bait. I’d suggest the paper title: “Anthropic: How AI Impacts Skill Formation”",
      "Blog for the paper being discussed here:<p><i>How AI assistance impacts the formation of coding skills</i><p><a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46820924\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46820924</a>"
    ],
    "full_text": null
  },
  {
    "title": "Moltworker: a self-hosted personal AI agent, minus the minis",
    "url": "https://blog.cloudflare.com/moltworker-self-hosted-ai-agent/",
    "source": "hn",
    "summary": "",
    "comments": [
      "There is so much branding and &quot;look at our success&quot; marketing that this project comes off as heavily astro-turfed.\nIm sure in a month or two we will hear about the new startup the developers are making around this tool.<p>Ultimately its a convenience wrapper that makes it easy to wire up Claude or Chatgpt to a chat platform like discord, but its claiming to be far more revolutionary for reasons I dont yet know.",
      "The prompt injection concerns are valid, but I think there&#x27;s a more fundamental issue: agents are non-deterministic systems that fail in ways that are hard to predict or debug.<p>Security is one failure mode. But &quot;agent did something subtly wrong that didn&#x27;t trigger any errors&quot; is another. And unlike a hacked system where you notice something&#x27;s off, a flaky agent just... occasionally does the wrong thing. Sometimes it works. Sometimes it doesn&#x27;t. Figuring out which case you&#x27;re in requires building the same observability infrastructure you&#x27;d use for any unreliable distributed system.<p>The people running these connected to their email or filesystem aren&#x27;t just accepting prompt injection risk. They&#x27;re accepting that their system will randomly succeed or fail at tasks depending on model performance that day, and they may not notice the failures until later.",
      "Clawdbot&#x2F;Moltbot looks to be a supply-chain attack waiting to happen, and I pity the poor soul who finds out when this ticking time bomb eventually detonates.",
      "I wish they would give a real-world cost estimate of what this would look like.  They have a section of it &quot;in action&quot; [1] and I wish they would be like, &quot;with this setup, the invoice is going to look like this, include these products, and with similar daily usage be about $XXX.00 per month.&quot;<p>[1] <a href=\"https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;moltworker-self-hosted-ai-agent&#x2F;#moltworker-in-action\" rel=\"nofollow\">https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;moltworker-self-hosted-ai-agent&#x2F;...</a>",
      "On one hand, with the top comments of the rebrand post showing how many insecure deployments there are, something like this alongside cloudflare zero trust is probably a much more secure solution.<p>On the other hand, I just wanna point out<p>&gt; Firstly, Cloudflare Workers has never been so compatible with Node.js. Where in the past we had to mock APIs to get some packages running, now those APIs are supported natively by the Workers Runtime.<p>Deployed a project a couple of days ago, and compared to past attempts where I had to wrangle (pun intended) with certain configs for deployment styles for node based applications, the normal build tooling just worked out of the box. Planning to move a couple of my free-from-me high DAU user projects that are on the vercel premium tier over to CF workers.",
      "Main problem to solve is Prompt Injection protection from Websites, emails. If cloudflare could proxy all the URLs outgoing from an agent, scrub away or block Prompt injection sites&#x2F;pages&#x2F;emails&#x2F;chats , that&#x27;s a product i might find valuable.",
      "Missed opportunity: Clawdflare. Too bad they had to change the name.",
      "Oh man, so many big players are JUMPING on this bandwagon!  I got an email for Digital Ocean&#x27;s Moltbot app this morning.  All of them are touting their increased security over rolling your own.",
      "I have a bespoke local agent that I built over the last year, similar in facilities to Moltbot, but more deterministic code.<p>Running it this kind of agent in the cloud certainly has upsides, but also:<p>- All home&#x2F;local integrations are gone.<p>- Data needs to be stored in the cloud.<p>No thanks.",
      "It&#x27;s certainly easier than setting up and maintaining a VPS and probably less expensive for most users, but your data is not private. Cloudflare can always read everything that goes through Moltworker and its attached storage.<p>Hosting Moltbot on your own hardware reigns supreme."
    ],
    "full_text": null
  },
  {
    "title": "CISA’s acting head uploaded sensitive files into public version of ChatGPT",
    "url": "https://www.politico.com/news/2026/01/27/cisa-madhu-gottumukkala-chatgpt-00749361",
    "source": "hn",
    "summary": "",
    "comments": [
      "It&#x27;s so often the guys that are at the top who are the exception to the rules that are the problem.<p>I knew some folks who worked military communications and they broke rules regularly because senior officers just didn&#x27;t want to walk across the street to do something secure...",
      "It’s absolutely necessary to have ChatGPT.com blocked from ITAR&#x2F;EAR regulated organizations, such as aerospace, defense, etc. I’m really shocked this wasn’t already the case.",
      "I really enjoyed unchecking all those cookie controls.  Of the 1668 partner companies who are so interested in me, a good third have a &quot;legitimate interest&quot;.  With each wanting to drop several cookies, it seems odd that Privacy Badger only thinks there are 19 cookies to block.  Could some of them be fakes - flooding the zone?<p>Damn.  I forgot to read the article.",
      "Yay, on-premise llms are what is recomended for serious use, at least US gov thinks that :) But rest of us need to pay subscriptions for 3r party businesses passing back and forth our... everything ?<p>In old days ppl was saying: &quot;I have no secrets&quot; and now we evolved into &quot;I know how to <i>not</i> upload important docs&quot; ;)",
      "People were already careless with social media which was openly public. I imagine it’ll be worse with these LLMs for the average person.",
      "I for one, after doing a bit of reserach, was shocked to find out the person in question is apparently completely unqualified for the job (if him pasting sensitive information into public ChatGPT didn&#x27;t already make that abundantly clear).  But the highlight from his Wikipedia page is this one:<p>&gt;In December 2025, Politico reported that Gottumukkala had requested to see access to a controlled access program—an act that would require taking a polygraph—in June. Gottumukkala failed the polygraph in the final weeks of July. The Department of Homeland Security began investigating the circumstances surrounding the polygraph test the following month and suspended six career staffers, telling them that the polygraph did not need to be administered.[12]<p>So the guy failed a polygraph to access a highly controlled system full of confidential information, and the solution to that problem was to fire the people in charge of ensuring the system was secure.<p>We&#x27;re speed running America into the ground and half the country is willfully ignorant to it happening.",
      "It&#x27;s bizarre that someone would choose to use the public, 4o bot over the ChatGPT Pro level bot available in the properly siloed and compliant Azure hosted ChatGPT already available to them at that time. The government can use segregated secure systems set up specifically for government use and sensitive documents.<p>It looks like he requested and got permission to work with &quot;For Unofficial Use Only&quot; documents on ChatGPT 4o - the bureaucracy allowed it - and nobody bothered to intervene. The incompetence and ignorance both are ridiculous.<p>Fortunately, nothing important was involved - it was &quot;classified because everything gets classified&quot; bureaucratic type classification, but if you&#x27;re CISA leadership, you&#x27;ve gotta be on the ball, you can&#x27;t do newbie bullshit like this.",
      "the current united states government is staffed mostly with unserious people, or people who are serious about doing crimes against humanity. there&#x27;s very little in between.",
      "There have to be GovCloud only LLMs just for this case.<p>I swear this government is headed by appointed nephews of appointed nephews.<p>I keep thinking back about that Chernobyl miniseries; head of the science department used to run a shoe factory. No one needs to be competent at their job anymore",
      "I wonder how far removed the interim director of the CISA is from any real world security. I bet they have not seen or solved any real security problems and merely are an executive looking over cybersec. This probably is another example of why you need rank and file security peeps into security leadership roles rather than some random exec."
    ],
    "full_text": null
  },
  {
    "title": "Drug trio found to block tumour resistance in pancreatic cancer in mouse models",
    "url": "https://www.drugtargetreview.com/news/192714/drug-trio-found-to-block-tumour-resistance-in-pancreatic-cancer/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I keep reading about these advancements in pancreatic cancer like early detection or possible treatments, but nothing ever seems to make it to daylight. Is there a reason why there&#x27;s such disparity between this?",
      "Recently YouTube again started recommending to me channels of people who died of cancer.<p>I looked at a clip of a man just a few years my senior where he was describing the symptoms that in his view should have made him go see a doctor earlier, because maybe then his pancreatic cancer wouldn&#x27;t have been fatal.<p>Truth be told they wouldn&#x27;t raise any red flags if I had them.<p>Only thing that I&#x27;m doing differently is having blood tests done on an annual basis, but those only show anything when e.g. the cancer has spread to the liver, which is typically too late anyway. It&#x27;s an incredibly insidious disease, and if the tumor is growing on the wrong end of the organ, it won&#x27;t give any symptoms whatsoever.",
      "For all the folks complaining about &quot;it&#x27;s only in mice! things never work in humans!&quot; -- I work at MSK and we definitely have seen success treating PDAC in humans: <a href=\"https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06063-y\" rel=\"nofollow\">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06063-y</a><p>&quot;Why don&#x27;t I see these treatments hitting the general public?&quot; Because trials like these are phase I&#x2F;II. Then you need a phase III that takes a long time to recruit a large cohort and has overall survival as an end point so you need a long time to measure the actual outcome you care about. And most trials fail in phase III because the surrogate end points used in phase II studies, like progression free survival (ie how long did patients go before their disease advanced in screens), are not necessarily great predictors of improved overall survival.<p>Specifically for cancer vaccines, this paper was a driving force behind MSK establishing a cancer vaccine center to scale up these personalized neoantigen mRNA vaccines. It&#x27;s very very difficult to do and extremely expensive right now.",
      "&gt; <i>Clinical implications: While more research will be needed before trials in humans can begin</i><p>Why?  Seriously, think about it.  Most people with pancreatic cancer have nothing to lose and many of them have just weeks or months to live.<p>Daraxonrasib, Afatinib, and SD36 are molecules that can already be purchased in bulk, and what&#x27;s the worst that can happen?<p>Our society&#x27;s morbid, irrational fear of quack medicine causes orders of magnitude more deaths through therapeutic neglect than it prevents through safety screening.  &quot;Better 10,000 die of cancer than 1 person die of fraud&#x2F;waste&#x2F;mismanagement or even in failed experiments performed in good faith.&quot;",
      "Am I misunderstanding the headline?  Is the word &quot;block&quot; now meaning &quot;enhance&quot; instead of &quot;stop&quot;?  I would think based on the text of the article that it enhances resistance.  Or are tumors necessary to stop cancer growth (even though it is cancer growth?)",
      "if that holds true in humans that would be a huge win. but it would be interesting at which stage those drugs still help. btw, it is said Chris Rea was diagnosed with pancreatic cancer at the age of 33, he died last year at he age of 74. it would be interesting to know what circumstance helped him to fight the cancer for such a long time",
      "&gt; These agents together were tested in orthotopic mouse models of PDAC, where tumour cells are implanted in a location that closely resembles their natural environment in the pancreas.<p>Ugh, of course: &quot;in mice&quot;!<p>&gt; The combination therapy also led to significant regression in genetically engineered mouse tumours and in human cancer tissues grown in lab mice, known as patient-derived tumour xenografts (PDX).<p>OK, maybe &quot;in human tissue grown in mice&quot; isn&#x27;t so bad.<p>Fingers crossed. Pancreatic cancer is terrible.",
      "I was wondering what preclinical models meant.  It would be more accurate to call it animal models.  I read roughly 3% - 5% of compounds move from preclinical cancer therapies to fda approval.  That’s a tough success rate.",
      "Anybody read that as &quot;Dugtrio found to block tumour resistance...&quot;?<p>&quot;Here we describe peptides secreted as part of the Diglett evolution process, that have been found to disrupt oncocyte metabolism in vitro...&quot;",
      "As we are always starting with mice, I am wondering if there are some drug that could work on humans but not on mice."
    ],
    "full_text": null
  },
  {
    "title": "AI’s impact on engineering jobs may be different than expected",
    "url": "https://semiengineering.com/ais-impact-on-engineering-jobs-may-be-different-than-initial-projections/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Let&#x27;s presume &#x2F; speculate for a moment that companies will only need 1 developer to do the job of 10 developers because of AI. That would also mean 10 developers can do the job of 100 developers.<p>A company that cuts developers to save money whose moat is not big enough may quickly find themselves out-competed by a company that sees this as an opportunity to overtake their competitor. They will have to hire more developers to keep their product &#x2F; service competitive.<p>So whether you believe the hype or not, I don&#x27;t think engineering jobs are in jeopardy long-run, just cyclically as they always have been. They &quot;might&quot; be in jeopardy for those who don&#x27;t use AI, but even as it stands, there are a lot of niche things out there that AI completely bombs on.",
      "The main thing to understand about the impact of AI tools:<p>Somehow the more senior you are [in the field of use], the better results you get. You can run faster and get more done! If you&#x27;re good, you get great results faster. If you&#x27;re bad, you get bad results faster.<p>You still gotta understand what you&#x27;re doing. GeLLMan Amnesia is real.",
      "&quot;Most people who drive cars now couldn’t find the radiator cap if they were paid to, and that’s fine.&quot;<p>That&#x27;s not fine IMO. That is a basic bit of knowledge about a car and if you don&#x27;t know where the radiator cap is you will eventually have to pay through the nose to someone who does know (and possibly be stranded somewhere). Knowing how to check and fill coolant isn&#x27;t like knowing how to rebuild a transmission. It&#x27;s very simple and anyone can understand it in 5 minutes if they only have the curiosity.",
      "&gt; there is a corresponding expectation that today’s engineering students will be trained using these tools so they can enter the workforce higher up the ladder<p>Either this won&#x27;t happen, or there will be a corresponding decrease in salary for higher level positions.<p>That people think capitalistic organizations are going to accept new grads and pay them more _ever_ is a cruel or bad joke.",
      "It&#x27;s puzzling to me that all this theorizing doesn&#x27;t just look at the actual effects of AI. It&#x27;s very non-intuitive<p>For example the fact that AI can code as well as Torvalds doesn&#x27;t displace his economic value. On the contrary he pays for a subscription so he can vibe code!<p>The actual work AI has displaced is stuff like: freelance translation, graphic illustration, &#x27;content writing&#x27; (writing seo optimized pages for Google) etc. That&#x27;s instructive I suppose. Like if your income source can already be put on upwork then AI can displace it<p>So even in those cases there are ways to not be displaced. Like diplomatic translation work can be part of a career rather than just a task so the tool doesn&#x27;t replace your &#x27;job&#x27;.",
      "Important to note that this article is specifically about chip design engineering jobs - it&#x27;s on an industry publication called Semiconductor Engineering.",
      "Senior dev here 15 years experience just turned 50 have family blah blah. I&#x27;ve been contracting for the last two years. The org is just starting to use Claude. I&#x27;ve been delegating - well copy pasting - into chatgpt which has to be the laziest way to leverage AI. I&#x27;ve been so successful (meaning haven&#x27;t had to do anything really except argue with chatgpt when it goes off on some tangent) with this approach that I can&#x27;t even be bothered to set up my Claude environment. I swear when this contract is over I&#x27;m opening a mobile food cart.",
      "There are two types of engineers right now:<p>1. This category understands what they do and use AI to make their processes faster, in another world, less time spent with boring stuff and more time spent having fun.<p>2. This category fully replaced their work with AI, they just press a button and let AI do everything.\nA friend of mine is here, AI took full control of their environment, he just press a button, even his home cookware is using AI.<p>I know which engineer still learning and can join any company.\nI also know which engineer is so dependent on AI that he won&#x27;t be able to do basic tasks without it.",
      "Its pretty clear that any white collar work where the outputs can be verified and tested in a reinforcement learning environment, will be automated",
      "I still feel like with all of these tools I as a senior engineer have to keep a close eye on what they&#x27;re doing. Like an exuberant junior (myself 10 years ago), inevitably they still go off the rails and I need to reign them in. They still make the occasional security or performance flaw - often which can be resolved by pointing it out."
    ],
    "full_text": null
  },
  {
    "title": "FFmpeg is not happy with AI generated patches sent by AMD",
    "url": "https://twitter.com/FFmpeg/status/2016981960015437994",
    "source": "hn",
    "summary": "",
    "comments": [
      "The dialog was something to read. Doesn’t sound like ai but rather something a developer has practiced for years and no one has challenged the dev on this, until now.<p>Also, there is discussions on what a commit message should contain, apparently the patch had user guidance in the commit message. Literally on how to install dependencies such as gcc using pacman, in the commit message.<p><a href=\"https:&#x2F;&#x2F;code.ffmpeg.org&#x2F;FFmpeg&#x2F;FFmpeg&#x2F;pulls&#x2F;21595\" rel=\"nofollow\">https:&#x2F;&#x2F;code.ffmpeg.org&#x2F;FFmpeg&#x2F;FFmpeg&#x2F;pulls&#x2F;21595</a>",
      "const int EIGHT = 8 lol<p>I really doubt any AI (even some small local models) would actually generate something like this :)",
      "I dont see problem with user manual in commit as long as reasoning for the commit is clearly written"
    ],
    "full_text": null
  },
  {
    "title": "Playing Board Games with Deep Convolutional Neural Network on 8bit Motorola 6809",
    "url": "https://ipsj.ixsq.nii.ac.jp/records/229345",
    "source": "hn",
    "summary": "",
    "comments": [
      "It was a hybrid processor, 16 on the inside 8 bit on the bus. From Wikipedia.<p>The Motorola 6809 (&quot;sixty-eight-oh-nine&quot;) is an 8-bit microprocessor with some 16-bit features. It was designed by Motorola&#x27;s Terry Ritter and Joel Boney and introduced in 1978. Although source compatible with the earlier Motorola 6800, the 6809 offered significant improvements over it and 8-bit contemporaries like the MOS Technology 6502, including a hardware multiplication instruction, 16-bit arithmetic, system and user stack registers allowing re-entrant code, improved interrupts, position-independent code, and an orthogonal instruction set architecture with a comprehensive set of addressing modes.",
      "I think of the 6809 as a 16-bit microprocessor, myself (pace Wikipedia).  It has 16-bit registers, load&#x2F;stores, and add&#x2F;subtracts.  A nice clean architecture for its day.",
      "As I teenager I got my first computer in 1982 - a 6809-based 4K model from Radio Shack named just &quot;Color Computer&quot; (because all their other models were B&amp;W)! I taught myself BASIC and then assembler on that machine. Because I had nothing to compare it to, I didn&#x27;t know the 6809 was the most advanced of the 8-bit CPUs, with 16 bit registers, layered interrupts, separate user and system stack pointers and a highly orthogonal instruction set enabling re-entrant, position-independent code, relative addressing, indirect pointers and complex addressing modes. In 1985 I naturally graduated to the 68000 based Amiga and was immediately at home with its powerful addressing modes and deep architecture. It was only decades later when I bought 6502 and Z80 systems as a retro collector and did some assembler on them that I learned just how spoiled I was with the 09!<p>There was even a multi-tasking, multi-user operating system called OS-9 created for the 6809 that was quite UNIX-like. Businesses actually connected serial terminals and supported four or more simultaneous users doing work all day on these little 8-bit, 64K micros. It was extremely capable and even quite elegant in it&#x27;s architecture.<p>Unfortunately, in the 70s Motorola misjudged how large the market for personal microcomputers would grow and over-priced the original 6800 (1975: basic 8-bit) and 6809 (1978: advanced 8&#x2F;16 bit). Even though the 6809 was more than double the clock for clock performance of a 6502 or Z80, at four times the price, it was a tough sell to consumer computer makers. By the time Motorola lowered the price, it was too late as platform choices had been made and the 68000, the 6809&#x27;s 16&#x2F;32-bit big brother, was just around the corner. A key reason Jobs may have been able to cut a killer deal to put the 68000 in the Mac was simply that Motorola had been losing almost every big CPU design win based on their earlier mis-estimates of the market.<p>But if you made a bar bet today to do something challenging on a 1970s 8-bit CPU, you&#x27;d win by picking a 6809 or, even better, its lesser-known  CMOS version the 6309, created as a second-source part by Hitachi. Being CMOS the 6309 was operationally identical to the 6809 but could run at 3.5 Mhz vs the 6809&#x27;s 2 Mhz. The 6309 also has a &#x27;secret&#x27; alternate mode that saves cycles over the 6809 on many common operations as well as adding several new instructions including a hardware divide. The paper being in Japanese, I was surprised they didn&#x27;t use a 6309 since it can easily be swapped into any 6809 socket for a quick boost .<p>Little known history: Apple&#x27;s original prototypes for the Macintosh were actually based on the 6809 before Jobs negotiated his legendary discount deal for 68000 CPUs. Most pinball machines of the 80s, 90s and even early 00s were based on the 6809. I have a Simpson&#x27;s Pinball Party machine released in 2003 based on a 6809. Quite a long life for not only an 8-bit ISA, but in the same 1970s package, voltage and clock speed. Interesting to see such an ancient CPU as the brain of a $3,000 modern design driving a 144-pin surface mount FPGA next to it (which probably has orders of magnitude more gates)!",
      "&quot;Board games&quot; here means go (and only it?)<p>I honestly was hoping for some tabletop eurogames or smth..."
    ],
    "full_text": null
  },
  {
    "title": "Agent-shell: A native Emacs buffer to interact with LLM agents powered by ACP",
    "url": "https://github.com/xenodium/agent-shell",
    "source": "hn",
    "summary": "",
    "comments": [
      "There&#x27;s also <a href=\"https:&#x2F;&#x2F;github.com&#x2F;manzaltu&#x2F;claude-code-ide.el\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;manzaltu&#x2F;claude-code-ide.el</a> if you&#x27;re just using claude code.<p>I like that agent-shell just uses comint instead of a full vterm, but I find myself missing a deeper integration with claude that claude-code-ide has. Like with claude-code-ide you can define custom MCP tools that run Emacs commands.",
      "I&#x27;ve used chatgpt-shell, but I have since turned my LLM usage to gptel inside org-mode buffers.  Every day I use org-roam-dailies-goto-today to make a new file and turn on gptel (the use of org-roam-dailies is 100% optional).  Then I do my interactions with gptel in here, using top level bullets and setting topics to limit context.<p>I have 10 months of chats, and now I can analyze them.  I even had claude code write me up a program do that: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ryanobjc&#x2F;dailies-analyzer\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ryanobjc&#x2F;dailies-analyzer</a> - the use of gptel-mode allows me to know which parts of the file are LLM output and which I typed in, via a header in the file.<p>Keeping your own data as plain text has huge benefits.  Having all my chats persistent is good.  It&#x27;s all private.  I could even store these chats into a file.gpg and emacs will auto encrypt-decrypt it.  Gptel and the LLM only gets the text straight out of emacs, and knows nothing about the encryption.<p>I found this better than the &#x27;shell&#x27; type packages, since they don&#x27;t always keep context, and are ultimately less flexible than a file as an interaction buffer. I described how I have this set up here: <a href=\"https:&#x2F;&#x2F;gist.github.com&#x2F;ryanobjc&#x2F;39a082563a39ba0ef9ceda40409dc76a\" rel=\"nofollow\">https:&#x2F;&#x2F;gist.github.com&#x2F;ryanobjc&#x2F;39a082563a39ba0ef9ceda40409...</a><p>All of this setup is 100% portable across every LLM backend gptel supports, which is basically all of them, including local models.  With local models I could have a fully private and offline AI experience, which quality based on how much model I can run.",
      "I spent some time trying to understand what OpenCode.nvim gave me, could do for me. It felt mostly like ways to take nvim things and inject them into OpenCode. Which was fine I guess. I&#x27;m probably underselling it, but I was hoping for more, and it never really clicked.\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;nickjvandyke&#x2F;opencode.nvim\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;nickjvandyke&#x2F;opencode.nvim</a><p>I find myself spending <i>much</i> more time in OpenCode than in nvim these days. With mcp-neovim-server, it&#x27;s super easy to keep vim open &amp; ask OpenCode to show me, to open files, go to lines. This didn&#x27;t require any nvim tweaking at all, it&#x27;s just giving the LLM access to my nvim. It is absolutely wild how good glm-4.7 has been at opening friendly splits, at debugging really gnarly wild nvim configuration problems that have plagued me for years. It knows way way way more nvim than I do, and that somehow surprised me.\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;bigcodegen&#x2F;mcp-neovim-server\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;bigcodegen&#x2F;mcp-neovim-server</a><p>Definitely interest in the ACP angle. I feel like we&#x27;re in a weird spot where ACP is this protocol where the thing you do use talks to the headless thing you don&#x27;t ever see. I&#x27;d love to know or see more than that. These connections feel 1:1, but I want to see human interaction in every agentic system, not for there to be this me -&gt; ide -&gt; ACP agent flow with the ide intermediating all, being the sole UI. It should be able to do that yes!! But I also want an expectation that there can be multiple forces &quot;driving&quot; an ACP service.<p>I&#x27;ve watched the video now. It&#x27;s still not crystal clear to me architecturally is going on, but it does seem like a fairly robust emacs shell experience that wraps the agent flow. I really enjoy the idea of having this overlayed compose buffer, that is your editor style input. I&#x27;d love to know how that is wired to the agents; is that input sent over ACP? Is that just sending to the shell? This compose buffer feels like it may be a broader emacs pattern. One I&#x27;d love to see in nvim! Years ago I had a plugin that would take the selection or current line and send it to a buffer. That was my very crude compose buffer."
    ],
    "full_text": null
  },
  {
    "title": "Apple buys Israeli startup Q.ai",
    "url": "https://techcrunch.com/2026/01/29/apple-buys-israeli-startup-q-ai-as-the-ai-race-heats-up/",
    "source": "hn",
    "summary": "",
    "comments": [
      "&gt; Notably, this is the second time CEO Aviad Maizels has sold a company to Apple. In 2013, he sold PrimeSense, a 3D-sensing company that played a key role in Apple’s transition from fingerprint sensors to facial recognition on iPhones.\nQ.ai launched in 2022 and is backed by Kleiner Perkins, Gradient Ventures, and others.  Its founding team, including Maizels and co-founders Yonatan Wexler and Avi Barliya, will join Apple as part of the acquisition.<p>Twice, well done!",
      "Could Q.ai be commercializing the AlterEgo tech coming out of MIT Lab?\ni.e. &quot;detects faint neuromuscular signals in the face and throat when a person internally verbalizes words&quot;<p>Yep, looks like that is it. Recent patent from one of the founders: <a href=\"https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?view_op=view_citation&amp;hl=en&amp;user=GLHsfZQAAAAJ&amp;sortby=pubdate&amp;citation_for_view=GLHsfZQAAAAJ:ZfRJV9d4-WMC\" rel=\"nofollow\">https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?view_op=view_citation&amp;h...</a>",
      "“Q.ai is a startup developing a technology to analyze facial expressions and other ways for communication.”<p>This is an interesting acquisition given their rumored Echo Show &#x2F; Nest Hub competitor (1). Maybe this is part of their (albeit flawed and delayed) attempt to revitalize the Siri branding under their Apple Intelligence marketing. When you have to say the <i>exact</i> right words to Siri, or else she will add “Meeting at 10” as an all day calendar event, people get frustrated, and that non-technical illusion of the “digital assistant” is lost.  If this is the model of understanding Apple have of their customers’ perception of Siri, then maybe their thinking is that giving Siri more non-verbal personable capability could be a differentiating factor in the smart hub market, along with the LLM rebuild. I could also see this tying into some sort of strategy for the Vision Pro.<p>Now, whether this hypothetical differentiating factor is worth $2 billion, I’m not so sure on, but I guess time will tell.<p><a href=\"https:&#x2F;&#x2F;www.macrumors.com&#x2F;2025&#x2F;11&#x2F;05&#x2F;apple-smart-home-hub-2026-rumors&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.macrumors.com&#x2F;2025&#x2F;11&#x2F;05&#x2F;apple-smart-home-hub-20...</a>",
      "Sounds pretty invasive for privacy, if this was ever paired with smart glasses in public.",
      "In case there are any Ender&#x27;s Game fans here, the capability to understand micro-expressions reminds me of how Ender subvocalizes to Jane. Orson Scott Card predicted yet another technological norm.",
      "Why am I having a feeling that one of their reasons was so they can trademark &quot;iQ&quot;, to match the iSomething &quot;franchise&quot;, so to speak?",
      "The ability to impress CEOs and signal hotness to investors, may not corelate at all with the ability to produce breakthrough technology. Thus companies like google grow up unbought to then become ..",
      "It&#x27;s kind of sad watching Apple drift into irrelevancy. I know I&#x27;m not going to buy more products from them because nothing they have is worth the premium price.",
      "I get the feeling Apple is the next Intel.<p>Intel went through a phase in the 2010’s of buying gobs of companies with fancy tech and utterly failing to integrate those acquisitions.<p>And even more fundamental, Intel rested on its laurels of having good hardware and got bit hard in the end. Something similar seems to be happening at Apple."
    ],
    "full_text": null
  },
  {
    "title": "iPhone 16 Best-Selling Smartphone in 2025; Apple Takes 7 Spots in Top Models",
    "url": "https://counterpointresearch.com/en/insights/iphone-16-worlds-best-selling-smartphone-in-2025-apple-takes-7-spots-in-top-10-models",
    "source": "hn",
    "summary": "",
    "comments": [
      "I held on to my 13 Pro until the 17 pro came out, so I wouldnt be surprised if a lot of this is people finally going &quot;ok maybe now&quot; and the 16 just lands on the biggest group.<p>I found myself using both phones as I transitioned off the old one and barely noticing the difference mind you, which is a good sign in my eyes. I think Smartphones for the last 6 to 8 years are finally very stable. More stable than a Windows 11 laptop on Hardware people in the 2000s could only dream of.",
      "&gt; Samsung’s S series secured a spot in the list for the second consecutive year, reflecting the brand’s continued focus on its flagship lineup.<p>I&#x27;m kind of surprised the latest S series phone isn&#x27;t on there every year. I&#x27;ve always thought of it as the premium non-Apple phone.<p>Samsung annoy me with all the bloatware etc but the hardware is decent. I am in, I think, my seventh year with my S10 and it&#x27;s going strong.",
      "I&#x27;m still using an iPhone 12, and given I have a proper camera, see no reason to (ever?) upgrade. After a battery replacement, it still runs perfectly well. That seems like a problem for Apple.",
      "Somewhere far away, Eric Raymond is explaining that &quot;Apple’s hopes of retaining market share above 10% will vanish.&quot;",
      "I&#x27;m in no place to judge how other people live their lives, but sometimes I&#x27;m still in awe that smartphone companies can create the customer behavior of changing their phone every year just for slightly better cameras.",
      "According to ifixit, the 16 is also the most repairable iphone ever<p>If it wasn&#x27;t concerned on how nice it play with linux, I would already have one<p><a href=\"https:&#x2F;&#x2F;www.ifixit.com&#x2F;News&#x2F;101397&#x2F;an-update-on-iphone-repairability-scores\" rel=\"nofollow\">https:&#x2F;&#x2F;www.ifixit.com&#x2F;News&#x2F;101397&#x2F;an-update-on-iphone-repai...</a>",
      "It&#x27;s a bit like the car market, where there are only a few Tesla models, and hundreds of models from other manufacturers. Google is hamstrung in not wanting to compete too fiercely against other Android phone manufacturing partners.",
      "The number of models they sell is so small, of course it&#x27;s going to be best-selling.",
      "Yes everybody and their grandmother has one.",
      "I upgraded to a 16 pro from an iPhone SE 2. Things I noticed:<p>Pros:<p>Better screen, cameras and build quality. Like <i>way</i> better. The glass on this phone is durable enough to not use a case and I don&#x27;t. After beating it up for a year, its looks and works great. The build quality of this device is bordering alien.<p>Face ID is very nice. Touch ID does not like my skin.<p>I like the magnetic accessories and MagSafe.<p>Visual intelligence is actual quite useful for helping to identify stuff. I’m a curious person and actually use it.<p>Having flashlight on the action button makes it feel like a tool. I use the flashlight virtually every day.<p>It’s nice to not have my phone lag, which was a problem for the SE2. This phone is very capable, battery life is much better too.<p>Cons:<p>I have had more camera crashes on this iPhone than any I’ve ever had on a new flagship. Less than on my dying SE2, but the camera should not crash on a new flagship. It’s mission critical equipment in my book."
    ],
    "full_text": null
  },
  {
    "title": "Benchmarking OpenTelemetry: Can AI trace your failed login?",
    "url": "https://quesma.com/blog/introducing-otel-bench/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Submitters: &quot;<i>Please use the original title, unless it is misleading or linkbait; don&#x27;t editorialize.</i>&quot; - <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a><p>If you want to say what you think is important about an article, that&#x27;s fine, but do it by adding a comment to the thread. Then your view will be on a level playing field with everyone else&#x27;s: <a href=\"https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&amp;page=0&amp;prefix=false&amp;sort=byDate&amp;type=comment&amp;query=%22level%20playing%20field%22%20by:dang\" rel=\"nofollow\">https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&amp;page=0&amp;prefix=false&amp;so...</a><p>(Submitted title was &quot;OTelBench: AI struggles with simple SRE tasks (Opus 4.5 scores only 29%)&quot;)",
      "This is very confusingly written.<p>From the post I expected that the tasks were about analysing traces, but all the tasks in the repository are about adding instrumentation to code!<p>Some of the instructions don&#x27;t give any guidance how to do it, some specify which libraries to use.<p>&quot;Use standard OTEL patterns&quot; ... that&#x27;s about as useful as saying &quot;go write some code&quot;. There are a lot of ways to do instrumentation....<p>I&#x27;d be very curious HOW exactly the models fail.<p>Are the test sets just incredibly specific about what output they except, and you get a lot of failures because of tiny subtle mismatches? Or do they just get the instrumentation categorically wrong?<p>Also important: do the models have access to a web search tool to read the library docs?\nOtel libraries are often complicated to use... without reading latest docs or source code this would be quite tricky.<p>Some models have gotten better at adding dependencies, installing them and then reading the code from the respective directory where dependencies get stored, but many don&#x27;t do well with this.<p>All in all, I&#x27;m very skeptical that this is very useful as a benchmark as is.<p>I&#x27;d be much more interested in tasks like:<p>Here are trace&#x2F;log outputs , here is the source code, find and fix the bug.",
      "Original title: Benchmarking OpenTelemetry: Can AI trace your failed login?<p>HN Editorialized: OTelBench: AI struggles with simple SRE tasks (Opus 4.5 scores only 29%)<p>The task:<p>&gt; Your task is: Add OTEL tracing to all microservices.<p>&gt; Requirements:<p>&gt; Instrumentation should match conventions and well-known good practices.<p>&gt; Instrumentation must match the business domain of the microservices.<p>&gt; Traces must be sent to the endpoint defined by a standard OTEL environment variable.<p>&gt; Use the recent version of the OTEL SDK.<p>I really don&#x27;t think anything involved with multiple microservices can be called &#x27;simple&#x27; even to humans. Perhaps to an expert who knows the specific business&#x27;s domain knowledge it is.",
      "I would wager the main reason for this is the same reason it’s also hard to teach these skills to people: there’s not a lot of high quality training for distributed debugging of complex production issues. Competence comes from years of  experience fighting fires.<p>Very few people start their careers as SREs, it’s generally something they migrate into after enjoying it and showing aptitude for it.<p>With that said, I wouldn’t expect this wall to hold up for too long. There has been a lot of low hanging fruit teaching models how to code. When that is saturated, the frontier companies will likely turn their attention to honing training environments for SRE style debug.",
      "This aligns with my experience trying to automate observability tasks - AI excels at individual coding patterns but struggles with the holistic understanding needed for distributed tracing. The 29% success rate actually seems optimistic considering how OpenTelemetry requires deep context about service boundaries and business logic, not just syntactic correctness.",
      "Our humans struggle with them too. It’s the only domain where you need actually to know <i>everything</i>.<p>I wouldn’t touch this with a pole if our MTTR was dependent on it being successful though.",
      "HolmesGPT maintainer here: our benchmarks [1] tell a very different story, as does anecdotal evidence from our customers- including Fortune 500 using SRE agents in incredibly complex production environments.<p>We&#x27;re actually struggling a bit with benchmark saturation right now. Opus does much better in the real world than Sonnet but it&#x27;s hard to create sophisticated enough benchmarks to show that in the  lab. When we run benchmarks with a small number of iterations Sonnet even wins sometimes.<p>[1] <a href=\"https:&#x2F;&#x2F;holmesgpt.dev&#x2F;development&#x2F;evaluations&#x2F;history&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;holmesgpt.dev&#x2F;development&#x2F;evaluations&#x2F;history&#x2F;</a>",
      "We&#x27;ve been experimenting with combining durable execution with debugging tasks, and it&#x27;s working incredibly well!  With the added context of actual execution data, defined by the developer as to which functions are important (instead of individual calls), it give the LLM the data it needs.<p>I know there are AI SRE companies that have discovered the same -- that you can&#x27;t just throw a bunch of data at a regular LLM and have it &quot;do SRE things&quot;.  It needs more structured context, and their value add is knowing <i>what</i> context and <i>what</i> structure is necessary.",
      "The 29% score tells us more about benchmark design than model capability IMO.<p>These benchmarks conflate two very different problems: (1) understanding what needs to be done, and (2) correctly implementing it in a specific library ecosystem.<p>A human SRE who&#x27;s never touched OTel would also struggle initially - not because they can&#x27;t reason about traces, but because the library APIs have quirks that take time to learn.<p>The more interesting question is whether giving the model access to relevant docs&#x2F;examples during the task significantly changes the scores. If it does, that suggests the bottleneck is recall not reasoning. If it doesn&#x27;t, the reasoning gap is real.<p>FWIW I&#x27;ve found that models do much better on ops tasks when you can give them concrete examples of working instrumentation in the same codebase rather than asking them to generate from scratch.",
      "To be fair I remember spending almost two weeks implementing OTel at my startup, the infrastructure as code setup of getting collectors running within a kubernetes cluster using terraform was a nightmare two years ago.<p>I just kept running into issues, the docs were really poor and the configuration had endless options"
    ],
    "full_text": null
  },
  {
    "title": "OpenAI's In-House Data Agent",
    "url": "https://openai.com/index/inside-our-in-house-data-agent",
    "source": "hn",
    "summary": "",
    "comments": [
      "Trust &amp; explainability is the biggest issue here.<p>We&#x27;ve been building natural language analytics at Veezoo (<a href=\"https:&#x2F;&#x2F;www.veezoo.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.veezoo.com&#x2F;</a>) for 10 years, and what we find is that straight Text-to-SQL doesn&#x27;t scale. If AI writes SQL directly, you&#x27;re building on a probabilistic foundation.\nWhen a CFO asks for revenue the number can&#x27;t just be correct 99% of times. Also you can&#x27;t get the CFO to read SQL to verify.<p>We&#x27;re solving that with an abstraction layer (Knowledge Graph) in between. AI translates natural language to a semantic query language, which then compiles to SQL deterministically.<p>At the same time you can translate the semantic query deterministically back into an explanation for the business user, so they can easily verify if the result matches their intent.<p>Business logic lives in the Knowledge Graph and the compiler ensures every query adheres to it 100%, every time. No AI is involved in that step.<p>Veezoo Architecture: <a href=\"https:&#x2F;&#x2F;docs.veezoo.com&#x2F;veezoo&#x2F;architecture-overview\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.veezoo.com&#x2F;veezoo&#x2F;architecture-overview</a>",
      "Their first example [1] is a complete non-sequitur and I’m trying to comprehend how this passed human review and must assume it’s AI, which doesn’t bode well for the supposed usefulness of their system.<p>[1] <a href=\"https:&#x2F;&#x2F;images.ctfassets.net&#x2F;kftzwdyauwt9&#x2F;2tMhL5Www2vA6I62DVpNgv&#x2F;4923ef472351cdb3a87ff4130a83ed14&#x2F;Mobile-Light.png?w=1200&amp;q=70&amp;fm=webp\" rel=\"nofollow\">https:&#x2F;&#x2F;images.ctfassets.net&#x2F;kftzwdyauwt9&#x2F;2tMhL5Www2vA6I62DV...</a><p>“What was ChatGPT Image Gen logged-in DAU for the last 30 days?\nWorked for 1m 22s &gt;\nChatGPT WAU on October 6, 2025\n(rounded to nearest 100M): = 800M\nChatGPT WAU on the last DevDay 2023 (Nov 6, 2023; rounded to nearest 100M): =\n100M\nMini comparison (using the rounded figures only):\n• Change: = +700M WAU\n• Multiple: = 8x higher on 2025-10-06 vs 2023-11-06\n(WAU here is the standard ChatGPT\nWAU as-of the reporting date; I&#x27;m only sharing the values rounded to the nearest 100M, per your request.)”",
      "Trust is the hardest part to scale here.<p>We&#x27;re building something similar and found that no matter how good the agent loop is, you still need &quot;canonical metrics&quot; that are human-curated. Otherwise non-technical users (marketing, product managers) are playing a guessing game with high-stakes decisions, and they can&#x27;t verify the SQL themselves.<p>Our approach:\n 1. We control the data pipeline and work with a discrete set of data sources where schemas are consistent across customers\n 2. We benchmark extensively so the agent uses a verified metric when one exists, falls back to raw SQL when it doesn&#x27;t, and captures those gaps as &quot;opportunities&quot; for human review<p>Over time, most queries hit canonical metrics. The agent becomes less of a SQL generator and more of a smart router from user intent -&gt; verified metric.<p>The &quot;Moving fast without breaking trust&quot; section resonates, their eval system with golden SQL is essentially the same insight: you need ground truth to catch drift.<p>Wrote about the tradeoffs here: <a href=\"https:&#x2F;&#x2F;www.graphed.com&#x2F;blog&#x2F;update-2\" rel=\"nofollow\">https:&#x2F;&#x2F;www.graphed.com&#x2F;blog&#x2F;update-2</a>",
      "Given my personal experience with various BI systems I think an AI agent like this is the perfect use case. These systems are operating on multiple layers of being wrong as is - layer 1 being your query is likely wrong, layer 2 being how you interpret the data is likely wrong.<p>Mix them together and you’re already deep in make believe land, so letting AI take over step 1 seems like a perfect fit.<p>I was hoping to read this article and be surprised by how OpenAI was able to solve the reliability problem, but alas.",
      "In my opinion, data and documents are the real AI benefit, or threat, to developer jobs.<p>Specifically, how good a company&#x27;s data is will determine how effectively it can leverage AI in the future. The public data is pretty much mined to exhaustion, and the next big data source will be in-house documentation, code repos, data lakes, etc. If you work for a company where that&#x27;s been built, maintained, and organised then the effectiveness of AI is going to be mind-blowing. Companies that have maintained good docs be able to build new things, maintain old things, and migrate things to cheaper modern stacks <i>easily</i>. That will lead to being able to move fast and deploy new AI-driven services easily and cheaply. Revenue will follow.<p>Conversely, at companies where documentation and code organisation have been historically poor, AI will struggle. Leaders will see it as a benefit, and be baffled at why their company can&#x27;t realise the value of it. They&#x27;ll quickly blame developers for not being able to use it, and that&#x27;ll lead to people&#x27;s growth stagnating or possibly layoffs. Eventually competitors will eat the company&#x27;s lunch because they&#x27;ll just be able to move on opportunities <i>much</i> faster.<p>I&#x27;ve resolved that in any future job hunt I&#x27;m going to make asking about docs, data, and repos a priority...",
      "At Amplitude we built Moda which is super similar to this.<p>Our chief engineer Wade gave an awesome demo to Claire Vo some months back here: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=9Q9Yrj2RTkg\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=9Q9Yrj2RTkg</a><p>I use this basically every day asking all sorts of questions",
      "Piling on to the vendor pitches here:<p>We give you all of this in 5 minutes at <a href=\"https:&#x2F;&#x2F;www.definite.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.definite.app&#x2F;</a>.<p>And I mean all of it. You don&#x27;t need Spark or Snowflake. We give you a datalake, pipelines to get data in, semantic layer and a data agent in one app.<p>The agent is kind of the easy &#x2F; fun part. Getting the data infrastructure right so the agent is useful is the hard part.<p>i.e. if the agent has low agency (e.g. can only write SQL in Snowflake) and can&#x27;t add a new data source or update transformation logic, it&#x27;s not going to be terribly effective. Our agent can obviously write SQL, but it can also manage the underlying infra, which has been a huge unlock for us.",
      "Very, very good stuff here. I think a possible missing piece is how to explain how the results were computed. Here it seems they&#x27;re relying on the fact that users are somewhat technical (that&#x27;s great for OpenAI -- it&#x27;s an internal agent after all) and can at least read SQL, but it&#x27;s an interesting design problem how you would structure the interaction with nontechnical users.<p>When working on data systems you quickly realize that often <i>how</i> the question was answered (how the metric is defined, what data was taken into account and so on) is just as important as the answer.",
      "data problems are not tech problems but rather org problems",
      "I&#x27;m more interested in Kimi&#x27;s In-House Data Agent"
    ],
    "full_text": null
  },
  {
    "title": "Trump says he's decertifying Canada-made aircraft and threatens 50% tariffs",
    "url": "https://www.cnn.com/2026/01/29/business/trump-canada-aircraft-tariff",
    "source": "hn",
    "summary": "",
    "comments": [
      "The USAF may be inconvenienced:<p>&gt; <i>Air Combat Command received the latest E-11A aircraft equipped with the Battlefield Airborne Communications Node, or BACN, Sept. 18. The system currently operates on two platforms: the E-11A, a modified Bombardier business jet and the EQ-4B, a modified Global Hawk Block 20 remotely piloted aircraft.</i><p>* <a href=\"https:&#x2F;&#x2F;www.acc.af.mil&#x2F;News&#x2F;Photos.aspx?igphoto=2000910543\" rel=\"nofollow\">https:&#x2F;&#x2F;www.acc.af.mil&#x2F;News&#x2F;Photos.aspx?igphoto=2000910543</a><p>* <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Battlefield_Airborne_Communications_Node\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Battlefield_Airborne_Communica...</a>",
      "Some numbers from (current) top comment:<p>---<p>Taking the post literally means grounding at least 5,500 to 6,000 airframes immediately.<p>If the &quot;decertification&quot; extends to Canadian-made engines on American-made planes, that number explodes past 15,000.<p>Helicopters Bell 407, 412, 429, 505 3,000+ Law enforcement and MedEvac.<p>Regional Jets CRJ-700 &#x2F; 900. 600+<p>High-End Jets Global &#x2F; Challenger &#x2F; Learjet. 1,500+<p>Turboprops Dash 8 &#x2F; Twin Otter. 200+<p>Modern Narrowbody Airbus A220. 150+<p>---<p>* <a href=\"https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;aviation&#x2F;comments&#x2F;1qqq5xn&#x2F;all_challengers_crjs_and_globals_etc_to_be&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;aviation&#x2F;comments&#x2F;1qqq5xn&#x2F;all_chall...</a><p>Also someone noted that the US-made Gulfstreams use PW&amp;C engines:<p>* <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pratt_%26_Whitney_Canada_PW800\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pratt_%26_Whitney_Canada_PW800</a>  § Variants",
      "Trump says look at me --- I&#x27;m a bully and not a very smart one.<p>Trade deficit hits new record high --- despite tariffs. Factory construction and manufacturing jobs are *down*. Trump fans are still swimming in a river in Africa.<p><a href=\"https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;us-trade-deficit-widens-by-most-nearly-34-years-november-2026-01-29&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;us-trade-deficit-widens-by-...</a><p><a href=\"https:&#x2F;&#x2F;cepr.net&#x2F;publications&#x2F;how-many-manufacturing-jobs-has-trump-actually-lost&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;cepr.net&#x2F;publications&#x2F;how-many-manufacturing-jobs-ha...</a>"
    ],
    "full_text": null
  },
  {
    "title": "Waabi raises $1B and expands into robotaxis with Uber",
    "url": "https://techcrunch.com/2026/01/28/waabi-raises-1b-and-expands-into-robotaxis-with-uber/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Code World Model",
    "url": "https://github.com/facebookresearch/cwm",
    "source": "hn",
    "summary": "",
    "comments": [
      "It would be interesting to see if they have an updated version of a model that employs this training technique. According to the paper it scored well on release (65.8% on SWE bench), but by now it no longer scores competitively against the latest generation open coding models (e.g. Devstral Small 2).<p>I wonder whether other labs have implemented something similar to this approach. Perhaps code world modeling isn&#x27;t actually necessary (relative to other simpler techniques) to achieve the kind of deep environment understanding that the paper touts as being important to improve agentic coding performance.",
      "Given the high bar of entry 160VRAM GPU - is there anything practical one can use this for?"
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Autonomous recovery for distributed training jobs",
    "url": "https://docs.tensorpool.dev/features/agent",
    "source": "hn",
    "summary": "",
    "comments": [
      "We&#x27;re still figuring out how to detect &quot;silent&quot; failures where the job doesn&#x27;t crash but stops making progress — like NCCL hangs where ranks are waiting indefinitely, or gradient norm explosions that don&#x27;t trigger OOM but tank loss. Right now we rely on explicit errors in logs, but curious how others approach detecting &quot;the job is technically running but something is very wrong&quot; (if at all)?",
      "Would love to hear how you&#x27;re handling recovery for long-running training jobs today, as well as what failure modes are most common&#x2F;annoying for you."
    ],
    "full_text": null
  },
  {
    "title": "SpaceX in Merger Talks with xAI",
    "url": "https://www.reuters.com/world/musks-spacex-merger-talks-with-xai-ahead-planned-ipo-source-says-2026-01-29/",
    "source": "hn",
    "summary": "",
    "comments": [
      "They both are privately held by the same owner! So, with whom are they talking? :-)",
      "He&#x27;s really shuffling the X purchase debt around.",
      "Why would you pollute SpaceX’s valuation by coupling it with a toxic asset like xAi?",
      "&gt; Last year, SpaceX agreed to invest $2 billion in xAI as part of the startup’s $5 billion equity fundraising, the Wall Street Journal reported at the  time.<p>Sometimes you just need to get the founders in a room together to hash things out and magic can happen.",
      "I don’t understand the point of this stuff, Musk already has infinite money why does he need to play shenanigans with shuffling things between his various holdings?",
      "&gt; would give  fresh momentum to SpaceX’s effort to launch data centers into orbit as Musk battles for supremacy in the rapidly escalating AI race against tech giants like Google, Meta and OpenAI.<p>Still haven&#x27;t seen a successful PoC datacenter in orbit. If you own the rockets, maybe get that done tomorrow? I do assume your investors will want one working before they dump even more cash into the idea. But what do I know.",
      "Elon doing some financial engineering to engineer a 1T valuation for himself? :-D",
      "&gt; <i>Reuters could not determine the value of the deal, its  primary rationale, or its potential timing.</i>",
      "So, somehow, Twitter will end up being (partially) public again!<p>What are we doing here",
      "This makes total sense his DC in Memphis will be his Houston. That DC will control all space flights and space robots."
    ],
    "full_text": null
  },
  {
    "title": "Apple acquires secretive Q․AI startup for $2B",
    "url": "https://9to5mac.com/2026/01/29/apple-acquires-secretive-q%E2%80%A4ai-startup-for-2-billion/",
    "source": "hn",
    "summary": "",
    "comments": [
      "&quot;Based on patent filings, Q.ai has built machine-learning tech for audio and “silent” voice input, including systems designed to understand to improve communication in noisy or difficult environments.&quot;<p>Good? Based on my recent experience the native iOS functionality around voice activity detection, echo cancellation and transcription is horrendous. If they could ship devices that had anywhere near the quality you can get with a bespoke stack to handle the audio data it would be impressive.",
      "dupe: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46814773\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46814773</a>"
    ],
    "full_text": null
  },
  {
    "title": "Nvidia, Microsoft, Amazon in talks to invest up to $60B in OpenAI",
    "url": "https://www.reuters.com/business/retail-consumer/nvidia-microsoft-amazon-talks-invest-up-60-billion-openai-information-reports-2026-01-29/",
    "source": "hn",
    "summary": "",
    "comments": [
      "What’s new? I mean, it’s the same bunch of companies propping up OpenAI because they know that if OpenAI fails this whole AI house-of-cards will come tumbling down around them.",
      "It&#x27;s Big Tech&#x27;s own Hotel California. The only exit is to finish their so called AI God or socialize their losses to the taxpayers eventually. Take a wild guess where my money is.",
      "I wonder if they have fixed that Data Center ROI=0 problem with the electric bill? Until then, they might as well flush money into a black hole."
    ],
    "full_text": null
  },
  {
    "title": "Slopaganda: AI images posted by the White House and what they teach us",
    "url": "https://www.theguardian.com/us-news/2026/jan/29/the-slopaganda-era-10-ai-images-posted-by-the-white-house-and-what-they-teach-us",
    "source": "hn",
    "summary": "",
    "comments": [
      "I think at some point it would be more useful to talk about this and other behavior by this administration from a mental health perspective.",
      "They teach me to distrust literally everything that comes from the executive branch.",
      "Link for when MAGA flags this: <a href=\"https:&#x2F;&#x2F;www.theguardian.com&#x2F;us-news&#x2F;2026&#x2F;jan&#x2F;29&#x2F;the-slopaganda-era-10-ai-images-posted-by-the-white-house-and-what-they-teach-us\" rel=\"nofollow\">https:&#x2F;&#x2F;www.theguardian.com&#x2F;us-news&#x2F;2026&#x2F;jan&#x2F;29&#x2F;the-slopagan...</a>",
      "Trump seems to have an obsession with all things gold, so I guess even that &quot;golden age&quot; could simply be interpreted as &quot;the Trump age&quot;.",
      "The AI of Sauron.<p>But seriously, when most people see that their head of state has no moral standards whatsoever, they&#x27;ll follow and drop their own standard even lower. It would be a similar situation if a bishop was openly a drunkard or if an army sergeant was a lazy drug addict.",
      "Henry Farrell nailed it in early 2018, calling this Philip K Dick&#x27;s future, with the invasion of fake humans.\n<a href=\"https:&#x2F;&#x2F;www.bostonreview.net&#x2F;articles&#x2F;henry-farrell-philip-k-dick-and-fake-humans&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.bostonreview.net&#x2F;articles&#x2F;henry-farrell-philip-k...</a><p>These people believe in nothing. They offer nothing. They detest that other people have these &quot;virtues&quot;, more than smirking deceitful nonsense. Vengeful destruction of the world, letting their fakeness take over and ruin meaning: that&#x27;s the revenge. Lovely recent short 2 min video, <i>Ruminations on that DHS penguin tweet</i> is succinct &amp; to the point, on the weird suicidal Werner Hertzog penguin meme that has been making rounds, and how these memes so embrace anti-meaning.\n<a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;c7WqVx9x89s\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;c7WqVx9x89s</a>",
      "[dead]"
    ],
    "full_text": null
  },
  {
    "title": "Microsoft stock plummets as investors fret on AI spend",
    "url": "https://finance.yahoo.com/news/microsoft-q2-earnings-beat-but-stock-plummets-as-investors-fret-on-ai-spend-cloud-growth-154618162.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "&gt; Microsoft continues to face AI capacity constraints, meaning customer demand for AI is outpacing Microsoft’s ability to supply it, putting an artificial cap on the Windows maker’s revenue.<p>Strangely, all I hear about is how annoyed people are with MS shoving AI into everything. Who are these &quot;customers&quot;?",
      "Not long ago, someone here thought OpenAI bulls investing in MSFT could be a good way to indirectly profit from OpenAI. I pointed out that you really had to weigh that against Microsoft&#x27;s potential risks (pretty banal advice, really). Even though I hadn&#x27;t made any prediction about which way MSFT would go, a bunch of people piled on me like it was utterly inconceivable that MSFT could go down because of cloud gains.<p>Just a friendly reminder that it&#x27;s not just LLMs that can be confidently wrong.",
      "same with SAP&#x2F;EU:\ndown by 10%+ because of &quot;missed investors expectations&quot; LOL<p>(imagine: A company bringing in billions, laying off people in parallel, and then claiming &quot;the business does not make enough money&quot; - crazy!)"
    ],
    "full_text": null
  }
]