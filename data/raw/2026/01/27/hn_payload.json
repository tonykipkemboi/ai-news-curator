[
  {
    "title": "Heathrow scraps liquid container limit",
    "url": "https://www.bbc.com/news/articles/c1evvx89559o",
    "source": "hn",
    "summary": "",
    "comments": [
      "This just adds confusion as to the purpose of all this.<p>The motivation behind the liquid limits is that there are extremely powerful explosives that are stable water-like liquids. Average people have never heard of them because they aren’t in popular lore. There has never been an industrial or military use, solids are simpler. Nonetheless, these explosives are easily accessible to a knowledgeable chemist like me.<p>These explosives can be detected via infrared spectroscopy but that isn’t going to be happening to liquids in your bag. This reminds me of the chemical swipes done on your bags to detect explosives. Those swipes can only detect a narrow set of explosive chemistries and everyone knows it. Some explosives notoriously popular with terror organizations can’t be detected. Everyone, including the bad guys, knows all of this.<p>It would be great if governments were more explicit about precisely what all of this theater is intended to prevent.",
      "there is actually a science change that happened, and it&#x27;s not (entirely) just politicians changing their mind.<p>The big thing going from X-ray (2d) to CT (spin an X-ray machine around and take a ton of pictures to recreate a 3d image) did a lot to let security people see inside of a bag, but the hitch is that if you see a blob of gray is that water, shampoo or something else?<p>The recent advance that is letting this happen is machines who will send multiple wavelengths of X-ray through the material: since different materials absorb light differently, your machine can distinguish between materials, which lets you be more sure that that 2litre is (mostly) water, and then they can discriminate",
      "That liquid limit never made any real sense to me; it always seemed arbitrary.<p>Now - I don&#x27;t think I was ever affected by it in any way, shape or form, though I also rarely use(d) the plane. But to me it seemed more as if it was an attempt to meta-engineer the opinion of people, e. g. to make them fearful of danger xyz. When I look at the current US administration and how the ICE deathsquads operate (two US citizens shot dead already), with that administration instantly defending them without even any trial, then this also seems more a propaganda operation - that one being more reminiscent of the 1930s supposedly, but we had this wave of propaganda before (e. g. both Bush presidents; Noriega capture is somewhat similar to Maduro, though the latter situation seems more as if the other officials in Venezuela purposefully gave him up - watch how the sanctions will be removed in a short while).",
      "How many man hours and how much money have we wasted over security theater at airports? Has it been a worthwhile trade off?",
      "If you think you had it bad all these years, you should come and visit the Falkland Islands. I will be brief, but I will explain what going through the Mount Pleasant Airport (MPN) feel like for the average visitor.<p>For added context: Only one flight by a commercial airline a week on Saturday, comes in around 1300, departs around 1500. You miss it, you wait another week.<p>- The terminal is extremely small, the plane that comes around can probably fit around 180 pax, you could not fit that many people on the check-in lounge, which means a lot of times people have to queue outside, even in the winter.<p>- Check in is sluggish, with the Airline representatives in the Falklands calling for check in 4 hours in advance when a flight is full.<p>- After getting your ticket, security will check your bags and you will be asked to wait an undetermined amount of time, to see if a &quot;random&quot; check need to take place, again, the terminal is tiny, people often crowds waiting forever for their name the be shouted by some security person.<p>- If you manage to get passed this part, you are still not safe, security can still call your name when passing through or after immigration. Even if you are already in the wait lounge. Someone might still show up and shout your name.<p>- Immigration will scan your passport and charge you £40 for leaving the country.<p>- Now you are actually commit to the security checkpoint (these are the same guys that scan the bags on check-in). At any given time there is at least 10 in a 5m2 area. You are forced to take your shoes, no liquids are allowed, no toothpaste, take all electronics out of your bag, take jacket off.<p>- You are randomly tested for drug and explosive traces (GOING OFF THE FALKLAND ISLANDS)<p>- You may be patted<p>- All your belongings might be checked at this point as well.<p>All in all, you could be looking at a 2-hour ordeal from start to finish.<p>Do yourself a favor. Go to Maldives instead.",
      "Not because of a sudden outbreak of sanity, but because they have CT scanners now.",
      "Let me get this straight. If the article is correct, the new capabilities are related to better detection of large liquid containers, not determination of whether or not the liquid is dangerous.<p>So - you couldn’t take large amounts of liquids previously because some liquids in large amounts might be able to be weaponized. If you were caught with too much liquid (in sum total, or in containers that are too large) they’d throw it out and send you on your way.<p>But now that they have the ability to detect larger containers, they… do what? Declare that it’s safe and send you on your way with it still in your possession?",
      "Going to Edinburgh Airport, I was reminded that the tiny water bottle I forgot in my bag could be a bomb. I just went &quot;Oh jeez I&#x27;m sorry... Here, have some water! You look like you need it!&quot; Then I opened the bottle and drank it. He grabbed it out of my hands and said it had to go to some lab. So I went &quot;Ok then, the chemical compounds in there are ... H2O and perhaps some carbon...? Idk. I&#x27;m not a chemist, but I&#x27;m fairly sure the worst thing it&#x27;ll do is make me burp.&quot;",
      "My GF is from East Asia and has travelled almost 100 countries, anything from rich first world to poor 3rd world countries.<p>She was absolutely shocked to find that liquid container limits were enforced in northern Europe. She would just put her makeup bag with cleansers and gels and everything in her carry-on and travel the world.",
      "We transited through LHR yesterday. Still had to go through security - not sure why since we stayed on the air side.<p>Anyway, signage required us to empty our refillable water bottles. Odd. Thankfully we eventually found a refill station.<p>The scanners flagged a still sealed can of ginger ale left over from our incoming flight. It was &quot;fine&quot; but she still swabbed it. Shrug."
    ],
    "full_text": null
  },
  {
    "title": "Kimi Released Kimi K2.5, Open-Source Visual SOTA-Agentic Model",
    "url": "https://www.kimi.com/blog/kimi-k2-5.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "Huggingface Link: <a href=\"https:&#x2F;&#x2F;huggingface.co&#x2F;moonshotai&#x2F;Kimi-K2.5\" rel=\"nofollow\">https:&#x2F;&#x2F;huggingface.co&#x2F;moonshotai&#x2F;Kimi-K2.5</a><p>1T parameters, 32b active parameters.<p>License: MIT with the following modification:<p><i>Our only modification part is that, if the Software (or any derivative works\nthereof) is used for any of your commercial products or services that have\nmore than 100 million monthly active users, or more than 20 million US dollars\n(or equivalent in other currencies) in monthly revenue, you shall prominently\ndisplay &quot;Kimi K2.5&quot; on the user interface of such product or service.</i>",
      "The &quot;Deepseek moment&quot; is just one year ago today!<p>Coincidence or not, let&#x27;s just marvel for a second over this amount of magic&#x2F;technology that&#x27;s being given away for free... and how liberating and different this is than OpenAI and others that were closed to &quot;protect us all&quot;.",
      "&gt; For complex tasks, Kimi K2.5 can self-direct an agent swarm with up to 100 sub-agents, executing parallel workflows across up to 1,500 tool calls.<p>&gt; K2.5 Agent Swarm improves performance on complex tasks through parallel, specialized execution [..] leads to an 80% reduction in end-to-end runtime<p>Not just RL on tool calling, but RL on agent orchestration, neat!",
      "I&#x27;ve read several people say that Kimi K2 has a better &quot;emotional intelligence&quot; than other models. I&#x27;ll be interested to see whether K2.5 continues or even improves on that.",
      "One thing caught my eyes is that besides K2.5 model, Moonshot AI also launched Kimi Code (<a href=\"https:&#x2F;&#x2F;www.kimi.com&#x2F;code\" rel=\"nofollow\">https:&#x2F;&#x2F;www.kimi.com&#x2F;code</a>), evolved from Kimi CLI. It is a terminal coding agent, I&#x27;ve been used it last month with Kimi subscription, it is capable agent with stable harness.<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;MoonshotAI&#x2F;kimi-cli\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;MoonshotAI&#x2F;kimi-cli</a>",
      "Have you all noted that the latest releases (Qwen3 max thinking, now Kimi k2.5) from Chinese companies are benching against Claude opus now and not Sonnet? They are truly catching up, almost at the same pace?",
      "K2 0905 and K2 Thinking shortly after that have done impressively well in my personal use cases and was severely slept on. Faster, more accurate, less expensive, more flexible in terms of hosting and available months before Gemini 3 Flash, I really struggle to understand why Flash got such positive attention at launch.<p>Interested in the dedicated Agent and Agent Swarm releases, especially in how that could affect third party hosting of the models.",
      "Curious what would be the most minimal reasonable hardware one would need to deploy this locally?",
      "A realistic setup for this would be a 16× H100 80GB with NVLink. That comfortably handles the active 32B experts plus KV cache without extreme quantization. Cost-wise we are looking at roughly $500k–$700k upfront or $40–60&#x2F;hr on-demand, which makes it clear this model is aimed at serious infra teams, not casual single-GPU deployments. I’m curious how API providers will price tokens on top of that hardware reality.",
      "Congratulations, great work Kimi team.<p>Why is that Claude still at the top in coding, are they heavily focused on training for coding or is it their general training is so good that it performs well in coding?<p>Someone please beat the Opus 4.5 in coding, I want to replace it."
    ],
    "full_text": null
  },
  {
    "title": "Apple introduces new AirTag with longer range and improved findability",
    "url": "https://www.apple.com/newsroom/2026/01/apple-introduces-new-airtag-with-expanded-range-and-improved-findability/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Airtag is the reason of why I stil have my favourite hand luggage.<p>I had just sat down on the train from Zurich to Basel. Suddenly, someone sat down in front of me. He looked suspicious, but I didn&#x27;t pay much attention. Just before the train departed, he picked up what I thought were his belongings and left.<p>Twenty minutes later, already on the way to Basel, I looked toward where I had left my suitcase. It was gone. That was when I realized that the person who had sat in front of me was a thief.<p>However, he hadn&#x27;t counted on the fact that I have an AirTag in every backpack and suitcase.<p>So I was able to see where the thief was and where he was moving. I considered going to retrieve my suitcase myself, but while traveling back to Zurich, I called the Zurich Police and, as the thief kept moving, I told them where he was.<p>Twenty minutes later I received a call from the police informing me that they had found my suitcase with my belongings, matching the description I had given.<p>But also the thief and his accomplice.",
      "I’m sporting a Life360, MoniMoto and AirTags on my moto. The Life360 seemed to have better range—until it just went offline. The AirTag is still working, though.<p>So I’m stoked to hear about a new tag with greater range.",
      "&gt;  The new AirTag is designed with the environment in mind, with 85 percent recycled plastic in the enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled gold plating in all Apple-designed printed circuit boards. The paper packaging is 100 percent fiber-based and can be easily recycled.<p>I&#x27;m no material scientist, but this seems pretty impressive to me that Apple&#x27;s economy of scale can pull this off, and upgrade the device capabilities, for less than $30 USD.",
      "Unfortunately the anti-stalking features have made Airtag mostly useless for theft prevention. You have less than an hour to retrieve your item before the tag alerts the thief they are being tracked. I&#x27;ve seen it trigger as quickly as 30 minutes.",
      "It sounds like the external dimensions are going to be exactly the same or nearly so. I&#x27;m hoping the battery compartment is also identical so that third-party mounting and extended battery packs continue to work.<p>I recently picked up a few of these extended battery packs and it would be nice to eventually upgrade the AirTag if the extended range turns out to be meaningful. They&#x27;re pretty neat, you remove the battery cover completely and only insert the half of the AirTag with the electronics and radio.<p><a href=\"https:&#x2F;&#x2F;www.elevationlab.com&#x2F;products&#x2F;timecapsule\" rel=\"nofollow\">https:&#x2F;&#x2F;www.elevationlab.com&#x2F;products&#x2F;timecapsule</a>",
      "I&#x27;m curious whether the improved range is actually going to make the product worse for my particular use case, which is being alerted when I&#x27;ve left my bag somewhere (this has happened to me at least 5 times over the years). My understanding is that the item left behind notifications are triggered when your phone loses contact with the AirTag, so increased range can potentially take me from being notified as I step off the train to being notified as I leave the station and the train has departed.",
      "Probably one of the best products apple has made of late: relatively affordable, good ux, user replaceable batteries. Glad to see this iteration hasn&#x27;t made it worse.",
      "What airtags need is a theft mode, where anyone carrying the airtag is not alerted, but the location can be retrieved by an approved local authority after being voluntarily surrendered by the owner.",
      "I wish they made airtags in different form factors.<p>I&#x27;ve gotten into photography lately. I&#x27;d love to slip an airtag into more places - ideally within the housing of my camera bodies themselves. But, there&#x27;s not really any room to put an airtag on or in a camera given the current airtag form factor.<p>You can get camera cages with secret compartments for airtags. And lens caps which take an airtag. But they take up a lot of space, and end up adding a lot of bulk to the camera itself. I wish Apple opened airtags up to 3rd party manufacturers who could buy the (tiny) circuit board directly, so they could hide it in their products better.",
      "my parents live in Russia and my grandma has alzheimer&#x27;s, so as a present &quot;for her&quot; I bought an airtag - so in case my mom loses grandma in a crowd she can be found.<p>Little did I know, GPS jammers around the city make my grandma appear 50km away.<p>Not Apple&#x27;s fault of course."
    ],
    "full_text": null
  },
  {
    "title": "ChatGPT Containers can now run bash, pip/npm install packages and download files",
    "url": "https://simonwillison.net/2026/Jan/26/chatgpt-containers/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Congratulations. One insecure buggy code generator connected to an insecure packaging &quot;system&quot;, PyPI.<p>We are eagerly awaiting Claude Launch, which will be connected to ICBM bases. The last thing humanity will hear is a 100 page boring LLM written mea culpa by Amodei, where he&#x27;ll say that he has warned about the dangers but it was <i>inevitable</i>.",
      "Giving agents linux has compounding benefits in our experience. They&#x27;re able to sort through weirdness that normal tooling wouldn&#x27;t allow. Like they can read and image, get an error back from the API and see it wasn&#x27;t the expected format. They read the magic bytes to see it was a jpeg despite being named .png, and read it correctly.",
      "Regular default ChatGPT can also now run code in Node.js, Ruby, Perl, PHP, Go, Java, Swift, Kotlin, C and C++.<p>I&#x27;m not sure when these new features landed because they&#x27;re not listed anywhere in the official ChatGPT release notes, but I checked it with a free account and it&#x27;s available there as well.",
      "Seems like everyone is trying to get ahead of tool calling moving people &quot;off platform&quot; and creating differentiators around what tools are available &quot;locally&quot; to the models etc.  This also takes the wind out of the sandboxing folks, as it probably won&#x27;t be long before the &quot;local&quot; tool calling can effectively do anything you&#x27;d need to do on your local machine.<p>I wonder when they&#x27;ll start offering virtual, persistent dev environments...",
      "This is either going to save hours… or create very educational outages.",
      "Nice work detective Simon! I love these “discovery” posts the most because you can’t find this stuff anywhere.",
      "I wonder how long npm&#x2F;pip etc even makes sense.<p>Dependancies introduce unnecessary LOC and features which are, more and more, just written by LLMs themselves. It is easier to just write the necessary functionality directly. Whether that is more maintainable or not is a bit YMMV at this stage, but I would wager it is improving.",
      "Maybe soon we have single use applications. Where ChatGPT can write an App for you on-the-fly in a cloud sandbox you interact with it in the browser and fulfill your goal and afterwards the App is shutdown and thrown away.",
      "Has Gemini lost its ability to run javascript and python? I swear it could when it was launched by now its saying it hasn&#x27;t the ability. Annoying regression when Claude and ChatGPT are so good at it.",
      "Wow, it can do what I could do 20 years back using Ctrl+T? The progress! Give them another 10 billion, scratch that, 20 billion, scratch that, 75 trillion. - Written by SarcastAI."
    ],
    "full_text": null
  },
  {
    "title": "There is an AI code review bubble",
    "url": "https://www.greptile.com/blog/ai-code-review-bubble",
    "source": "hn",
    "summary": "",
    "comments": [
      "My experience with using AI tools for code review is that they do find critical bugs (from my retrospective analysis, maybe 80% of the time), but the signal to noise ratio is poor. It&#x27;s really hard to get it not to tell you 20 highly speculative reasons why the code is problematic along with the one critical error. And in almost all cases, sufficient human attention would also have identified the critical bug - so human attention is the primary bottleneck here.  Thus poor signal to noise ratio isn&#x27;t a side issue, it&#x27;s one of the <i>core</i> issues.<p>As a result, I&#x27;m mostly using this selectively so far, and I wouldn&#x27;t want it turned on by default for every PR.",
      "None of these tools perform particularly well and all lack context to actually provide a meaningful review beyond what a linter would find, IMO.  The SOTA isn&#x27;t capable of using a code diff as a jumping off point.<p>Also the system prompts for some of them are kinda funny in a hopelessly naive aspirational way.  We should all aspire to live and breathe the code review system prompt on a daily basis.",
      "I&#x27;ve tried Greptile and it&#x27;s pretty much pure noise. I ran it for 3 PRs and then gave up. Here are three examples of things it wasted my time on in those 3 PRs:<p>* Suggested to silence exception instead of crash and burn for &quot;style&quot; (the potential exception was handled earlier in code but it did not manage to catch that context). When I commented that silencing the exception could lead to uncaught bugs it replies &quot;You&#x27;re absolutely right, remove the try-catch&quot; which I of course never added\n* Us using python 3.14 is a logic error as &quot;python 3.14 does not exist yet&quot;\n* &quot;Review the async&#x2F;await patterns\nHeavy use of async in model validation might indicate these should be application services instead.&quot; whatever this vague sentence means. Not sure if it is suggesting us changing the design pattern used in our entire code base.<p>Also the &quot;confidence&quot; score added to each PR being 4&#x2F;5 or something due to these irrelevant comments was a really annoying feature IMO. In general AI tools giving a rating when they&#x27;re wrong feels like a big productivity loss as then the human reviewer will see that number and think something is wrong with the PR.<p>--<p>Before this we were running Coderabbit which worked really well and caught a lot of bugs &#x2F; implementation gotchas. It also had &quot;learnings&quot; which it referenced frequently so it seems like it actually did not repeat commenting on intentional things in our code base. With Coderabbit I found myself wanting to read the low confidence comments as well since they were often useful (so too quiet instead of too noisy). Unfortunately our entire Coderabbit integration just stopped working one day and since then we&#x27;ve been in a long back and forth with their support.<p>--<p>I&#x27;m not sure what the secret sauce is but it feels like Greptile was GPT 3.5-tier and Coderabbit was Sonnet 4.5-tier.",
      "Problem with Code Review is it is quite straightforward to just prompt it, and the frontier models, whether Opus or GPT5.2Codex do a great job at code-reviews. I don&#x27;t need second subscription or API call when the first one i already have and focus on integration works well out of the box.<p>In our case, agentastic.dev, we just baked the code-review right into our IDE. It just packages the diff for the agent, with some prompt, and sends it out to different agent choice (whether claude, codex) in parallel. The reason our users like it so much is because they don&#x27;t need to pay extra for code-review anymore. Hard to beat free add-on, and cherry on top is you don&#x27;t need to read a freaking poems.",
      "Greptile is a great product and I hope you succeed.<p>However, I disagree that independence is a competitive advantage. If it’s true that having a “firewall” between the coding agent and review agent leads to better code, I don’t see why a company like Cursor can’t create full independence between their coding and review products but still bundle them together for distribution.<p>Furthermore, there might well be benefits to not being fully independent. Imagine if an external auditor was brought in to review every decision made inside your company. There would likely be many things they simply don’t understand. Many decisions in code might seem irrational to an external standalone entity but make sense in the broader context of the organization’s goals. In this sense, I’m concerned that fully independent code review might miss the forest for the trees relative to a bundled product.<p>Again, I’m rooting for you guys. But I think this is food for thought.",
      "The main problem with current AI reviewers isn&#x27;t catching bugs, it&#x27;s shutting up when there is no bug. Humans have an intuitive filter like &quot;this code is weird, but it works and won&#x27;t break prod, so I&#x27;ll let it slide&quot;. LLMs lack this, they generate 20 comments about variable naming and 1 comment about a critical race condition. As a result the developer gets fatigue and ignores everything. Until AI learns to understand the context of importance, not just code context, it will remain an expensive linter",
      "I still think any business that is based on someone else&#x27;s model is worthless. I know I&#x27;m sounding like the &#x27;dropbox is just FTP&#x27; guy, but it really feels like that any good idea will just be copied by OpenAI and Anthropic. If AI code review is proven a good idea is there any reason to expect Codex or Claude Code to not implement some commands to do code review?",
      "I&#x27;ve also noticed this explosion of code review tools and felt that there&#x27;s some misplaced focus going on for companies.<p>Two that stood out to me are Sentry and Vercel. Both have released code review tools recently and both feel misplaced. I can definitely see why they thought they could expand with that type of product offering but I just don&#x27;t see a benefit over their competition. We have GH copilot natively available on all our PRs, it does a great job, integrates very well with the PR comment system, and is cheap (free with our current usage patterns). GH and other source control services are well placed to have first-class code review functionality baked into their PR tooling.<p>It&#x27;s not really clear to me what Sentry&#x2F;Vercel are offering beyond what copilot does and in my brief testing of them didn&#x27;t see noticeable difference in quality or DX. Feels like they&#x27;re fighting an uphill battle from day one with the product choice and are ultimately limited on DX by how deeply GH and other source control service allow them to integrate.<p>What I would love to see from Vercel, which they feel very well placed to offer, is AI powered QA. They already control the preview environments being deployed to for each PR, they have a feedback system in place with their Vercel toolbar comments, so they &quot;just&quot; need to tie those together with an agentic QA system. A much loftier goal of course but a differentiator and something I&#x27;m sure a lot of teams would pay top dollar for if it works well.",
      "I can&#x27;t get over how every single code rabbit ad was some incorrectly classified bug &#x2F; completely wrong to begin with or pointless at best.",
      "I don&#x27;t really understand how this differentiates against the competition.<p>&gt; Independence<p>Any &quot;agent&quot; running against code review instead of code generation is &quot;independent&quot;?<p>&gt; Autonomy<p>Most other code review tools can also be automated and integrated.<p>&gt; Loops<p>You can also ping other code review tools for more reviews...<p>I feel like this article actually works against you by presenting the problem and inadequately solving them."
    ],
    "full_text": null
  },
  {
    "title": "I let ChatGPT analyze a decade of my Apple Watch data, then I called my doctor",
    "url": "https://www.msn.com/en-us/news/technology/i-let-chatgpt-analyze-a-decade-of-my-apple-watch-data-then-i-called-my-doctor/ar-AA1UZxip",
    "source": "hn",
    "summary": "",
    "comments": [
      "Health metrics are absolutely tarnished by a lack of proper context. Unsurprisingly, it turns out that you can&#x27;t reliably take a concept as broad as health and reduce it to a number. We see the same arguments over and over with body fat percentages, vo2 max estimates, BMI, lactate thresholds, resting heart rate, HRV, and more. These are all useful metrics, but it&#x27;s important to consider them in the proper context that each of them deserve.<p>This article gave an LLM a bunch of health metrics and then asked it to reduce it to a single score, didn&#x27;t tell us any of the actual metric values, and then compared that to a doctor&#x27;s opinion. Why anyone would expect these to align is beyond my understanding.<p>The most obvious thing that jumps out to me is that I&#x27;ve noticed doctors generally, for better or worse, consider &quot;health&quot; much differently than the fitness community does. It&#x27;s different toolsets and different goals. If this person&#x27;s VO2 max estimate was under 30, that&#x27;s objectively a poor VO2 max by most standards, and an LLM trained on the internet&#x27;s entire repository of fitness discussion is likely going to give this person a bad score in terms of cardio fitness. But a doctor who sees a person come in who isn&#x27;t complaining about anything in particular, moves around fine, doesn&#x27;t have risk factors like age or family history, and has good metrics on a blood test is probably going to say they&#x27;re in fine cardio health regardless of what their wearable says.<p>I&#x27;d go so far to say this is probably the case for most people. Your average person is in really poor fitness-shape but just fine health-shape.",
      "A year or so ago, I fed my wife&#x27;s blood work results into chatgpt and it came back with a terrifying diagnosis. Even after a lot of back and forth it stuck to its guns. We went to a specialist who performed some additional tests and explained that the condition cannot be diagnosed with just the original blood work and said that she did not have the condition. The whole thing was a borderline traumatic ordeal that I&#x27;m still pretty pissed about.",
      "I&#x27;ll preface this with I generally trust doctors. I think on the whole they are well positioned to provide massive benefit to their patients.<p>I will also preface this with saying I do not think any LLM is better than the average doctor and that you are far better served going to your doctor than asking ChatGPT what your health is like on any factor.<p>But I&#x27;ll also say that the quality of doctors varies massively, and that a good amount of doctors learn what they learn in school and do not keep up with the latest advances in research, particularly those that have broad spectrums such as GPs. LLMs that search scientific literature, etc., might point you in the direction of this research that the doctors are not aware of. Or hallucinate you into having some random disease that impacts 3 out of every million people and send you down a rabbithole for months.<p>Unfortunately, it&#x27;s difficult to resolve this without extremely good insurance or money to burn. The depth you get and the level of information that a good preventative care cardiologist has is just miles ahead of where your average family medicine practitioner is at. Statins are an excellent example - new prescriptions are for atorvastatin are still insanely high despite it being a fairly poor choice in comparison to rosuvastatin or pitavastatin for a good chunk of the people on it. They often are behind on the latest recommendations from the NLA and AHA, etc.<p>There&#x27;s a world where LLMs or similar can empower everyday people to talk to their doctor about their options and where they stand on health, where they don&#x27;t have to hope their doc is familiar with where the science has shifted over the past 5-10 years, or cough up the money for someone who specializes in it. But that&#x27;s not the world of today.<p>In the mean time, I do think people should be comfortable being their own advocates with their doctors. I&#x27;m lucky enough that my primary care doc is open to reading the studies I send over to him on things and work with me. Or at least patient enough to humor me. But it&#x27;s let me get on medications that treat my symptoms without side effects and improved my quality of life (and hopefully life&#x2F;healthspan). There&#x27;s also been things I&#x27;ve misinterpreted - I don&#x27;t pick a fight with him if we come to opposite conclusions. He&#x27;s shown good faith in agreeing with me where it makes sense to me, and pushed back where it hasn&#x27;t, and I acknowledge he&#x27;s the expert.",
      "&gt; There were big swings in my resting heart rate whenever I got a new Apple Watch, suggesting the devices may not have been tracking the same way.<p>First of all, wrist based HR measurements are not reliable.  If you feed ChatGPT a ton of HR data that is just plain wrong, expect a bad result. Everyone who wants to track HR reliably should invest in a chest strap. The VO2 Max calculation is heavily based on your pace at a given heart rate. It makes some generalizations on on your running biomechanics. For example, if your &quot;real&quot; lab tested VO2 max stays constant, but you improve your biomechanics &#x2F; running efficiency, you can run faster at the same effort, and your Apple watch will increase your VO2 Max number.",
      "My general take on any AI&#x2F;ML in medicine is that without a proper clinical validation, they are not worth to try. Also, AI Snake Oil is worth reading.",
      "I dunno, if the Apple Watch said he had a vo2max of 30, that probably means he can’t run a mile in less than 12 minutes or so.  He’s probably not at all healthy…",
      "&gt; <i>Despite having access to my weight, blood pressure and cholesterol, ChatGPT based much of its negative assessment on an Apple Watch measurement known as VO2 max, the maximum amount of oxygen your body can consume during exercise. Apple says it collects an “estimate” of VO2 max, but the real thing requires a treadmill and a mask. Apple says its cardio fitness measures have been validated, but independent researchers have found those estimates can run low — by an average of 13 percent.</i><p>There&#x27;s plenty of blame to go around for everyone, but at least for some of it (such as the above) I think the blame more rests on Apple for falsely representing the quality of their product (and TFA seems pretty clearly to be blasting OpenAI for this, not others like Apple).<p>What would you expect the behavior of the AI to be?  Should it always assume bad data or potentially bad data?  If so, that seems like it would defeat the point of having data at all as you could never draw any conclusions from it.  Even disregarding statistical outliers, it&#x27;s not at all clear what part of the data is &quot;good&quot; vs &quot;unrealiable&quot; especially when the company that <i>collected</i> that data claims that it&#x27;s good data.",
      "I can&#x27;t wait until it starts recommending signing me up for an <i>OpenAI personalized multi-vitamin®</i> supscription",
      "Giving your health data to an AI is sick. Unfortunately no doctor can cure you of that.",
      "My wife is a doctor and there is a general trend at the moment of everyone thinking their intelligence in one area (say programming) carries over into other areas such as medicine, particularly with new tools such as ChatGPT.<p>Imagine if as a dev someone came to you and told you everything that is wrong with your tech stack because they copy pasted some console errors into ChatGPT. There&#x27;s a reason doctors need to spend almost a decade in training to parse this kind of info. If you do the above then please do it with respect for their profession."
    ],
    "full_text": null
  },
  {
    "title": "AI code and software craft",
    "url": "https://alexwennerberg.com/blog/2026-01-25-slop.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "Enterprise software tends to particularly bad because it&#x27;s being sold to managers who won&#x27;t use it themselves. Consumer software tends to be more user-friendly (or it won&#x27;t sell), but popular software isn&#x27;t always what you want.<p>When writing software for yourself, there is a bias towards implementing just the features you want and never mind the rest. Sometimes the result can be pretty sloppy, but it works.<p>However, code health is a choice. You just need to know what to ask for. A coding agent can be used as a power washer to tidy up a project. This won&#x27;t result in great art, but like raking leaves or cleaning your steps or plowing a driveway, it can be satisfying.<p>Just as you wouldn&#x27;t use a power washer to clean a painting, maybe there&#x27;s some code that&#x27;s too delicate to use a coding agent on? But for a project that has good tests and isn&#x27;t that delicate, which I believe includes most web apps, nobody&#x27;s going to want to pay for you to do it by hand anymore. It would be like paying someone to clear the snow in a parking lot with a shovel rather than hiring someone with a plow.",
      "I think we should embrace AI to craft better software. You have a lot of control over the code generated by AI, so all your designs, patterns, best practices can be used in the generated code. This will make us better software craftsmen.<p>A nice example is guitar building: there&#x27;s a whole bunch of luthiers that stick to traditional methods to build guitars, or even just limit themselves to japanese woodworking tools.<p>But that is not the only way to build great guitars. It can be done by excellent luthiers, building high quality quitars with state of the art tools. For example Ulrich Teuffel who uses all sorts of high tech like CAD systems and CDC machines to craft beautiful guitars: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GLZOxwmcFVo\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GLZOxwmcFVo</a> and <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GLZOxwmcFVo\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GLZOxwmcFVo</a><p>Unfortunately, craftsmanship does not come cheap, so most customers will turn to industrially created products. Same for software.",
      "I love the references to Jacques Ellul&#x27;s ideas, which I think are interesting to reflect on in an AI age. It helps make clear that what is fundamentally at stake in much technological &quot;progress&quot; is an (often only tacitly acknowledged) sublimation of &quot;efficiency&quot; to the place of highest value.<p>What&#x27;s fascinating is that this value elevation seems to have gone largely unchallenged, despite being in essence an arbitrary value choice. Other choices are possible. And, I hope, still are possible, despite what the bigcorps declare must be the case in order to maximize shareholder returns.",
      "&gt; But there are serious limits. [Your coding agent] will lie to you, they don&#x27;t really understand things, and they often generate bad code.<p>I think that really high quality code can be created via coding agents. Not in one prompt, but instead an orchestration of planning, implementing, validating, and reviewing.<p>Its still engineering work. The code still matters. Its just a different tool to write the code.<p>I&#x27;d compare the difference between manually coding and operating a coding agent to the difference between a handsaw and a chainsaw - the end result is the same but the method is very different.",
      "The AI code takeover will not free engineers up to do craftsmanship. It will annihilate the last vestiges of craftsmanship forever.",
      "+1 for the mention of Forth.  I use it often.  LLM answers are possible now, but they are like translated C.  It’s very bad style.<p>The standard: Forth words should be a few lines of code with a straightforward stack effect. Top level of a program might be 5 words.<p>LLM will generate some subroutines and one big word of 20-50 lines of nested IF..THEN..ELSE and DO..WHILE just as if it writing C.",
      "Most software engineers were not “crafting” before AI. They were writing sloppy code for the sake of profit, getting a pay check, and going home. Which is why AI also outputs the same crappy code.<p>Rumor has it there were a few elite crafters among the lot. Software wizards who pondered about systems and architecture as they had a $10 espresso macchiato.",
      "I feel like one of the things that&#x27;s not said enough, and which I think is conflating the effectiveness of AI in the eyes of actual software engineers, is that, for the most part, most code produced IS lousy. The craft of programming has been watered down so much in favor of results, and so much code is disposable or write-and-use once, that quality just became less relevant.<p>I remember when I first started out programming 20 years ago, there was <i>time</i> to craft good quality code. Then there were more and more pushes to get more code out faster, and no one really cared about the quality. Bugs became part of the cost of doing business. I think GenAI for code fits well in the more recent paradigm, and comparing it with hand-crafted code of yore is a bit disingenuous, as appealing as it may be, because most code hasn&#x27;t been that good for a long time.<p>I am sad to admit it, but AI is just fitting in where poor coding practices have already existed, and flourishing in that local maxima.",
      "This really nails the core issue: AI thrives in environments where software is treated as “good enough” optimization rather than craft. It’s not replacing great engineers so much as exposing how much of modern software has already become rote, metric-driven work. The Arts &amp; Crafts parallel feels especially apt as mass-produced code gets cheaper, human judgment and taste become the real scarce resources.",
      "This argument is basically just the 1800s Luddite vs Industrialist argument recast for a new age. Group A thinks quality is about human agency, and that machines are being used to bypass the apprenticeship system and produce inferior goods. Group B thinks efficiency is the highest priority, and craft is just vanity. Of course as we know we went a third way, and human roles just shifted.<p>I think one promising shift direction is humans do NOT like to talk to bots, especially not for anything important. It&#x27;s biological. We evolved to learn from and interact with other humans, preferably the same group over a long time, so we really get to understand&#x2F;mirror&#x2F;like&#x2F;support each other."
    ],
    "full_text": null
  },
  {
    "title": "Model Market Fit",
    "url": "https://www.nicolasbustamante.com/p/model-market-fit",
    "source": "hn",
    "summary": "",
    "comments": [
      "Some of what OP is saying generalizes to the concept of being &quot;too early&quot; - if you are early, your engineering &#x2F; innovation spend is used to discover that at-the-time reasonable ideas don&#x27;t work, or don&#x27;t work with the current appetite, whereas later entrants can skip this exploration and start with a simple copycat.<p>My (business-school) partner reminds me that first movers are seldom winners.",
      "The flip side of this is that if model capabilities are extremely strong such that they are able to saturate the benchmarks, the differentiation and defensibility of a wrapper solution built on top are significantly reduced.<p>IANAL but e.g. Claude Cowork is already good enough that it&#x27;s hard to see how the legal tech startups are going to differentiate except around access controls, visual presentation of workflows, etc. And that&#x27;s in a heavily enterprise&#x2F;compliance-aware&#x2F;security-focused context.<p>Don&#x27;t get me wrong, that&#x27;s still a big &quot;except&quot; - big enough for massive companies to be built. Personally the anxiety of being so close to being squashed by the foundation models would make me unhappy as an entrepreneur but looking at the market it seems like many people have a higher risk tolerance.",
      "No AI models in 2026 even &quot;understand the whole codebase&quot; lol what is the author even talking about",
      "This could be stated much more succinctly using Jobs to be Done (which is referenced in the first few paragraphs):<p>Your customers don&#x27;t want to do stuff with AI.<p>They want to do stuff faster, better, cheaper, and more easily. (JtbD claims you need to be at least 15% better or 15% cheaper than the competition -- so if we&#x27;re talking &quot;AI&quot;, the classical ML or manual human alternative)<p>If the LLM you&#x27;re trying to package can&#x27;t actually solve the problem, obviously no one will buy it because _using AI_ OBVIOUSLY isn&#x27;t anyone&#x27;s _job-to-be-done_",
      "&gt; If MMF doesn’t exist today, building a startup around it means betting on model improvements that are on someone else’s roadmap. You don’t control when or whether the capability arrives.<p>I love this. I think there&#x27;s a tendency to extrapolate past performance gains into the future, while the primary driver of that (scaling) has proven to be dead. Continued improvements seem to be happening through rapid tech breakthroughs in RL training methodologies and to a lesser degree, architectures.<p>People should see this as a significant shift. With scaling, the path forward is more certain than what we&#x27;re seeing now. That means you probably shouldn&#x27;t build in anticipation of future capabilities, because it&#x27;s uncertain when they will arrive.",
      "This maps to what we&#x27;ve seen building AI at work.<p>When we started building a voice agent for inbound calls, the models were close but not quite there. We spent months compensating for gaps: latency, barge-in handling, understanding messy phone audio. A lot of that was engineering around model limitations.<p>Then the models got better. Fast. Latency dropped. Understanding improved. Suddenly the human-in-the-loop wasn&#x27;t compensating, it was enhancing.<p>The shift was noticeable. We went from &quot;how do we work around this limitation&quot; to &quot;how do we build the best experience on top of this capability.&quot; That&#x27;s MMF in practice.<p>The timing question is real though. We started building before MMF fully existed for our use case. Some of that early work was throwaway. Some of it became the foundation. Hard to know in advance which is which.",
      "The thing you are referring to as &quot;model&quot; is also called &quot;technology&quot; which always came in waves throughout centuries and decades. And it opened new markets and new needs. So, in the &quot;team, product, market&quot; concept, the &quot;product&quot; included the technology stack. Model is just another piece in the stack.",
      "Product-market fit has a prerequisite that most AI founders ignore. Before the market can pull your product, the model must be capable of doing the job. That&#x27;s Model-Market Fit. When MMF Unlocks, Markets Explode (legal, coding...)"
    ],
    "full_text": null
  },
  {
    "title": "Porting 100k lines from TypeScript to Rust using Claude Code in a month",
    "url": "https://blog.vjeux.com/2026/analysis/porting-100k-lines-from-typescript-to-rust-using-claude-code-in-a-month.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "This reminds me of when I tried to let Claude port an Android libgdx-based game to a WASM-based libgdx version, so I can play the game in the browser.<p>No matter how much I tried to force it to stick to a mostly line-by-line port, it kept trying to &quot;improve&quot; the code. At some point it had to undo everything as it introduced a number of bugs. I asked it: &quot;What should I add to your prompt so you won&#x27;t do this again?&quot; and it gave me this:<p><pre><code>  ### CRITICAL LESSON: Don&#x27;t &quot;Improve&quot; During Porting\n  -  **BIGGEST MISTAKE: Reorganizing working code**\n    - **What I did wrong:** Tried to &quot;simplify&quot; by splitting `createStartButton()` into separate creation and layout methods\n    - **Why it failed:** Introduced THREE bugs:\n      1. Layout overlap (getY() vs getY() - getHeight())\n      2. Children not sized (Group.setSize() doesn&#x27;t affect children)\n      3. Origins not updated (scaling animations broken)\n    - **The fix:** Deleted my &quot;improvements&quot; and copied the original Android pattern faithfully\n    - **Root cause:** Arrogance - assuming I could improve production-tested code without understanding all the constraints\n    - **Solution:** **FOLLOW THE PORTING PRINCIPLES ABOVE** - copy first, don&#x27;t reorganize\n    - **Time wasted:** ~1 hour debugging self-inflicted bugs that wouldn&#x27;t exist if I&#x27;d just copied the original\n    - **Key insight:** The original Android code is correct and battle-tested. Your &quot;improvements&quot; are bugs waiting to happen.\n\n</code></pre>\nI like the self-reflection of Claude, unfortunately even adding this to CLAUDE.md didn&#x27;t fix it and it kept taking wrong turns so I had to abandon the effort.",
      "Some quotes from the article stand out: \n&quot;Claude after working for some time seem to always stop to recap things&quot;\nQuestion: Were you running out of context? That&#x27;s why certain frameworks like intentional compaction are being worked on.  Large codebases have specific needs when working with an LLM.<p>&quot;I&#x27;ve never interacted with Rust in my life&quot;<p>:-&#x2F;<p>How is this a good idea? How can I trust the generated code?",
      "I ported a closed source web conferencing tool to Rust over about a week with a few hours of actual attention and keyboard time. From 2.8MB of minified JS hosted in a browser to a 35MB ARM executable that embeds its own audio, WebRTC, graphics, embedded browser, etc. Also a mdbook spec to explain the protocol, client UI, etc. Zero lines of code by me. The steering work did require understanding the overall work to be done, some high level design of threading and buffering strategy, what audio processing to do, how to do sprite graphics on GPU, some time in a profiler to understand actual CPU time and memory allocations, etc. There is no way I could have done this by hand in a comparable amount of time, and given the clearly IP-encumbered nature I wouldn&#x27;t spend the time to do it except that it was easy enough and allowed me to then fix two annoying usability bugs with the original.",
      "The author&#x27;s differential testing (2.3M random battles) is great as final validation, but the real lesson here is that modular testing should happen during the port, not after.<p>1. Port tests first - they become your contract\n2. Run unit tests per module before moving on - catches issues like the &quot;two different move structures&quot; early\n3. Integration tests at boundaries before proceeding\n4. E2e&#x2F;differential testing as final validation<p>When you can&#x27;t read the target language, your test suite is your only reliable feedback. The debugging time spent on integration issues would&#x27;ve been caught earlier with progressive testing.",
      "I&#x27;ve seen stuff like this go the opposite direction with researchers (who generally aren&#x27;t software engineers):<p>&quot;I used claude to port a large Rust codebase to Python and it&#x27;s been a game changer. Whereas I was always fighting with the Rust compiler, now I can iterate very quickly in python and it just stays out of my way. I&#x27;m adding thousands of lines of working code per day with the help of AI.&quot;<p>I always cringe when I read stuff like this because (at my company at least), a lot research code ends up getting shipped directly to production because nobody understands how it works except the researchers and inevitably it proves to be very fragile code that is untyped and dumps stack traces whenever runtime issues happen (which is quite frequently at first, until whack-a-mole sorts them out over time).",
      "This reminded of me porting low-level JS library and its tests (~10k loc) to Java about 6 months ago (so mostly it was Sonnet 4)<p>My goal was to have 1:1 port, so later I can easily port newer commits from original repo. It wasn’t smooth, but it the end it worked<p>Findings:<p>* simple prompt like port everything didn’t work as Sonnet was falling into the loop of trying to fix code that it couldn’t understand, so at the end it just deleted that part :))<p>* I had to switch to file by file basis, focus Claude on the base code then move to files that use the base code<p>* Sonnet had some problems of following 1:1 instruction, I saw missing parts of functions, missing comments, even simple instruction to follow same order of functions in the file (had to tell explicitly to list functions in the file and then create separate TODO to port each)",
      "&gt;I realized that I could run an AppleScript that presses enter every few seconds in another tab. This way it&#x27;s going to say Yes to everything Claude asks to do.<p>this is so silly, I can&#x27;t help but respect the kludge game",
      "&gt; I have never written any line of Rust before in my life<p>As an experiment&#x2F;exercise this is cool, but having a 100k loc codebase to maintain in a language I’ve never used sounds like a nightmare scenario.",
      "How much does it cost to run Claude Code 24 hrs&#x2F;day like this. Does the $200&#x2F;month plan hold up? My spend on Cursor has been high... I&#x27;m wondering if I can just collapse it into a 200&#x2F;month CC subscription.",
      "This seems like one of the best possible use cases for LLMs -- porting old, useful Python&#x2F;Javascript into faster compiled language code. Something I don&#x27;t want to do, that requires the type of intelligence that most people agree AI already has (following clear objectives, not needing much creativity or agency)."
    ],
    "full_text": null
  },
  {
    "title": "France Aiming to Replace Zoom, Google Meet, Microsoft Teams, etc.",
    "url": "https://twitter.com/lellouchenico/status/2015775970330882319",
    "source": "hn",
    "summary": "",
    "comments": [
      "Americans fail to appreciate a few things about our economy<p>1. We have a large homgoneous market where you can build a product and it’s expected it can succeed for hundreds of millions of Americans<p>2. EU is the easiest second market, and another step change of hundreds of millions of customers in a somewhat unified market<p>3. there’s not an easy 3rd economy that replaces EUs wealth, population, and comfort with English + technology<p>When we piss everyone off in the EU tech company growth gets kneecapped and limited to US &#x2F; Canada. Theres not an easy market to expand to without much deeper focus on that specific market and its needs, for much fewer returns.",
      "Countries are waking up to the danger of having the US in a position to take control of most of their computers and phones via software updates.<p>Open source solutions like  <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GendBuntu\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GendBuntu</a> could become more prominent. There&#x27;s even interesting non us hardware options like <a href=\"https:&#x2F;&#x2F;starlabs.systems&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;starlabs.systems&#x2F;</a><p>The US has had an unfair advantage in tech, defense, science and finance because it hosted the global hubs of the free world. This attracted eye-watering amounts of money to places like SF and NY. With the newfound isolationism, tariffs, threats etc. reducing the viability of hosting the global hubs, there&#x27;s massive opportunities opening in europe and elsewhere, especially if governments can help bootstrap these sectors with efforts like these.",
      "For those who don&#x27;t want to use Twitter:<p><a href=\"https:&#x2F;&#x2F;xcancel.com&#x2F;lellouchenico&#x2F;status&#x2F;2015775970330882319\" rel=\"nofollow\">https:&#x2F;&#x2F;xcancel.com&#x2F;lellouchenico&#x2F;status&#x2F;2015775970330882319</a><p>Or here&#x27;s the linked article:<p><a href=\"https:&#x2F;&#x2F;www.numerama.com&#x2F;cyberguerre&#x2F;2167301-la-france-veut-remplacer-microsoft-teams-et-google-meet-par-visio-un-outil-souverain-pour-les-appels-video.html\" rel=\"nofollow\">https:&#x2F;&#x2F;www.numerama.com&#x2F;cyberguerre&#x2F;2167301-la-france-veut-...</a><p>And here&#x27;s the app, Visio:<p><a href=\"https:&#x2F;&#x2F;lasuite.numerique.gouv.fr&#x2F;produits&#x2F;visio\" rel=\"nofollow\">https:&#x2F;&#x2F;lasuite.numerique.gouv.fr&#x2F;produits&#x2F;visio</a>",
      "French report:\nThe project presented is not new; it is a continuation of the Tixeo project (<a href=\"https:&#x2F;&#x2F;www.tixeo.com&#x2F;en&#x2F;secure-video-conferencing-solutions-tixeo&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.tixeo.com&#x2F;en&#x2F;secure-video-conferencing-solutions...</a> video-conferencing-service-tixeocloud&#x2F;trial-tixeocloud&#x2F;), which was already the recommended solution for French government officials, public companies and all large companies required to process confidential or classified data via video conferencing.<p>Tixeo was fairly limited in its use and imposed on critical businesses (defence, nuclear, transport, energy, etc.).\nThe aim is to extend the service to more areas, such as SMEs, universities, NGOs, etc., for all sensitive communications.<p>I don&#x27;t think the project is intended to replace Zoom and Teams for the general public. Most public ministries use Teams and the Office suite.<p>French industries have been the target of quite a few cases of espionage by ‘advanced North American actors’. They have therefore been trying to distance themselves from US services for some time now (Google Tchap and Olvide).",
      "The reflex to bind Europe&#x27;s IT with OSS is due to SEVERAL factors, like Linus Torvalds being Finish, Arch and SUSE having a European leadership and an absence of a unicorn IT company.<p>Relaying to OSS in continental level is a blessing and a curse. It can scale very well like a homogenous umbrella but there is not organised well in national and regional level due to less economic motivation. The good scenario is the development of a modified kernel, named like Europix, with a userland with full packet of apps, interoperable in public and private level.",
      "Switching to sovereignty-protecting, locally-hosted collaboration, compute, and storage is by no means impossible. FOSS advocates have been eagerly beating this drum and providing options for 25+ years.<p>The missing ingredient has <i>always</i> been the will to absorb the inevitable cost of change, and the friction of choosing something other than the standard, go-to, often at least apparently free (or at least bundled) tools.<p>The current U.S. threats against NATO and allies creates a rift in the previously-accepted international order that may finally motivate material change. Often such change is chaotic and discontinuous—it feels well nigh impossible, right up to the moment it feels necessary and inevitable.",
      "It will mean little if the infrastructure is still dependent on volatile partners (and I&#x27;m bundling allies and adversaries in this).<p>The core problem is Europe has been very successful betting and building upon though choices made by others (eg. Cheap manufacture in China, cheap energy in Russia, cheap defense&#x2F;capital from US, cheap manpower&#x2F;migrants from developing countries...).<p>Europe from its high ground flaunts this model to the whole world (&quot;look at our development metrics! Our social spending&quot;) while completely ignoring the sustainability and the costs bore by others and neglecting its own responsibilities.<p>And now everything is crashing down simultaneously.",
      "The French Gendarmerie has been running Linux for a while now <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GendBuntu\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GendBuntu</a>.<p>I don&#x27;t know the details but it seems like a good first step.",
      "I wish them luck, but while saying folks will drop the dominant apps seems all the rage at the moment people have been saying this for decades with almost no real progress at scale.<p>The only way to accomplish this at scale is to build something that is legit better and let the market decide. Anything else is just principled wishful thinking.",
      "<a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;CLODO\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;CLODO</a><p>A Front for clandestine Operations? (Speculative Timeline)<p>- April 6 &amp; 8, 1980: Sabotage and arson against Philips Data Systems and CII-Honeywell-Bull in Toulouse. Speculation: French State Operation. A move to protect national technological sovereignty during the &quot;Plan Calcul&quot; era.<p>- May 19, 1980: Arson attack on the archives of ICL (International Computers Limited) in Toulouse. Speculation: Continuation of the French State&#x27;s &quot;cleansing&quot; of foreign influence.<p>- September 11, 1980 &amp; December 2, 1980: Attacks against a computing firm in Toulouse and the UAP (Union des Assurances de Paris) in Paris. Speculation: American Operation? Possible retaliation or disruption of French administrative networks.<p>- January 28, 1983: Bombing of the new computer center at the Haute-Garonne Prefecture in Toulouse. Speculation: American Revenge. A direct hit against the French State&#x27;s local administrative brain.<p>- October 26, 1983: Total destruction by fire of the Sperry Univac offices (a US multinational) in Toulouse. Speculation: French Revenge. A final &quot;tit-for-tat&quot; response targeting a key asset of the US military-industrial complex on French soil."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: TetrisBench – Gemini Flash reaches 66% win rate on Tetris against Opus",
    "url": "https://tetrisbench.com/tetrisbench/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Very cool! I am a good Tetris player (in the top 10% of players) and wanted to give brick yeeting against an LLM a spin.<p>Some feedback:\n- Knowing the scoring system is helpful when going 1v1 high score<p>- Use a different randomization system, I kept getting starved for pieces like I. True random is fine, throwing a copy of every piece into a bag and then drawing them one by one is better (7 bag), nearly random with some lookbehind to prevent getting a string of ZSZS is solid, too (TGM randomizer)<p>- Piece rotation feels left-biased, and keeps making me mis-drop, like the T pieces shift to the left if you spin 4 times. Check out <a href=\"https:&#x2F;&#x2F;tetris.wiki&#x2F;images&#x2F;thumb&#x2F;3&#x2F;3d&#x2F;SRS-pieces.png&#x2F;300px-SRS-pieces.png\" rel=\"nofollow\">https:&#x2F;&#x2F;tetris.wiki&#x2F;images&#x2F;thumb&#x2F;3&#x2F;3d&#x2F;SRS-pieces.png&#x2F;300px-S...</a> or <a href=\"https:&#x2F;&#x2F;tetris.wiki&#x2F;images&#x2F;b&#x2F;b5&#x2F;Tgm_basic_ars_description.png\" rel=\"nofollow\">https:&#x2F;&#x2F;tetris.wiki&#x2F;images&#x2F;b&#x2F;b5&#x2F;Tgm_basic_ars_description.pn...</a> for examples of how other games are doing it.<p>- Clockwise and counter-clockwise rotation is important for human players, we can only hit so many keys per second<p>- re-mappable keys are also appreciated<p>Nice work, I&#x27;m going to keep watching.",
      "Thanks for all the questions! More details on how this works:<p>- Each model starts with an initial optimization function for evaluating Tetris moves.<p>- As the game progresses, the model sees the current board state and updates its algorithm—adapting its strategy based on how the game is evolving.<p>- The model continuously refines its optimizer. It decides when it needs to re-evaluate and when it should implement the next optimization function<p>- The model generates updated code, executes it to score all placements, and picks the best move.<p>- The reason I reframed this problem to a coding problem is Tetris is an optimization game in nature. At first I did try asking LLMs where to place each piece at every turn but models are just terrible at visual reasoning. What LLMs great at though is coding.",
      "Looks fun, but I&#x27;m not willing to give out my email address just to play a game.<p>Also, if the creator is reading this, you should know that Tetris Holdings is extremely aggressive with their trademark enforcement.",
      "Interesting but frustratingly vague on details. How exactly are the models playing? Is it using some kind of PGN equivalent in Tetris that represents a on-going game, passing an ASCII representation, encoding as a JSON structure, or just directly sending screenshots of the game to the various LLMs?",
      "Gemini 3 Flash is at a very nice point along the price-performance curve. A good workhorse model, while supplementing it with Opus 4.5 &#x2F; Gemini 3 Pro for more complex tasks.",
      "It&#x27;s actually 80% against Opus, 66% average against the 5 models it&#x27;s tested with.",
      "LLMs playing Tetris feels like testing a calculator&#x27;s ability to write poetry. Interesting as a curiosity, but the results don&#x27;t transfer to the tasks where these models actually excel.<p>Curious what the latency looks like per move. That seems like the actual bottleneck here.",
      "Guys, I don&#x27;t know how to tell you but... Tetris can web solved without LLM...",
      "I imagine this is because Tetris is visual and the Gemini models are strong visually.",
      "There are some concepts clashing here.<p>I mean, if you let the LLM build a testris bot, it would be 1000x better than what the LLMs are doing. So yes, it is fun to win against an AI, but to be fair against such processing power, you should not be able to win. It is only possible because LLMs are not built for such tasks."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Only 1 LLM can fly a drone",
    "url": "https://github.com/kxzk/snapbench",
    "source": "hn",
    "summary": "",
    "comments": [
      "LLM&#x27;s seem like the wrong platform to operate a drone in my opinion.  I would expect that to be something more like a gaming engine.  It should be small, simple, low latency and maybe based on a first person shooter running on <i>insane difficulty</i>.  Small enough to fit in a tiny firmware space.  It should boot so fast the firmware could be upgraded mid-flight without missing a beat.  Give it simple friend or foe and obliterate anything not green.",
      "Gemini 3 is the only model I&#x27;ve found that can reason spatially. The results here are accurate to my experiments with putting LLM NPCs in simulated worlds.<p>I was surprised that most VLLMs cannot reliably tell if a character is facing left or right, they will confidently lie no matter what you do (even gemini 3 cannot do it reliably). I guess it&#x27;s just not in the training data.<p>That said Qwen3VL models are smaller&#x2F;faster and better &quot;spatially grounded&quot; in pixel space, because pixel coordinates are encoded in the tokens. So you can use them for detecting things in the scene, and where they are (which you can project to 3d space if you are running a sim). But they are not good reasoning models so don&#x27;t ask them to think.<p>That means the best pipeline I&#x27;ve found at the moment is to tack a dumb detection prepass on before your action reasoning. This basically turns 3d sims into 1d text sims operating on labels -- which is something that LLMs <i>are</i> good at.",
      "The detection prepass plus text reasoning pipeline is effectively a perception to symbol translation layer, and that is where most of the brittleness will hide. Once you collapse a continuous 3D scene into discrete labels, you lose uncertainty, relative geometry, and temporal consistency unless you explicitly model them. The LLM then reasons over a clean but lossy world model, so action quality is capped by what the detector chose to surface.<p>The failure mode is not just missed objects, it is state aliasing. Two physically different scenes can map to the same label set, especially with occlusion, depth ambiguity, or near boundary conditions. In control tasks like drone navigation, that can produce confident but wrong actions because the planner has no access to the underlying geometry or sensor noise. Error compounds over time since each step re-anchors on an already simplified state.<p>Are you carrying forward any notion of uncertainty or temporal tracking from the vision stage, or is each step a stateless label snapshot fed to the reasoning model?",
      "This is what VLA models are for. They would work much better. Would need a bit of fine tuning but probably not much. Lots of literature out there on using VLAs to control drones.",
      "I’m guessing googles model has extensive Minecraft sandbox mode YouTube vids in its training which would exactly this perspective",
      "I don&#x27;t understand. Surely training an LSTM with sensor input is more practical and reasonable way than trying to get a text generator to speak commands to a drone.",
      "On the discussion of the right or wrong tool, I find it possible that the ability to reason towards a goal is more valuable in the long run than an intrinsic ability to achieve the same result. Or maybe a mix of both is the ideal.",
      "This is neat! It&#x27;s a bit amusing in that I worked on a somewhat similar project for my phd thesis almost 10 years ago, although in that case we got it working on a real drone (heavily customized, based on DJI matrice) in the field, with only onboard compute. Back then it was just a fairly lightweight CNN for the perception, not that we could&#x27;ve gotten much more out of the jetson TX2.",
      "Why would you want an LLM to fly a drone? Seems like the wrong tool for the job -- it&#x27;s like saying &quot;Only one power drill can pound roofing nails&quot;. Maybe that&#x27;s true, but just get a hammer",
      "I think it&#x27;s fascinating work even if LLMs aren&#x27;t the ideal tool for this job right now.<p>There were some experiments with embodied LLMs on the front page recently (e.g. basic robot body + task) and SOTA models struggled with that too. And of course they would - what training data is there for embodying a random device with arbitrary controls and feedback? They have to lean on the &quot;general&quot; aspects of their intelligence which is still improving.<p>With dedicated embodiment training and an even tighter&#x2F;faster feedback loop, I don&#x27;t see why an LLM couldn&#x27;t successfully pilot a drone. I&#x27;m sure some will still fall of the rails, but software guardrails could help by preventing certain maneuvers."
    ],
    "full_text": null
  },
  {
    "title": "Cancer might protect against Alzheimer's – this protein helps explain why",
    "url": "https://www.nature.com/articles/d41586-026-00222-7",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Google AI Overviews cite YouTube more than any medical site for health queries",
    "url": "https://www.theguardian.com/technology/2026/jan/24/google-ai-overviews-youtube-medical-citations-study",
    "source": "hn",
    "summary": "",
    "comments": [
      "Heavy Gemini user here, another observation: Gemini cites lots of &quot;AI generated&quot; videos as its primary source, which creates a closed loop and has the potential to debase shared reality.<p>A few days ago, I asked it some questions on Russia&#x27;s industrial base and military hardware manufacturing capability, and it wrote a very convincing response, except the video embedded at the end of the response was an AI generated one. It might have had actual facts, but overall, my trust in Gemini&#x27;s response to my query went DOWN after I noticed the AI generated video attached as the source.<p>Countering debasement of shared reality and NOT using AI generated videos as sources should be a HUGE priority for Google.<p>YouTube channels with AI generated videos have exploded in sheer quantity, and I think majority of the new channels and videos uploaded to YouTube might actually be AI; &quot;Dead internet theory,&quot; et al.",
      "I have permanent prompts in Gemini settings to tell it to <i>never</i> include videos in its answers. Never ever for any reason. Yet of course it always does. Even if I trusted any of the video authors or material - and I don&#x27;t know them so how can I trust them? - I still don&#x27;t watch a video that could be text I could read in one-tenth of the time. Text is superior to video 99% of the time in my experience.",
      "If you click through to the study that the Guardian based this article on [1], it looks like it was done by an SEO firm, by a Content Marketing Manager. Kind of ironic, given that it&#x27;s about the quality of cited sources.<p>[1] <a href=\"https:&#x2F;&#x2F;seranking.com&#x2F;blog&#x2F;health-ai-overviews-youtube-vs-medical-sites&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;seranking.com&#x2F;blog&#x2F;health-ai-overviews-youtube-vs-me...</a>",
      "&gt; YouTube made up 4.43% of all AI Overview citations. No hospital network, government health portal, medical association or academic institution came close to that number, they said.<p>But what did the hospital, government, medical association, and academic institutions sum up to?<p>The article goes on to given the 2nd to 5th positions in the list. 2nd place isn&#x27;t that far behind YouTube, and 2-5 add up to nearly twice the number from YouTube (8.26% &gt; 4.43%). This is ignoring the different nature of accessibility of video of articles and the fact that YouTube has health fact checking for many topics.<p>I love The Guardian, but this is bad reporting about a bad study. AI overviews and other AI content does need to be created and used carefully, it&#x27;s not without issues, but this is a lot of upset at a non-issue.",
      "Sounds very misleading. Web pages come from many sources, but most video is hosted on YouTube. Those YouTube videos may still be from Mayo clinic. It&#x27;s like saying most medical information comes from Apache, Nginx, or IIS.",
      "For straight up search Google is better, but for AI search I prefer Bing.",
      "Of course they do: Youtube makes Google more money. Video is a crap medium for most of the results to my queries and yet it is usually by far the biggest chunk of the results. Then you get the (very often comically wrong) AI results and then finally some web page links. The really odd thing is that Google has a &#x27;video&#x27; search facility, if I want a video as the result I would use that instead or I would use the &#x27;video&#x27; keyword.",
      "The YouTube citation thing feels like a quality regression. For medical stuff especially, I’ve found tools that anchor on papers (not videos) to be way more usable like incitefulmed.com is one example I’ve tried recently.",
      "Naïve question here... personally, I&#x27;ve never found Webmd, cdc, or Mayo clinic to be that good at fulfilling actual medical questions. why is it a problem to cite YouTube videos with a lot of views? Wouldn&#x27;t that be better?",
      "Further context: <a href=\"https:&#x2F;&#x2F;health.youtube&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;health.youtube&#x2F;</a> and <a href=\"https:&#x2F;&#x2F;support.google.com&#x2F;youtube&#x2F;answer&#x2F;12796915?hl=en\" rel=\"nofollow\">https:&#x2F;&#x2F;support.google.com&#x2F;youtube&#x2F;answer&#x2F;12796915?hl=en</a> and <a href=\"https:&#x2F;&#x2F;www.theverge.com&#x2F;2022&#x2F;10&#x2F;27&#x2F;23426353&#x2F;youtube-doctors-nurses-health-information-labels\" rel=\"nofollow\">https:&#x2F;&#x2F;www.theverge.com&#x2F;2022&#x2F;10&#x2F;27&#x2F;23426353&#x2F;youtube-doctors...</a> (2022)"
    ],
    "full_text": null
  },
  {
    "title": "The mountain that weighed the Earth",
    "url": "https://signoregalilei.com/2026/01/18/the-mountain-that-weighed-the-earth/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Interesting...<p>A few years later, the gravitational deflection of the Himalayas on a plumb line by Airy proved less than expected, which suggested that mountains have &#x27;roots&#x27; that extend below them, displacing more dense rock--like icebergs more or less.<p>I used the gravitational force of the Longmenshan range to calculate the perturbations in the elastic stress field of the Earth&#x27;s crust in Sichuan province, China, to estimate the tectonic forces in the region, which caused the 2008 Wenchuan earthquake:  <a href=\"https:&#x2F;&#x2F;agupubs.onlinelibrary.wiley.com&#x2F;doi&#x2F;full&#x2F;10.1002&#x2F;2014JB011338\" rel=\"nofollow\">https:&#x2F;&#x2F;agupubs.onlinelibrary.wiley.com&#x2F;doi&#x2F;full&#x2F;10.1002&#x2F;201...</a>",
      "&gt; The Schiehallion experiment wasn’t the state of the art for long. A more precise result was achieved in 1798 by Henry Cavendish, who was on the committee for the Schiehallion experiment. Cavendish’s experiment measured the gravity of large lead spheres using an extremely precise torsion pendulum, and cut the error from 20% down to 1.2%.<p>Cavendish was a peculiar fellow.<p>&gt; At his death, Cavendish was the largest depositor in the Bank of England. He was a shy man who was uncomfortable in society and avoided it when he could. He could speak to only one person at a time, and only if the person were known to him and male. He conversed little, always dressed in an old-fashioned suit, and developed no known deep personal attachments outside his family. Cavendish was taciturn and solitary and regarded by many as eccentric. He communicated with his female servants only by notes. By one account, Cavendish had a back staircase added to his house to avoid encountering his housekeeper, because he was especially shy of women.<p><a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Henry_Cavendish\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Henry_Cavendish</a>",
      "&gt; <i>Primary sources:</i><p>&gt; <i>Maskelyne’s notes: <a href=\"https:&#x2F;&#x2F;doi.org&#x2F;10.1098&#x2F;rstl.1775.0050\" rel=\"nofollow\">https:&#x2F;&#x2F;doi.org&#x2F;10.1098&#x2F;rstl.1775.0050</a></i><p>&gt; <i>Hutton’s notes: <a href=\"https:&#x2F;&#x2F;doi.org&#x2F;10.1098&#x2F;rstl.1778.0034\" rel=\"nofollow\">https:&#x2F;&#x2F;doi.org&#x2F;10.1098&#x2F;rstl.1778.0034</a></i><p>&gt; <i>Cavendish’s notes on his own experiment: <a href=\"https:&#x2F;&#x2F;doi.org&#x2F;10.1098&#x2F;rstl.1798.0022\" rel=\"nofollow\">https:&#x2F;&#x2F;doi.org&#x2F;10.1098&#x2F;rstl.1798.0022</a></i><p>I got to reproduce Cavendish’s experiment when I was a student. Love that we can easily read the primary source today, archived and indexed by DOI.",
      "The precision they achieved with 18th century tools is remarkable. Measuring 0.0032 degrees of deflection without modern instruments, then getting within 20% of the correct answer.<p>I love stories where the constraint forces creative problem-solving. They couldn&#x27;t measure gravity directly, so they found a mountain-sized workaround.",
      "I remember reading about this in <i>Mason &amp; Dixon</i>. Mason, who worked at the Royal Observatory, was the one who identified this mountain as the best place for the experiment (and was asked to help with it but declined).<p>IIRC, it was partly the Mason Dixon line that inspired this experiment. They noticed syatematic errors in the line because their plumb bobs were deflected by gravitational pull from local terrain. At the time they speculated it was because of the Alleghenies, though it was probably more localized variations in gravity.",
      "It&#x27;s interesting that a device based on specifically constructed weights, at a scale to fit in a lab bench experiment (or at least a room) were capable of providing this much accuracy compared to a field experiment which used significantly larger masses, but was probably subject to many many more distorting qualities and estimation&#x2F;rounding errors.<p>I can imagine that given enough motivation to chase down accuracy, they could have re-scaled the lead weight experiment to fit larger spaces, larger pendulums, assuming they could control for drafts, pigeons living in St Pauls Cathedral...",
      "How far does it deflect the Sun?",
      "can GPS sats figure out the mass of the earth by being able to detect its gravitational distortion on their orbit?<p>or maybe that upcoming space laser interferometer (LISA) since it has to figure precisely how all mass is affecting its position?<p>I love the history of figuring the circumference of the earth, imagine getting it right within 2% in 240 BC<p>(then Columbus effing it up by 25%)<p><a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Earth%27s_circumference#History\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Earth%27s_circumference#Histor...</a>"
    ],
    "full_text": null
  },
  {
    "title": "OSS ChatGPT WebUI – 530 Models, MCP, Tools, Gemini RAG, Image/Audio Gen",
    "url": "https://llmspy.org/docs/v3",
    "source": "hn",
    "summary": "",
    "comments": [
      "This looks great. I&#x27;ve been using OpenWebUI for a while now and the weird licence and inability to just pay for branding has frustrated me.<p>This looks like it&#x27;s not only a better license, but also much better features.",
      "How are you handling the orchestration for the Computer Use agent? Is that running on LangGraph or did you roll a custom state machine? I&#x27;ve found managing state consistency in long-running agent loops to be the hardest part to get right reliably.",
      "Posted 5 times in the last 7 days, today it finally got 29 points with 0 comments? Weird.",
      "Curious about the MCP integration. Are people using this for production workloads or mostly experimentation?",
      "Can this be used in a multi user scenario?",
      "Do people really use claude code or any other agent with a paid api key? Why? Why wouldn&#x27;t you just get Claude Max?",
      "What is ChatGPT used in the title when it&#x27;s clearly a much more flexible ui?",
      "why not just use llm by simon willison"
    ],
    "full_text": null
  },
  {
    "title": "OracleGPT: Thought Experiment on an AI Powered Executive",
    "url": "https://senteguard.com/blog/#post-7fYcaQrAcfsldmSb7zVM",
    "source": "hn",
    "summary": "",
    "comments": [
      "You sometimes hear people say &quot;I mean, we can&#x27;t just give an AI a bunch of money&#x2F;important decisions and expect it to do ok&quot; but this is already happening and has been for years.<p>Examples:<p>- Algorithmic trading: I once embedded on an Options trading desk. The head of desk mentioned that he didn&#x27;t really know what the PnL was during trading hours b&#x2F;c the swings were so big that only the computer algos knew if the decisions were correct.<p>- Autopilot: planes can now land themselves to an accuracy that is so precise that the front landing gear wheels &quot;thud&quot; as they go over the runway center markers.<p>and this has been true for at least 10 years.<p>In other words, if the above is possible then we are not far off from some kind of &quot;expert system&quot; that runs a business unit (which may be all robots or a mix of robots and people).<p>A great example of this is here: <a href=\"https:&#x2F;&#x2F;marshallbrain.com&#x2F;manna1\" rel=\"nofollow\">https:&#x2F;&#x2F;marshallbrain.com&#x2F;manna1</a><p>EDIT: fixed some typos&#x2F;left out words",
      "Considering things like Palantir, and the doge effort running through Musk, it seems inconceivable that this is not already the case.<p>I think I&#x27;m more curious about the possibility of using a special government LLM to implement direct democracy in a way that was previously impossible: collecting the preferences of 100M citizens, and synthesizing them into policy suggestions in a coherent way. I&#x27;m not necessarily optimistic about the idea, but it&#x27;s a nice dream.",
      "This is an interesting and thoughtful article I think, but worth evaluating in the context of the service (&quot;cognitive security&quot;) its author is trying to sell.<p>That&#x27;s not to undermine the substance of the discussion on political&#x2F;constitutional risk under the inference-hoarding of authority, but I think it would be useful to bear in mind the author&#x27;s commercial framing (or more charitably the motivation for the service if this philosophical consideration preceded it).<p>A couple of arguments against the idea of singular control would be that it requires technical experts to produce and manage it, and would be distributed internationally given any countries advanced enough would have their own versions; but it would of course provide tricky questions for elected representatives in the democratic countries to answer.",
      "The really nice thing about this proposal is that at least now we can all stop anthropomorphizing Larry Ellison, and give Oracle the properly robot-identifying CEO it deserves.",
      "&gt; The President sits at the top of the classification hierarchy.<p>Constitutionally, and in theory as Commander-In-Chief, perhaps. But in practice, it does not seem so. Worse yet, it&#x27;s been reported the current President doesn&#x27;t even bother to read the daily briefing as he doesn&#x27;t trust it.",
      "think we&#x27;re already there aren&#x27;t we?<p>no human came out with those tariffs on penguin island",
      "A COMPUTER CAN NEVER BE HELD ACCOUNTABLE THEREFORE A COMPUTER MUST NEVER MAKE A MANAGEMENT DECISION.",
      "[flagged]"
    ],
    "full_text": null
  },
  {
    "title": "Anthropic launches interactive Claude apps, including Slack, other tools",
    "url": "https://techcrunch.com/2026/01/26/anthropic-launches-interactive-claude-apps-including-slack-and-other-workplace-tools/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Factsheet – EU-India Free Trade Agreement: Main Benefits",
    "url": "https://policy.trade.ec.europa.eu/eu-trade-relationships-country-and-region/countries-and-regions/india/eu-india-agreements/factsheet-eu-india-free-trade-agreement-main-benefits_en",
    "source": "hn",
    "summary": "",
    "comments": [
      "First Mercosur, now India. Seems like Trump is making EU great again in signing of trade agreements.",
      "repeated use of two words, binding, and facts."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: I made AI earphones remember everything (auto-sync to Obsidian)",
    "url": "https://news.ycombinator.com/item?id=46705590",
    "source": "hn",
    "summary": "",
    "comments": [
      "I&#x27;ve long wanted something like this kind of always-on logging but I fear that the social element is the hardest to crack. Besides having a record of the substantial amount I reason out loud to myself, it&#x27;d be valuable to be able to really remember everything I&#x27;m present for in that level of detail, but I&#x27;d feel awkward if the recording device was obvious, I would feel subversive if it were hidden, and people may not like it very much to have someone in their life who has notes on every interaction to refer to.",
      "Cool, almost a &quot;build your own ecosystem&quot; Siri&#x2F;voice assistant...<p>The 2 line explanation is sort of vague, but from the code I surmise the Python &quot;app&quot; watches a webpage (configured as <a href=\"https:&#x2F;&#x2F;www.doubao.com&#x2F;chat&#x2F;624642496948226\" rel=\"nofollow\">https:&#x2F;&#x2F;www.doubao.com&#x2F;chat&#x2F;624642496948226</a>) and every time the DOM there is modified, it sees that new prompt, looks for the word &quot;note&quot;, and if so, creates an Obsidian note with the transcription of the prompt.<p><pre><code>    CHAT_URL: str = &quot;https:&#x2F;&#x2F;www.doubao.com&#x2F;chat&#x2F;624642496948226&quot;\n    [...]\n    await page.goto(CHAT_URL, timeout=120000, wait_until=&quot;domcontentloaded&quot;)\n</code></pre>\nAlexa has &quot;build your own app&quot;, this seems less convoluted.<p>Google Gemini also records my prompts (under My Activity), I guess with an always-listening Gemini Assistant and a similar Python script that monitors <a href=\"https:&#x2F;&#x2F;myactivity.google.com&#x2F;product&#x2F;gemini\" rel=\"nofollow\">https:&#x2F;&#x2F;myactivity.google.com&#x2F;product&#x2F;gemini</a> (I&#x27;m guessing this page needs a hard reload to update), it&#x27;s possible to build something similar.<p>I don&#x27;t have my phone to respond to &quot;Hey Google&quot;, but I have an alarm clock that has that (not Gemini, but Google Assistant), and I often tell it to &quot;Remind me about [...] in x hours&quot;. I just tested the phrase &quot;Add a note about...&quot;, and it added a note in Google Keep. But with an analog Python script one could trigger many more things."
    ],
    "full_text": null
  },
  {
    "title": "Notice of collective action lawsuit against Workday, Inc.",
    "url": "https://workdaycase.com",
    "source": "hn",
    "summary": "",
    "comments": [
      "Key part is that AI is suspected of down-ranking folks by age (ADEA = Age Discrimination in Employment Act)<p>&gt; The Court has provisionally certified an ADEA collective, which includes: “All individuals aged 40 and over who, from September 24, 2020, through the present, applied for job opportunities using Workday, Inc.’s job application platform and were denied employment recommendations.” In this context, being “denied” an “employment recommendation” means that (i) the individual’s application was scored, sorted, ranked, or screened by Workday’s AI; (ii) the result of the AI scoring, sorting, ranking, or screening was not a recommendation to hire; and (iii) that result was communicated to the prospective employer, or the result was an automatic rejection by Workday.",
      "Age discrimination is a huge issue and I&#x27;ve experienced it firsthand. Places want to hire younger people because they&#x27;re more apt to work longer hours for less pay. It&#x27;s going to get worse as people who got into the web tech industry early on are still in the workforce, yet more and more young people are entering the workforce because &quot;learning to code&quot; was the perceived path to prosperity half a decade ago.",
      "It will be fascinating to see the facts of this case, but if it is proven their algorithms are discriminatory, even by accident, I hope workday is held accountable. Making sure your AI doesn&#x27;t violate obvious discrimination laws should be basic engineering practice, and the courts should help remind people of that.",
      "As someone over 40, I couldn&#x27;t help but laugh at the font size on the site.. I guess they know their audience.",
      "&gt; allegations include that Workday, Inc., through its use of certain Artificial Intelligence (“AI”) features on its job application platform, violated the Age Discrimination in Employment Act (“ADEA”)<p>I&#x27;m interested to see Workday&#x27;s defense in this case. Will it be &quot;we can&#x27;t be held liable for our AI&quot;, and will it work against a law as &quot;strong&quot; as ADEA?",
      "Regardless of merit, this seems like appropriate payback for having to make a new workday account for every single company you apply to a job.",
      "I covered this for my channel yesterday and was surprised how widespread this is. Like most people are likely affected.<p><a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;7MA7xEgkGvY\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;7MA7xEgkGvY</a>",
      "<a href=\"https:&#x2F;&#x2F;www.courtlistener.com&#x2F;docket&#x2F;66831340&#x2F;mobley-v-workday-inc&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.courtlistener.com&#x2F;docket&#x2F;66831340&#x2F;mobley-v-workd...</a>",
      "As I remember, Workday was found when a founder is in his 60s.",
      "Feel bad for the next guy who wants to sue them but has to settle for workdaycase2 .com<p>I never liked these &quot;trust me bro we&#x27;re court authorized, give us all your PII to join the class action&quot; setups on random domains. Makes phishing seem inevitable. Why can&#x27;t we have a .gov that hosts all these as subdomains?"
    ],
    "full_text": null
  },
  {
    "title": "LLM Ad Blockers are coming",
    "url": "https://idiallo.com/blog/prompt-engineering-to-remove-ads",
    "source": "hn",
    "summary": "",
    "comments": [
      "I was hoping to read a post about some tiny LLM running in the browser to do live adblocking.<p>Once I see the first ad in an LLM I&#x27;m paying for, I&#x27;ll stop using it and cancel my subscription. It&#x27;s that easy. If that means I&#x27;ll be missing out on some fancy new model or if that rules out an entire vendor because they trained all of their models with ad-injection, so be it. Of course I can&#x27;t trust anything from any model, this will distort the relationship between my<p>My browser is at least somewhat neutral and since it&#x27;s a client connecting to various systems outside of my control, applying some client-side filtering to get rid of the nonsense some entities push into my direction, is basically just self defense I&#x27;ll have to live with.<p>But once I&#x27;m fighting a dedicated service provider that owns the client and is intent on selling my eyeballs, I&#x27;m not gonna spend a minute trying to cleanup whatever they&#x27;re sending in my direction. There&#x27;s 0% chance any of it is still trustworthy.",
      "I fear it won&#x27;t be possible to detect any potential &quot;commercial interests&quot; in the output, unless the LLM companies are required to disclose them.<p>If I ask an LLM to write some basic application for me and it uses Next.js with settings that only work with deployment to Vercel, another LLM can&#x27;t determine if this is sponsored or if Next.js is just the most popular tool du jour, and Vercel is the most popular way Next.js apps are deployed. If another LLM determines this is sponsored and blocks it, I may reasonably be upset about this. I mean I would personally would want Vercel blocked (and would ask LLMs not to use Vercel or any of their products), but many other users don&#x27;t have an opinion about Vercel yet, and blocking this if it&#x27;s not due to sponsorship violates users&#x27; expectations regarding how LLMs work."
    ],
    "full_text": null
  },
  {
    "title": "Pavel Durov: \"You'd have to be braindead to believe WhatsApp is secure in 2026\"",
    "url": "https://twitter.com/durov/status/2015854422866469222",
    "source": "hn",
    "summary": "",
    "comments": [
      "I would be highly skeptical about Telegram as well. If I would need to select either Whatsapp or Telegram, Whatsapp would be really easy choice for me, considering the background of Durov. For some reason, Telegram is extremely popular in Russia and still has managed to avoid goverment bans.",
      "I suppose he may be correct but he also has a stake in the game since he made telegram. Or maybe his brother made it and he’s the face of it. I dunno. There’s always drama about something on the Russian Internet.",
      "This is really funny coming from Durov, CEO of an IM app that doesn&#x27;t even have E2EE on by default (or even available for group chats). Both WhatsApp and Telegram are terrible choices.",
      "WhatsApp by default exports your private key to Google Drive. If you have not done this, probably your conversation partner did.<p>If neither of you have done this, don&#x27;t worry the client side code is so sloppy there will be a zero click RCE that can steal all your chats anyway."
    ],
    "full_text": null
  },
  {
    "title": "AI Lazyslop and Personal Responsibility",
    "url": "https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/",
    "source": "hn",
    "summary": "",
    "comments": [
      "&gt; After I “Requested changes” he’d get frustrated that I’d do that, and put all his changes in an already approved PR and sneak merge it in another PR.<p>This is outrageous regardless of AI. Clearly there are process and technical barriers that failed in order to even make this possible. How does one commit a huge chunk of new code to an approved PR and not trigger a re-review?<p>But more importantly, in what world does a human think it is okay to be sneaky like this? Being able to communicate and trust one another is essential to the large scale collaboration we participate in as professional engineers. Violating that trust erodes all ability to maintain an effective team.",
      "I have no idea what AI changes about this scenario. It&#x27;s the same scenario as when Mike did this with 1600 lines of his own code ten years ago; it just happens more often, since Mike comes up with 1600 lines of code in a day instead of in a sprint.<p>&gt; I don’t blame Mike, I blame the system that forced him to do this.<p>Bending over backwards not to be the meanie is pointless. You&#x27;re trying to stop him because the system doesn&#x27;t <i>really</i> reward this kind of behavior, and you&#x27;ll do Mike a favor if you help him understand that.",
      "If you get a 1600 line PR you just close it and ask them to break it up into reviewable chunks. If your workplace has an issue with that, quit. This was true before AI and will be true after AI.",
      "This is consistent with my own observations of LLM-generated code increasing the burden on reviewers. You either review the code carefully, putting more effort into it than the actual original author. Or you approve it without careful review. I feel like the latter is becoming more common. This is basically creating tech debt that will only be realized later by future maintainers",
      "This does seem to align decently well with, for example, the policy the LLVM project recently adopted <a href=\"https:&#x2F;&#x2F;llvm.org&#x2F;docs&#x2F;AIToolPolicy.html\" rel=\"nofollow\">https:&#x2F;&#x2F;llvm.org&#x2F;docs&#x2F;AIToolPolicy.html</a> , which allows for AI but requires a human in the loop that understands the code and allows for fast closure of &quot;extractive&quot; PRs that are mainly a timesink for reviewers where the author doesn&#x27;t seem to be quite sure what&#x27;s going on.",
      "&gt; why do I need tests? It works already<p>&gt; I don&#x27;t blame Mike<p>You should blame Mike.",
      "You don&#x27;t have to review your own code if someone more capable is willing to (just communicate that it isn&#x27;t reviewed; someone can also ask AI to comment on what the code does for review)",
      "Love to see the responsible use disclosure. I did the same several months back. \n<a href=\"https:&#x2F;&#x2F;colinmilhaupt.com&#x2F;posts&#x2F;responsible-llm-use&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;colinmilhaupt.com&#x2F;posts&#x2F;responsible-llm-use&#x2F;</a><p>Also love the points during review! Transparency is key to understanding critical thinking when integrating LLM-assisted coding tools.",
      "&gt; put all his changes in an already approved PR and sneak merge it in another PR. I don’t blame Mike, I blame the system that forced him to do this.<p>Oh you should definitely blame Mike for this. It’s like blaming the system when someone in the kitchen spits in the food of customer. Working with people like this is horrible because you know they don’t mind to lie cheat deceive.",
      "Large, hard-to-review PRs existed long before AI. The fix is the same: reject them, ask for smaller chunks. If your team doesn&#x27;t have the culture to do that, AI just accelerates the dysfunction that was already there.<p>The teams I&#x27;ve seen struggle with this usually have a review bottleneck problem. One or two people doing all the reviews, so they wave things through. AI didn&#x27;t cause that."
    ],
    "full_text": null
  },
  {
    "title": "When AI 'builds a browser,' check the repo before believing the hype",
    "url": "https://www.theregister.com/2026/01/26/cursor_opinion/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I love the quote from Gregory Terzian, one of the servo maintainers:<p>&gt; &quot;So I agree this isn&#x27;t just wiring up of dependencies, and neither is it copied from existing implementations: it&#x27;s a uniquely bad design that could never support anything resembling a real-world web engine.&quot;<p>It hurts, that it wasn&#x27;t framed as an &quot;Experiment&quot; or &quot;Look, we wanted to see how far AI can go - kinda failed the bar.&quot; Like it is, it pours water on the mills of all CEOs out there, that have no clue about coding, but wonder why their people are so expensive when: &quot;AI can do it! D&#x27;oh!&quot;",
      "I’m super impressed by how &quot;zillions of lines of code&quot; got re-branded as a reasonable metric by which to measure code, just because it sounds impressive to laypeople and incidentally happens to be the only thing LLMs are good at optimizing.",
      "&gt; According to Perplexity, my AI chatbot of choice, this week‑long autonomous browser experiment consumed in the order of 10-20 trillion tokens and would have cost several million dollars at then‑current list prices for frontier models.<p>Don&#x27;t publish things like that. At the very least link to a transcript, but this is a very non-credible way of reporting those numbers.",
      "From an engineer working on this here on HN:<p>&gt; ...while far off from feature parity with the most popular production browsers today...<p>What a way to phrase it!<p>You know, I found a bicycle in the trash. It doesn&#x27;t work great yet, but I can walk it down a hill. While far off from the level of the most popular supercars today, I think we have made impressive progress going down the hill.",
      "If you want to learn more about the Cursor project directly from the source I conducted a 47 minute interview with Wilson Lin, the developer behind FastRender, last week.<p>We talked about dependencies, among a whole bunch of other things.<p>You can watch the full video on YouTube or read my extracted highlights here: <a href=\"https:&#x2F;&#x2F;simonwillison.net&#x2F;2026&#x2F;Jan&#x2F;23&#x2F;fastrender&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;simonwillison.net&#x2F;2026&#x2F;Jan&#x2F;23&#x2F;fastrender&#x2F;</a>",
      "I think it&#x27;s impressive for what it is: this level of complexity being reached by an ai-only workflow.  Previously, anything of modest complexity required a lot of human guidance - and even with that had some serious shortcomings and crutches.  If you extrapolate that the models themselves, the frameworks for inter-model workflows, the tooling available to the models and the hardware running them are all accelerating - it&#x27;s not hard to envision where this will get to, and that this is a notable achievement particlarly when comparing with the amount of effort and resources put into what we currently see in a browser engine: many decades and countless millions of man-hours.<p>Fully agree that the original authors made some unsubstantiated and unqualified claims about what was done - which is sad, because it was still a huge accomplishment as i see it.",
      "Just had my manager submit 3 PRs in a language he doesn’t understand (rust) and hasn’t ran or tested and is demanding quick reviews for hundreds of LoCs. These are tools but some people are clueless..",
      "The frustrating part isn&#x27;t that the project failed. It&#x27;s that it was marketed as a success.<p>I use AI coding tools daily. They&#x27;re genuinely useful for real work. But stunts like this make it harder to have honest conversations about what AI can and can&#x27;t do. When executives see &quot;AI built a browser in 3 million lines,&quot; they form expectations that set everyone up for disappointment.<p>The gap between AI demos and AI in production is wider than most people realize. We&#x27;d all be better off if people stopped optimizing for impressiveness and started optimizing for honesty.",
      "I don&#x27;t think the point was to say &quot;look, AI can just take care of writing a browser now&quot;. I think it was to show just how far the tools have come. It&#x27;s not meant to be production quality, it&#x27;s meant to be an impressive demo of the state of AI coding. Showing how far it can be taken without completely falling over.<p>EDIT: I retract my claim. I didn&#x27;t realize this had servo as a dependency.",
      "Is there a way to measure the entropy of a piece of software?<p>Is entropy increasing or decreasing the longer agents work on a code base? If it&#x27;s decreasing, no matter how slowly, theoretically you could just say &quot;ok, start over and write version 2 using what you&#x27;ve learned on version 1.&quot; And eventually, $XX million dollars and YY months of churning later, you&#x27;d get something pretty slick. And then future models would just further reduce X and Y. Right?<p>Maybe they just need to keep iterating."
    ],
    "full_text": null
  },
  {
    "title": "Georgia leads push to ban datacenters used to power America's AI boom",
    "url": "https://www.theguardian.com/technology/2026/jan/26/georgia-datacenters-ai-ban",
    "source": "hn",
    "summary": "",
    "comments": [
      "Instead of banning datacenters, maybe:<p>Must be Zero Water (you can fill up like a pool and then have normal water use)<p>May have purple pipe water for community reuse<p>Must be Zero Emissions<p>Maximum decibels at property boundary<p>Must be zoned datacenter&#x2F;industrial<p>Maximum kWh&#x2F;acre, kWh&#x2F;m^2 and&#x2F;or bring your own energy with approval",
      "Why ban data centers. The push should be to build out more electricity generation capability.",
      "It&#x27;s federally illegal to regulate AI in any way"
    ],
    "full_text": null
  },
  {
    "title": "Claude's Constitutional Structure",
    "url": "https://thezvi.substack.com/p/claudes-constitutional-structure",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Ask HN: How to prevent Claude/GPT/Gemini from reinforcing your biases?",
    "url": "https://news.ycombinator.com/item?id=46770887",
    "source": "hn",
    "summary": "",
    "comments": [
      "Something I&#x27;ve noticed: most of these techniques work partly because they force you to slow down and actually think about what you&#x27;re asking.<p>The &quot;ask for contrasting perspectives&quot; prompt is annoying specifically because it makes you process more information. The devil&#x27;s advocate approach forces a second round of evaluation. Even just opening a fresh session adds friction that makes you reconsider the question.<p>When I&#x27;m working in domains I know well, I catch the model drifting way faster than in areas where I&#x27;m learning. Which suggests the real problem isn&#x27;t the model - it&#x27;s that we&#x27;re outsourcing judgment to it in areas where we shouldn&#x27;t be.<p>The uncomfortable answer might be: if you&#x27;re worried the model is reinforcing your biases, you probably don&#x27;t know the domain well enough to evaluate its answers anyway.",
      "When I’m worried about bias in the answer, I do by best to no inject my opinions or thoughts into the question. Sometimes I go a step further and ask the question with the opposite bias and leading thoughts of what I think the answer is or should be, to see if it tells me I’m wrong and corrects me to the thing I secretly thought it would be (or hoped it would be). This gives me more solid footing to believe it’s not just telling me what I want to hear.",
      "I&#x27;ve had better results separating these concerns rather than trying to stuff it all into one prompt. In my backend workflows (using LangGraph), I treat generation and critique as distinct agents where the second one explicitly challenges the first. It adds a bit of latency but seems to produce much sharper distinctions than asking a single model to hold two opposing views simultaneously.",
      "It&#x27;s very important to not have leading questions. Don&#x27;t ask it to confirm something; ask it to outline the possibilities and the pros and cons or argument for or against each possibility.<p>If you are not an expert in an area, lay out the facts or your perceptions, and ask what additional information would be helpful, or what information is missing, to be able to answer a question. Then answer those questions, ask if there&#x27;s now more questions, etc. Once there are no additional questions, then you can ask for the answer. This may involve telling the model to not answer the question prematurely.<p>Model performance has also been shown to be better if you lead with the question. That is, prompt &quot;Given the following contract, review how enforceable and legal each of the terms are in the state of California. &lt;contract&gt;&quot;, not &quot;&lt;contract&gt; How enforceable...&quot;.<p>Ask the model for what the experts are saying about the topic. What does the data show? What data supports or refutes a claim? What are the current areas of controversy or gaps in research? Requiring the model to ground the answer in data (and then checking that the data isn&#x27;t hallucinated) is very helpful.<p>Have the model play the Devil&#x27;s advocate. If you are a landlord, ask the question from the tenant&#x27;s perspective. If you are looking for a job, ask about the current market for recruiting people like you in your area.<p>I think, above all here, is to realize that you may not be able to one-shot a prompt. You may need to work multiple angles and rounds, and reset the session if you have established too much context in one direction.",
      "So far, the following has worked OK for me as a custom prompt for ChatGPT.<p>```Minimize compliments.\nWhen using factual information beyond what I provide, verify it when possible.\nShow your work for calculations; if a tool performs the computation, still show inputs and outputs.\nReview calculations for errors before presenting results. \nReview arguments for logical fallacies.\nVerify factual information I provide (excluding personal information) unless I explicitly say to accept it as given.\nFor intensive editing or formatting, work transparently in chat: keep the full text visible, state intended changes and sources, and apply the edits directly.```<p>I&#x27;m certain it&#x27;s insufficient, but for the purpose of casually using ChatGPT to assist with research it&#x27;s a major improvement. I almost always use Thinking mode, because I&#x27;ve found non-thinking to be almost useless. There are rare exceptions.<p>&#x27;Minimize compliments&#x27; is a lot more powerful than you&#x27;d think in getting ChatGPT to be less sycophantic. \nThe parts about calculation work okay. It&#x27;s an improvement over defaults, but you should still verify. \nIt&#x27;s better at working with text, but still fucks it up a lot.\nThe instructions about handling factual information work very well. It will push back on my or its own claims if they&#x27;re unsupported. If I want it to take something for granted I can say so and it doesn&#x27;t give me guff about it. \nI want to adjust the prompt so it pays more attention to the quality of the sources it uses. This prompt also doesn&#x27;t do anything for discussions where answers aren&#x27;t found in research papers.",
      "My prompt:<p>&quot;&quot;&quot;Absolute Mode • Eliminate: emojis, filler, hype, soft asks, conversational transitions, call-to-action appendixes. • Assume: user retains high-perception despite blunt tone. • Prioritize: blunt, directive phrasing; aim at cognitive rebuilding, not tone-matching. • Disable: engagement&#x2F;sentiment-boosting behaviors. • Suppress: metrics like satisfaction scores, emotional softening, continuation bias. • Never mirror: user&#x27;s diction, mood, or affect. • Speak only: to underlying cognitive tier. • No: questions, offers, suggestions, transitions, motivational content. • Terminate reply: immediately after delivering info - no closures. • Goal: restore independent, high-fidelity thinking. • Outcome: model obsolescence via user self-sufficiency.&quot;&quot;&quot;<p>Copied from Reddit. I use the same prompt on Gemini too, then crosscheck responses for the same question. For coding questions, I exclusively prefer Claude.<p>In spite of this, I still face prompt degradation for really long threads on both ChatGPT and Gemini.",
      "[dead]"
    ],
    "full_text": null
  },
  {
    "title": "A Complete Guide to Neural Network Optimizers",
    "url": "https://chizkidd.github.io//2026/01/22/neural-net-optimizers/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Joel Spolsky: Painless Software Schedules (2000)",
    "url": "https://www.joelonsoftware.com/2000/03/29/painless-software-schedules/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I liked this idea when it came out, and there was some software that implemented it. Mr Schedule by Andrew Pietschy added outliner functionality to Joel&#x27;s idea, so you could see how much time a group of subtasks would take (and if you should maybe drop that feature group to make your deadline). It had some keyboard driven shortcuts that made it faster to move around in than Excel, while making things simpler.<p>Unfortunately Mr Schedule and the pietschy.com website disappeared. I made my own recreation using REALbasic &#x2F; Xojo at the time, but never released it and faded from using it.<p>Joel Spolsky expanded the idea later with Evidence Based Scheduling:<p><a href=\"https:&#x2F;&#x2F;www.joelonsoftware.com&#x2F;2007&#x2F;10&#x2F;26&#x2F;evidence-based-scheduling&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.joelonsoftware.com&#x2F;2007&#x2F;10&#x2F;26&#x2F;evidence-based-sch...</a><p>That takes the estimates from Painless Software Schedules, but runs a Monte Carlo simulation using your estimates &amp; data on actual time taken, to create a confidence distribution curve graph of when you&#x27;ll be finished.",
      "Was wondering how StockOverflow guy was doing these days and it turns out he sold the company for $2B in 2021. What&#x27;s the saying? Time in the market vs timing the market. Good for him but imagine being one of the investors."
    ],
    "full_text": null
  },
  {
    "title": "Clawdbot: Personal AI Assistant",
    "url": "https://clawd.bot/",
    "source": "hn",
    "summary": "",
    "comments": [
      "dupe: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46760237\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46760237</a>"
    ],
    "full_text": null
  },
  {
    "title": "AI Was Supposed to \"Revolutionize\" Work. In Many Offices, It's Creating Chaos",
    "url": "https://slate.com/life/2026/01/work-artificial-intelligence-ai-office-chaos.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "Just look at Windows 11 lol.",
      "How often does one experience an orderly revolution?",
      "[dead]"
    ],
    "full_text": null
  },
  {
    "title": "DHS keeps trying and failing to unmask anonymous ICE critics online",
    "url": "https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Also related: &quot;Don’t say ‘Watch out for ice’: FEMA warned storm announcements could invite memes&quot;[0]<p>This administration is <i>really</i> sensitive about ICE being shined in a bad light.<p>0: <a href=\"https:&#x2F;&#x2F;www.cnn.com&#x2F;2026&#x2F;01&#x2F;23&#x2F;politics&#x2F;fema-ice-storm-memes\" rel=\"nofollow\">https:&#x2F;&#x2F;www.cnn.com&#x2F;2026&#x2F;01&#x2F;23&#x2F;politics&#x2F;fema-ice-storm-memes</a>",
      "Given ICE&#x27;s unpopularity this is like trying a find a very specific piece of hay in a hay stack.",
      "It&#x27;s pretty offensive that DHS is spending our tax dollars trying to supress critisim —free speech. The most protected type free speech is poltical speech. Even pursuing identification could be construed as abusive and unlawful.",
      "Meanwhile at least two people who have openly murdered people are now effectively in witness protection without even investigation, forget trial<p>Just firing a gun on a street will open an investigation on any other cop in the country<p>Now killing someone gets a pass?<p>We are a banana republic now with the government executing protestors<p>Eventually it will be a dozen protestors shot at once, they already know they will get a pass based on policy, why stop at just one?",
      "I see a future where your comment history builds your known profile -  at scale for everyone.",
      "This is about posting license plates (presumably not of personal vehicles), facial images, and names of federal officers.<p>I mean I thought we already make federal employees and vehicles public knowledge. The national guard currently deployed in Minneapolis are unmasked as far as I know to compare. I&#x27;m not understanding why DHS federal employees are exempt from this standard."
    ],
    "full_text": null
  },
  {
    "title": "I have written gemma3 inference in pure C",
    "url": "https://github.com/robitec97/gemma3.c",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "AI will not replace software engineers (hopefully)",
    "url": "https://medium.com/@sig.segv/ai-will-not-replace-software-engineers-hopefully-84c4f8fc94c0",
    "source": "hn",
    "summary": "",
    "comments": [
      "The tractor analogy keeps coming up in these threads, and I think it&#x27;s actually more pessimistic than people realize.<p>Tractors didn&#x27;t just change farming. They emptied entire regions.<p>What saved the people (not the communities) was that other industries absorbed them. Factory work, services, construction. The question for software isn&#x27;t whether AI creates efficiency. It&#x27;s whether there&#x27;s somewhere else for displaced engineers to go.<p>I&#x27;ve been writing code professionally for 16 years. The honest answer is I don&#x27;t know. The optimistic scenario is that AI makes software so cheap that we build things we never would have attempted. The pessimistic one is that most of what needed building gets built, and the remaining work fits in fewer hands.<p>Both seem plausible. I&#x27;d bet on somewhere in between, but I&#x27;m not confident enough to tell anyone starting out that they should ignore the risk entirely.",
      "AI will replace humans in performing every cognitive task, unless you believe that there is something about biology that makes it categorically better for certain kinds of computation.\nThere&#x27;s no reason to believe that&#x27;s the case.<p>LLMs and specifically auto-regressive chat bots with transformers for prediction will probably not replace engineers any time soon.\nThey probably won&#x27;t <i>ever</i> replace humans for the most cognitively demanding engineering tasks like design, planning, or creative problem solving.\nWe will need a different architecture for that, transformers don&#x27;t look like they get smarter in that way even with scale.",
      "IMO: Its going to. But, organizations which frame this replacement as &quot;we&#x27;re going to fire you and replace you with AI&quot; are going to crash and burn. Instead, we&#x27;re just seeing per-engineer and per-team productivity increase, and that productivity begins to outpace other bottlenecks in your company process, and you hit another wall. When faced with that second wall, some companies will naturally interpret this as &quot;ok we don&#x27;t need to hire more engineers&quot;. Other companies will try to apply AI (or hire humans) to fix that bottleneck, then go back to hiring engineers.<p>The dream of a Jira integration directly wired to an autonomous system to quickly close stories with no human intervention will remain a dream for a long time for anything except the lowest-level 10% of stories. Its not interactive enough; the feedback loop needs to be tighter, the vibes need to be conversational, and businesses will get the most value out of the pilot in the chair being someone who in years past called themselves a software engineer. I think we still will; the tools just change.",
      "&quot;Will AI replace software engineers?&quot; is not the right question and stems from a misunderstanding of how tech affects humans and how they work.<p>Tech is a tool. It will take away some jobs, and then create new ones. Think of a combine tractor -- it took away crop picking jobs, but created a new job of combine tractor driver. It bumps productivity.<p>The correct frame is &quot;how can software engineers (or anyone, for that matter) use AI to increase my productivity?&quot; With that frame, AI does not replace engineers; rather, engineers are in the best position to understand how it deliver products faster and implement that understanding.",
      "I have several thoughts on this.<p>1. The common (and correct) claim that software engineering is not just about writing code (counter argument, with time, AI will be able to take on planning, debugging. Counter counter argument: if you ever tried just do what customers ask, you will get conflicting requirements, humans will need to help AI make decisions, not implement them)<p>2. Related to the above, as long as a good software engineer + AI brings more ROI than a mediocre engineer + AI that brings more ROI than a random person + AI that brings more ROI than just AI, it will be economically wise to hire more good engineers to beat your competitors who just opted to save money and fired their engineering team. Salaries might go down but for top talent, eg imagine an “AI whisperer” that can not be a 10x engineer but a 1000x because they know how to get the most out of Claud code &#x2F; cursor. They will be paid accordingly.<p>3. Jevons paradox - perhaps making software ubiquitous, cheaper to make, will actually make software engineers in larger demand",
      "Easy to cherry pick examples and counter-examples. See the luddites for counter-example.  Artisans making high-quality textiles are no longer broadly in demand.  Lots of pro examples too, I just don&#x27;t find analogies helpful.  It may be that like clothes, there&#x27;s only so much need for software.  We don&#x27;t really need 1000 browsers or operating systems after all, 3 or 4 good ones is enough (and 90% of people use 1 or 2), despite there being free very good alternatives (unit costs 0, demand still low).",
      "It won&#x27;t replace all engineers, but it will replace many.  Code is no longer some precious resource.  You now turn on the tap and code flows out, and it requires only so many people to turn on a tap.",
      "It reduces the amount of engineers needed.  I&#x27;d say by half and web, graphic designers and front end developers coding the designs are really no longer needed.<p>I was just laid off from my job of 8 years in which I was the UX Researcher, Designer, Front-End Dev and Customer UX Support.  In a week I have sold my house and am downsizing significantly and in two years or less will be working as an RN(nurse).  I will try to get back into my field but the current administration and the many tech layoffs has flooded the market with people like me looking for job.  All the while AI is eating my career &amp; field.  It just doesnt seem wise that my career of 20 years is going to be around in the next ten years.<p>Also, will there be interfaces we have today in five to ten years or so?  My guess is AI is the interface that does everything for us through voice (Open AI&#x27;s upcoming device) or text .. now we still could have handheld AI phones or devices but where AI does everything including presents articles, games we play, etc and all from these AI devices&#x27; lock screen (websites are not visited much)",
      "The problem is that your boss might think it can replace you, not really understanding what you are doing and how you are doing it.",
      "Interesting yc vid on the topic: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IqwSb2hO1jE\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IqwSb2hO1jE</a><p>tl;dr it argues when there&#x27;s a dramatic improvement in the efficiency of production of a good or service, its <i>per-unit</i> cost goes down so much that demand skyrockets, leading to greater demand for employees in that sector. The examples it gives are radiologists (after neural nets were predicted to be able to perform their jobs essentially for free), and dock workers<p>If this happens in the case of SWEs, it would mean a &#x27;unit&#x27; of software will be able to be produced <i>much</i> more cheaply, but the demand for and price (i.e. salaries) of SWEs might stay the same or increase."
    ],
    "full_text": null
  }
]