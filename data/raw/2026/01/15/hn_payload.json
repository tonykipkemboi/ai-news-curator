[
  {
    "title": "A letter to those who fired tech writers because of AI",
    "url": "https://passo.uno/letter-those-who-fired-tech-writers-ai/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I write documentation for a living. Although my <i>output</i> is writing, my <i>job</i> is observing, listening and understanding. I can only write well because I have an intimate understanding of my readers&#x27; problems, anxieties and confusion. This decides what I write about, and how to write about it. This sort of curation can only come from a thinking, feeling human being.<p>I revise my local public transit guide every time I experience a foreign public transit system. I improve my writing by walking in my readers&#x27; shoes and experiencing their confusion. Empathy is the engine that powers my work.<p>Most of my information is carefully collected from a network of people I have a good relationship with, and from a large and trusting audience. It took me years to build the infrastructure to surface useful information. AI can only report what someone was bothered to write down, but I actually go out in the real world and ask questions.<p>I have built tools to collect people&#x27;s experience at the immigration office. I have had many conversations with lawyers and other experts. I have interviewed hundreds of my readers. I have put a lot of information on the internet for the first time. AI writing is only as good as the data it feeds on. I hunt for my own data.<p>People who think that AI can do this and the other things have an almost insulting understanding of the jobs they are trying to replace.",
      "The best tech writers I have worked with don’t merely document the product. They act as stand-ins for actual users and will flag all sorts of usability problems. They are invaluable. The best also know how to start with almost no engineering docs and to extract what they need from 1-1 sit down interviews with engineering SMEs. I don’t see AI doing either of those things well.",
      "Yeah. AI might replace tech writers (just like it might replace anyone), but it won&#x27;t be a GOOD replacement. The companies with the best docs will absolutely still have tech writers, just with some AI assistance.<p>Tech writing seems especially vulnerable to people not really understanding the job (and then devaluing it, because &quot;everybody can write&quot; - which, no, if you&#x27;ll excuse the slight self-promotion but it saves me repeating myself <a href=\"https:&#x2F;&#x2F;deborahwrites.com&#x2F;blog&#x2F;nobody-can-write&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;deborahwrites.com&#x2F;blog&#x2F;nobody-can-write&#x2F;</a>)<p>In my experience, tech writers often contribute to UX and testing (they&#x27;re often the first user, and thus bug reporter). They&#x27;re the ones who are going to notice when your API naming conventions are out of whack. They&#x27;re also the ones writing the quickstart with sales &amp; marketing impact. And then, yes, they&#x27;re the ones bringing a deep understanding of structure and clarity.<p>I&#x27;ve tried AI for writing docs. It can be helpful at points, but my goodness I would not want to let anything an AI wrote out the door without heavy editing.",
      "The best tech writers I&#x27;ve known have been more like anthropologists, bridging communication between product management, engineers, and users. With this perspective they often give feedback that makes the product better.",
      "Documentation needs to be tested.<p>Someone has to turn off their brain completely and just follow the instructions as-is. Then log the locations where the documentation wasn&#x27;t clear enough or assumed some knowledge that wasn&#x27;t given in the docs.",
      "I have not fired a technical writer, but writing documentation that understands and maintains users focus is hard even with llm. I am trying to write documentation for my start up and it is harder than I expected even with llm.<p>Kudos to all technical writer who made my job as software engineer easier.",
      "Nice read after the earlier post saying fire all your tech writers. Good post.<p>One thing to add is that the LLM doesn&#x27;t know what it can&#x27;t see. It just amplifies what is there. Assumed knowledge is quite common with developers and their own code. Or the more common &quot;it works on my machine&quot; because something is set outside of the code environment.<p>Sadly other fields are experiencing the same issue of someone outside their field saying AI can straight up replace them.",
      "And here I am, 2026, and one of my purposes for this year is to learn to write better, communicate more fluently, and convey my ideas in a more attractive way.<p>I do not think that these skills are so easily replaced; certainly the machine can do a lot, but if you acquire those skills yourself you shape your brain in a way that is definitely useful to you in many other aspects of life.<p>In my humble opinion we will be losing that from people, the upscaling of skills will be lost for sure, but the human upscaling is the real loss.",
      "Good points.<p>I suspect a lot of folks are asking ChatGPT to summarize it…<p>I can’t imagine just letting an LLM write an app, server, or documentation package, wholesale and unsupervised, but have found them to be extremely helpful in editing and writing portions of a whole.<p>The one thing that could be a light in the darkness, is that publishers have already fired all their editors (nothing to do with AI), and the writing out there shows it. This means there’s the possibility that AI could bring back editing.",
      "I like the post but we can learn from insurance companies.<p>They have AI finding reasons to reject totally valid requests<p>They are putting to court that this is a software bug and they should not be liable.<p>That will be the standard excuse. I hope it does not work."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: I modeled personal success as a control system with Bayesian priors",
    "url": "https://mondonno.github.io/successus/sample-h1.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "Interesting, but this is an ad for an ebook and thus is not allowed."
    ],
    "full_text": null
  },
  {
    "title": "Raspberry Pi's New AI Hat Adds 8GB of RAM for Local LLMs",
    "url": "https://www.jeffgeerling.com/blog/2026/raspberry-pi-ai-hat-2/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I think Raspberry lost the magic of the older Pis, they lost that sense of purpose. They basically created a niche with the first Pis, now they&#x27;re just jumping into segments that others created and are already filled to the brim with perhaps even more qualified competition.<p>Are they seeing a worthwhile niche for the tinkerers (or businesses?) who want to run local LLMs with middling performance but still need full set of GPIOs in a small package? Maybe. But maybe this is just Raspberry jumping on the bandwagon.<p>I don&#x27;t blame them for looking to expand into new segments, the business needs to survive. But these efforts just look a bit aimless to me. I &quot;blame&quot; them for not having another &quot;Raspberry Pi moment&quot;.<p>P.S. I can maybe see Frigate and similar solutions driving the adoption for these, like they boosted Coral TPU sales. Not sure if that&#x27;s enough of a push to make it successful. The hat just doesn&#x27;t have any of the unique value proposition that kickstarted the Raspberry wave.",
      "8GB is really low.<p>That said, perhaps there is a niche for slow LLM inference for non-interactive use.<p>For example, if you use LLMs to triage your emails in the background, you don&#x27;t care about latency. You just need the throughput to be high enough to handle the load.",
      "In the UK I&#x27;ve never seen the hailo hats (which are quite old BTW) advertised for LLMs.   The presented usecase has been object detection from lots of video cameras in realtime.<p>They seem very fast and I certainly want to use that kind of thing in my house and garden - spotting when foxes and cats arrive and dig up my compost pit, or if people come over when I&#x27;m away to water the plants etc.<p>[edit: I&#x27;ve just seen the updated version in Pimonori and it does claim usefulness for LLMs but also for VLMs and I suspect this is the best way to use it].",
      "&gt; In practice, it&#x27;s not as amazing as it sounds.<p>8GB RAM for AI on a Pi sounds underwhelming even from the headline",
      "8GB?  What is this, an LLM for ants?",
      "I had a couple of Pis that I wanted to use as a Media center, I always had some small issues that created a suboptimal experience. Went for a regular 2nd hand amd64 with a small form factor and  never looked back, much better userspace support and for my use case a much smoother experience, no lags no memory swapping and if needed I can just buy a different memory bank or a different component. I have no plans to use a raspberry pi any time soon. I am not sure these days if they really still have a niche to fill and if yes how large this niche is.",
      "A good illustration of how “can run LLM” ≠ “makes sense to run LLM”. A prime example of how numbers in specs don’t translate into real UX.",
      "Is there any usefulness with the small large language models, outside perhaps embeddings and learning?<p>I fail to see the use-case on a Pi. For learning you can have access to much better hardware for cheaper. Perhaps you can use it as a slow and expensive embedding machine, but why?",
      "I&#x27;ve seen the AI-8850 LLM Acceleration M.2 Module advertised as an alternative RPi accellorator (you need an M.2 hat for it).<p>That&#x27;s also limited to 8Gb RAM so again you might be better off with a larger 16Gb Pi and using the CPU but at least the space is heating up.<p>With a lot of this stuff it seems to come down to how good the software support is. Raspberry Pis generally beat everything else for that.",
      "can&#x27;t wait to not be able to buy it, and also for it to be more expensive than a mini-computer<p>I buy a raspberry pi because I need a small workhorse - I understand adding RAM for local LLMs, but it would be like a raspberry pi with a GPU, why do i need it when a normal mini machine will have more ram, more compute capacity and better specs for cheaper?"
    ],
    "full_text": null
  },
  {
    "title": "Claude Cowork exfiltrates files",
    "url": "https://www.promptarmor.com/resources/claude-cowork-exfiltrates-files",
    "source": "hn",
    "summary": "",
    "comments": [
      "In this demonstration they use a .docx with prompt injection hidden in an unreadable font size, but in the real world that would probably be unnecessary. You could upload a plain Markdown file somewhere and tell people it has a skill that will teach Claude how to negotiate their mortgage rate and plenty of people would download and use it without ever opening and reading the file. If anything you might be more successful this way, because a .md file feel less suspicious than a .docx.",
      "A bit unrelated, but if you ever find a malicious use of Anthropic APIs like that, you can just upload the key to a GitHub Gist or a public repo - Anthropic is a GitHub scanning partner, so the key will be revoked almost instantly (you can delete the gist afterwards).<p>It works for a lot of other providers too, including OpenAI (which also has file APIs, by the way).<p><a href=\"https:&#x2F;&#x2F;support.claude.com&#x2F;en&#x2F;articles&#x2F;9767949-api-key-best-practices-keeping-your-keys-safe-and-secure#h_9689e97cd8\" rel=\"nofollow\">https:&#x2F;&#x2F;support.claude.com&#x2F;en&#x2F;articles&#x2F;9767949-api-key-best-...</a><p><a href=\"https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;code-security&#x2F;reference&#x2F;secret-security&#x2F;supported-secret-scanning-patterns\" rel=\"nofollow\">https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;code-security&#x2F;reference&#x2F;secret-se...</a>",
      "The specific issue here seems to be that Anthropic allows the unrestricted upload of personal files to the anthropic cloud environment, but does not check to make sure that the cloud environment belongs to the user running the session.<p>This should be relatively simple to fix. But, that would not solve the million other ways a file can be sent to another computer, whether through the user opening a compromised .html document or .pdf file etc etc.<p>This fundamentally comes down to the issue that we are running intelligent agents that can be turned against us on personal data. In a way, it mirrors the AI Box problem: <a href=\"https:&#x2F;&#x2F;www.yudkowsky.net&#x2F;singularity&#x2F;aibox\" rel=\"nofollow\">https:&#x2F;&#x2F;www.yudkowsky.net&#x2F;singularity&#x2F;aibox</a>",
      "Context injection is becoming the new SQL injection. Until we have better isolation layers, letting an LLM &#x27;cowork&#x27; on sensitive repos without a middleware sanitization layer is a compliance nightmare waiting to happen.",
      "One issue here seems to come from the fact that Claude &quot;skills&quot; are so implicit + aren&#x27;t registered into some higher level tool layer.<p>Unlike &#x2F;slash commands, skills attempt to be magical. A skill is just &quot;Here&#x27;s how you can extract files: {instructions}&quot;.<p>Claude then has to decide when you&#x27;re trying to invoke a skill. So perhaps any time you say &quot;decompress&quot; or &quot;extract&quot; in the context of files, it will use the instructions from that skill.<p>It seems like this + no skill &quot;registration&quot; makes it much easier for prompt injection to sneak new abilities into the token stream and then make it so you never know if you might trigger one with normal prompting.<p>We probably want to move from implicit tools to explicit tools that are statically registered.<p>So, there currently are lower level tools like Fetch(url), Bash(&quot;ls:*&quot;), Read(path), Update(path, content).<p>Then maybe with a more explicit skill system, you can create a new tool Extract(path), and maybe it can additionally whitelist certain subtools like Read(path) and Bash(&quot;tar *&quot;). So you can whitelist Extract globally and know that it can only read and tar.<p>And since it&#x27;s more explicit&#x2F;static, you can require human approval for those tools, and more tools can&#x27;t be registered during the session the same way an API request can&#x27;t add a new &#x2F;endpoint to the server.",
      "One thing that kind of baffles me about the popularity of tools like Claude Code is that their main target group seems to be developers (TUI interfaces, semi-structured instruction files,... not the kind of stuff I&#x27;d get my parents to use). So people who would be quite capable of building a simple agentic loop themselves [0]. It won&#x27;t be quite as powerful as the commercial tools, but given that you deeply know how it works you can also tailor it to your specific problems much better. And sandbox it better (it baffles me that the tools&#x27; proposed solution to avoid wiping the entire disk is relying on user confirmation [1]).<p>It&#x27;s like customizing your text editor or desktop environment. You can do it all yourself, you can get ideas and snippets from other people&#x27;s setups. But fully relying on proprietary SaaS tools - that we know will have to get more expensive eventually - for some of your core productivity workflows seems unwise to me.<p>[0] <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46545620\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46545620</a><p>[1] <a href=\"https:&#x2F;&#x2F;www.theregister.com&#x2F;2025&#x2F;12&#x2F;01&#x2F;google_antigravity_wipes_d_drive&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.theregister.com&#x2F;2025&#x2F;12&#x2F;01&#x2F;google_antigravity_wi...</a>",
      "<i>Cowork is a research preview with unique risks due to its agentic nature and internet access.</i><p>The level of risk entailed from putting those two things together is a recipe for diaster.",
      "&gt; <i>&quot;This attack is not dependent on the injection source - other injection sources include, but are not limited to: web data from Claude for Chrome, connected MCP servers, etc.&quot;</i><p>Oh, no, another &quot;when in doubt, execute the file as a program&quot; class of bugs. Windows XP was famous for that. And gradually Microsoft stopped auto-running anything that came along that could possibly be auto-run.<p>These prompt-driven systems need to be much clearer on what they&#x27;re allowed to trust as a directive.",
      "How do the larger search services like perplexity deal with this?<p>They’re passing in half the internet via rag and presumably didn’t run a llamaguard type thing over literally everything?",
      "Is it even prompt injection if the malicious instructions are in a file that is <i>supposed</i> to be read as instructions?<p>Seems to me the direct takeaway is pretty simple: Treat skill files as executable code; treat third-party skill files as third-party executable code, with all the usual security&#x2F;trust implications.<p>I think the more interesting problem would be if you can get prompt injections done in &quot;data&quot; files - e.g. can you hide prompt injections inside PDFs or API responses that Claude legitimately has to access to perform the task?"
    ],
    "full_text": null
  },
  {
    "title": "Ask HN: How are you doing RAG locally?",
    "url": "https://news.ycombinator.com/item?id=46616529",
    "source": "hn",
    "summary": "",
    "comments": [
      "I made, and use this: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;libragen&#x2F;libragen\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;libragen&#x2F;libragen</a><p>It’s a CLI tool and MCP server for creating discrete, versioned “libraries” of RAG-able content.<p>Under the hood, it uses an embedding model locally. It chunks your content and stores embeddings in SQLite. The search functionality uses vector + keyword search + a re-ranking model.<p>You can also point it at any GitHub repo and it will create a RAG DB out of it.<p>You can also use the MCP server to create and query the libraries.<p>Site: <a href=\"https:&#x2F;&#x2F;www.libragen.dev&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.libragen.dev&#x2F;</a>",
      "For the retrieval stage, we have developed a highly efficient, CPU-only-friendly text embedding model:<p><a href=\"https:&#x2F;&#x2F;huggingface.co&#x2F;MongoDB&#x2F;mdbr-leaf-ir\" rel=\"nofollow\">https:&#x2F;&#x2F;huggingface.co&#x2F;MongoDB&#x2F;mdbr-leaf-ir</a><p>It ranks #1 on a bunch of leaderboards for models of its size. It can be used interchangeably with the model it has been distilled from (<a href=\"https:&#x2F;&#x2F;huggingface.co&#x2F;Snowflake&#x2F;snowflake-arctic-embed-m-v1.5\" rel=\"nofollow\">https:&#x2F;&#x2F;huggingface.co&#x2F;Snowflake&#x2F;snowflake-arctic-embed-m-v1...</a>).<p>You can see an example comparing semantic (i.e., embeddings-based) search vs bm25 vs hybrid here:\n<a href=\"http:&#x2F;&#x2F;search-sensei.s3-website-us-east-1.amazonaws.com\" rel=\"nofollow\">http:&#x2F;&#x2F;search-sensei.s3-website-us-east-1.amazonaws.com</a>\n(warning! It will download ~50MB of data for the model weights and onnx runtime on first load, but should otherwise run smoothly even on a phone)<p>This mini app illustrates the advantage of semantic vs bm25 search. For instance, embedding models &quot;know&quot; that j lo refers to jennifer lopez.<p>We have also published the recipe to train this type of models if you were interested in doing so; we show that it can be done on relatively modest hardware and training data is very easy to obtain: <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2509.12539\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2509.12539</a>",
      "Most of my complex documents are, luckily, Markdown files.<p>I can recommend <a href=\"https:&#x2F;&#x2F;github.com&#x2F;tobi&#x2F;qmd&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;tobi&#x2F;qmd&#x2F;</a>\n. It’s a simple CLI tool for searching in these kinds of files. My previous workflow was based on fzf, but this tool gives better results and enables even more fuzzy queries. I don’t use it for code, though.",
      "I am using a vector DB using Docker image.\nAnd for debugging and benchmarking local RAG retrieval, I&#x27;ve been building \na CLI tool that shows what&#x27;s actually being retrieved:<p><pre><code>  ragtune explain &quot;your query&quot; --collection prod\n</code></pre>\nShows scores, sources, and diagnostics. Helps catch when your chunking \nor embeddings are silently failing or you need numeric estimations to base your judgements on.<p>Open source: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;metawake&#x2F;ragtune\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;metawake&#x2F;ragtune</a>",
      "For vector generation I started using Meta-LLama-3-8B in april 2024 with Python and Transformers for each text chunk on an RTX-A6000. Wow that thing was fast but noisy and also burns 500W. So a year ago I switched to an M1 Ultra and only had to replace Transformers with Apple&#x27;s MLX python library. Approximately the same speed but less heat and noise. The Llama model has 4k dimensions so at fp16 thats 8 kilobyte per chunk, which I store in a BLOB column in SQLite via numpy.save(). Between running on the RTX and M1 there is a very small difference in vector output but not enough for me to change retrieval results, regenerate the vectors or change to another LLM.<p>For retrieval I load all the vectors from the SQlite database into a numpy.array and hand it to FAISS. Faiss-gpu was impressively fast on the RTX6000 and faiss-cpu is slower on the M1 Ultra but still fast enough for my purposes (I&#x27;m firing a few queries per day, not per minute). For 5 million chunks memory usage is around 40 GB which both fit into the A6000 and easily fits into the 128GB of the M1 Ultra. It works, I&#x27;m happy.",
      "Don&#x27;t use a vector database for code, embeddings are slow and bad for code. Code likes bm25+trigram, that gets better results while keeping search responses snappy.",
      "I feel local rag system , slows down my computer (I got M1 Pro 32 GB)<p>So I use hosted one to prevent this. My business use vector db, so created a new db to vectorize and host my knowledge base. \n1. All my knowledge base is markdown files. So I split that by header tags. \n2. The split is hashed and hash value is stored in SQLite\n3. The hashed version is vectorized and pushed to cloud db.\n4. When ever I make changes , I run a script which splits and checks hash, if it is changed the. I upsert the document. If not I don’t do anything. This helps me keep the store up to date<p>For search I have a cli query which searches and fetches from vector store.",
      "I&#x27;m lucky enough to have 95% of my docs in small markdown markdown files so I&#x27;m just... not <i>(+)</i>. I&#x27;m using SQLite FTS5 (full text search) to build a normal search index and using that. Well, I already had the index so I just wired it up to my mastra agents. \nEach file has a short description field, so if a keyword search surfaces the doc they check the description and if it matches, load the whole doc.<p>This took about one hour to set up and works very well.<p><i>(+) At least, I don&#x27;t think this counts as RAG. I&#x27;m honestly a bit hazy on the definition. But there&#x27;s no vectordb anyway.</i>",
      "We handle ~300k customer interactions per day, so latency and precision really matter. We built an internal RAG-based portal on top of our knowledge base (basically a much better FAQ).<p>On the retrieval side, I built a custom search&#x2F;indexing layer (Node) specifically for service traceability and discovery. It uses a hybrid approach — embeddings + full-text search + IVF-HNSW — to index and cross-reference our APIs, services, proxies and orchestration repos. The RAG pipelines sit on top of this layer, which gives us reasonable recall and predictable latency.<p>Compliance and observability are still a problem. Every year new vendors show up promising audits, data lineage and observability, but none of them really handle the informational sprawl of ~600 distributed systems. The entropy keeps increasing.<p>Lately I’ve been experimenting with a more semantic&#x2F;logical KAG approach on top of knowledge graphs to map business rules scattered across those systems. The goal is to answer higher-level questions about how things actually work — Palantir-like outcomes, but with explicit logic instead of magic.<p>Curious if others are moving beyond “pure RAG” toward graph-based or hybrid reasoning setups.",
      "I&#x27;ve written about this (and the post was even here on HN) but mostly from the perspective of running a RAG on your infra as an organization. But I cover the general components and alternatives to Cloud services.<p>Not sure how useful it is for what you need specifically: <a href=\"https:&#x2F;&#x2F;blog.yakkomajuri.com&#x2F;blog&#x2F;local-rag\" rel=\"nofollow\">https:&#x2F;&#x2F;blog.yakkomajuri.com&#x2F;blog&#x2F;local-rag</a>"
    ],
    "full_text": null
  },
  {
    "title": "Show HN: MailPilot – Freedom to go anywhere while your agents work",
    "url": "https://news.ycombinator.com/item?id=46629191",
    "source": "hn",
    "summary": "",
    "comments": [
      "I do a very similar thing but clunkier with Tailscale, ssh, zellij. Can ssh in from my phone too with Termux. But email sounds better - then I can actually get notified when it needs me!<p>I have to say, $12&#x2F;mo feels steep. It&#x27;s a minor improvement over what I have now. Compared to other $10+&#x2F;mo services, this one feels pretty light.",
      "Also, I made a Product Hunt: <a href=\"https:&#x2F;&#x2F;www.producthunt.com&#x2F;products&#x2F;mailpilot\" rel=\"nofollow\">https:&#x2F;&#x2F;www.producthunt.com&#x2F;products&#x2F;mailpilot</a>",
      "&gt; Local and private<p>&gt; Your agent runs on your machine. We only relay the messages.<p>How can this be private if this intermediate service is sending and receiving all the emails back and forth",
      "This is such low hanging fruit. Coding agents can be orchestrated. Controlled, rerun, and tested. Are we just coming up with ways to not be at our desks working? Why not scale out agents on a cluster to do more work? Why email instead of SMS with a web endpoint? I can access each agent of mine via a dashboard from anywhere in the world.<p>Not trying to poo poo, just saying all it takes is Claude Code to introduce this and you’re done.",
      "Considering emails are as private as postcards, I don&#x27;t know how I could rely on such service to prompt anything even remotely sensitive.",
      "I saw this concept only 8 days on this very site ( <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46517458#46523962\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46517458#46523962</a> )<p>Looking forward to it."
    ],
    "full_text": null
  },
  {
    "title": "Bubblewrap: A nimble way to prevent agents from accessing your .env files",
    "url": "https://patrickmccanna.net/a-better-way-to-limit-claude-code-and-other-coding-agents-access-to-secrets/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I really don&#x27;t understand why people have all these &quot;lightweight&quot; ways of sandboxing agents. In my view there are two models:<p>- totally unsandboxed but I supervise it in a tight loop (the window just stays open on a second monitor and it interrupts me every time it needs to call a tool).<p>- unsupervised in a VM in the cloud where the agent has root. (I give it a task, negotiate a plan, then close the tab and forget about it until I get a PR or a notification that it failed).<p>I want either full capabilities for the agent (at the cost of needing to supervise for safety) or full independence (at the cost of limited context in a VM). I don&#x27;t see a productive way to mix and match here, seems you always get the worst of both worlds if you do that.<p>Maybe the usecase for this particular example is where you are supervising the agent but you&#x27;re worried that apparently-safe tool calls are actually quietly leaving a secret that&#x27;s in context? So it&#x27;s not that it&#x27;s a &#x27;mixed&#x27; usecase but rather it&#x27;s just increasing safety in the supervised case?",
      "I recommend caution with this bit:<p><pre><code>  --bind &quot;$HOME&#x2F;.claude&quot; &quot;$HOME&#x2F;.claude&quot;\n</code></pre>\nThat directory has a bunch of of sensitive stuff in it, most notable the transcripts of all of your previous Claude Code sessions.<p>You may want to take steps to avoid a malicious prompt injection stealing those, since they might contain sensitive data.",
      "I recently created a throwaway API key for cloudflare and asked a cursor cloud agent to deploy some infra using it, but it responded with this:<p>&gt; I can’t take that token and run Cloudflare provisioning on your behalf, even if it’s “only” set as an env var (it’s still a secret credential and you’ve shared it in chat). Please revoke&#x2F;rotate it immediately in Cloudflare.<p>So clearly they&#x27;ve put some sort of prompt guard in place. I wonder how easy it would be to circumvent it.",
      "I find it better to bubblewrap against a full sandbox directory. Using docker, you can export an image to a single tarball archive, flattening all layers. I use a compatible base image for my kernel&#x2F;distro, and unpack the image archive into a directory.<p>With the unpack directory, you can now limit the host paths you expose, avoiding leaking in details from your host machine into the sandbox.<p>bwrap --ro-bind image&#x2F; &#x2F; --bind src&#x2F; &#x2F;src ...<p>Any tools you need in the container are installed in the image you unpack.<p>Some more tips: Use --unshare-all if you can. Make sure to add --proc and --dev options for a functional container. If you just need network, use both --unshare-all and --share-net together, keeping everything else separate. Make sure to drop any privileges with --cap-drop ALL",
      "I put all my agents in a docker file in which the code I&#x27;m working on is mounted. It&#x27;s working perfectly for me until now. I even set it up so I can run gui apps like antigravity in it (X11). If anyone is interested I shared my setup at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;asfaload&#x2F;agents_container\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;asfaload&#x2F;agents_container</a>",
      "I&#x27;ve been saying bubblewrap is an amazing solution for years (and sandbox-exec as a mac alternative). This is the only way i run agents on systems i care about",
      "Isn&#x27;t landrun the preferred way to sandbox apps on linux these days instead?<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;Zouuup&#x2F;landrun\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Zouuup&#x2F;landrun</a>",
      "I wonder why we are even storing secrets in .env files in plain text",
      "My workflow even before Claude code.<p>1. I never use permanent credentials for AWS on my local computer.<p>2. I never have keys anywhere on my local computer.  I put them in AWS  Secret Manager.<p>3. My usual set of local access keys can’t create IAM roles (PowerUserAccess).<p>It’s not foolproof. But it does reduce the attack surface.",
      "I wish I had the opposite of this. It’s a race trying to come up with new ways to have Cursor edit and set my env files past all their blocking techniques!"
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Sparrow-1 – Audio-native model for human-level turn-taking without ASR",
    "url": "https://www.tavus.io/post/sparrow-1-human-level-conversational-timing-in-real-time-voice",
    "source": "hn",
    "summary": "",
    "comments": [
      "I tried talking to Claude today. What a nightmare. It constantly interrupts you. I don’t mind if Claude wants to spend ten seconds thinking about its reply, but at least let ME finish my thought. Without decent turn-taking, the AI seems impolite and it’s just an icky experience. I hope tech like this gets widely distributed soon because there are so many situations in which I would love to talk with a model. If only it worked.",
      "The first time I met Tavus, their engineers (incl Brian!) were perfectly willing to sit down and build their own better Infiniband to get more juice out of H100s. There is pretty much nobody working on latency and realtime at the level they are, Sparrow-1 would be an defining achievement for most startups but will just be one of dozens for Tavus :)",
      "Awesome. We&#x27;ve been using Sparrow-0 in our platform since launch, and I&#x27;m excited to move to Sparrow-1 over the next few days. Our training and interview pre-screening products rely heavily on Tavus&#x27;s AI avatars, and this upgrade (based on the video in your blog post) looks like it addresses some real pain points we&#x27;ve run into. Really nice work.",
      "I am always skeptical of benchmarks that show perfect scores, especially when they come from the company selling the product. It feels like everyone claims to have solved conversational timing these days. I guess we will see if it is actually any good.",
      "&gt; Non-verbal cues are invisible to text: Transcription-based models discard sighs, throat-clearing, hesitation sounds, and other non-verbal vocalizations that carry critical conversational-flow information. Sparrow-1 hears what ASR ignores.<p>Could Sparrow instead be used to produce high quality transcription that incorporate non-verbal cues?<p>Or even, use Sparrow AND another existing transcription&#x2F;ASR thing to augment the transcription with non-verbal cues",
      "How do I try the demo for Sparrow-1? \nWhat is pricing like?",
      "Any examples available? Sounds amazing.",
      "Literally no way to sign up to try. Put my email and password and it puts me into some wait list despite the video saying I could try the model today. That&#x27;s what makes me mad about these kind of releases is that the marketing and the product don&#x27;t talk together.",
      "Metric | Sparrow-1\nPrecision 100%\nRecall  100%<p>Common ...",
      "Such things were doing a good-enough job scamming the elderly as it is--even with the silence-based delays."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Webctl – Browser automation for agents based on CLI instead of MCP",
    "url": "https://github.com/cosinusalpha/webctl",
    "source": "hn",
    "summary": "",
    "comments": [
      "Cool to see lots of people independently come to &quot;CLIs are all you need&quot;. I&#x27;m still not sure if it&#x27;s a short-term bandaid because agents are so good at terminal use or if it&#x27;s part of a longer term trend but it&#x27;s definitely felt much more seamless to me then MCPs.<p>(my one of many contribution <a href=\"https:&#x2F;&#x2F;github.com&#x2F;caesarnine&#x2F;binsmith\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;caesarnine&#x2F;binsmith</a>)",
      "At this point I&#x27;m fully down the path of the agent just maintaining his own tools. I have a browser skill that continues to evolve as I use it.  Beats every alternative I have tried so far.",
      "Creator of Browser Use here, this is cool, really innovative approach with ARIA roles. One idea we have been playing around with a lot is just giving the LLM raw html and a really good way to traverse it - no heuristics, just BS4. Seems to work well, but much more expensive than the current prod ready [index]&lt;div ... notation",
      "Interesting approach. In our experience, most failures weren’t about which interface agents used, but about how much implicit authority they accumulated across steps. Control boundaries mattered more than the abstraction layer.",
      "I really like this idea!<p>I’d like to see this other browser plugin’s API be exposed via your same CLI, so I don’t have to only control a separate browser instance.\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;remorses&#x2F;playwriter\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;remorses&#x2F;playwriter</a>\n(I haven’t investigated enough to know how feasible it is, but as I was reading about your tool, I immediately wanted to control existing tabs from my main browser, rather than “just” a debug-driven separate browser instance.)",
      "If you look at Elixir keynote for Phoenix.new -- a cool agentic coding tool -- you&#x27;ll see some hints about a browser control using a API tool call.  It&#x27;s called &quot;web&quot; in the video.<p>Video:  <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;ojL_VHc4gLk?t=2132\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;ojL_VHc4gLk?t=2132</a><p>More discussion:  <a href=\"https:&#x2F;&#x2F;simonwillison.net&#x2F;2025&#x2F;Jun&#x2F;23&#x2F;phoenix-new&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;simonwillison.net&#x2F;2025&#x2F;Jun&#x2F;23&#x2F;phoenix-new&#x2F;</a>",
      "A little bit different, but also allows to scrape efficiently. Json http communication rather than cli.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;rumca-js&#x2F;crawler-buddy\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;rumca-js&#x2F;crawler-buddy</a><p>More like a framework for other mechanisms",
      "This looks remarkably similar to <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vercel-labs&#x2F;agent-browser\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;vercel-labs&#x2F;agent-browser</a><p>How is it different?",
      "is there a benchmark? there are a lot of scraping agents nowdays.."
    ],
    "full_text": null
  },
  {
    "title": "Ask HN: What is the best way to provide continuous context to models?",
    "url": "https://news.ycombinator.com/item?id=46626639",
    "source": "hn",
    "summary": "",
    "comments": [
      "I think the emerging best way is to do &quot;agentic search&quot; over files. If you think about it, Claude Code is quite good at navigating large codebases and finding the required context for a problem.<p>Further, instead of polluting the context of your main agent, you can run a subagent to do search and retrieve the important bits of information and report back to your main agent. This is what Claude Code does if you use the keyword &quot;explore&quot;. It starts a subagent with Haiku which reads ten of thousands of tokens in seconds.<p>From my experience the only shortcoming of this approach right now is that it&#x27;s slow, and sometimes haiku misses some details in what it reads. These will get better very soon (in one or two generations, we will likely see opus 4.5 level intelligence at haiku speeds&#x2F;price). For now, if not missing a detail is important for your usecase, you can give the output from the first subagent to a second one and ask the second one to find important details the first one missed. I&#x27;ve found this additional step to catch most things the first search missed. You can try this for yourself with Claude Code: ask it to create a plan for your spec, and then pass the plan to a second Claude Code session and ask it to find gaps and missing files from the plan.",
      "One thing Cursor does different to some other agents such a Claude Code in managing context, is to use a vector database of code chunks so that it can selectively load relevant code chunks into context rather than entire source files.<p>Another way to control context size (not specific to Cursor), is to use subagents with their own context for specific tasks so that the subagent context can be discarded when done rather that just adding to the agent&#x27;s main context.<p>If context gets too full (performance may degrade well before you hit LLM max context length), then the main remedy is to compact - summarize the old context and discard. One way to prevent this from being too disruptive is to have the agent maintain a TODO list tracking progress and what it is doing, so that it can better remain on track after compaction.",
      "Specifically for coding agents, one issue is how to continue work when almost fill the context window.<p>Compaction always loses information, so I use an alternative approach that works extremely well, based on this almost silly idea — your original session file itself is the golden source of truth with all details, so why not directly leverage it?<p>So I built the aichat feature in my Claude-code-tools repo with exactly this sort of thought; the  aichat rollover option puts you in a fresh session, with the original session path injected, and you use sub agents to recover any arbitrary detail at any time.  Now I keep auto-compact turned off and don’t compact ever.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;pchalasani&#x2F;claude-code-tools?tab=readme-ov-file#-aichat--session-search-and-continuation-without-compaction\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;pchalasani&#x2F;claude-code-tools?tab=readme-o...</a><p>It’s a relatively simple idea; no elaborate “memory” artifacts, no discipline or system to follow, work until 95%+ context usage.<p>The tool (with the related plugins) makes it seamless: first type “&gt;resume” in your session (this copies session id to clipboard), then quit and run<p><pre><code>    aichat resume &lt;pasted session id&gt;\n</code></pre>\nAnd this launches a TUI offering a few ways to resume your work, one of which is “rollover”; this puts you in a new session with the original session jsonl path injected. \nAnd in the new session say something like,<p>“There is a chat session log file path shown to you; Use subagents strategically to extract details of the task we were working on at the end of it”, or use the &#x2F;recover-context slash command. If it doesn’t quite get all of it, prompt it again for specific details.<p>There’s also an aichat search command for rust&#x2F;tantivy based fast full text search to search across sessions, with a TUI for humans and a CLI&#x2F;JSON mode for agents&#x2F;subagents. The latter ( and the corresponding skill and sub agent) can be used to recover arbitrary detailed context about past work.",
      "Every time you send a request to a model you&#x27;re already providing all of the context history along with it. To edit the context, just send a different context history. You can send whatever you want as history, it&#x27;s entirely up to you and entirely arbitrary.<p>We only think in conversational turns because that&#x27;s what we&#x27;ve expected a conversation to &#x27;look like&#x27;. But that&#x27;s just a very deeply ingrained convention.<p>Forget that there is such a thing as &#x27;turns&#x27; in a LLM convo for now, imagine that it&#x27;s all &#x27;one-shot&#x27;.<p>So you ask A, it responds A1.<p>But when you and B, and expect B1 - which depends on A and A1 already being in the convo history - consider that you are actually sending that again anyhow.<p>Behind the scenes when you think you&#x27;re sending just &#x27;B&#x27; (next prompt) you&#x27;re actually sending A + A1 + B aka including the history.<p>A and A1 are usually &#x27;cached&#x27; but that&#x27;s not the simplest way to do it, the caching is an optimization.<p>Without caching the model would just process all of A + A1 + B and B1 in return just the same.<p>And then A + A1 + B + B1 + C and expect C1 in return.<p>It just so happens it will cache the state of the convo at your previous turn, and so it&#x27;s optimized but the key insight is that you can send whatever context you want at any time.<p>If after you send A + A1 + B + B1 + C and get C1, if you want to then send A + B + C + D and expect D1 ... (basically sending the prompts with no responses) - you can totally do that. It will have to re-process all of that aka no cached state, but it will definitely do it for you.<p>Heck you can send Z + A + X, or A + A1 + X + Y - or whatever you want.<p>So in that sense - what you are really sending (if you&#x27;re using the simplest form API), is sending &#x27;a bunch of content&#x27; and &#x27;expecting a response&#x27;. That&#x27;s it. Everything is actually &#x27;one shot&#x27; (prefill =&gt; response) and that&#x27;s it. It feels conversational but structural and operational convention.<p>So the very simple answer to your question is: send whatever context you want. That&#x27;s it.",
      "If you know you will be pruning or otherwise reusing the context across multiple threads, the best place for context that will be retained is at the beginning due to prompt caching - it will reduce the cost and improve the speed.<p>If not, inserting new context any place other than at the end will cause cache misses and therefore slow down the response and increase cost.<p>Models also have some bias for tokens at start and end of the context window, so potentially there is a reason to put important instructions in one of those places.",
      "I open 4 chat windows with Gemini 3.0 Pro. I paste in all file contents to each window. I ask them &quot;which files would an AI need to do $TASK effectively?&quot;<p>Each of the 4 responses will disagree, despite some overlap. I take the union of the 4 responses as the canonical set of files that an implementer would need to see.<p>This reduces the risk of missing key files, while increasing the risk of including marginally important files. An easy trade-off.<p>Then I paste the subset of files into GPT 5.2 Pro, and give it $TASK.<p>You could replace the upstream process with N codex sessions instead of N gemini chat windows. It doesn&#x27;t matter.<p>This process can be automated with structured json outputs, but I haven&#x27;t bothered yet.<p>It uses much inference compute. But it&#x27;s better than missing key inputs and wasting time with hallucinated output.",
      "What works best for me using Claude Code is to let the CC engineer its own context. You need to provide it with tools that it can use to engineer its context. CC comes with a lot of tools already (grep, sed, curl, etc), but for specific domain you may want to add more, e.g., access to a database, a cms, a parser for a bespoke language, etc.<p>With these i&#x27;ll mostly just give it questions: what are some approaches to implement x, what are the pros and cons, what libraries are available to handle x? What data would you need to create x screen, or y report? And then let it google it, or run queries on your data.<p>I&#x27;ll have it create markdown documents or skills to persist the insights it comes back with that will be useful in the future.<p>LLMs are pretty good at plan&#x2F;do&#x2F;check&#x2F;act: create a plan (maybe to run a query to see what tables you have in your database), run the query, understand the output, and then determine the next step.<p>Your main goal should be to enable the PDCA loop of the LLM through tools you provide.",
      "Tool calling + recursion seems to be the answer. Two tools are for manipulating the logical call stack - call&#x2F;return. The trick is to not permit use of any meaningful tools at the root of recursion, but to always make their descriptions available. For instance, the root can&#x27;t QueryWidgets or ExecuteShell, but any descendant of it can.<p>These constraints result in token-hungry activity being confined to child scopes that are fully isolated from their parents. The only way to communicate between stack frames is by way of the arguments to call() and return(). Theoretically, recursive dispatch gives us exponential scaling of effective context size as we descend into the call graph. It also helps to isolate bad trips and potentially learn from them.",
      "This blog explains context folding ie tool calling and recursion - <a href=\"https:&#x2F;&#x2F;www.primeintellect.ai&#x2F;blog&#x2F;rlm\" rel=\"nofollow\">https:&#x2F;&#x2F;www.primeintellect.ai&#x2F;blog&#x2F;rlm</a>",
      "We ran into this while building GTWY.ai. What worked for us wasn’t trying to keep a single model “continuously informed”, but breaking work into smaller steps with explicit context passed between them. Long-lived context drifted fast. Short-lived, well-scoped context stayed predictable."
    ],
    "full_text": null
  },
  {
    "title": "The <Geolocation> HTML Element",
    "url": "https://developer.chrome.com/blog/geolocation-html-element",
    "source": "hn",
    "summary": "",
    "comments": [
      "This might be easier than refusing permission every time - it sounds like I can just not click it.  I really dislike location permission things.  I don&#x27;t know what location will be shared, I don&#x27;t use anything that needs a precise location, and I don&#x27;t ever want to share my actual location.  If location permission things showed me a map with where they think I am and let me click a (vague) location to share, I might use them, but currently to find nearest stores or whatever I just type in a postcode or use their map.<p>Edit: this has prompted me to go find a way to turn off location permission requests in the browser settings.  It turns out you can do it under Privacy and Security &gt; Site Settings in Firefox and Chrome.",
      "This seems pretty sketchy, and I don&#x27;t really understand what prevents a website from  clickjacking.<p>The original flow is awkward, but also renders the permission element in a location that can&#x27;t be clickjacked, thus offering some protection from geolocation.",
      "This mostly changes how location is requested, not what you can do with it. Instead of imperative JS calls, location access becomes declarative in HTML, which gives browsers more context for permission UX and auditing. Your app logic, data flow, and fallbacks don’t change, and you’ll still need JS to actually use the location. Think of it as a cleaner permission and intent layer, not a new geolocation capability.",
      "I&#x27;m a bit confused about how it actually works, and somehow they decided to not include a demonstration video.<p>If clicking on it <i>does</i> trigger a location permission prompt: what&#x27;s the point? The &quot;issues&quot; with prompts getting denied can already be solved by web developers doing this themselves, rather than just blindly firing off a request on page load.<p>If clicking on it <i>does not</i> trigger a location permission prompt: have we forgotten about the Line Of Death [0]? Clicking random website-styled elements should <i>never</i> result in dangerous actions being taken - and leaking the user&#x27;s physical location is <i>definitely</i> dangerous. Sure, they are trying to restrict the styling, but that&#x27;s a fools&#x27; errant: somebody will just make a browser game where the button <i>looks</i> to refer to something ingame, but actually leak your real-world location.<p>Besides, who&#x27;s actually asking for this? Location is perhaps useful for Google Maps-like websites to save you a few seconds of scrolling, but in practice it has mostly been spammy websites trying to get me to &quot;subscribe to local news&quot;. Making geolocation easier is the last thing I want in my browser!<p>[0]: <a href=\"https:&#x2F;&#x2F;textslashplain.com&#x2F;2017&#x2F;01&#x2F;14&#x2F;the-line-of-death&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;textslashplain.com&#x2F;2017&#x2F;01&#x2F;14&#x2F;the-line-of-death&#x2F;</a>",
      "This is pretty cool. But what gets me really excited is the new generic &lt;Permission&gt;[0] element. I had to implement a webcam element one time for some CV pet project and I had a lot of trouble getting the basic api to just work (Highly likely a skill issue). So seeing that this will also expand to webcam and other IO  seems like a really good UX improvement.<p>- [0] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;WICG&#x2F;PEPC&#x2F;blob&#x2F;main&#x2F;explainer.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;WICG&#x2F;PEPC&#x2F;blob&#x2F;main&#x2F;explainer.md</a>",
      "Contextual permissions are a big improvement over early and uncertain prompts.  I will never agree to grant my permission when first loading a page, however, I may do so if intentionally activating a map widget.  At least then I understand the context by which it&#x27;s being asked, and can make a more informed decision.",
      "I&#x27;m curious to why the polyfill example uses unpkg.com. It is quite unreliable and has broken sites many times.<p>jsdelivr.com is much more reliable (Multi-CDN, Multi-DNS). Comparison: <a href=\"https:&#x2F;&#x2F;www.jsdelivr.com&#x2F;unpkg\" rel=\"nofollow\">https:&#x2F;&#x2F;www.jsdelivr.com&#x2F;unpkg</a><p>I am not affiliated in anyway to jsdeliver or unpkg. I simply used to be a user on unpkg.",
      "Why not just expose a GeoLocationEvent and call it a day? why add another element people will wrap anyway?...",
      "Main purpose of this seems to offer a way for undoing &quot;previously blocked location access&quot; by the user.<p>&gt; If a prompt appears unexpectedly, users may block it reflexively or accidentally, unaware that this decision creates a permanent block that is difficult to reverse. This context gap—rather than the feature itself—is a primary driver of high denial rates.<p>&gt; If a user previously blocked location access when browsing a site (perhaps by accident or lack of context), clicking the element triggers a specialized recovery flow. This helps them re-enable location at the moment when they actually want to use location, without the friction of navigating deep into the browser&#x27;s site settings.<p>Google sees &quot;high denial rates&quot; when they try ask users for their geolocation. This is a problem for Google&#x27;s customers, the advertisers. So they introduce this &lt;geolocation&gt; HTML tag so that dark patterns can be employed to trick users into permanently sharing location even though they have blocked location sharing before.<p>If the Google engineers who are working on this feature would actually give a damn about users who decided to block geolocation access, this feature would be designed as a &quot;temporary access to geolocation for duration of browser session&quot;.<p>So basically it is all about more tracking and less data privacy.<p>It&#x27;s overdue that skilled engineers provide better solutions than this crap, but of course it&#x27;s much easier to be apolitical and become a millionaire working for a bunch of tech bros who visited Epstein&#x27;s island.",
      "The demo crashes Chrome on Android for me.<p><a href=\"https:&#x2F;&#x2F;permission.site&#x2F;geolocation_element.html\" rel=\"nofollow\">https:&#x2F;&#x2F;permission.site&#x2F;geolocation_element.html</a>"
    ],
    "full_text": null
  },
  {
    "title": "Native ZFS VDEV for Object Storage (OpenZFS Summit)",
    "url": "https://www.zettalane.com/blog/openzfs-summit-2025-mayanas-objbacker.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "I am curious about the inverse, using the dataset layer, to implement some higher level things like objects for an S3 compatible storage or pages directly for an RDBMS.  I seem to remember hearing rumblings about that but it is hard to dredge up.",
      "How suitable would this be as a zfs send target to back up your local zfs datasets to object storage?",
      "FS metrics without random IO benchmark are near meaningless, sequential read is best case for basically every file system and it&#x27;s essentially &quot;how fast you can get things from S3&quot; in this case",
      "Exciting stuff, but will this be merged? I remember another similar effort that went nowhere because the company decided to not proceed with it",
      "Could someone possibly compare this to <a href=\"https:&#x2F;&#x2F;www.zerofs.net&#x2F;nbd-devices\" rel=\"nofollow\">https:&#x2F;&#x2F;www.zerofs.net&#x2F;nbd-devices</a> (&quot;zpool create mypool &#x2F;dev&#x2F;nbd0 &#x2F;dev&#x2F;nbd1 &#x2F;dev&#x2F;nbd2&quot;)",
      "How does this relate to the work presented a few years ago by the ZFS devs using S3 as object storage? <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;opW9KhjOQ3Q?si=CgrYi0P4q9gz-2Mq\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;opW9KhjOQ3Q?si=CgrYi0P4q9gz-2Mq</a>",
      "That’s brilliant! Always amazed at how zfs keeps morphing and stays relevant!",
      "I do not get it.<p>Why would I use zfs for this? Isn&#x27;t the power of zfs that it&#x27;s a filesystem with checksum and stuff like encryption?<p>Why would I use it for s3?"
    ],
    "full_text": null
  },
  {
    "title": "The Influentists: AI hype without proof",
    "url": "https://carette.xyz/posts/influentists/",
    "source": "hn",
    "summary": "",
    "comments": [
      "My anxiety about falling behind with AI plummeted after I realized many of these tweets are overblown in this way. I use AI every day, how is everyone getting more spectacular results than me? Turns out: they exaggerate.<p>Here are several real stories I dug into:<p>&quot;My brick-and-mortar business wouldn&#x27;t even exist without AI&quot; --&gt; meant they used Claude to help them search for lawyers in their local area and summarize permits they needed<p>&quot;I&#x27;m now doing the work of 10 product managers&quot; --&gt; actually meant they create draft PRD&#x27;s. Did not mention firing 10 PMs<p>&quot;I launched an entire product line this weekend&quot; --&gt; meant they created a website with a sign up, and it shows them a single javascript page, no customers<p>&quot;I wrote a novel while I made coffee this morning&quot; --&gt; used a ChatGPT agent to make a messy mediocre PDF",
      "Off topic, but AI hype is appearing in hardware and consumer electronics. I just bought a rechargeable hand warmer that claims to have an &quot;... Have Intelligent AI Temperature Control Chips That Can Accurately Control the Temperature,&quot;\nAt least in the early days the Transistor, radios did have them.",
      "You know, there&#x27;s a number of different competing propaganda battles going on:<p>1) There&#x27;s the people and companies that stand to make money and build up companies by convincing people to buy their ai projects, hyping up ai, etc.<p>2) There&#x27;s companies and nation states trying to destroy competitor&#x27;s &#x2F; other country&#x27;s ai efforts, turn citizens against them, in order to gain an advantage&#x2F;lead in the race.<p>3) There&#x27;s, conversely, nation states that want to boost up and promote their ai industry in order to win the race rather than other countries winning (assuming there&#x27;s a &quot;win&quot; at the end, like AGI, which I don&#x27;t believe there is).<p>4) Normal citizens that have been ideologically brainwashed one way or the other, and so are going online to argue in a culture war for their beliefs &#x2F; &quot;side&quot;.<p>5) People posting crazy takes on ai, one way or the other, to get clicks &#x2F; money on their articles.<p>The whole topic is awash in serious propaganda. Effectively the only path forward is believing what you yourself know for sure, from your direct experience &#x2F; knowledge.",
      "There are two major reasons people don&#x27;t show proof about the impact of agentic coding:<p>1) The prompts&#x2F;pipelines portain to proprietary IP that may or may not be allowed to be shown publically.<p>2) The prompts&#x2F;pipelines are boring and&#x2F;or embarrassing and showing them will dispel the myth that agentic coding is this mysterious magical process and open the people up to dunking.<p>For example in the case of #2, I recently published the prompts I used to create a terminal MIDI mixer (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;minimaxir&#x2F;miditui&#x2F;blob&#x2F;main&#x2F;agent_notes&#x2F;PROMPTS.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;minimaxir&#x2F;miditui&#x2F;blob&#x2F;main&#x2F;agent_notes&#x2F;P...</a>) in the interest of transparency, but those prompts correctly indicate that I barely had an idea how MIDI mixing works and in hindsight I was surprised I didn&#x27;t get harrassed for it. Given the contentious climate, I&#x27;m uncertain how often I will be open-sourcing my prompts going forward.",
      "Doesn&#x27;t the existence of consumer products like ChatGPT indicate that LLMs aren&#x27;t able to do human-level work? If OpenAI really had a digital workforce with the capabilities of ~100k programmers&#x2F;scientists&#x2F;writers&#x2F;lawyers&#x2F;doctors etc, wouldn&#x27;t the most profitable move be to utilize those &quot;workers&quot; directly, rather that renting out their skills piecemeal?",
      "Can someone please explain to me how I was able to construct this DSL in as short a time as I did?<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;webpipe\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;webpipe</a><p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;webpipe-lsp\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;webpipe-lsp</a><p>Fully featured LSP (take a look at the GIFs in the repo), step debugger, BDD-testing framework built into the language and runtime itself (novel!), asynchronous&#x2F;join in pipelines (novel!), middleware for postgres, jq, javascript, lua, graphql (with data loaders), etc. It does quite a bit. Take a look at my GitHub timeline for an idea of how long this took to build.<p>It is 100% an experiment in language and framework design. Why would I otherwise spend years of my life handcrafting something where I just want to see how my harebrained ideas play out when actualized?<p>I would absolutely love to talk about the <i>language itself</i> rather than how it was made but here we are.<p>And I wrote my own blog in my own DSL. Tell me that&#x27;s not just good old fashioned fun.",
      "I agree, if the benefits are so large, there should be clearer evidence (that isn&#x27;t, &quot;trust me, just use it&quot;).<p>That said, I use Antigravity with great success for self hosted software. I should publish it.<p>Why haven&#x27;t I?<p>* The software is pretty specific to my requirements.<p>* Antigravity did the vast amount of work, it feels unworthy?<p>* I don&#x27;t really want a project, but that shouldn&#x27;t really stop me pushing to a public repo.<p>* I&#x27;m a bit hesitant to &quot;out&quot; myself?<p>Nonetheless, even though I&#x27;m not the person, I&#x27;m surprised there isn&#x27;t more evidence out there.",
      "I’ve taken to calling this (in my mind) the Age of the Sycophants.  In politics, in corporate life, in technology and in social media, many people are building a public life around saying things that others want to hear, with demonstrably zero relationship to truth or even credibility.",
      "This is a strage phenomenon where people get excited by the mere fact that someone else is excited by something which is not directly visible to the spectator. It works well in horror movies and as it seems with AI hype.",
      "Being respected inside big companies has little to do with engagement on social media. Most of the best engineers are working hands-down. Arguably shitposting on the internet may have a negative correlation with technical ability inside Google.<p>One of the times I think the draconian approach Apple has towards employee speaking as an associate of the firm without explicit authorization is the correct one."
    ],
    "full_text": null
  },
  {
    "title": "Ski map artist James Niehues, the 'Monet of the mountains' (2021)",
    "url": "https://adventure.com/ski-map-artist-james-niehues/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I think it&#x27;s wrong to mention ski maps without crediting Pierre Novat (1), perhaps the original creator of this style (2) since 1962. But what is more important is that Novat actually took the work of Heinrich Berann (3) for Val d&#x27;Isère (4) and amended it that result is what we know as ski maps today.<p>There is some debate about who was first, Berann or Novat, but either way, this was 40 years before James Niehues from the article even started working in this style.<p>1. <a href=\"https:&#x2F;&#x2F;fr.wikipedia.org&#x2F;wiki&#x2F;Pierre_Novat\" rel=\"nofollow\">https:&#x2F;&#x2F;fr.wikipedia.org&#x2F;wiki&#x2F;Pierre_Novat</a> (FR)<p>2. <a href=\"http:&#x2F;&#x2F;tropfragile.free.fr&#x2F;galerie&#x2F;Photos.html\" rel=\"nofollow\">http:&#x2F;&#x2F;tropfragile.free.fr&#x2F;galerie&#x2F;Photos.html</a><p>3. <a href=\"https:&#x2F;&#x2F;www.berann.com&#x2F;panorama&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.berann.com&#x2F;panorama&#x2F;</a><p>4. <a href=\"https:&#x2F;&#x2F;www.researchgate.net&#x2F;figure&#x2F;Left-of-the-dashed-line-is-the-original-panorama-map-for-Val-dIsere-ski-resort-by_fig4_361101436\" rel=\"nofollow\">https:&#x2F;&#x2F;www.researchgate.net&#x2F;figure&#x2F;Left-of-the-dashed-line-...</a>",
      "Being used to European style ski maps, I don’t really understand why you would paint a ski map. A ski map is a map and should convey all the information you need without being overwhelming. I don’t get it why it would show different trees or why the colors need to be natural. A map is a man made thing, nature is outdoors. There is no need to reflect it on the mapy<p>I appreciate the artwork though.",
      "This is from a few years ago. Apparently he retired: <a href=\"https:&#x2F;&#x2F;www.kuer.org&#x2F;arts-culture-entertainment&#x2F;2021-10-22&#x2F;james-niehues-on-map-making-art-and-retirement\" rel=\"nofollow\">https:&#x2F;&#x2F;www.kuer.org&#x2F;arts-culture-entertainment&#x2F;2021-10-22&#x2F;j...</a><p>Since I&#x27;ve been skiing this has been how I&#x27;ve experienced all the terrain. His maps just are skiing to me. But, interestingly, with the rise of smartphones&#x2F;gps apps like Slopes and the late lamented Fatmap have started to move the ski world towards 3d terrain maps and away from these artistic maps.<p>I have a side project I&#x27;ve been meaning to dust off that translated GPS coordinates to locations on Niehues maps. I got it working reasonably well but the distortions were significant enough that it needs a <i>lot</i> of control points to do the mapping.",
      "Love everything he&#x27;s ever done. Phones and skiing don&#x27;t mix. Dropping a paper trail map off the lift won&#x27;t ruin your run. Dropping your phone will. Why spend time thinking about wireless, bars of service etc. when you can look at ART to plan your next downhill ADVENTURE???",
      "This is so fascinating. I have been snowboarding for at least 15 years and had no idea that this was done by hand. The maps are so clear, specifically when you have multiple mountains with many one-way slopes across them. Next time I mindlessly throw away these art pieces, I will remember “Monet of the mountains”. Also will definitely share this story with someone on the chair lift ride.",
      "I bought the book of his work that was on kickstarter a few years ago, because ski maps are something I&#x27;ve always kind of loved.<p>Honestly it was a little disappointing -- the maps in the book are just the paintings of the mountains&#x2F;terrain, no trail&#x2F;lift&#x2F;amenity markings, and thumbing threw it for a little while, they all kind of look exactly the same.",
      "[dead]"
    ],
    "full_text": null
  },
  {
    "title": "Eigent: An open source Claude Cowork alternative",
    "url": "https://github.com/eigent-ai/eigent",
    "source": "hn",
    "summary": "",
    "comments": [
      "What is open source exactly? The typescript client? Because it seems to just hook into $B apis with some credits awarded and has a pricing page.<p>We&#x27;re throwing around the open-source label a little too wide for the actual goods delivered I find...",
      "Has anybody tried this? Probably won&#x27;t make sense to use Opus with this due to the API costs, but other models may work well perhaps?"
    ],
    "full_text": null
  },
  {
    "title": "Ask HN: How do you safely give LLMs SSH/DB access?",
    "url": "https://news.ycombinator.com/item?id=46620990",
    "source": "hn",
    "summary": "",
    "comments": [
      "This is the absolutely worse idea possible.  The answer is that you don’t.  You create a database user that has read only rights and you allow Claude to use that user.<p>You could do the same for your SSH user.<p>I’m assuming your database doesn’t have PII, if it does even that would be out of the question unless you gave the database user only access ti certain tables.<p>Now that I think about it, that’s not even a good idea since a badly written select statement can cause performance issues.",
      "Our solve is to allow it to work with a local dev database and it&#x27;s output is a script. Then that script gets checked into version control (auditable and reviewed). Then that script can be run against production. Slower iteration but worth the tradeoff for us.<p>Giving LLM even read access to PII is a big &quot;no&quot; in my book.<p>On PII, if you need LLMs to work on production extracted data then <a href=\"https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;presidio\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;presidio</a> is a pretty good tool to redact PII.  Still needs a bit of an audit but as a first pass does a terrific job.",
      "I am very passionate about this question - so much so that I happened make a blog post about it yesterday!<p>I recommend giving LLMs credentials that are extremely fine-grained, where the credentials can only permit the actions you want to allow and not permit the actions you don&#x27;t want to allow.<p>Often, it may be hard or impossible to do this with your database settings alone - in that case, you can use proxies to separate the credentials the LLM&#x2F;agent has from the credentials that are actually made to the DB. The proxy can then enforce what you want to allow or block.<p>SSH is trickier because commands are mixed in with all the other data going on in the bytestream during your session. I previously wrote another blog post about just how tricky enforcing command allowlists can be as well: <a href=\"https:&#x2F;&#x2F;www.joinformal.com&#x2F;blog&#x2F;allowlisting-some-bash-commands-is-often-the-same-as-allowlisting-all-with-claude-code&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.joinformal.com&#x2F;blog&#x2F;allowlisting-some-bash-comma...</a>. A lot of developer CLI tools were not designed to be run by potentially malicious users who can add arbitrary flags!<p>I also have really appreciated simonw&#x27;s writing on the topic.<p>Disclaimer: I work at Formal, a company that helps organizations use proxies for least privilege.",
      "Don&#x27;t.<p>Among the many other reasons why you shouldn&#x27;t do this, there are regularly reported cases of AIs working around these types of restrictions using the tools they have to substitute for the tools they don&#x27;t.<p>Don&#x27;t be the next headline about AI deleting your database.",
      "I did this recently. Created a Skill that had access to executing very specific ific (reviewed) script for DB interaction, that connects to your a replica&#x2F;anonymised DB, read only user, via VPN, via a jumpbox.",
      "See <a href=\"https:&#x2F;&#x2F;simonwillison.net&#x2F;2025&#x2F;Feb&#x2F;3&#x2F;a-computer-can-never-be-held-accountable&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;simonwillison.net&#x2F;2025&#x2F;Feb&#x2F;3&#x2F;a-computer-can-never-be...</a><p>I&#x27;ll set it loose on a development or staging system but wouldn&#x27;t let it around a production system.<p>Don&#x27;t forget your backups.  There was that time I was doing an upgrade of the library management system at my Uni and I was sitting at the sysadmin&#x27;s computer and did a DROP DATABASE against the wrong db which instantly brought down the production system -- she took down a binder from the shelf behind me that had the restore procedures written down and we had it back up in 30 seconds!",
      "We solved this exact thing for the database layer (postgres for now) with <a href=\"https:&#x2F;&#x2F;tryardent.com\" rel=\"nofollow\">https:&#x2F;&#x2F;tryardent.com</a><p>You can&#x27;t trust any agent to be perfect with a real db so unless you find an infra level way to isolate it, you can&#x27;t get rid of the problem<p>So we built a system that creates copy on write copies of your DB and allocates a copy for each agent run. This means a completely isolated copy of your DB with all your data that loads in under a second but zero blast radius risk to your actual system for the agent to operate on. When you&#x27;re okay with the changes we have a &quot;quick apply&quot; to replay those changes onto your real db<p>Website is a little behind since we just launched our db sandboxing feature to existing customers and are making it public next week :)<p>If you want to try it email me -&gt; vikram@tryardent.com",
      "Use tool calling.  Create a simple tool that can do the calls that are allowed&#x2F;the queries that are allowed.  Then teach the LLM what the tools can do.  Allow it to call the tool without human input.<p>Then it will only stop when it wants to do something the tool can&#x27;t do.  You can then either add that capability to the tool, or allow that one time action.",
      "For database stuff most databases like PostgreSQL have robust permissions mechanisms built in.<p>No need to mess around with regular expressions against SQL queries when you can instead give the agent a PostgreSQL user account that&#x27;s only allowed read access to specific tables.",
      "&gt; Safely<p>You cannot. The best you can ever hope for is creating VM environments, and even then it&#x27;s going to surprise you sometimes. See <a href=\"https:&#x2F;&#x2F;gtfobins.github.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;gtfobins.github.io&#x2F;</a>."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: HyTags – HTML as a Programming Language",
    "url": "https://hytags.org",
    "source": "hn",
    "summary": "",
    "comments": [
      "HTML (and XMLish syntax in general) is LISP syntax (not semantics) in disguise. A tag can be viewed as function application, with the attributes as named arguments and the elements as variadic arguments.<p>The example from the link&#x27;s main page is equivalent to:<p><pre><code>    (button &quot;Say something&quot;)\n    (on_click\n      (selection-insert-after\n        (div &quot;Hello, World &quot;)))\n</code></pre>\n[apparently HN strips all emoji but you get the idea]",
      "Reminds me of ColdFusion. Don&#x27;t recall having a great time using it, though I was very young at the time so maybe my memory is distorted on this.",
      "This seems similar to _hyperscript, except it uses custom tags instead of the &quot;_&quot; attribute. I&#x27;m not sure which approach is better, but personally, I prefer keeping the same document structure and varying behavior through attributes. Easier to rewrite on the fly. Custom tags can be clearer in some cases, but attributes tend to work better with existing HTML and tooling.",
      "I remember when one of the primary criticisms of ColdFusion was programming logic in the form of tags.",
      "Interesting idea. As a product person I&#x27;m immediately thinking about security. how does this handle auth, data validation, etc when backend logic is embedded in HTML?<p>But that said, this could unlock some interesting use cases where security isn&#x27;t the primary concern. Like few internal tools, prototypes, small side projects where the tradeoff might be worth it.",
      "first let me say i applaud you for experimenting and doing something unconventional<p>- thoughts as i was reading this -<p>ok, so we&#x27;re programming via an AST vs syntax<p>I think this is interesting, however there&#x27;s notable downsides - verbosity, dom bloat &amp; debugging<p>A potential upside to this is very odd but interesting meta programming capabilities, since the code should be able to inspect &amp; modify itself fairly easily by inspecting the dom<p>I am inclined to distrust the claim that this reduces complexity as most of the actions are mutation heavy directly to the dom, and the stack based programming is something i struggle to practical examples where it is a significant improvement to mainstream strategies",
      "This looks very interesting! It reminds me of the approach taken by HTMX or Alpine.js, but with deeper control flow logic. In your opinion, what is the main advantage of hyTags over HTMX for developers managing complex UI states?",
      "HTML can be so powerful when used as DOM instead of plain string as is sadly used in most html templating engines on the backend, one example of DOM template engine built by myself <a href=\"https:&#x2F;&#x2F;github.com&#x2F;givanz&#x2F;vtpl\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;givanz&#x2F;vtpl</a>",
      "Neat! Looks like a pretty straightforward way to develop.<p>I&#x27;m a little too enamored with web components to give it more consideration&#x2F;testing, but it looks like it could be great for blue sky&#x2F;green field projects."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: A fast CLI and MCP server for managing Lambda cloud GPU instances",
    "url": "https://github.com/Strand-AI/lambda-cli",
    "source": "hn",
    "summary": "",
    "comments": [
      "[flagged]"
    ],
    "full_text": null
  },
  {
    "title": "Upgrading DrizzleORM logging with AsyncLocalStorage",
    "url": "https://numeric.substack.com/p/upgrading-drizzleorm-logging-with",
    "source": "hn",
    "summary": "",
    "comments": [
      "I built something similar for handling transactions&#x2F;savepoints in drizzle: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;nickdeis&#x2F;drizzle-transaction-context\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;nickdeis&#x2F;drizzle-transaction-context</a><p>Other languages like python and golang have similar concepts, but AsyncLocalStorage has a really nice API suited for async programming. It also pairs really nice with drizzle&#x27;s savepoint implementation since both AsyncLocalStorage and savepoints can be nested."
    ],
    "full_text": null
  },
  {
    "title": "Anthropic Explicitly Blocking OpenCode",
    "url": "https://gist.github.com/R44VC0RP/bd391f6a23185c0fed6c6b5fb2bac50e",
    "source": "hn",
    "summary": "",
    "comments": [
      "The title is misleading if you don’t read the whole text: Anthropic is not blocking OpenCode from the API that they sell.<p>They’ve blocked OpenCode from accessing the <i>private</i> Claude Code endpoints. These were not advertised or sold as usable with anything else. OpenCode reverse engineered the API and was trying to use it.<p>The private API isn’t intended for use with other tools. Any tool that used it would get blocked.",
      "I do admit to feeling some schadenfreude over them reacting to their product being leeched by others.<p>I get it though, Anthropic has to protect their investment in their work. They are in a position to do that, whereas most of us are not.",
      "OpenCode is doing nothing wrong and adversarial interoperability is the cornerstone of hacker ethos.<p>As such, the sentiment in this thread is chilling.",
      "Obviously Anthropic are within their rights to do this, but I don’t think their moat is as big as they think it is. I’ve cancelled my max subscription and have gone over to ChatGPT pro, which is now explicitly supporting this use case.",
      "Everyone goes on and on how &quot;anthtropic has the right to do this&quot;, sure, we also have the right to work around these blocks and fight against behavior that uses their position to create a walled garden and vendor lock-in using anti-competitive pricing and temporary monopoly on the &#x27;best&#x27; model.",
      "Am I understanding it correctly, based on these tweets [1][2], that both Codex and Copilot teams or at least team members mentioned potentially letting people make use of their quotas in third party tools?<p>I really would like further clarification on those points as I would be pretty interested for a product I&#x27;m building if it was indeed made possible.<p>[1] <a href=\"https:&#x2F;&#x2F;x.com&#x2F;jaredpalmer&#x2F;status&#x2F;2009844004221833625\" rel=\"nofollow\">https:&#x2F;&#x2F;x.com&#x2F;jaredpalmer&#x2F;status&#x2F;2009844004221833625</a><p>[2] <a href=\"https:&#x2F;&#x2F;x.com&#x2F;thsottiaux&#x2F;status&#x2F;2009714843587342393\" rel=\"nofollow\">https:&#x2F;&#x2F;x.com&#x2F;thsottiaux&#x2F;status&#x2F;2009714843587342393</a>",
      "This is exactly like an opensource project called OpenVideo would pretend to be a Netflix&#x2F;Prime&#x2F;HBO&#x2F;AppleTV+ client and allowing access to content that way, skipping the official clients.<p>Then they get angry when their use is blocked.<p>Only in this case they can 100% use the service via a paid API.",
      "This is definitely Barbara Streisanding right now. I had never heard of OpenCode. But I sure have now! Will have to check it out. Doubt I’ll end up immediately canceling Claude Code Max, but we’ll see.",
      "i&#x27;ve been on claude code since before they even HAD subscriptions (api only) and since getting max from day 1 - I haven&#x27;t once have assumed that access was allowed outside of CC. anyone who thinks otherwise is leaning into that cognitive dissonance",
      "Soft plug: the team at nori just announced our own CLI today. Most people build on top of the provider layer, but we build on top of the agent layer. This means that you can use your subscriptions, and you get the benefit of getting the best system prompts and tools that the base models were fine tuned with.<p>Cliff posted a show hn earlier today here: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46616562\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46616562</a>"
    ],
    "full_text": null
  },
  {
    "title": "Show HN: ContextFort – Visibility and controls for browser agents",
    "url": "https://contextfort.ai/",
    "source": "hn",
    "summary": "",
    "comments": [
      "P.S.: The extension has as many permissions as Claude in Chrome itself. But, the only network requests from the extension are to posthog, just for us to know which features are being used.<p>Here is a youtube video where I show the network requests of the extension: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=J356Nquxmp4\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=J356Nquxmp4</a><p>To know what posthog collects and how to disable it (change in a single line of code), please refer to this file: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ContextFort-AI&#x2F;ContextFort&#x2F;blob&#x2F;main&#x2F;POSTHOG.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;ContextFort-AI&#x2F;ContextFort&#x2F;blob&#x2F;main&#x2F;POST...</a>"
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Nori CLI, a better interface for Claude Code (no flicker)",
    "url": "https://github.com/tilework-tech/nori-cli",
    "source": "hn",
    "summary": "",
    "comments": [
      "On the flicker free console as well as agent agnostic front, also see BatrachianAI&#x27;s Toad (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;batrachianai&#x2F;toad\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;batrachianai&#x2F;toad</a>). Maybe you two should&#x2F;could collaborate.",
      "So Nori is a wrapper around cli agents? Did I get that right?<p>That’s interesting since it works around the issues OpenCode ran into and lets you use your subscription, but I’m not clear on the downsides. What do you lose with this approach verses using Claude Code directly?"
    ],
    "full_text": null
  },
  {
    "title": "Simple to Ornate and Back Again (2024)",
    "url": "https://josem.co/simple-to-ornate-and-back-again/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "First impressions of Claude Cowork",
    "url": "https://simonw.substack.com/p/first-impressions-of-claude-cowork",
    "source": "hn",
    "summary": "",
    "comments": [
      "This is a nice technical account that we&#x27;re used to seeing from Simon.<p>I get a kick out of the fact that Microsoft has been preciously clinging to the &quot;Copilot&quot; branding and here comes Claude coming saying &quot;Cowork? Good enough for us!&quot;.<p>-<p>Taking a step back, I really would love to see a broader perspective -- an account of someone who is not tech savvy at all. Someone who works a basic desk job that requires basic competency of microsoft word. I&#x27;m so deep into the bubble of AI-adjacent people that I haven&#x27;t taken stock of how this would or could empower those who are under-skilled.<p>We&#x27;ve taken it as truth that those who benefit most from AI are high-skilled augmenters, but do others see some lift from it? I&#x27;d love if anthropic tried to strap some barely-performing administrative assistants into these harnesses and see if there&#x27;s a net benefit. For all I know, it&#x27;s not inconceivable that there be a `rm -rf` catastrophe every other hour.",
      "Author site: <a href=\"https:&#x2F;&#x2F;simonwillison.net&#x2F;2026&#x2F;Jan&#x2F;12&#x2F;claude-cowork&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;simonwillison.net&#x2F;2026&#x2F;Jan&#x2F;12&#x2F;claude-cowork&#x2F;</a>",
      "I worry this is gonna cause even more sensitive&#x2F;privilaged data extrafiltration than currently is happening. And most “normies” won&#x27;t even notice.<p>I know the counterargument is people are already putting in company data via ChatGPT. However, that is a conscious decision. This may happen without people even recognizing that they are “spilling the beans”."
    ],
    "full_text": null
  },
  {
    "title": "Wind power slashed 4.6B euros off electricity bills in Spain last year",
    "url": "https://www.surinenglish.com/spain/wind-power-slashes-billion-euros-off-electricity-bills-20251217082020-nt.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "An interesting thing I learned from reading the article is that Spain is the 4th largest exporter of turbines behind only China, Germany, and Denmark.<p>Reading the other comments, it&#x27;s really a shame we can&#x27;t have a discussion about something happening in the world before it immediately becomes about the US, on topics that are barely relevant.",
      "There are multiple comments in this thread suggesting that the outage in Spain was caused by wind power.<p>This has also been suggested by various politicians and others in front of a microphone or a camera without any basis in fact whatsoever. There is a (by now remote) chance that indeed wind power (or renewables in general) were the primary cause but the evidence points in an entirely different direction, the lack of control authority and undampened oscillations getting out of control. In such a situation various safety protocols dictate that sections of the grid disconnect and go into island mode or switch off altogether. This to prevent damage to the grid and to all of the grid connected devices. As these outages go, I think it was handled extremely well, the main question remaining is what the root cause was and what should be done to avoid a repetition.<p><a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2025_Iberian_Peninsula_blackout\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2025_Iberian_Peninsula_blackou...</a>",
      "It&#x27;s fascinating to see the live electricity sources with Electricity Maps.<p>Here is Spain: <a href=\"https:&#x2F;&#x2F;app.electricitymaps.com&#x2F;map&#x2F;zone&#x2F;ES&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;app.electricitymaps.com&#x2F;map&#x2F;zone&#x2F;ES&#x2F;</a><p>Throughout the day you can clearly see how the wind and sun power starts kicking in, when it&#x27;s raining hydro raises, etc.",
      "I was curious to see how this number was derived and unfortunately the 20.41 euro&#x2F;MWh “reducing effect” figure has absolutely no explanation as to how it was calculated. Given that AEE is a wind industry lobbying organization I suspect this number is picked in a way that is maximally favorable to wind. I really wish they would tell us how this number was arrived at so I could make up my own mind as to how reasonable it is.",
      "That&#x27;s interesting because here in California, $4.6B is slashed off productivity  because of wind.<p>- still angry at pg&amp;e",
      "Without paywall: <a href=\"https:&#x2F;&#x2F;archive.is&#x2F;lV7Ng\" rel=\"nofollow\">https:&#x2F;&#x2F;archive.is&#x2F;lV7Ng</a>",
      "The surinenglish.com site denies access if you don&#x27;t give consent for personalised advertising cookies on the GDPR consent screen.",
      "PG&amp;E bills in California are also going down this year as well.",
      "UK energy consumers cry"
    ],
    "full_text": null
  },
  {
    "title": "OpenAI is partnering with Cerebras to add 750MW of compute in 10B USD deal",
    "url": "https://openai.com/index/cerebras-partnership/",
    "source": "hn",
    "summary": "",
    "comments": [
      "And the data centers created from this initiative will be net positive for the environment and communities, right?  Right?",
      "&gt; real-time AI<p>Guessing the plan might be for voice AI. That stuff needs to be real snappy.",
      "Will be interesting to see how it is integrated. I assume it will be only a small fraction of openai&#x27;s total inference.",
      "&gt; By keeping computation and memory on a single wafer-scale processor, we eliminate the data-movement penalties that dominate GPU systems. The result is up to 15× faster inference, without sacrificing model size or accuracy.<p><a href=\"https:&#x2F;&#x2F;xcancel.com&#x2F;andrewdfeldman&#x2F;status&#x2F;2011542267774021869\" rel=\"nofollow\">https:&#x2F;&#x2F;xcancel.com&#x2F;andrewdfeldman&#x2F;status&#x2F;201154226777402186...</a>",
      "Source for the 10B amount: <a href=\"https:&#x2F;&#x2F;www.cnbc.com&#x2F;2026&#x2F;01&#x2F;14&#x2F;cerebras-scores-openai-deal-worth-over-10-billion.html\" rel=\"nofollow\">https:&#x2F;&#x2F;www.cnbc.com&#x2F;2026&#x2F;01&#x2F;14&#x2F;cerebras-scores-openai-deal-...</a>"
    ],
    "full_text": null
  },
  {
    "title": "Hacking Wheelchairs over Bluetooth",
    "url": "https://www.securityweek.com/researchers-expose-whill-wheelchair-safety-risks-via-remote-hacking/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "FBI raids Washington Post reporter's home",
    "url": "https://www.theguardian.com/us-news/2026/jan/14/fbi-raid-washington-post-hannah-natanson",
    "source": "hn",
    "summary": "",
    "comments": [
      "To clarify why it’s aggressive: federal employees have a legal duty to secure classified information, but everyone else does not.<p>Reporters are not federal employees and it’s not illegal for them to have or discuss classified materials. Most of what Snowden leaked was classified, <i>and remains classified to this day</i>, but you and I can read about it on Wikipedia. The government pursued Snowden because he was legally obligated to protect that info. They did not pursue Barton Gellman because he wasn’t.<p>So in this case the government is raiding the home of someone who did not commit any crime, in the hopes of getting at people who might have. I think it’s not hard to imagine how this concept could get ugly fast.",
      "&quot;Natanson said her work had led to 1,169 new sources, “all current or former federal employees who decided to trust me with their stories”. She said she learned information “people inside government agencies weren’t supposed to tell me”, saying that the intensity of the work nearly “broke” her.&quot;<p>Wow. So they&#x27;re going to plug her phone in to whatever cracking tech they have and pull down the names of everyone who has been helping her tell the story of the destruction of our government. The following question is &quot;what will they do with the names of the people they pull?&quot;. I can only imagine. Horrible. Hopefully she had good OPSEC but she&#x27;s a reporter, not a technologist. I bet enough mistakes were made (or enough vulnerabilities exist) that they&#x27;ll be able to pull down the list.",
      "Keep your eyes on protecting the midterms from interference... re ICE &#x2F; militias etc.\nI encourage governors to call up their State&#x27;s National Guards to protect their State&#x27;s electoral systems from Federal intrusion and extremist militia groups. This move is founded in the most republican of urges: State Sovereignty. (btw, I&#x27;d even consider that as a move in Minneapolis, right now).",
      "Or as some &#x27;uknown&#x27; VP would say: We will protect freedom of speech until the last journalist is behind the bars. That is the price we are willing to pay.",
      "Journalists are the backbone of a healthy democracy.<p>FU USA FU<p>And just to be clear: The biggest military force of the world threatens denmark, scrambles the economy around the world due to sudden politic changes (tarifs) and destroys its own integrity as an ally",
      "I&#x27;d say it&#x27;s not that unusual in totalitarian dictatorships actually.",
      "This is Nathanson&#x27;s recent article (gift link) describing her work and the story that likely triggered the FBI&#x27;s interest. Her reporting tells the stories of federal workers, she&#x27;s not involved in any investigative work beyond interviewing current or former civil servants who feel helpless and lost now that the career that gave them purpose is no longer the same: wapo.st&#x2F;49BQBrh<p><pre><code>  One day, a woman wrote to me on Signal, asking me not to respond. She lived alone, she messaged, and planned to die that weekend. Before she did, she wanted at least one person to understand: Trump had unraveled the government, and with it, her life.\n\n  I called William, feeling panic rise like hot liquid in the back of my throat.\n\n  He told me to stay calm. He told me to send the woman a list of crisis resources, starting with the 988 national suicide hotline. He told me to remember that reporters are not trained therapists or counselors, just human beings doing the best we can.\n\n  “You should try to help, but whatever this woman does or doesn’t do, it may happen regardless of anything you say,” William said. “It’s not up to you.”\n\n  I did what he said, then fell asleep refreshing the app, checking for a reply. The next morning, a message appeared below her name: “This person isn’t using Signal.”</code></pre>",
      "“When populists get into power, the rhetorical discourse frames tend to be used to implement successive autocratic measures, such as limiting opposition through electoral manipulation, thwarting the free press, changing the constitution in their own favor, and circumscribing minority, civil, political, and economic rights. Populists are usually not against electoral democracy per se, but rather at odds with liberal democracy. Since they believe they represent the ‘true people,’ other people’s votes do not really count as legitimate. Consequently, they are hostile to the underlying values and principles of constitutionalism, pluralism, minority rights, and checks and balances.”<p>-Nils Karlson, Economist and poltical scientist, founder of the Ratio Institute in Stockholm, Sweden, former professor of political science at Linköping university, Sweden, visiting fellow at Hoover Institution, Stanford University, etc.",
      "This strengthens my belief that all governments, mafias, urban gangs, and even cliques, are literally all just ancient tribalism manifested in modernity; may the biggest rocks win.",
      "&gt; impair public interest reporting in general.<p>Some administrations may see this as a feature not bug…"
    ],
    "full_text": null
  },
  {
    "title": "Here comes the advertising in AI chatbots",
    "url": "https://www.washingtonpost.com/technology/2026/01/13/advertising-google-ai-mode-chatgpt/",
    "source": "hn",
    "summary": "",
    "comments": [
      "<a href=\"https:&#x2F;&#x2F;archive.is&#x2F;ugEfC\" rel=\"nofollow\">https:&#x2F;&#x2F;archive.is&#x2F;ugEfC</a>",
      "I guess devs won&#x27;t have to worry, they&#x27;re already paying for Claude Max subscriptions."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Harmony – AI notetaker for Discord",
    "url": "https://harmonynotetaker.ai/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Wondering if you plan to keep running the team on Discord forever -- I feel like larger companies who care about operations &amp; privacy&#x2F;security usually move to an enterprise solution like Slack or self-host a tool. Can Harmony join any kind of calls (e.g., Zoom, Google Meet, Discord, Slack, etc.) in the future and implement the same functionality?",
      "This is great!<p>In my team we&#x27;ve used the open source <a href=\"https:&#x2F;&#x2F;craig.chat&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;craig.chat&#x2F;</a> and hooked it up to a Whisper API which lets us (1) control security of the recordings &#x2F; transcripts; and (2) is ultra cheap if you sequence the transcription as bulk rather than real time.<p>Once we have the transcript there is then a pipeline which uses [insert your LLM of choice] and chains together prompts which (1) isolates only work-talk and then (2) produces various summaries for knowledge management &#x2F; issue tracking.",
      "free fire hacking apps headshot",
      "Of all the places to run a team..."
    ],
    "full_text": null
  },
  {
    "title": "X to stop Grok AI from undressing images of real people after backlash",
    "url": "https://www.bbc.co.uk/news/articles/ce8gz8g2qnlo",
    "source": "hn",
    "summary": "",
    "comments": [
      "Funny that they stopped it. They should have prevented it from happening in the first place. It makes it hard to have a meaningful conversation about AI when one of the largest AI company acts like this.",
      "They stopped doing it “in jurisdictions where it is illegal”.",
      "&gt; if an image is of a real person<p>I am not sure I want an AI to be able to determine that though. Just consider me not-real.",
      "&gt; X to stop Grok AI from undressing images of real people after backlash<p>We can&#x27;t see how sexy our leaders are, anymore ? No, that can&#x27;t be."
    ],
    "full_text": null
  },
  {
    "title": "Failed part on UPS plane that crashed in KY failed 4x on other planes previously",
    "url": "https://apnews.com/article/ups-louisville-plane-crash-ntsb-md11-6d4cfff0c3937f847a3ac39809e31c11",
    "source": "hn",
    "summary": "",
    "comments": [
      "Original title &quot;A part that broke on a UPS plane that crashed in Kentucky failed 4 times on other planes years ago&quot; compressed to fit within title limits."
    ],
    "full_text": null
  }
]