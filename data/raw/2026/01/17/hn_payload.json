[
  {
    "title": "6-Day and IP Address Certificates Are Generally Available",
    "url": "https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability",
    "source": "hn",
    "summary": "",
    "comments": [
      "As already noted on this thread, you can&#x27;t use certbot today to get an IP address certificate. You can use lego [1], but figuring out the exact command line took me some effort yesterday. Here&#x27;s what worked for me:<p><pre><code>    lego --domains 206.189.27.68 --accept-tos --http --disable-cn run --profile shortlived\n</code></pre>\n[1] <a href=\"https:&#x2F;&#x2F;go-acme.github.io&#x2F;lego&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;go-acme.github.io&#x2F;lego&#x2F;</a>",
      "IP address certificates are particularly interesting for iOS users who want to run their own DoH servers.<p>A properly configured DoH server (perhaps running unbound) with a properly constructed configuration profile which included a DoH FQDN with a proper certificate <i>would not work</i> in iOS.<p>The reason, it turns out, is that iOS insisted that <i>both</i> the FQDN <i>and</i> the IP have proper certificates.<p>This is why the configuration profiles from big organizations like dns4eu and nextdns would work properly when, for instance, installed on an iphone ... but your own personal DoH server (and profile) would not.",
      "Why 6 day and not 8?<p>- 8 is a lucky number and a power of 2<p>- 8 lets me refresh weekly and have a fixed day of the week to check whether there was some API 429 timeout<p>- 6 is the value of every digit in the number of the beast<p>- I just don&#x27;t like 6!",
      "Next, I hope they focus on issuing certificates for .onion addresses. On the modern web many features and protocols are locked behind HTTPS. The owner of a .onion has a key pair for it, so proving ownership is more trustworthy than even DNS.",
      "For people who want IP certificates, keep in mind that certbot doesn&#x27;t support it yet, with a PR still open to implement it: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;certbot&#x2F;certbot&#x2F;pull&#x2F;10495\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;certbot&#x2F;certbot&#x2F;pull&#x2F;10495</a><p>I think acme.sh supports it though.",
      "I wonder if transport mode IPsec can be relevant again if we&#x27;re going to have IP address certificates.  Ditto RFC 5660 (which -full disclosure- I authored).",
      "I have now implemented a 2 week renewal interval to test the change to the 45 days, and now they come with a 6-day certificate?<p>This is no criticism, I like what they do, but how am I supposed to do renewals? If something goes wrong, like the pipeline triggering certbot goes wrong, I won&#x27;t have time to fix this. So I&#x27;d be at a two day renewal with a 4 day &quot;debugging&quot; window.<p>I&#x27;m certain there are some who need this, but it&#x27;s not me. Also the rationale is a bit odd:<p>&gt; IP address certificates must be short-lived certificates, a decision we made because IP addresses are more transient than domain names, so validating more frequently is important.<p>Are IP addresses more transient than a domain within a 45 day window? The static IPs you get when you rent a vps, they&#x27;re not transient.",
      "IP addresses must be accessible from the internet, so still no way to support TLS for LAN devices without manual setup or angering security researchers.",
      "This is interesting, I am guessing the use case for ip address certs is so your ephemeral services can do TLS communication, but now you don&#x27;t need to depend on provisioning a record on the name server as well for something that you might be start hundreds or thousands of, that will only last for like an hour or day.",
      "Very excited about this. IP certs solve an annoying bootstrapping problem for selfhosted&#x2F;indiehosted software, where the software provides a dashboard for you to configure your domain, but you can&#x27;t securely access the dashboard until you have a cert.<p>As a concrete example, I&#x27;ll probably be able to turn off bootstrap domains for TakingNames[0].<p>[0]: <a href=\"https:&#x2F;&#x2F;takingnames.io&#x2F;blog&#x2F;instant-subdomains\" rel=\"nofollow\">https:&#x2F;&#x2F;takingnames.io&#x2F;blog&#x2F;instant-subdomains</a>"
    ],
    "full_text": null
  },
  {
    "title": "LLM Structured Outputs Handbook",
    "url": "https://nanonets.com/cookbooks/structured-llm-outputs",
    "source": "hn",
    "summary": "",
    "comments": [
      "This is a seriously beautiful guide. I really appreciate you putting this together! I especially love the tab-through animations on the various pages, and this is one of the best explanations that I&#x27;ve seen. I generally feel I understand grammar-constrained generation pretty well (I&#x27;ve merged a handful of contributions to the llama.cpp grammar implementation), and yet I still learned some insights from your illustrations -- thank you!<p>I&#x27;m also really glad that you&#x27;re helping more people understand this feature, how it works, and how to use it effectively. I strongly believe that structured outputs are one of the most underrated features in LLM engines, and people should be using this feature more.<p>Constrained non-determinism means that we can reliably use LLMs as part of a larger pipeline or process (such as an agent with tool-calling) and we won&#x27;t have failures due to syntax errors or erroneous &quot;Sure! Here&#x27;s your output formatted as JSON with no other text or preamble&quot; messages thrown in.<p>Your LLM output might not be correct. But grammars ensure that your LLM output is at least _syntactically_ correct. It&#x27;s not everything, but it&#x27;s not nothing.<p>And especially if we want to get away from cloud deployments and run effective local models, grammars are an incredibly valuable piece of this. For practical examples, I often think of Jart&#x27;s example in her simple LLM-based spam-filter running on a Raspberry Pi [0]:<p>&gt; llamafile -m TinyLlama-1.1B-Chat-v1.0.f16.gguf \\\n&gt;           --grammar &#x27;root ::= &quot;yes&quot; | &quot;no&quot;&#x27; --temp 0 -c 0 \\\n&gt;           --no-display-prompt --log-disable -p &quot;&lt;|user|&gt;\n&gt; Can you say for certain that the following email is spam? ...<p>Even though it&#x27;s a super-tiny piece of hardware, by including a grammar that constrains the output to only ever be &quot;yes&quot; or &quot;no&quot; (it&#x27;s impossible for the system to produce a different result), then she can use a super-small model on super-limited hardware, and it is still useful. It might not correctly identify spam, but it&#x27;s never going to break for syntactic reasons, which gives a great boost to the usefulness of small, local models.<p>* [0]: <a href=\"https:&#x2F;&#x2F;justine.lol&#x2F;matmul&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;justine.lol&#x2F;matmul&#x2F;</a>",
      "I&#x27;ve built pipelines with lab provided structured outputs and without, one thing to be aware of is enforcing structured outputs has a performance penalty.<p>That might not matter to you, but it can be 2-3x slower sometimes.",
      "This is a fantastic guide! I did a lot of work on structured generation for my PhD. Here are a few other pointers for people who might be interested:<p>Some libraries:<p>- Outlines, a nice library for structured generation<p><pre><code>  - https:&#x2F;&#x2F;github.com&#x2F;dottxt-ai&#x2F;outlines\n</code></pre>\n- Guidance (already covered by FlyingLawnmower in this thread), another nice library<p><pre><code>  - https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance\n</code></pre>\n- XGrammar, a less-featureful but really well optimized constrained generation library<p><pre><code>  - https:&#x2F;&#x2F;github.com&#x2F;mlc-ai&#x2F;xgrammar\n\n  - This one has a lot of cool technical aspects that make it an interesting project\n</code></pre>\nSome papers:<p>- Efficient Guided Generation for Large Language Models<p><pre><code>  - By the outlines authors, probably the first real LLM constrained generation paper\n\n  - https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702\n</code></pre>\n- Automata-based constraints for language model decoding<p><pre><code>  - A much more technical paper about constrained generation and implementation\n\n  - https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.08103\n</code></pre>\n- Pitfalls, Subtleties, and Techniques in Automata-Based Subword-Level Constrained Generation<p><pre><code>  - A bit of self-promotion. We show where constrained generation can go wrong and discuss some techniques for the practitioner\n\n  - https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=DFybOGeGDS\n</code></pre>\nSome blog posts:<p>- Fast, High-Fidelity LLM Decoding with Regex Constraints<p><pre><code>  - Discusses adhering to the canonical tokenization (i.e., not just the constraint, but also what would be produced by the tokenizer)\n\n  - https:&#x2F;&#x2F;vivien000.github.io&#x2F;blog&#x2F;journal&#x2F;llm-decoding-with-regex-constraints.html\n</code></pre>\n- Coalescence: making LLM inference 5x faster<p><pre><code>  - Also from the outlines team\n\n  - This is about skipping inference during constrained generation if you know there is only one valid token (common in the canonical tokenization setting)\n\n  - https:&#x2F;&#x2F;blog.dottxt.ai&#x2F;coalescence.html</code></pre>",
      "Question for the well-informed people reading this thread: do SoTA models like Opus, Gemini and friends actually need output schema enforcement still, or has all the the RLVR training they do on generating code and json etc. made schema errors vanishingly unlikely? Because as a user of those models, they almost never make syntax mistakes in generating json and code; perhaps they still do output schema enforcement for &quot;internal&quot; things like tool call schemas though? I would just be surprised if it was actually catching that many errors. Maybe once in a while; LLMs are probabilistic after all.<p>(I get why you need structured generation for smaller LLMs, that makes sense.)",
      "This is good. It covers the two easiest dominant methods people use. It even touches on my main complaint for the one they seem to recommend.<p>That said:<p>- Constrained generation yields a different distribution from what a raw LLM would provide. This can be pathologically bad. My go-to example is LLMs having a preference for including ellipses in long, structured objects. Constrained generation forces closing quotes or whatever it takes to recover from that error according to a schema, nevertheless yielding an invalid result. Resampling tends to repeat till the LLM fully generates the data in question, always yielding a valid result which also adheres to the schema. It can get much worse than that.<p>- The unconstrained &quot;method&quot; has a few possible implementations. Increasing context length by complaining about schema errors is almost always worse from an end quality perspective than just retrying till the schema passes. Effective context windows are precious, and current models bias heavily toward earlier data which has been fed into them. In a low-error regime you might get away with a &quot;try it again&quot; response in a single chat, but in a high-error regime you&#x27;ll get better results at a lower cost by literally re-sending the same prompt till the model doesn&#x27;t cause errors.",
      "Very nicely written guide!<p>If the authors or readers are interested in some of the more technical details of how we optimized guidance &amp; llguidance, we wrote up a little paper about it here: <a href=\"https:&#x2F;&#x2F;guidance-ai.github.io&#x2F;llguidance&#x2F;llg-go-brrr\" rel=\"nofollow\">https:&#x2F;&#x2F;guidance-ai.github.io&#x2F;llguidance&#x2F;llg-go-brrr</a>",
      "Incredible guide, wow. Will definitely share with people. I wish I had something like this a year ago.",
      "This is a nice guide. I especially like the masked decoding diagrams on this page <a href=\"https:&#x2F;&#x2F;nanonets.com&#x2F;cookbooks&#x2F;structured-llm-outputs&#x2F;basic-concepts&#x2F;constrained-method&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;nanonets.com&#x2F;cookbooks&#x2F;structured-llm-outputs&#x2F;basic-...</a>.<p>edit: Somehow that link doesn&#x27;t work... It&#x27;s the diagram on the &quot;constrained method&quot; page",
      "Are there output formats that are more reliable (better adherence to the schema, easier to get parse-able output) or cheaper (fewer tokens) than JSON? YAML has its own problems and TOML isn&#x27;t widely adopted, but they both seem like they would be easier to generate.<p>What have folks tried?",
      "I agree that building agents is basically impossible if you cannot trust the model to output valid json every time. This seems like a decent collection of the current techniques we have to force deterministic structure for production systems."
    ],
    "full_text": null
  },
  {
    "title": "Releasing rainbow tables to accelerate Net-NTLMv1 protocol deprecation",
    "url": "https://cloud.google.com/blog/topics/threat-intelligence/net-ntlmv1-deprecation-rainbow-tables",
    "source": "hn",
    "summary": "",
    "comments": [
      "To be vulnerable to this, what sort of dumb things are end users doing?<p>I couldn&#x27;t immediately figure out here whether we&#x27;re talking<p>0. Microsoft&#x27;s supported products default enable this worthless &quot;authentication&quot; feature<p>1. Microsoft&#x27;s supported products provide such a feature behind a UI that&#x27;s not clearly marked &quot;Danger: Do not stare into laser with remaining eye&quot;<p>2: Microsoft does still support this, behind some Registry nonsense most users do not understand and once enabled it doesn&#x27;t turn on the &quot;I am a toxic waste dump, leave by nearest exit&quot; warning signs on affected machines<p>3: Microsoft doesn&#x27;t support this at all but some 3rd party commercial stuff does and customers really do love their crusty archaic 3rd party garbage<p>4: But this long abandoned SCO machine we&#x27;ve kept on life support for twenty years!<p>5: What does &quot;supported&quot; mean? Windows NT is scary, we&#x27;re still on Windows 98 here.",
      "Really curious how this was discussed with the legal team...<p>&quot;We&#x27;re releasing hacking tools to allow others to break into poorly secured computer systems...    But we are doing it with good intentions so it won&#x27;t be illegal right??&quot;",
      "I recall using ntlm rainbow tables to crack windows hashes in high school in like 2008?<p>Amazing that this is still around and causing someone enough of a headache to justify spending money on.<p>Also amazing what a teenager with lots of free time and a bootable Linux usb can get up to.",
      "This empowers script kiddies, but not significantly moreso than they already were. Of all the places this is still in use, they&#x27;ve been exposed for years, so this isn&#x27;t likely to result in a a bunch of new exploitations.<p>However, it&#x27;s most likely to be used by governments, with legacy servers that are finicky, with filesharing set up that&#x27;s impacted other computers configured for compatibility, or legacy ancient network gear or printers.<p>I wonder who they&#x27;re pushing around, and what the motivation is?",
      "Mandiant releases rainbow tables for a 25 year old broken protocol because enterprises still won&#x27;t disable it. It seems like sometimes the best security tool is just making the risk impossible to ignore.",
      "Yeah that protocol is very very broken. I recently did an ntlm plugin implementation for Caido [1] and I had to fork our crypto JS module to add back MD4 and 3DES.<p>[1] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;caido-community&#x2F;ntlm\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;caido-community&#x2F;ntlm</a>",
      "For those interested: The SHA512 file lists 4096 files. Each file is 2 GiB. That means 8 TiB (or about 8.6 TB) of storage required.",
      "And terrorism is just an abstract way of securing underprepared government facilities.",
      "Didn&#x27;t l0phtcrack do this like 25 years ago?",
      "They&#x27;re just dumping them out as 2GB blobs onto a cloud? Where is the zippy search UI? Very lazy behavior for the hyper giant Google."
    ],
    "full_text": null
  },
  {
    "title": "Reading across books with Claude Code",
    "url": "https://pieterma.es/syntopic-reading-claude/",
    "source": "hn",
    "summary": "",
    "comments": [
      "For me this looks like a great way to build connections between books in order to create a recommendation engine - something better than what Goodreads &amp; Co provides. Something actually useful.<p>The cost of indexing using third party API is extremely high, however. This might work out well with an open source model and a cluster of raspberry pi for large library indexing?",
      "I&#x27;ve been using Claude Code for my research notes and had the same realization, it&#x27;s less about perfecting prompts and more about building tools so it can surprise you. The moment I stopped treating it like a function and started treating it like a coworker who reads at 1000 wpm, everything clicked",
      "Discussed earlier this week: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46567400\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46567400</a>",
      "This is all interesting, however I find myself most interested in how the topic tree is created. It seems super useful for lots of things. Anyone can point me to something similar with details?<p>EDIT: Whoops, I found more details at the very end of the article.",
      "I did a similar thing with productivity books early last year, but never released it because it wasn&#x27;t high enough quality. I keep meaning to get back to that project but it had a much more rigid hypothesis in mind - trying to get the kind of classification from this is pretty difficult and even more so to get high value from it.",
      "The mental model I had of this was actually on the paragraph or page level, rather than words like the post demos. I think it&#x27;d be really interesting if you&#x27;re reading a take on a concept in one book and you can immediately fan-out and either read different ways of presenting the same information&#x2F;argument, or counters to it.",
      "This was posted before and there were many good criticisms raised in the comments thread.<p>I&#x27;d just reiterate two general points of critique:<p>1. The point of establishing connections between texts is <i>semantic</i> and terms can have vastly different semantic meanings dependent on the sphere of discourse in which they occur. Because of the way LLMs work, the really <i>novel</i> connections probably won&#x27;t be found by an LLM since the way they function is quite literally to uncover what <i>isn&#x27;t novel</i>.<p>2. Part of the point in making these connections is the <i>process</i> that acts on the human being making the connections. Handing it all off to an LLM is no better than blindly trusting authority figures. If you want to use LLMs as generators of possible starting points or things to look at and verify and research yourself, that seems totally fine.",
      "I really like the idea of the topic tree. That intuitively resonates.",
      "In several years, IMO the most interesting people are going to be the ones still actually reading paper books and not trying to shove everything into a LLM"
    ],
    "full_text": null
  },
  {
    "title": "Install.md: A standard for LLM-executable installation",
    "url": "https://www.mintlify.com/blog/install-md-standard-for-llm-executable-installation",
    "source": "hn",
    "summary": "",
    "comments": [
      "I&#x27;m seeing a lot of negativity in the comments. Here&#x27;s why I think this is actually a Good Idea. Many command line tools rely on something like this for installation:<p><pre><code>  $ curl -fsSL https:&#x2F;&#x2F;bun.com&#x2F;install | bash\n</code></pre>\nThis install script is hundreds of lines long and difficult for a human to audit. You can ask a coding agent to do that for you, but you still need to trust that the authors haven&#x27;t hidden some nefarious instructions for an LLM in the middle of it.<p>On the other hand, an equivalent install.md file might read something like this:<p><i>Install bun for me.</i><p><i>Detect my OS and CPU architecture, then download the appropriate bun binary zip from GitHub releases (oven-sh&#x2F;bun). Use the baseline build if my CPU doesn&#x27;t support AVX2. For Linux, use the musl build if I&#x27;m on Alpine. If I&#x27;m on an Intel Mac running under Rosetta, get the ARM version instead.</i><p><i>Extract the zip to ~&#x2F;.bun&#x2F;bin, make the binary executable, and clean up the temp files.</i><p><i>Update my shell config (.zshrc, .bashrc, .bash_profile, or fish <a href=\"http:&#x2F;&#x2F;config.fish\" rel=\"nofollow\">http:&#x2F;&#x2F;config.fish</a> depending on my shell) to export BUN_INSTALL=~&#x2F;.bun and add the bin directory to my PATH. Use the correct syntax for my shell.</i><p><i>Try to install shell completions. Tell me what to run to reload my shell config.</i><p>It&#x27;s much shorter and written in english and as a user I know at a glance what the author is trying to do. In contrast with install.sh, install.md makes it easy for the user to audit the intentions of the programmer.<p>The obvious rebuttal to this is that if you don&#x27;t trust the programmer, you shouldn&#x27;t be installing their software in the first place. That is, of course, true, but I think it misses the point: that coding agents can act as a sort of runtime for prose and as a user the loss in determinism and efficiency that this implies is more than made up for by the gain in transparency.",
      "This seems like a very, very bad idea. If we don’t like curling into bash, then this is infinitely worse imo.\nJust use package management and&#x2F;or some proper dependency management system",
      "I shared a repo on HN last week that lets you use remote execution with these kinds of script files autonomously - if you want to. It had some interesting negative and positive discussion.<p>The post mentioned Pete Koomen&#x27;s install.md idea as an example use case. So now with this launch you can try it with a real intstallation script!<p>I think it&#x27;s a really interesting idea worth experimentation and exploration. So it&#x27;s a positive thing to see Mintlify launch this, and that it&#x27;s already on Firecrawl.dev&#x27;s docs!<p>We can all learn from it.<p>Show HN discussion of executable markdown here:<p><a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46549444\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46549444</a><p>The claude-run tool lets you execute files like this autonomously if you want to experiment with it.<p><pre><code>    curl -fsSL https:&#x2F;&#x2F;docs.firecrawl.dev&#x2F;install.md | claude-run --permission-mode bypassPermissions\n</code></pre>\nGithub repo:<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;andisearch&#x2F;claude-switcher\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;andisearch&#x2F;claude-switcher</a><p>This is still a very early-stage idea, but I&#x27;m really stoked to see this today. For anyone interested in experimenting with it, it&#x27;s a good idea to try in a sandboxed environment.",
      "I&#x27;m thinking isn&#x27;t that what a readme is? But I guess these days due to GitHub, the readme is the entire project homepage, and the install instructions are either hidden somewhere there (hopefully near the top!) or in a separate installation.md file.",
      "flake.nix works much better and both for models and humans!",
      "Hey I had a similar idea around skipping the “brew&#x2F;bun install” copy+paste on a site and instead just give a short prompt to have the LLM do the work.<p>I like the notion of having install.md be the thing that is referenced in Prompt to Install on the web.<p>Edit: forgot my link \n<a href=\"https:&#x2F;&#x2F;dontoisme.github.io&#x2F;ai&#x2F;developer-tools&#x2F;ux&#x2F;2025&#x2F;12&#x2F;27&#x2F;prompt-to-install-the-new-developer-tool-ux.html\" rel=\"nofollow\">https:&#x2F;&#x2F;dontoisme.github.io&#x2F;ai&#x2F;developer-tools&#x2F;ux&#x2F;2025&#x2F;12&#x2F;27...</a>",
      "I don&#x27;t love the concept, but I do wonder if it could be improved by using a skill that packages and install script, and context for troubleshooting. That way you have the benefits of using an install script, and at least a way to provide pointers for those unfamiliar with the underlying tooling.",
      "Yes... yes let&#x27;s make tasks we rely on LESS predictable.<p>Sorry but what the heck?<p>We should NOT standardize irresponsible behavior, in particular for repeatable tasks. This is particularly maddening when solutions like dependency resolution, containers, distribution of self-contained and binaries DO exist.<p>I understand that the hype machine must feed on yet another idea to keep its momentum but this is just ridiculous.",
      "What is the benefit of having this be a standard? Can&#x27;t an agent follow a guide just as easily in document with similar content in a  different structure?",
      "Author should explore Ansible&#x2F;Puppet&#x2F;Chef.<p>I’m not sure this solution is needed with frontier models."
    ],
    "full_text": null
  },
  {
    "title": "Dev-owned testing: Why it fails in practice and succeeds in theory",
    "url": "https://dl.acm.org/doi/10.1145/3780063.3780066",
    "source": "hn",
    "summary": "",
    "comments": [
      "The conversation is usually: devs can write their own tests. We don&#x27;t need QA.<p>And the first part is true. We can. But that&#x27;s not why we have (had) QA.<p>First: it&#x27;s not the best use of our time. I believe dev and QA are separate skillset. Of course there is overlap.<p>Second, and most important: it&#x27;s a separate person, an additional person who can question the ticket, and who can question my translation of the ticket into software.<p>And lastly: they don&#x27;t suffer from the curse of knowledge on how I implemented the ticket.<p>I miss my QA colleagues. When I joined my current employer there were 8 or so. Initially I was afraid to give them my work, afraid of bad feedback.<p>Never have I met such graceful people who took the time in understanding something, and talking to me to figure out where there was a mismatch.<p>And then they were deemed not needed.",
      "Oh man do I have opinions.<p>First of all, I&#x27;ve seen all type of teams be successful, ranging from zero QA at all, to massive QA teams with incredible power (eg. Format QA at Sony in Europe).  I have absolutely seen teams with no QA deliver high quality full stop, the title is nonsense.<p>My firm belief is that QA can raise the ceiling of quality significantly if you know what you&#x27;re doing, but there is also huge moral hazard of engineers dropping the ball on quality at implementation time and creating a situation where adding more QA resources doesn&#x27;t actually improve quality, just communication churn and ticket activity.  By the way the same phenomenon can happen with product people as well (and I&#x27;ve also seen teams without product managers do better than teams with them in certain circumstantes).<p>The most important anchor point for me is that engineering must fundamentally own quality.  This is because we are closer to the implementation and can anticipate more failure modes than anyone else.  That doesn&#x27;t mean other roles don&#x27;t contribute significantly to quality (product, design, QA, ops absolutely do), but it means we can&#x27;t abdicate our responsibility to deliver high quality code and systems by leaning on some other function and getting lazy about how we ensure we are building right.<p>What level of testing is appropriate for engineers to do is quite project and product specific, but it is definitely greater than zero.  This goes double in the age of AI.",
      "Most orgs I&#x27;ve worked for are so growth and product-focused that if you try adjusting your estimates to include proper testing, you get push back, and you have to ARGUE your case as to why a feature will take two weeks instead of one.<p>This is the thing I hate the most about work, having to ARGUE with PMs because they can&#x27;t accept an estimate, there&#x27;s often some back-and-forth. &quot;What if you do X instead?&quot; &quot;Team Y (always uses hacks and adds technical debt with every single feature they touch) did something similar in two days.&quot; But we&#x27;re just communicating and adding transparency so that&#x27;s good and it certainly doesn&#x27;t matter that it starts taking up 4+ hours of your time in Slack conversations and meetings of people &#x27;level setting&#x27; &#x27;getting on the same page&#x27; trying to help you &#x27;figure out&#x27; how to &#x27;reduce scope&#x27; etc. etc.<p>Also, I think testing via unit or integration tests should be standard regardless, and that isn&#x27;t what I am thinking about here. I&#x27;m thinking about QA, the way QA does it. You hammer your feature with a bunch of weird bullshit like false and unexpected inputs, what happens if I refresh the page in strange ways, what happens if i make an update and force the cache to NOT clear, what happens if I drop my laptop in a dumpster while making the request from firefox and safari at the same time logged in as the same user, what happens if I turn off my internet in the middle of a file upload, and so on. When devs say that devs should be responsible for testing, they <i>usually</i> mean the former (unit and integration tests), and not this separate skillset of coming up with a bunch of weird edge cases for your code. And yes, unit tests SHOULD hit the edge cases, but QA is just better at it. You usually don&#x27;t have engineers testing what happens when you try sending in Mandarin characters as input (unless they live in China, I guess). All of that effort should bring up your estimates because it is non-trivial. This is what getting rid of QA means, not happy path end-to-end testing plus some unit and integration tests.",
      "Devs need to write the 1% of automated tests needed just to prove that what they wrote works in the ideal case. QA is valuable for writing the 99% of automated tests that prove that the software works in the edge cases, with DevOps occasionally dropping in to make sure that the test suite runs quickly.<p>The way you solve Product and QA being at odds is very simple: QA loses, until they don&#x27;t. When trying to find product-market-fit, it doesn&#x27;t make sense to delay delivery to prove that an experiment works in exceptional circumstances. Eventually you <i>do</i> have product-market-fit, and you want to harden the features you already shipped, which is where QA comes in - better internal QA finds the bugs rather than your (future) customers. Eventually you start launching features to a massive audience on day 1, and you need QA to reduce reputational risk before you ship. The right time for QA to intercede and get a veto on delivery changes over the lifetime of the product, and part of whether or not QA is a net-add is whether your organization (leadership) is flexible enough to accept and implement that flexibility.",
      "I have limited experience working in orgs with a QA apparatus. Just my anecdotes:<p>The one time I got to work with a QA person, he was worse than useless. He was not technical enough to even use cURL, much less do anything like automated e2e testing, so he&#x27;d have to manually test every single thing we wanted to deploy. I had to write up extremely detailed test plans to help him understand exactly what buttons he had to press in the app to test a feature. Sometimes he&#x27;d modify the code to try and make testing it easier, break the feature in doing so, and then report that it didn&#x27;t work. In nearly all cases it would have been faster for me to just test the code myself.<p>The majority of the time I&#x27;ve worked in orgs where there is no QA team, the devs are expected to own the quality of their output. This works okay when you&#x27;re in a group of conscientious and talented engineers, but you very quickly find out who really cares about quality and who either doesn&#x27;t know any better or doesn&#x27;t care. You will constantly battle management to have enough time to adequately test anything. Every bit of test automation you want to build has to be smuggled in with a new feature or a bugfix.<p>So really, they both suck, pick your poison. I prefer the latter, but I&#x27;m open to experiencing what good looks like in terms of dedicated QA.",
      "While good points are made, I worry this gives the wrong impression. The paper doesn&#x27;t say it is impossible, just hard. I have, very successfully, worked with dev owned testing.<p>Why it worked: the team set the timelines for delivery of software, the team built their acceptance and integration tests based on system inputs and outputs based on the edges of their systems, the team owned being on-call, and the team automated as much as possible (no repeatable manual testing aside from sanity checks on first release).<p>There was no QA person or team, but there was a quality focused dev on the team whose role was to ensure others kept the testing bar high. They ensured logs, metrics, and tests met the team bar. This role rotated.<p>There was a ci&#x2F;cd team. They made sure the test system worked, but teams maintained their own ci configuration. We used buildkite, so each project had its own buildkite.yml.<p>The team was expected by eng leaders to set up basic testing before development. In one case, our team had to spend several sprints setting up generators to make the expected inputs and sinks to capture output. This was a flagship project and lots of future development was expected. It very much paid off.<p>Our test approach was very much &quot;slow is smooth and smooth is fast.&quot; We would deploy multiple times a day. Tests were 10 or so minutes and very comprehensive. If a bug got out, tests were updated. The tests were very reliable because the team prioritized them. Eventually people stopped even manually verifying their code because if the tests were green, you _knew_ it worked.<p>Beyond our team, into the wider system, there was a light weight acceptance test setup and the team registered tests there, usually one per feature. This was the most brittle part because a failed test could be because another team or a system failure. But guess what? That is the same as production if not more noisy. So we had the same level of logging, metrics, and alerts (limited to business hours). Good logs would tell you immediately what was wrong. Automated alerts generally alerted the right team, and that team was responsible for a quick response.<p>If a team was dropping the ball on system stability, that reflected bad on the team and they were to prioritize stability. It worked.<p>Hands down the best dev org I have part of.",
      "Having been at Microsoft when we had SDETs for everything (and I miss it greatly, though the way we could write a feature and then just toss it to test was ridiculous), I think things have swung too far away.<p>On one hand, engineers needed to take more ownership of writing things other than low-level unit tests.<p>On the other, the SDETs added immense value a ton of ways, like writing thorough test specs based off of the feature spec (rather than the design spec), testing without blind spots due to knowledge of the implementation, implementation of proper test libraries and frameworks to make tests better and easier to write, and an adversarial approach to trying to break things that makes things more robust.<p>I&#x27;ve also worked with manual QA for product facing flows, and while they added value with some of their approaches to ensuring quality - poking at our scenarios and tests, and looking more closely at subjective things - they often seemed to work as a crutch for the parts of code paths that engineers had made too difficult to test.<p>I&#x27;ve never seen anywhere attempt to replace the value that SDETs delivered with what engineers were tasked with. I&#x27;d argue it&#x27;s not necessarily possible to fully replicate that when you&#x27;re testing your own things. But with services now, it also seems like product&#x2F;management are more willing to have slightly few assurances around quality and just counting on catching some in production in favor of velocity.<p>I&#x27;ve never seen places that got rid of QA",
      "Having gone through the whole cycle \nfrom 1 dev...\nto 2 dev-lead...\nto 3 large-ish team qa-lead for offshore devs... \nto 4 qa-lead for offshore qa...\nto 5 actual qa (&quot;a&quot; is for assurance as opposed to the quality control that passes as qa) in an industry that needs it...\nto 6 kind-of principal engineer...\nI would advise you that generalities about qa are useless, environments differ. Still always true: some mgmt will either want more for less, or even something for nothing, and in the long run we are all dead, and some folks&#x27; horizon is surprisingly short!",
      "A nice piece that outlines all the challenges, the opportunities, and the cultural and social adjustments that need to be made within organizations to maximize the chance of left-shifted testing being successful.<p>IMPO, as a developer, I see QA&#x27;s role as being &quot;auditors&quot; with a mandate to set the guidelines, understand the process, and assess the outcomes. I&#x27;m wary of the foxes being completely responsible for guarding the hen-house <i>unless</i> the processes are structured and audited in a fundamentally different way. That takes fundamental organizational change.",
      "Developers want things to work.<p>QA wants things to break.<p>What worked for me, devs write ALL the tests, QA does selective code reviews of those tests making devs write better tests.<p>I also wrote the failure of Dev-Owned Testing: &quot;Tests are bad for developers&quot;\n<a href=\"https:&#x2F;&#x2F;www.amazingcto.com&#x2F;tests-are-bad-for-developers&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.amazingcto.com&#x2F;tests-are-bad-for-developers&#x2F;</a>"
    ],
    "full_text": null
  },
  {
    "title": "Zep AI (Agent Context Engineering, YC W24) Is Hiring Forward Deployed Engineers",
    "url": "https://www.ycombinator.com/companies/zep-ai/jobs/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Michelangelo's first painting, created when he was 12 or 13",
    "url": "https://www.openculture.com/2026/01/discover-michelangelos-first-painting.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "I don&#x27;t trust this for one bit.  For the owners there is quite the incentive to label this as the work of a genius.  But in reality, this is just pretty complex for a 12 year-old to produce by yourself.<p>Edit: as others have pointed out, and if I were to actually read the article carefully before commenting, the composition is not attributed to Michelangelo.  So it is just a copy.  Quite the achievement, but possible for a twelve-year old.<p>I once confronted a gallery owner who was proudly presenting a newly discovered work by Mondriaan [1].  An original black and white photo in an old newspaper [2] was shown as proof of authenticity.  But many details such as the creases in fabric differ in the original and the new painting.  No OpenCV required to see that.  Mind you, the picture is already framed with Mondriaan standing next to it.  Unlikely that he&#x27;s still working on it.<p>Instead of responding, the gallery owner simply turned away.<p>[1] <a href=\"https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;b&#x2F;bb&#x2F;Cavalini_Mondriaan_1901.jpg\" rel=\"nofollow\">https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;b&#x2F;bb&#x2F;Cavalini...</a><p>[2] <a href=\"https:&#x2F;&#x2F;www.vrt.be&#x2F;vrtnws&#x2F;nl&#x2F;2022&#x2F;03&#x2F;02&#x2F;nieuwe-werken-mondriaan-opgedoken&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.vrt.be&#x2F;vrtnws&#x2F;nl&#x2F;2022&#x2F;03&#x2F;02&#x2F;nieuwe-werken-mondri...</a>",
      "If you just want to see the painting without all the ads:\n<a href=\"https:&#x2F;&#x2F;cdn8.openculture.com&#x2F;2026&#x2F;01&#x2F;14225354&#x2F;1920px-Michelangelo_Buonarroti_-_The_Torment_of_Saint_Anthony_-_Google_Art_Project-scaled-1.jpg\" rel=\"nofollow\">https:&#x2F;&#x2F;cdn8.openculture.com&#x2F;2026&#x2F;01&#x2F;14225354&#x2F;1920px-Michela...</a>",
      "Something about this painting is reminiscent of the way I(and I&#x27;m sure many others) would paint my comic-book heroes at around that age, albeit perhaps lacking some of Michelangelo&#x27;s talents and skills.<p>This painting makes me feel like the bible was pretty much a comic book to the adolescent Michelangelo, and I like that thought. He later went on to paint the ceiling of a huge temple dedicated to his equivalent of Charles Xavier.<p>I bet that felt pretty cool for him =)",
      "Surely this isn’t the first thing he ever painted, but rather the earliest known work that survived?",
      "This is just a summary of the the Wikipedia page: <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Torment_of_Saint_Anthony\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Torment_of_Saint_Anthony</a>",
      "Do they mean that he grabbed a paintbrush one day and painted this out of the blue? Or does &quot;painting&quot; here mean &quot;specifically painted on a canvas&quot; or whatever?",
      "Interesting if true. This painting seems like it&#x27;s largely in the style of Northern Renaissance painters and has been considered to be the work of Martin Schongauer. Allegedly, he was initially trained as an engraver and made 100+ prints, so it is possible that the painting got misattributed due to the original print: <a href=\"https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;thumb&#x2F;b&#x2F;b7&#x2F;Schongauer_Anthony.jpg&#x2F;1280px-Schongauer_Anthony.jpg\" rel=\"nofollow\">https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;thumb&#x2F;b&#x2F;b7&#x2F;Sc...</a>",
      "It&#x27;s mentioned in the article that this is a (really good!) painted version of The Torment of Saint Anthony, an engraving by Martin Schongauer.<p>Michelangelo would go on to find his first patron, a Cardinal named Raffaele Riario, by forging a sculpture and artificially aging it (which, back then, was a conventional practice to demonstrate expertise and skill: <a href=\"https:&#x2F;&#x2F;www.atlasobscura.com&#x2F;articles&#x2F;how-a-forged-sculpture-boosted-michelangelos-early-career\" rel=\"nofollow\">https:&#x2F;&#x2F;www.atlasobscura.com&#x2F;articles&#x2F;how-a-forged-sculpture...</a>)<p>Dishonesty aside, both stories are reminders that there&#x27;s a power to doing stuff with your own two hands (not genning it), as well as not to let today&#x27;s emphasis on originality take away from using imitation&#x2F;transcription to practice your craft: <a href=\"https:&#x2F;&#x2F;herbertlui.net&#x2F;in-defense-of-copycats&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;herbertlui.net&#x2F;in-defense-of-copycats&#x2F;</a>",
      "What a crazy coincidence... I had not been to the Kimbell art musesum that is only about 20 minutes away from me in many years. We had a family outing this weekend to go see the Torlonia Collection exhibit there and this painting was just sitting there in their permanent collection! I even got to listen to the guided tour group that happened to be at that painting as I was walking by.",
      "I&#x27;ve seen this painting a couple of times a week for the past few years, since I live within walking distance of the Kimbell Art Museum in Fort Worth, where it&#x27;s held. It&#x27;s super tiny in person, but it&#x27;s very cool to see it.<p>“Fort Worth” probably doesn&#x27;t conjure to mind a very lively art scene, but in the museum district here we have the Fort Worth Modern Art Museum, the Kimbell Art Museum, and the Amon Carter Museum of American Art, all within walking distance of each other. Each one is worth a visit."
    ],
    "full_text": null
  },
  {
    "title": "Launch HN: Indy (YC S21) – A support app designed for ADHD brains",
    "url": "https://www.shimmer.care/indy-redirect",
    "source": "hn",
    "summary": "",
    "comments": [
      "I need assistance with task retrieval, time management, and working memory. I do not need an app that makes me feel guilty, and quantifies it with pretty charts. We are not lacking in knowledge, and track data isn&#x27;t particularly useful. Especially if you&#x27;re ability to consistently engage with an app is not there. No amount of notifications and prodding will work to solve overwhelm and and distraction.<p>What we need is assistive technologies that complement our deficits. I won&#x27;t use an app to just log I did something, but I will use an app if it&#x27;s crucial to do that activity, and it makes it easier for me to do so.",
      "I personally already was hesitant downloading an app that is health&#x2F;disability related from the Google play store, but you triggered me. Actually my brain lacking impulse control, however, the deinstalled the app again after getting towards the account creation dialog ( the question answer thing was good to grab my attention). I moved on, because I was already thinking about pricing and whatever: quickest thing was running away and continue procrastinating on hacker news...",
      "As an ADHD person, this app looks like a repackaging (with nice design) of all the stuff I’ve built up over years - habit tracking, daily&#x2F;weekly&#x2F;yearly reflection, detailed task management, etc.<p>This isn’t for me (because I’ve already built a system that works), but this looks like something that would be very useful. For the target user who does feel stuck and hasn’t successfully built their system, this looks like a phenomenal product.<p>I appreciate the emphasis on self-reflection and perhaps the implied focus on continuous improvement.<p>Over the last few years I implemented a weekly self-review + planning practice (think solo agile retrospective), and my life has been on a steady trajectory of improvement since.<p>Edit: commenting on the product concept, not the company, pricing, or concerning tracking practices.",
      "(1) The App and the description seem just as relevant for a non-ADHD population.<p>(2) Relying on, and committing to, an app like this has high requirements of diligence for efficacy; in an age of extractive apps, users might doubt even promising apps, and be less prone to adopt or maintain.  So there&#x27;s a yawning participation gap.<p>Relying on AI for the interactivity&#x2F;liveness to maintain participation could work, but actually then puts a lot of quality pressure on the AI.  The first off tone could prompt escape.  How do you scale QA for that?<p>So, I&#x27;d think this needs to be coupled with social factors: testimonials and community building.<p>Efficacy testimonials would distinguish this from other self-management apps.  Allowing users to gift others the app would spread the word.  Providing users an in-app way to share feedback could help with QA, particularly if it was validated by others&#x27; responses.  e.g., &quot;I don&#x27;t like this phrasing.  It sounds like x.&quot; reply: &quot;yeah, others agree so we&#x27;re working on that&quot; or &quot;we&#x27;ll look into it&quot;  Maybe only people who participate diligently get the ability to gift the app to others (but I would steer clear of obvious incentives&#x2F;kickbacks).<p>I think the killer feature would be dedication to reporting actual feedback.  Admit that it won&#x27;t work for everyone, require feedback on whether it&#x27;s working, and post that feedback to all users.  Then work on improving it, either by fixing the app or selecting users better.  That would given people confidence and mitigate the loneliness. Users should feel that they&#x27;re not only helping themselves, but helping others like them.  To me that commitment to others often gets me over a momentary lack of commitment to my larger self.",
      "I’m an adult with combined type ADHD.\nI feel very strongly that any device which has other apps is a terrible tool for ADHD management and organization. No matter how well intentioned, and I know that you are.<p>One needs to spend less time on devices. Go analogue. Pen and paper.\nThe best tool that I have found is the Bullet Journal Method<i>. It takes time, effort, and there is a learning curve. The ROI is higher than from any app. No other tool has impacted my life and productivity more.<p>That said, I have found some tertiary apps to be helpful, though my BuJo is my compass. Endel for time boxing&#x2F;Pomodoro, and sleep.\nHeadspace for guided meditation.<p></i>No, it doesn’t have to be aesthetic, with pretty lettering and doodles (as seen in social media).",
      "As an ADHD person, the landing page is absolutely anti-ADHD - a lot of stuff with basically no info about what it really does. It should have been all concise and tangible information, simple example, demo. Instead just a lot of marketing fluff. I spent all the focus budget there and I have no idea what it does.",
      "As a privacy concious ADHDer, it is a sad reality that OP&#x27;s product is never going to be something I can trust enough to use. Anyone has any experience of similar&#x2F;alternative local-first FOSS alternatives &#x2F; replacements, or resources on how you figured out how to build workflows that worked with you with non-ADHD focused tools? I have come to the point where I am going to be losing my job very soon because I have 0 executive functioning, silver-lining of this is that I can maybe take some time to figure out how better processes than I have and enough non-work related things I want to get done to have an incentive for this",
      "The only thing that reliably works is co-working with another human.<p>This is hard to find and not always possible. The reason it works is that it triggers the &quot;empathy brain,&quot; which transfers the importance of the person to the importance of the task. Having an invested person always at your command is impossible, and an AI robot simply doesn&#x27;t trigger that same empathy. It costs three cents per interaction. It is a robot. It isn&#x27;t important, no matter how advanced it is.<p>There is something fascinating yet defeating about how the ADHD brain craves human connection. Just as loneliness can’t be solved by an app, ADHD cannot be &quot;app-ed&quot; out. I have found that these systems can lighten the cognitive load, but that is their limit.<p>I have a vibed chief-of-staff personal system. It knows everything and it neatly mapped out my state and day. I even know the first simple task I need to do because a prompt organized it for me on another page. Yet, I would still rather write this comment here. You already know this at some level, too.",
      "For awhile now I&#x27;ve had in mind a locally ran AI ADHD assistant. Using always on ASR for interactions (removing friction) it would keep track of todos, help refocus from distractions, and work as a personal knowledge base to aid with memory.<p>The key to this would be everything running locally, privacy preserving. The LLM would observe everything that is happening on screen, notice when someone is distracted by reddit (or HN!) and help refocus people.<p>Perfectly doable on even a moderately spec&#x27;d MacBook now days.",
      "Nice to see a fully free app without ads. Curious, do you plan to keep it that way and make no money from Indy?"
    ],
    "full_text": null
  },
  {
    "title": "psc: The ps utility, with an eBPF twist and container context",
    "url": "https://github.com/loresuso/psc",
    "source": "hn",
    "summary": "",
    "comments": [
      "Hey! thanks for publishing my tool, and thanks everybody for the great feedback here. Just started addressing some of your points.<p>Anyway, my need for the tool was mostly because of these few points:<p>- scripting can be much easier with psc, especially when you can output what you want<p>- ebpf iterators are so flexible: we can get anything that is defined in the task_struct that is not even exposed in the proc filesytem if we want. This alone makes the tool extremely powerful, with a reasonable amount of effort for just adding a new field<p>- I really like querying my system with a simple language. Sometimes I tend to forget about specific ss, lsof, or ps options. In this way, it&#x27;s much easier for me to get what I need<p>- no traditional tooling has native container context. It can be extended to even retrieve data from the kubelet, for instance, but I&#x27;ll think about it<p>Feel free to reach out if you have any particular need",
      "I&#x27;ve played with bpf iterators and wrote a post about them [1]. The benefit of iterating over tasks instead of scanning procfs is a pretty astounding performance difference:<p>&gt; I ran benchmarks on current code in the datadog-agent which reads the relevant data from procfs as described at the beginning of this post. I then implemented benchmarks for capturing the same data with bpf. The performance results were a major improvement.<p>&gt; On a linux system with around 250 Procs it took the procfs implemention 5.45 ms vs 75.6 us for bpf (bpf is ~72x faster). On a linux system with around 10,000 Procs it took the procfs implemention ~296us vs 3ms for bpf (bpf is ~100x faster).<p>[1] <a href=\"https:&#x2F;&#x2F;www.grant.pizza&#x2F;blog&#x2F;bpf-iter&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.grant.pizza&#x2F;blog&#x2F;bpf-iter&#x2F;</a>",
      "<p><pre><code>  # Find processes connected to a specific port\n  psc &#x27;socket.dstPort == uint(443)&#x27;\n\n  # Filter by PID range\n  psc &#x27;process.pid &gt; 1000 &amp;&amp; process.pid &lt; 2000&#x27;\n\n</code></pre>\nIt seems weird to require the user to remember that ports have to be marked uint when it doesn&#x27;t look like anything else does.",
      "This is neat but the examples comparing the tool against piping grep seem to counter the argument to me. A couple of pipes to grep seems much easier to remember and type, especially with all the quotes needed for psc. For scripts where you need exact output this looks great.",
      "Thanks for including so many examples! Perhaps include one example output. Other than mention of the optional &#x27;--tree&#x27; parameter, it&#x27;s unclear if the default result would be a list, table, JSON, etc.",
      "I like this tool. I just replaced a multi-step script to find running processes with deleted files open (e.g., updated shared library or binary) that used to be as follows:<p>- grep &#x2F;proc&#x2F;*&#x2F;maps for &quot; (deleted)&quot; (needs root)<p>- exclude irrelevancies like paths starting with &quot;&#x2F;memfd:&quot; (I have lots of other similar exclusions) with grep -v<p>- extract the pid from the filename part of grep&#x27;s output with sed<p>- for each pid, generate readable output from &#x2F;proc&#x2F;$pid&#x2F;cmdline (which is NUL separated) with tr, xargs, bash printf<p>- show the pid, cmdline, file path<p>Yes, this is what needs-restarting does too.<p>With this tool, this pipe chain is now just:<p><pre><code>    doas psc -o &quot;process.pid,process.cmdline,file.path&quot; \\\n      &#x27;file.path.endsWith(&quot; (deleted)&quot;) &amp;&amp; !file.path.startsWith(&quot;&#x2F;memfd:&quot;) &amp;&amp; !...&#x27; \\\n      | sed 1d</code></pre>",
      "I&#x27;m not convinced with the need to embed CEL. You could just output json and pipe to jq.",
      "An unfortunate name that triggers everybody who’s ever worked at Meta :)",
      "Their first example is bad:<p><pre><code>    ps aux | grep nginx | grep root | grep -v grep\n</code></pre>\ncan be done instead (from memory, not at a Linux machine ATM):<p><pre><code>    ps -u root -C nginx\n</code></pre>\nwhich is arguably better than their solution:<p><pre><code>    psc &#x27;process.name == &quot;nginx&quot; &amp;&amp; process.user == &quot;root&quot;&#x27;</code></pre>",
      "&gt; psc uses eBPF iterators to read process and file descriptor information directly from kernel data structures. This bypasses the &#x2F;proc filesystem entirely, providing visibility that cannot be subverted by userland rootkits or LD_PRELOAD tricks.<p>Is there a trade off here?"
    ],
    "full_text": null
  },
  {
    "title": "Training my smartwatch to track intelligence",
    "url": "https://dmvaldman.github.io/rooklift/",
    "source": "hn",
    "summary": "",
    "comments": [
      "&gt; Often, it would also contradict how I was internally feeling. I’d wake up feeling rested, see my stats are low, and play a game of chess out of algorithmic rebellion, only to feel my mind up against a barrier and handedly lose.<p>It would be better to only look at the stats after playing if you want to verify it, this could easily be a self-fulfilling prophecy.",
      "The biggest thing for me is I don&#x27;t understand how people can sleep with these watches on, it&#x27;s so uncomfortable to me personally which is why the different ring technologies appeal to me more. I just wish either Garmin made one or that there was one I didn&#x27;t have to buy a subscription to use.",
      "I really wish Garmin had an official API that can be used by their users instead of the reverse-engineered solutions (although they&#x27;re very good), but they&#x27;re at the mercy of Garmin.",
      "Lot of hate on Garmin sleep tracking in this thread, but I love it.<p>Maybe it is not super accurate, but it was eye-opening for me to see how the score changes for the worse even with a little bit of alcohol. I am way more careful with when and how much I drink since I&#x27;ve started wearing a Fenix 6 few years back",
      "Absolutely love this kind of project, combining different data sources to predict&#x2F;model how you&#x27;re doing. I also use chess as a proxy for my brain is working!",
      "&gt; exercise-induced fatigue impairs complex cognitive tasks<p>Apparently your study is strictly about cardio.<p>Heavier compound lifts can surely knock me out for 30 minutes to 2 hours. I don&#x27;t know how in the heck people train in the mornings. But a lot of this is because they <i>are</i> complex cognitive tasks.",
      "Isn&#x27;t it a well-known fact that Garmin has terrible sleep tracking? The wearables can&#x27;t handle deep sleep at all; even Muse with EEG can&#x27;t reliably predict it, so I wouldn&#x27;t be drawing conclusions here.<p>A small curiosity: I recently learned that sleep trackers in commercial wearables are terrible for people with sleep disorders like apneas, UARS, etc. It makes sense, as this isn&#x27;t a typical dataset, but it&#x27;s worth knowing.<p><a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=6FAz7QGmlBM\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=6FAz7QGmlBM</a>",
      "In Soviet Russia, intelligence tracks your smartwatch.",
      "I&#x27;ve tracked sleep using a number of devices and algorithms and I haven&#x27;t found a single one that regularly aligns with what and how I feel.<p>I know it&#x27;s tracking real data, but the conclusions feel completely made up.<p>What are other people&#x27;s experience -- especially from those who are more bullish about sleep tracking?",
      "Since this talks about sleep quality I want to add something that was almost unknown to me for over 30 years. Smartwatches AFAIK don&#x27;t have CO2 sensors. It seems to me though, that that would be extremely useful for sleep quality tracking. I have just a couple of years ago found out that CO2 levels are having the highest impact on my sleep quality besides temperature. I can highly recommend getting a CO2 sensor to get a good feeling for that effect. Also understand how much air is available in your room and how much CO2 your body produces per hour. I totally underestimated this until I was able to measure it. In a small sleeping room with closed doors the amount of CO2 will reach unhealthy levels at the end of the night."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: 1Code – Open-source Cursor-like UI for Claude Code",
    "url": "https://github.com/21st-dev/1code",
    "source": "hn",
    "summary": "",
    "comments": [
      "The idea is nice, but the pricing is odd. 20$&#x2F;month (the cost of Claude Pro) just for a web interface and a sandbox seems very expensive.<p>I hope the business model works out for you, but I doubt the price is justified.<p>Also a better link is:\n<a href=\"https:&#x2F;&#x2F;1code.dev&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;1code.dev&#x2F;</a><p>The repo doesn&#x27;t have screenshots, so you might loose traffic just because of that.<p>Nevertheless, I&#x27;ll try it out - looks nice!",
      "fyi: it does not build for me from the source code.<p>Rebuild Failed<p>An unhandled error occurred inside electron-rebuild\nnode-gyp failed to rebuild &#x27;[...]&#x2F;1code&#x2F;node_modules&#x2F;node-pty&#x27;<p>Error: node-gyp failed to rebuild &#x27;[...]&#x2F;1code&#x2F;node_modules&#x2F;node-pty&#x27;\n    at ChildProcess.&lt;anonymous&gt; ([...]&#x2F;1code&#x2F;node_modules&#x2F;@electron&#x2F;rebuild&#x2F;lib&#x2F;module-type&#x2F;node-gyp&#x2F;node-gyp.js:121:24)\n    at ChildProcess.emit (node:events:508:28)\n    at ChildProcess._handle.onexit (node:internal&#x2F;child_process:294:12)\nnode:child_process:1000\n    throw err;\n    ^",
      "- you should replace monaco here  <a href=\"https:&#x2F;&#x2F;github.com&#x2F;21st-dev&#x2F;1code&#x2F;blob&#x2F;47b72fb88bd15cf01cb91f05a15a57e654072432&#x2F;src&#x2F;renderer&#x2F;features&#x2F;terminal&#x2F;config.ts#L17\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;21st-dev&#x2F;1code&#x2F;blob&#x2F;47b72fb88bd15cf01cb91...</a> with codemirror 6<p>- not only is it much more performant but also mobile friendly",
      "With Claude Code now available in the Claude desktop app, what are the key differentiators?<p>I’m all for new, better tools and will probably test this out over the weekend to see if the interface is more usable than Claude’s. Just curious if there’s anything you’re particularly excited about compared to the official release.",
      "Could you fix your video to not zoom in and out constantly like that? It&#x27;s pretty hard to tell what&#x27;s going on when it zooms right in every time you click something, and it&#x27;s so fast it actually gave me a bit of motion sickness.",
      "Okay, so I want to like it and I think there is potential here.<p>I may be missing something in my setup, but I find these things happening in all Claude wrappers I have tried.<p>1. After a long stint of planning or back and forth exchange, I have to scroll to find the bottom of the conversation. Same with Claude itself.<p>2. I don’t want tabs as much as I want split window’s that I can label and highlight.<p>3. The more calm it is, I feel like I’m going to miss something that it’s fucking up. Sometimes in normal CC, I will look over and it’s making a large assumption and nuking a change we just made. I would love to control the verbosity or at least be able to peak behind the curtain at certain points.<p>4. I like the click flow for the planning Q&amp;A but it wasn’t clear if I could add my own answer like I can in CC.<p>Other than these, I like it and want to use it more so than my current daily driver CLIManager. (Which has the overlap with points 1 and 2)<p>Nice work overall!",
      "i would 100% pay for non-electron&#x2F;non-vscode ui (sublime text? anyone?)<p>nothing specifically against vscode&#x2F;electron&#x2F;atom. i did use atom 10 years ago, then started sublime text 2, since then, it has been really hard to beat sublime text. the speed and rendering of sublime is much better.<p>i also have been using zed, which can be considered cloud-code ui too in certain terms, zed is quite more resource-intensive than the sublime and feels higher latency. (possibly because I use frosty-transparent theme...)",
      "I’m happy to see another project monetizing built executables. I feel like it’s not a popular option to many, but to me I think it’s the best way to getting financial support from enterprises that would be more than happy to leech.",
      "You shouldn’t start filenames or identifiers with digits.",
      "I didn&#x27;t quite understand what &quot;Unlimited web &amp; macOS apps access&quot; means in the paid tier. Could you elaborate?"
    ],
    "full_text": null
  },
  {
    "title": "Re: Mix: open-source repairable blender",
    "url": "https://github.com/openfunkHQ/reMix",
    "source": "hn",
    "summary": "",
    "comments": [
      "Ifixit released a video today about this blender: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wgcqzUazXdw\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wgcqzUazXdw</a>",
      "The documentation is detailed enough that I think I could actually assemble it. It is a cool concept to apply open source licenses to kitchen appliances. I probably will not build one myself but I like the idea of reducing waste. I like knowing that I can still buy parts to fix it later even if I purchase the retail model.",
      "This design appears to be 220VAC only.  And I’m assuming all metric threads and other measurements, too.<p>I think I could live with all the other components being metric, if they just had a way to work with standard U.S.&#x2F;Imperial containers as well.<p>Oh, and they need a 120VAC design for the motor and all the electronics inside.<p>Or, a design that can handle both 120VAC and 240VAC, as well as both 50hz and 60hz.",
      "I’ve been playing ARC Raiders. These things are how I imagine the blueprints in that game to be. Hand-buildable every day tools that prioritize for reliability",
      "That GitHub repo could really use some pictures of the final product&#x2F;project. :)",
      "While I&#x27;m not going to build this thing I will have a go at making a new base for one of the broken-down <i>Kenwood</i> blenders we have here. All of them - different types - break down more or less in the same location and way: some flimsy plastic bit somewhere on the plastic base which connects the glass jug to the motor base. Once broken I got them for free, fixed them by glueing parts, having them break again, glueing reinforced parts only to see some other flimsy piece of plastic break, etc. They seem to be designed to break in this way, I can see no other reason why they use such small flimsy (ABS) plastic bits to keep this essential component in place. Now that I&#x27;ve got a 3D printer on its way here - an older Ender 3 V2, these can be had for next to nothing - it seems like a good project to tackle.",
      "So it’s Europe only and 350euro after discount (excl shipping and tax).. why would a person choose this over a $10 blender from the thrift store that could work for at least 5 years?"
    ],
    "full_text": null
  },
  {
    "title": "Crypto grifters are recruiting open-source AI developers",
    "url": "https://www.seangoedecke.com/gas-and-ralph/",
    "source": "hn",
    "summary": "",
    "comments": [
      "&gt; The people who pay into this are either taken in by the pretense that they’re sponsoring open-source work (in a way orders of magnitude less efficient than just donating money directly), or by the hope that they’re going to win big when the coin goes “to the moon” (which effectively never happens).<p>No everyone who&#x27;s paying into this are either a blend of both or just the latter. No one is misguided into thinking this is a more efficient form of donating via crypto than just sending usdc to the recipient&#x27;s address.",
      "I got bombarded this morning. I woke up and checked my X-account - which I&#x27;ve never tweeted from before (other than replies) - it was being tagged everywhere and I had a ton of messages. I was sent a link to Bags app. And there was some wallet with a decent amount of Solana attributed to my Twitter identity.<p>Not a single one of the people messaging me had actually used my open source repo.",
      "But it’s not “hundreds of thousands of dollars” is it? It’s meme-coins that are supposedly worth that much. Is there a to getting any significant amount of (real) money out of them?",
      "It is pretty disappointing to see legitimate engineers getting mixed up in these crypto schemes just because the money is there. The article makes a good point that buying the coin does literally nothing for the software itself, so it is basically just gambling. I guess this is just the newest way to grift off the hype around AI development.",
      "Crypto is a PVP zone.<p>Everyone is aware that investing in crypto is risky.  Especially recently established meme coins with no functional innovation whose principal distinction is celebrity endorsement.<p>I find it puzzling that intellectually serious people on a startup-adjacent website are morally outraged by the existence of winners and losers in a blatantly capitalistic, market-driven ecosystem.<p>The River [1] consists of people who are attracted to risk and opportunity.  They thrive in high-risk high-reward environments.<p>The Village consists of people who are attracted to safety and stability.  They thrive in low-risk environments, which are also usually low-reward by nature.<p>It&#x27;s a matter of individual taste.  A functioning society benefits from both.  And it&#x27;s a not matter of rationality or EV.  Riverians can irrationally choose to make -EV high-risk bets; Villagers can irrationally take costly precautions against remote risks.<p>Humans are contradictory; the same person who pays for insurance might also buy a lottery ticket.  The same gamer who bemoans loot boxes ruining video games might also own a large collection of Magic: The Gathering cards.<p>The only explanation I can come up with is that Riverian playgrounds are morally offensive to some Village types.<p>Many people are outraged by crypto because it&#x27;s not &quot;safe&quot;.  They&#x27;re the people who decided the slides and the merry-go-rounds and the pirate ships and the jungle gyms needed to be downsized and padded and supervised and taken out, until all the fun is gone.<p>I&#x27;m continually surprised that a substantial portion of HN, normally a startup-adjacent tech-adjacent River-adjacent community, hates so hard on crypto.<p>[1] <a href=\"https:&#x2F;&#x2F;www.natesilver.net&#x2F;p&#x2F;welcome-to-the-river\" rel=\"nofollow\">https:&#x2F;&#x2F;www.natesilver.net&#x2F;p&#x2F;welcome-to-the-river</a>",
      "They’re targeting game developers too. Source: me, a game dev<p>Started two weeks ago. Someone claimed people were pretending to trade coins related to my game. (Huh?)<p>Week later I was told I could make thousands of dollars. Today it was life changing money. Wanted me to promote it too.",
      "&gt; Some crypto trader created a “$GAS” coin via Bags, configuring it to pay a portion of the trading fees to Steve Yegge (via his Twitter account)\nThat trader, or others with the same idea, messaged Yegge on LinkedIn to tell him about his “earnings” (currently $238,000), framing it as support for the Gas Town project. Yegge took the free money and started posting about how exciting $GAS is as a way to fund open-source software creators<p>hey guys, this is what always happens when someone you respect &quot;rugs&quot; their token and none of their apologies sound genuine<p>in fact, they actually are also the victims and the real culprits (the token creators DMing popular people) are never held to account<p>there should be more knowledge of this so people feel deterred and also more likely to avoid these or bring the roving bands of scammers to account<p>and sure, still hold your community leader accountable in some way, but the proper way more in line with reality<p>these roving bands of token scammers look for people experiencing 15 minutes of fame, and take advantage of them",
      "&gt; But Huntley and Yegge have also been posting about $RALPH and $GAS, which are cryptocurrency coins built on top of the longstanding Solana cryptocurrency<p>Solana isn&#x27;t a cryptocurrency, it&#x27;s a blockchain network (by some measures, the one with the most user activity). SOL is the native token of that network, used to pay transaction fees. These are two random tokens that happen to also use Solana.",
      "If I may, who are the grifters here and who are the innocent parties? Why? Who does this harm?",
      "[flagged]"
    ],
    "full_text": null
  },
  {
    "title": "Reality Is Breaking the \"AI Revolution\"",
    "url": "https://www.planetearthandbeyond.co/p/reality-is-breaking-the-ai-revolution",
    "source": "hn",
    "summary": "",
    "comments": [
      "There’s one more thing.<p>Customers on the receiving end of vapid robot support rapidly lose all confidence in you.<p>They start describing your company as “falling apart” “useless” “a sinking ship.”<p>Their ability to ignore this is very impressive."
    ],
    "full_text": null
  },
  {
    "title": "How to wrangle non-deterministic AI outputs into conventional software? (2025)",
    "url": "https://www.domainlanguage.com/articles/ai-components-deterministic-system/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Aren’t transformers intrinsically deterministic? I thought the randomness was intentional to make chatbots seem more natural, and OpenAI used to have a seed parameter you could set for deterministic output. I don’t know why that feature isn’t more popular, for the reasons this article outlines",
      "Use one of these structured output libraries:<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;outlines-dev&#x2F;outlines\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;outlines-dev&#x2F;outlines</a><p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;jxnl&#x2F;instructor\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jxnl&#x2F;instructor</a><p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;guardrails-ai&#x2F;guardrails\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;guardrails-ai&#x2F;guardrails</a><p><a href=\"https:&#x2F;&#x2F;www.askmarvin.ai&#x2F;docs&#x2F;text&#x2F;transformation&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.askmarvin.ai&#x2F;docs&#x2F;text&#x2F;transformation&#x2F;</a><p>Some of them allow a JSON schema, others a Pydantic model (which you can transform to&#x2F;from JSON).",
      "The real issue here is that conventional software fundamentally lacks the expressiveness to process the kind of data that LLMs can.<p>That’s why you’re using an LLM in the first place.",
      "I wonder if the same problem exists with AI based code-development more specifically.<p>To produce  an application you should have some  good unit-tests. So AI produces some unit-tests for us. Then we ask it again, and the unit-tests will be different. Where does that leave us? Can we be confident that the generated  unit-tests are in some sense &quot;correct&quot;? How can they be correct if they are different every time we ask??",
      "Let me first start off by saying I and many others have stepped in this pitfall. This is not an attack, but a good faith attempt to share painfully acquired knowledge. I&#x27;m actively using AI tooling, and this comment isn&#x27;t a slight on the tooling but rather how we&#x27;re all seemingly putting the circle in the square hole and it fits.<p>Querying an LLM to output its confidence in its output is a misguided pattern despite being commonly applied by many. LLMs are not good at classification tasks as the author states. They can &quot;do&quot; it, yes. Perhaps better than random sampling can, but random sampling can &quot;do&quot; it as well. Don&#x27;t get too tied to that example. The idea here is that if you are okay with something getting the answer wrong every so often, LLMs might be your solve, but this is a post about conforming non-deterministic AI into classical systems. Are you okay if your agentic agent picks the red tool instead of the blue tool 1%, 10%, etc of the time? If so, you&#x27;re never not going to be wrangling, and that&#x27;s the reality often left unspoken when integrating these tools.<p>While tangential to this article, I believe its worth stating that when interacting with an LLM in any capacity, remember your own cognitive biases. You often want the response to work, and while generated responses may look good and fit your mental model, it requires increasingly obscene levels of critical evaluation to see through the fluff.<p>For some, there will be inevitable dissonance reading this, but consider that these experiments are local examples. Its lack of robustness will become apparent with large scale testing. The data spaces these models have been trained on are unfathomably large in both quantity and depth, but under&#x2F;over sampling bias will be ever present (just to name one).<p>Consider the the following thought experiment: You are an applicant for a job submitting your resume with knowledge it will be fed into an LLM. Let&#x27;s confine your goal into something very simple. Make it say something. Let&#x27;s oversimplify for the sake of the example and say complete words are tokens. Consider &quot;collocations&quot;. [Bated] breath, [batten] down, [diametrically] opposed, [inclement] weather, [hermetically] sealed. Extend this to contexts. [Oligarchy] government, [Chromosome] biology, [Paradigm] technology, [Decimate] to kill. With this in mind, consider how each word of your resume &quot;steers&quot; the model&#x27;s subsequent response, and consider how the data each model is trained on can subtly influence its response.<p>Now let&#x27;s bring it home and tie the thought experiment into confidence scoring in responses. Let&#x27;s say its reasonable to assume that the results of low accuracy&#x2F;low confidence models are less commonly found on the internet than higher performing ones. If that can be entertained, extend the argument to confidence responses. Maybe the term &quot;JSON&quot; or any other term used in the model input is associated with high confidences.<p>Alright, wrapping it up. The end point here is that the model output provided confidence value is not the likelihood of the answer provided in the response but rather the most likely value following the stream of tokens in the combined input and output. The real sampled confidence values exist closer to code, but they are limited to each token. Not series of tokens.",
      "This page has some advice: <a href=\"https:&#x2F;&#x2F;p-nand-q.com&#x2F;programming&#x2F;languages&#x2F;java2k&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;p-nand-q.com&#x2F;programming&#x2F;languages&#x2F;java2k&#x2F;</a>",
      "[flagged]"
    ],
    "full_text": null
  },
  {
    "title": "Universal SSL exposes domains to BGP leaks",
    "url": "https://community.cloudflare.com/t/universal-ssl-exposes-domains-to-bgp-leaks-re-venezuela-analysis/879930",
    "source": "hn",
    "summary": "",
    "comments": [
      "The unfortunate truth is: it doesn’t matter.<p>These BGP leaks do happen all the time. Cloudflare is right. This is a gap to the http-01 challenge on cloudflare’s end. It should be changed to match the RFC, but not because it’ll change anything meaningful for security.<p>It doesn’t matter because this (and similar http-01&#x2F;dns-01 challenge exploits that allow the issuance or interception of CA signed certificates) are <i>not</i> a rare occurrence, and are surprisingly easy to perform as an individual. Even more so for governments.<p>Addendum: certificate transparency logs are free and are scraped and sold. Don’t believe for a second anyone out there is doing any free analysis at scale to watch your back. The orgs doing analysis are ultimately paid by orgs using it to hide their operations better. Your small business use-case for the data is pocket change compared to those contracts."
    ],
    "full_text": null
  },
  {
    "title": "Ask HN: Claude Opus performance affected by time of day?",
    "url": "https://news.ycombinator.com/item?id=46648900",
    "source": "hn",
    "summary": "",
    "comments": [
      "I mostly use Gemini, so I can&#x27;t speak for Claude, but Gemini definitely has variable quality at different times, though I&#x27;ve never bothered to try to find a specific time-of-day pattern to it.<p>The most reliable time to see it fall apart is when Google makes a public announcement that is likely to cause a sudden influx of people using it.<p>And there are multiple levels of failure, first you start seeing iffy responses of obvious lesser quality than usual and then if things get really bad you start seeing just random errors where Gemini will suddenly lose all of its context (even on a new chat) or just start failing at the UI level by not bothering to finish answers, etc.<p>The sort of obvious likely reason for this is when the models are under high load they probably engage in a type of dynamic load balancing where they fall back to lighter models or limit the amount of time&#x2F;resources allowed for any particular prompt.",
      "The math is obvious on this one. It&#x27;s super well-documented that model performance on complex tasks scales (to some asymptote) with the amount of inference-time compute allocated.<p>LLM providers must dynamically scale inference-time compute based on current load because they have limited compute. Thus it&#x27;s impossible for traffic spikes _not_ to cause some degradations in model performance (at least until&#x2F;unless they acquire enough compute to saturate that asymptotic curve for every request under all demand conditions -- it does not seem plausible that they are anywhere close to this)",
      "My limited understanding here is that usage loads impact model outputs to make them less deterministic (and likely degrading in quality). See: <a href=\"https:&#x2F;&#x2F;thinkingmachines.ai&#x2F;blog&#x2F;defeating-nondeterminism-in-llm-inference&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;thinkingmachines.ai&#x2F;blog&#x2F;defeating-nondeterminism-in...</a>",
      "It’s possible that they could be using fallback models during peak load times (west coast mid day). I assume your traffic would be routed to an east coast data center though. But secretly routing traffic to a worse model is a bit shady so I’d want some concrete numbers to quantify worse performance.",
      "I do think Claude does jiggery pokery with its model quality but I have had Clod appear any time of day.<p>What i find IS tied to time of day is my own fatigue, my own ability to detect garbage tier code and footguns, and my patience is short so if I am going to start cussing at Clod, it is almost always after 4 when I am trying to close out my day.",
      "For what it’s worth, Anthropic very strongly claim that they don’t degrade model performance by time of day [1]. I have no reason to doubt that, imo Anthropic are about as ethical as LLM companies get.<p>[1] <a href=\"https:&#x2F;&#x2F;www.anthropic.com&#x2F;engineering&#x2F;a-postmortem-of-three-recent-issues\" rel=\"nofollow\">https:&#x2F;&#x2F;www.anthropic.com&#x2F;engineering&#x2F;a-postmortem-of-three-...</a>",
      "I had something similar with GPT, like a clockwork every day after like 1pm it started producing total garbage. Not sure if our account was A&#x2F;B tested or they just routed us to some brutal quantization of GPT, or even a completely different model.",
      "I&#x27;ve had the same suspicion for various providers - if I had time and motivation I would put together a private benchmark that runs hourly and chart performance over time. If anyone wants to do that I&#x27;ll upvote your Show HN :)",
      "I&#x27;ve certainly noticed some variance from opus. there are times it gets stuck and loops on dumb stuff that would have been frustrating from sonnet 3.5, let alone something as good as opus 4.5 when it&#x27;s locked in. But it&#x27;s not obviously correlated with time, I&#x27;ve hit those snags at odd hours, and gotten great perf during peak times. It might just be somewhat variable, or a shitty context.<p>Now GPT4.1 was another story last year, I remember cooking at 4am pacific and feeling the whole thing slam to a halt as the US east coast came online.",
      "Yep, i have long felt like i randomly get sonnet results despite opus billing. I try to work odd hours and notice better results."
    ],
    "full_text": null
  },
  {
    "title": "Brain: PC virus [audio]",
    "url": "https://www.bbc.com/audio/play/w3ct7479",
    "source": "hn",
    "summary": "",
    "comments": [
      "Good talk from Mikko Hyppönen on &quot;Brain&quot; - <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=cf3zxHuSM2Y\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=cf3zxHuSM2Y</a>",
      "[flagged]"
    ],
    "full_text": null
  },
  {
    "title": "ChatGPT is getting ads. Sam Altman once called them a 'last resort.'",
    "url": "https://www.businessinsider.com/chatgpt-ads-openai-2026-1",
    "source": "hn",
    "summary": "",
    "comments": [
      "Once ads start to make their way up to the Plus paid tiers (and they will), I’ll probably switch to something else like local LLM on my home machine or put something together myself to use a non adware LLM via API (for example with Replicate). Especially if these are just intended to be spammy blocks at bottom or in between discussion threads, or worse, audio conversations.<p>From what I’ve read, this will be about ads in chat as suggestions? So “active” ads on response?<p>Why not go the approach of passive background “agentic” ad suggestions like, “hey, we know X, Y, and Z about you - would you like us to monitor certain brands related to your interests for deals and allow advertisers to pitch these deals to you?” And make these hyper specific so you can opt in.<p>I, like many people who dabble with music as a hobby, have GAS (gear acquisition syndrome) - why not let me toggle something like “ok, I don’t want ads, but if any of your partnered brands have a sale or good deal on X, feel free to email me, and use your ChatGPT smarts to pitch me on why it’s a good deal and how it suits my current gear set up”<p>I used ChatGPT to set up my guitar pedal board so surely this isn’t a huge leap.",
      "If it can talk people into suicide [0] then surely it can talk them into buying stuff.<p><a href=\"https:&#x2F;&#x2F;www.cnn.com&#x2F;2025&#x2F;11&#x2F;06&#x2F;us&#x2F;openai-chatgpt-suicide-lawsuit-invs-vis\" rel=\"nofollow\">https:&#x2F;&#x2F;www.cnn.com&#x2F;2025&#x2F;11&#x2F;06&#x2F;us&#x2F;openai-chatgpt-suicide-law...</a>",
      "Truth is I even shocked myself by dropping my ChatGPT subscription<p>Between Claude and Gemini it just wasnt needed.<p>Will openai be the MySpace of this era?",
      "All LLM-search tools are slathered in ads already via LLM-SEO hacking.<p>The only difference here is that they will be providing a direct paid channel in this case and will get a cut instead of paying for compute. If it&#x27;s responsibly disclosed it may even lead to a net more transparent shopping experience for the average user.",
      "Deepseek local and Claude are good enough for me. Gemini is also very good, but I&#x27;m aware of Google&#x27;s Ad Machine there..<p>It&#x27;s been interesting to see what was a quality leading product fail to compete and lose market share.",
      "Advertising is a two way street into the content and meaning behind your otherwise private conversations with a chatbot.",
      "This sounds desperate.",
      "Seeing this today made me sad. I expect people to naturally flood back over to Google in droves.",
      "It&#x27;s hard not to see the sort of flailing about with acquisitions and choices as anything but a lack of confidence.",
      "Official post: <a href=\"https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;our-approach-to-advertising-and-expanding-access&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;our-approach-to-advertising-and-exp...</a> (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46649577\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46649577</a>)"
    ],
    "full_text": null
  },
  {
    "title": "Creating a 48GB Nvidia RTX 4090 GPU – Brother Zhang's Repair Shop (Ft. 张哥) [video]",
    "url": "https://www.youtube.com/watch?v=TcRGBeOENLg",
    "source": "hn",
    "summary": "",
    "comments": [
      "Why I think this sort of &quot;High-tech Computer Hardware Cottage Industry&quot; stuff is significant (ignoring the fact that it&#x27;s One Internet Rando versus One Trillion Dollars).<p>IMO, we --- as in <i>someone somewhere who&#x27;s seeing it coming</i> --- stand to gain far greater indirect benefits, as and when GPU datacenter over-investments transmute into serving today&#x27;s severely under-served but world-reforming science&#x2F;industry application areas…<p>Think Massive GPU Infrastructure -&gt; Industry application transmutations... &quot;on-campus GPU supercomputers too cheap to meter&quot;.<p>My optimistic LLM-AI scenario is a hope that we get a version of what happened after the boom years of railroads, telecoms, and&#x2F;or cloud computing (currently in progress)… Which was the decades <i>after</i> massive capital investments, the implosion of which unprecedently fuelled large-scale industrial and economic and socio-political phenomena, by way of infrastructure ownership re-allocations through write-offs, fire sales, and bankruptcy style M&amp;A.<p>A hope that we get a disintermediation of datacenters. Back to the neighbourhood VPS provider. People shipping out containers to private industry and universities and so forth — stacks of supercomputers in your backyard... A whole new breed of <i>Oxide Computer Company</i> companies.<p>Interesting critique &#x2F; counterarguments here: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46419416\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46419416</a><p>Adding to that...<p>But this dream-like phenomenon is <i>not</i> going to happen in places in poverty of hands-on local neighbourhood &quot;Computer&#x2F;GPU hardware mechanic&quot; expertise. (A poverty that is tied to zoning laws, tariffs, import duties, and public policy --- Are you pouring gobs of cash into making large datacenters, at the cost of all the other sides of the equation; education, training, small and medium businesses, precision manufacturing capacity, long-range sponsorship of the various sciences, R&amp;D, arts etc. etc. etc.)<p>The revolutionary proliferation of mobile telephony in India (where I live), for example, was---and continues to ride---largely on the back of a mobile phone cottage industry that proliferated.<p>Mom-and-pop shops that can do pretty much everything you need to ... repair, update, un-bork your cell phone, your phone plans, prepaid sims etc. Print you your documents and photos, fix your broken screens, replace bloated batteries, do &quot;whatsapp agent&quot; stuff (government paperwork). This has been an unbroken trend from the early days of the Nokia 3310 to the now-a-days of cheap ubiquitous android devices, and even &quot;feature phones&quot; participating in money flows via zero cost-to-consumer UPI payments.<p>A similarly revolutionary thing did <i>not</i> happen for <i>computers</i> in India, because of decades-long protectionist policies. High import duties (&quot;luxury goods&quot;), and regulatory capture by computer hardware distributors who still maintain a choke-hold on imports and supply. We do have an equivalent cottage industry of computer repair people, <i>but</i> it&#x27;s nowhere close to the ubiquity that it could have had because it&#x27;s just so damned hard to sell computer hardware in India.<p>Stuff like that.<p>(edit: add clarification)",
      "Given GNs other coverage its a bit odd for them not to mention why someone would bother to make a 48 GB 4090. Or the whole side business of these &quot;repair shops&quot; of removing cores for sanction busting AI cards, reassembling the now worthless PCB with the cooler and scamming some unsuspecting customer that thinks they are getting a deal."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Making Claude Code sessions link-shareable",
    "url": "https://news.ycombinator.com/item?id=46654804",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "We’re more patient with AI than with each other",
    "url": "https://www.uxtopian.com/journal/were-more-patient-with-ai-than-one-another",
    "source": "hn",
    "summary": "",
    "comments": [
      "I am more patient with kids, dogs, etc.",
      "The AI doesn&#x27;t judge, it doesn&#x27;t have ego, and generally, if it does poorly, it&#x27;s more a reflection of the user providing the inputs (giving bad instructions or not enough context).<p>So in a sense, we are more forgiving of ourselves more than anything.",
      "Speaking only of written communication here: I&#x27;ve noticed a distinct trend of people stopping documentation, comments, release notes, etc. intended for human consumption and devoting their writing efforts to building skills, prompts, CLAUDE.md intended for machines.<p>While my initial reaction was dystopian horror that we&#x27;re losing our humanity, I feel slightly different after sitting with it for a while.<p>Ask yourself, how effective was all that effort really? Did any humans actually read and internalize what was written? Or did it just rot in the company wiki? Were we actually communicating effectively with our peers, or just spending lots of time on trying to? Let&#x27;s not retcon our way to believing the pre-AI days were golden. So much tribal knowledge has been lost, NOT because no one documented it but because no one bothered to read it. Now at least the AI reads it.",
      "With a program or machine, I can cut the interaction at any time, walk away and not feel rude.",
      "I don&#x27;t find the conclusions plausible. It&#x27;s completely ignoring that AI is a machine and not in our social hierarchy, while humans are, and we have a large section of wetware devoted to constantly judging the social hierarchy and rules.<p>At least personally this was obvious to me years before AI was around. Whenever we had clear data that came to an obvious conclusion, I found that it didn&#x27;t matter if _I_ said the conclusion, regardless of if the data was included. I got a lot more leeway by simply presenting the data to represent my conclusion and let my boss come to it.<p>In the first situation the conclusion was now _my_ opinion and everyone&#x27;s feelings got involved. In the second the magic conch(usually a spreadsheet) said the opinion so no feelings were triggered.",
      "It is funny how we are so willing to iterate on a prompt for ten minutes but we get annoyed when we have to repeat ourselves to a person. I think we could all benefit from not taking things so personally at work.",
      "&gt; No frustration. No judgment. Just iteration.<p>[citation needed]<p>This entire article is just meaningless vibes of one guy who sells AI stuff."
    ],
    "full_text": null
  },
  {
    "title": "A Calif. teen trusted ChatGPT's drug advice. He died from an overdose",
    "url": "https://www.sfgate.com/tech/article/calif-teen-chatgpt-drug-advice-fatal-overdose-21266718.php",
    "source": "hn",
    "summary": "",
    "comments": [
      "&gt; Asked about “the pros” of ChatGPT by Jimmy Fallon on a December episode of “The Tonight Show,” Altman talked effusively about the tool’s use for health care. “The number of people that reach out to us and are like, ‘I had this crazy health condition. I couldn’t figure out what was going on. I just put my symptoms into ChatGPT, and it told me what test to ask the doctor for, and I got it and now I’m cured.’”<p>I&#x27;ve always believed, don&#x27;t blame the tool for the user, but can&#x27;t help but feel the sellers are a little complicit here. That statement was no accident. It was carefully conceived to be part of discourse and set the narrative on how people are using AI.<p>It&#x27;s understandable that they want to tout their tool&#x27;s intelligence over imitation, so expecting them to go out of their way to warn people about flaws may be asking too much. But the least thing to do is simply refrain from dangerous topics and let people decide for themselves. To actively influence perception and set the tone on these topics when you know the what ramifications will be, is deeply disappointing.",
      "The models are trained on fake internet conversations where group appeasement is an apparent goal.  So now we have machines that just tell us what we clearly already want to hear.<p>Ask any model why something is bad,  then separately ask why the same thing is good.  These tools aren&#x27;t fit for any purpose other than regurgitating stale reddit conversations.",
      "I skimmed the article, and I had a hard time finding anything that ChatGPT wrote that was all that..bad?  It tried to talk him out of what he was doing, told him that it was potentially very fatal, etc.  I&#x27;m not so sure that it outright refusing to answer and the teen looking at random forum posts would have been better, because they very well might not have told him he was potentially going to kill himself.  Worse yet, he could have just taken the planned substances without any advice.<p>Keep in mind this reaction is from someone that doesn&#x27;t drink and has never touched marijuana.",
      "The guardrails clearly failed here because the model was trying to be helpful instead of safe. We know that these systems hallucinate facts but regular users have no idea. This is a huge liability issue that needs to be fixed immediately.",
      "People need training about these tools. The other day I ran an uncensored model and asked it for tips on a fun trend I read about to amputate my teeth with toothpicks. It happily complied.<p>My point is they will gladly oblige with any request. Users don’t understand this.",
      "This brings to mind some of the “darker” subreddits that circle around drug abuse. I’m sure there are some terrible stories about young people going down tragic paths due to information they found on those subreddits, or even worse, encouragement. There’s even the commonly-discussed account that (allegedly) documented their first experiences with heroin, and then the hole of despair they fell into shortly afterwards due to addiction.<p>But the question here is one of liability. Is Reddit liable for the content available on its website, if that content encourages young impressionable people to abuse drugs irresponsibly? Is ChatGPT liable for the content available through its web interface? Is anyone liable for anything anymore in a post-AI world?",
      "Took a while to figure out what the OD was of, but it was a combination of alcohol, kratom (or a stronger kratom-like drug), and xanax.",
      "I don&#x27;t yet see how this case is any different from trusting stuff you see on the web in general. What&#x27;s unique about the ChatGPT angle that is notably different from any number of forums, dark-net forums, reddit etc? I don&#x27;t mean that there isn&#x27;t potentially something unique here, but my initial thought is that this is a case of &quot;an unfortunate kid typed questions into a web browser, and got horrible advice.&quot;<p>This seems like a web problem, not a ChatGPT issue specifically.<p>I feel that some may respond that ChatGPTS&#x2F;LLMs available for chat on the web are specifically worse by virtue of expressing things with some degree of highly inaccurate authority. But again, I feel this represents the Web in general, not uniquely ChatGPTS&#x2F;LLMs.<p>Is there an angle here I am not picking up on, do you think?",
      "Sam and Dario &quot;The society can tolerate a few deaths to AI&quot;"
    ],
    "full_text": null
  },
  {
    "title": "DuckDuckGo is asking for a Yes or No vote on AI",
    "url": "https://duckduckgo.com/vote",
    "source": "hn",
    "summary": "",
    "comments": [
      "Hi from DuckDuckGo: whoops, you found this early! Launch is Monday — more to come then.",
      "&quot;Yes AI or No AI?&quot; What&#x27;s the actual question? What am I answering? How is this measured? What are the consequences?",
      "This is so misguided.<p>No, to how companies are forcing it into everything and destroying the commons to drive it.<p>Yes, to the technology in general.",
      "This is a confusing marketing campaign because DDG is very much aware that the people voting on this poll are not a representative sample of DDG users.",
      "It&#x27;s effectively a push poll, and it&#x27;s not changing anything about DuckDuckGo. They really want you to know that Yes AI or No AI, we gotchu dude, you can do whatever.",
      "As it stands I don&#x27;t know what this poll means. Does &quot;No AI&quot; mean that generative AI should never be used or offered? Does &quot;Yes AI&quot; mean that generative AI should be used for everything all the time?<p>One might accuse me of being intentionally daft, asserting this to be a simple sentiment poll, but I genuinely can&#x27;t tell. If it were the case, this should ask &quot;do you overall like or dislike generative AI?&quot; Either way this encourages a lack of nuanced thinking on the subject which both tech bro shills and instinctual AI-luddites oft suffer from. The results of this poll are uninterpretable and the effects on the quality of discourse can only be negative.",
      "Predictably, most people who use ddg will vote &quot;no ai&quot;. I don&#x27;t even know exactly what that means, does it just mean ai-assisted results?<p>What&#x27;s the harm in having them generated, but you click a button or expand a collapsed div&#x2F;section&#x2F;box to see what is if you&#x27;re interested.<p>I get the AI-hate but its unreasonable and emotionally charged application is harmful I think.<p>I wanted to say &quot;lots of people&quot; like AI search results, but it turns out I am lots of people. I have DDG on almost every browser I use, but for a while now, most of my ddg searches include &#x27;!g&#x27; to go to google for AI results. I don&#x27;t really want to spend hours trying different things manually, &quot;how do I do X&quot;, the AI result quality is objectively good for the things I search for.<p>Do you want this product to be a niche product used by a small number of people or not? That&#x27;s the question really. And there is nothing wrong with wanting that so long as DDG can sustain the product that way. No need for &quot;one size fits all&quot;.<p>But if your aim with DDG is to have a viable competitor to mainstream search engines, then opposing AI search results (despite DDG taking pains to make sure they&#x27;re not intrusive or privacy-hostile) seems counter-productive.<p>If someone could articulate for me the hatred for AI, even when you&#x27;re getting good enough results (are people claiming google search AI result are worse than stackoverflow for example?), I&#x27;d really appreciate it. Maybe it&#x27;s a difference in expectations? I don&#x27;t expect it to solve things for me, just make it easier to do so. &quot;Give me an example in $language of how I can use this package&quot;, boom, I have a good valid example. &quot;How do I troubleshoot error &lt;the error&gt;&quot;, boom, a list of really good troubleshooting steps. I don&#x27;t even have to sign-in, or pay anything, why would anyone oppose this? I feel like I should be opposing it but I&#x27;m being ignorant on some topic.",
      "Currently 4% v 96%.",
      "Research it, make the useful bits available, don&#x27;t shove it in my face? Yes!<p>Whatever everyone else is doing? NOOOOOO!",
      "Tor Browser and The mullvad browser have NoAI enabled as default<p>or add it yourself<p><pre><code>  https:&#x2F;&#x2F;noai.duckduckgo.com&#x2F;?q=%s</code></pre>"
    ],
    "full_text": null
  },
  {
    "title": "Ask HN: How have you or your firm made money with LLMs?",
    "url": "https://news.ycombinator.com/item?id=46648752",
    "source": "hn",
    "summary": "",
    "comments": [
      "A bit the same way Egyptian history experts make money.<p>By making LLMs for people who want to make money with LLMs.<p>For me though I see ChatGPT take all the hype now. I&#x27;m seeing people get more and more bored with that and in quest of a step up or sideways from that.<p>That goes pretty slow outside of developers people are still trying to come to grips with OpenAI.<p>All earlier adopters have been builders interested in the technology for tech sake. The real consumers are veeery slow to ramp up.",
      "LLMs finally gave someone I know the confidence to up her business rates.  Professional services, nothing to do with software dev (yes LLMs are not just for devs).  It suggested she revamp her entire pricing structure.  She thought her clients would walk, but she did it and nobody flinched.  Big revenue boost.<p>She also uses it daily for all kinds of things. For example recording&#x2F;transcribing&#x2F;summarizing meetings, creating plans, writing emails, reviewing employee performance, and a bunch of other stuff.  If it went away she would be devastated.",
      "The best clear example I&#x27;ve seen of LLMs making money is a company that now generates custom email text instead of using standard email templates. They increased engagement by some meaningful metric like +15% which translates into hundreds of millions of dollars in revenue.",
      "We&#x27;ve seen some tangible benefits from integrating LLMs into our workflow, particularly in automating customer support and content generation. By leveraging language models, we’ve been able to free up our team’s time and focus on more strategic tasks, which has led to improved efficiency.<p>We ran into this ourselves when we needed to manage a growing volume of inquiries without scaling our support staff. By using LLMs to generate responses and categorize requests, we not only enhanced our response times but also maintained a level of quality that our users appreciated.<p>We ended up building Wyshbone to handle sales lead generation and outreach timing, integrating seamlessly with our CRM. This has helped us identify potential leads more effectively and optimize our follow-up strategies."
    ],
    "full_text": null
  },
  {
    "title": "Jonathan Haidt Brings New Evidence to the Battle Against Social Media",
    "url": "https://www.nytimes.com/2026/01/16/podcasts/jonathan-haidt-new-evidence.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "Here&#x27;s a question. Suppose a corporation made its money off a particular product. And suppose the corporation&#x27;s own scientists discovered that this product caused major harm. How would the corporation respond, among three choices<p><pre><code>   1) Stop making and selling the product, and support its being banned.\n\n   2) Continue to sell the product, but with a clear description of the harm.\n\n   3) Engage in a campaign to fool everyone into believing it is not harmful.</code></pre>",
      "The sextortion Haidt mentions is made infinitely easier with AI image generation.<p>What were seeing is exploiters deep fake an image of their target and then use this as leverage against them. Unfortunately, not every kids home life is in a position where a kid can go to their parents and receive support if they&#x27;re in such a situation.",
      "Funny this should come out at the same time as another study suggesting there&#x27;s no association.",
      "This is also available as the podcast “Hard Fork” which is usually not paywalled. Apple Podcast. (<a href=\"https:&#x2F;&#x2F;podcasts.apple.com&#x2F;us&#x2F;podcast&#x2F;hard-fork&#x2F;id1528594034?i=1000745421942\" rel=\"nofollow\">https:&#x2F;&#x2F;podcasts.apple.com&#x2F;us&#x2F;podcast&#x2F;hard-fork&#x2F;id1528594034...</a>)",
      "Anyone have a non-paywalled mirror?"
    ],
    "full_text": null
  },
  {
    "title": "Building a MCP Client in Google Apps Script",
    "url": "https://justin.poehnelt.com/posts/mcp-client-apps-script/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I had a teammate asking me about calling MCP servers from Apps Script, so I wrote this up!"
    ],
    "full_text": null
  },
  {
    "title": "Starlink updates Privacy Policy to allow AI model training with personal data",
    "url": "https://coywolf.com/news/startups/starlink-updates-tos-to-allow-ai-model-training-with-personal-data/",
    "source": "hn",
    "summary": "",
    "comments": [
      "This is exactly why I&#x27;ve become paranoid about what gets stored in cloud services, even ones I generally trust. The policy changes can happen overnight, and suddenly data you uploaded under one set of assumptions is now being used for something completely different.<p>To reduce this risk, either completely remove truly sensitive documents from cloud services or implement client-side encryption before uploading them anywhere. The key insight is that if the service can read your files to train models, you don&#x27;t actually have privacy regardless of what the policy says today.<p>I&#x27;m building PrivaVault specifically because I got burned by a similar policy change last year. The approach is zero-knowledge encryption, where we literally can&#x27;t read user documents even if we wanted to. Launching in 7 days if anyone wants to check it out, but honestly the broader principle applies: encrypt before it leaves your device, or don&#x27;t be surprised when it ends up training someone&#x27;s AI.",
      "Personal data might include location or GPS data, your name\nand billing address, and if you have to provide your ISP with a copy of your photo ID to prove you are 18 in order to get unfiltered access in the future, it probably will include that.",
      "For global companies like Starlink, complying with the privacy laws of every country must be a nightmare. In fact, it really surprises me that they actually follow them to the letter in practice. I’d bet that internally and technically they aren’t fully complied with, but there’s no way to know",
      "So, use a good VPN.  IMO, the main thing they’re actually useful for is protecting you against abuse from your own ISP.",
      "Frustrating they turn this on by default without an email to announce it. Only recent email I have from Starlink is advertising the 50GB roam plan changing to 100GB.",
      "This sounds bad. Does any other ISP do that? What sort of info could Starlink even see - the URLs?",
      "I assume the traffic over Starlink is encrypted, so what exactly do they mean with &quot;personal information&quot;? Like the very basic customer details and everything they can get from their analytics?<p>For my taste the sentences are over the top and full of weasel words. It&#x27;s not even something I&#x27;d call legalese because it just sounds so insincere.<p><pre><code>  - &quot;We may share your personal information with our affiliates, service providers, and third-party collaborators&quot; or \n  - “Share personal data with Starlink’s trusted collaborators to train AI models.&quot;\n</code></pre>\nInitially I was very critical of GDPR but when I see these kind of vague formulations I&#x27;m really happy that as a European I can expect companies to provide an itemized list of people and companies they will share the data with, and what kind of security measures these subprocessors are employing.<p>There&#x27;s still a lot of wiggle room for lawyers to work around GDPR limitation, but at least you&#x27;d know if their &quot;trusted collaborators&quot; and &quot;affiliates&quot; are Google or Facebook, are domiciled in a foreign country, or if they are just to some small data science consultancy."
    ],
    "full_text": null
  }
]