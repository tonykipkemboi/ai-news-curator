[
  {
    "title": "Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI",
    "url": "https://arxiv.org/abs/2601.00794v1",
    "source": "arxiv",
    "summary": "Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net",
    "full_text": null
  },
  {
    "title": "Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning",
    "url": "https://arxiv.org/abs/2601.00791v1",
    "source": "arxiv",
    "summary": "We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spec",
    "full_text": "\n\n\n\n\n1 Introduction\n\nContributions.\n\n\n\n2 Related Work\n\nMechanistic Interpretability.\nProbing and Representation Analysis.\nGraph Signal Processing on Neural Networks.\nLLM Verification and Hallucination Detection.\nNeural Theorem Proving.\n\n\n\n3 Methods\n\n\n3.1 Attention as Dynamic Graphs\n\nHead Aggregation.\nGraph Laplacian.\n\n\n3.2 Graph Signals from Hidden States\n\n3.3 Spectral Diagnostics\n\nComputational Complexity.\n\n\n3.4 Validity Classification\n\n\n\n4 Experiments\n\n\n4.1 Experimental Setup\n\nDataset.\nModels.\nMetrics.\n\n\n\n4.2 Robustness Controls\n\nControl 1: Model-generated valid vs. invalid.\nControl 2: Human perturbations (style fixed, logic corrupted).\nEvaluation protocol.\nMultiple comparisons.\nInterpretation of accuracy metrics.\n\n\n\n4.3 Main Results\n\nUniversal Statistical Significance.\nLarge Effect Sizes.\nHigh Classification Accuracy.\nArchitecture-Specific Patterns.\n\n\n4.4 Two-Feature Classification\n\n4.5 Ablation Studies\n\nRandom Baseline.\nThreshold Robustness.\nProblem Difficulty.\nProof Length.\nMetric Independence.\nCross-Model Transfer.\n\n\n4.6 Comparison with Attention Baselines\n4.7 Controlling for Authorship\n\n4.8 Generalization to Natural Language\n\nSignal Attenuation and Metric Shift.\nInverse Overfitting.\n\n\n\n\n\n5 Analysis\n\n5.1 The Spectral Signature of Valid Reasoning\n5.2 Causal Mechanism: The Induction Head Link\n5.3 Platonic Validity\n5.4 The Mistral Architectural Effect\n5.5 A Cognitive Interpretation\n\n5.6 The Sparsity Penalty: Mixture-of-Experts Analysis\n\nSignal Attenuation.\nEntropy as a Routing Proxy.\nError Agnosticism.\n\n\n\n\n\n6 Discussion\n\nTheoretical Implications: A Unified Geometric Principle.\nTopological Divergence Across Modalities.\nPractical Applications.\nLimitations.\n\n\n7 Conclusion\n\nA Theoretical Background\n\nA.1 Graph Laplacians\nA.2 Algebraic Connectivity\nA.3 Graph Signal Processing\n\n\n\nB Implementation Details\n\nB.1 Attention Extraction\nB.2 Spectral Computation\nB.3 Computational Complexity\nB.4 Hardware and Runtime\n\n\n\nC Ablation Study Details\n\nC.1 Human Perturbation Control (Control 2)\nC.2 Train/Val/Test Split\nC.3 Nested Cross-Validation\nC.4 Random Baseline\nC.5 Threshold Robustness\nC.6 Problem Difficulty\nC.7 Proof Length\nC.8 Metric Correlations\nC.9 Cross-Model Transfer\nC.10 Head Aggregation Methods\nC.11 Laplacian Normalization\n\n\n\nD Complete Results Tables\n\nD.1 Label Correction Statistics\n\n\n\nE Reproducibility Checklist\n\nCode Availability.\nData Availability.\nCompute Requirements.\nHyperparameters.\nStatistical Reporting.\nRandom Seeds.\nE.1 Top 10 Discriminators per Model on MiniF2F (Corrected Labels)\n\n\nF Every layer plots\nG Every ablation plots\n\n\n\n\n\nGeometry of Reason: Spectral Signatures of Valid Mathematical Reasoning\n\n\n\nValentin No√´l \nDevoteam \nvalentin.noel@devoteam.com\n\n\n(Under review (2026))\n\nAbstract\nWe present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen‚Äôs d=3.30d=3.30 (p&lt;10‚àí116p&lt;10^{-116}), enabling 85.0‚Äì95.6% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93‚Äì95% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B‚Äôs Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness (d=2.09d=2.09, pMW=1.16√ó10‚àí48p_{\\text{MW}}=1.16\\times 10^{-48}), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.\n\n\n\n1 Introduction\n\nThe remarkable performance of large language models (LLMs) on mathematical reasoning tasks¬†(Lewkowycz et¬†al., 2022; Trinh et¬†al., 2024; Xin et¬†al., 2025) has intensified interest in understanding and verifying the computational mechanisms underlying their outputs. When a model generates a mathematical proof, practitioners face a fundamental epistemological challenge: determining whether the output reflects genuine logical reasoning or sophisticated pattern matching that produces plausible-looking but potentially flawed arguments. This challenge is particularly acute in high-stakes applications such as automated theorem proving¬†(Han et¬†al., 2022; Yang et¬†al., 2024; Lample &amp; Lacroix, 2025), mathematical education¬†(Welleck et¬†al., 2022), and scientific discovery¬†(Romera-Paredes et¬†al., 2024), where undetected reasoning errors can propagate with significant consequences.\n\n\nCurrent approaches to reasoning verification fall into two broad categories, each with substantial limitations. Output-based verification relies on formal proof assistants such as Lean¬†(de¬†Moura &amp; Ullrich, 2021), Coq¬†(Bertot &amp; Cast√©ran, 2013), or Isabelle¬†(Paulson, 1994) to check whether generated proofs compile successfully. While sound, this approach conflates logical validity with syntactic acceptability: proofs may be rejected due to timeout constraints, missing library imports, version incompatibilities, or formatting issues rather than genuine logical errors. Conversely, proofs with subtle semantic errors may pass compilation if they exploit gaps in type checking or axiom systems.\n\n\nLearned verification, on the other hand, trains classifiers on model internals¬†(Azaria &amp; Mitchell, 2023; Marks &amp; Tegmark, 2024) or utilizes process-based reward models (PRMs)¬†(Lightman et¬†al., 2023; Wang et¬†al., 2025) to predict correctness step-by-step. Recent trends focus on scaling inference-time compute to refine these verifiers¬†(Snell et¬†al., 2025; Wu &amp; Zhang, 2025). However, these methods require substantial labeled data, may not generalize across model architectures, and risk learning spurious correlations rather than fundamental properties of valid reasoning.\n\n\nWe propose an alternative paradigm grounded in spectral graph theory. Our central insight is that the self-attention mechanism in transformers induces a dynamic weighted graph over tokens, where edge weights correspond to attention scores. The spectral properties of this graph, eigenvalues and eigenvectors of its Laplacian matrix, encode global structural information about how the model routes information during processing. We hypothesize that valid mathematical reasoning produces characteristic spectral signatures reflecting coherent, structured information flow, while invalid reasoning produces disorganized patterns detectable through spectral analysis.\n\n\nThis hypothesis draws theoretical motivation from the graph signal processing literature¬†(Shuman et¬†al., 2013; Ortega et¬†al., 2018), which establishes that smooth graph signals (those varying slowly across edges) concentrate energy in low-frequency spectral components, while irregular signals exhibit high-frequency content. If valid reasoning corresponds to coherent information integration across tokens, we expect valid proofs to induce smoother graph signals with lower high-frequency energy. Conversely, if invalid reasoning reflects fragmented or inconsistent processing, we expect higher spectral irregularity.\n\n\nContributions.\n\nWe make the following contributions:\n\n\n\n\n1.\n\nWe introduce a training-free framework for reasoning validity detection based on spectral analysis of attention graphs, achieving 82.8‚Äì85.9% accuracy under nested cross-validation and up to 95.6% with calibrated thresholds (SectionsÀú3 and¬†4).\n\n\n\n2.\n\nWe demonstrate cross-architecture universality of the spectral signature across seven models from four independent families (Meta, Alibaba, Microsoft, Mistral AI), with effect sizes |d|‚â•2.09|d|\\geq 2.09 and pMW&lt;10‚àí47p_{\\text{MW}}&lt;10^{-47} in all cases (SectionÀú4).\n\n\n\n3.\n\nWe discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal systems reject due to technical failures. We term this phenomenon ‚ÄúPlatonic validity‚Äù (SectionÀú5.3).\n\n\n\n4.\n\nWe identify an architectural dependency: models using Sliding Window Attention exhibit shifted spectral signals, with validity captured by late-layer Smoothness rather than HFER (SectionÀú5.4).\n\n\n\n5.\n\nWe propose a cognitive interpretation of the spectral signature as reflecting the model‚Äôs epistemic state, its implicit certainty about its own reasoning process (SectionÀú5.5).\n\n\n\n\n\n\n\n\n2 Related Work\n\nMechanistic Interpretability.\n\nUnderstanding the internal computations of transformers has been a central goal of interpretability research. Foundational work by Elhage et¬†al. (2021) introduced mathematical frameworks for analyzing transformer circuits, while Olsson et¬†al. (2022) identified ‚Äúinduction heads‚Äù as key mechanisms for in-context learning. Subsequent work has analyzed attention patterns in arithmetic¬†(Nanda et¬†al., 2023; Hanna et¬†al., 2023), factual recall¬†(Meng et¬†al., 2022; Geva et¬†al., 2023), and reasoning tasks¬†(Stolfo et¬†al., 2023; Feng et¬†al., 2024).\nRecent advances have shifted toward scaling sparse autoencoders (SAEs) to decompose model activations into interpretable features¬†(Gao et¬†al., 2024; Cunningham et¬†a"
  },
  {
    "title": "Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries",
    "url": "https://arxiv.org/abs/2601.00787v1",
    "source": "arxiv",
    "summary": "Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-prov",
    "full_text": null
  },
  {
    "title": "FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing",
    "url": "https://arxiv.org/abs/2601.00785v1",
    "source": "arxiv",
    "summary": "Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE back",
    "full_text": null
  },
  {
    "title": "Categorical Reparameterization with Denoising Diffusion models",
    "url": "https://arxiv.org/abs/2601.00781v1",
    "source": "arxiv",
    "summary": "Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by int",
    "full_text": null
  },
  {
    "title": "LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization",
    "url": "https://arxiv.org/abs/2601.00770v1",
    "source": "arxiv",
    "summary": "Investment portfolio optimization is a task conducted in all major financial institutions. The Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem formulation is ubiquitous for portfolio optimization. The challenge of this type of portfolio optimization, a mixed-integer quadratic programming (MIQP) problem, arises from the intractability of solutions from exact solvers, whe",
    "full_text": "\n\n\n\n\n1 Introduction\n\n1.1 Context\n1.2 Rationale\n1.3 Contributions\n\n\n\n2 Preliminary\n\n\n2.1 LLM Agents\n\n2.1.1 Agent Framework\n2.1.2 Scoring\n\n\n\n2.2 Problem Formulation\n\n2.2.1 Objective\n2.2.2 Constraints\n\n\n\n\n\n3 Methods\n\n3.1 Approach\n3.2 Study Design\n\n\n\n4 Results\n\n4.1 Generated Algorithms\n4.2 Algorithm Portfolio Performance\n4.3 Pooled Metaheuristics\n\n\n5 Conclusion\n\n\n\n\n\nLLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization\n\n\nSimon Paquette-Greenbaum ‚ÄÉJiangbo Yu\nDepartment of Civil Engineering, McGill University\nMontreal, Quebec, Canada \n\nCorresponding author: jiangbo.yu@mcgill.ca\n\n\nAbstract\nInvestment portfolio optimization is a task conducted in all major financial institutions. The Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem formulation is ubiquitous for portfolio optimization. The challenge of this type of portfolio optimization, a mixed-integer quadratic programming (MIQP) problem, arises from the intractability of solutions from exact solvers, where heuristic algorithms are used to find approximate portfolio solutions. CCPO entails many laborious and complex workflows and also requires extensive effort pertaining to heuristic algorithm development, where the combination of pooled heuristic solutions results in improved efficient frontiers. Hence, common approaches are to develop many heuristic algorithms. Agentic frameworks emerge as a promising candidate for many problems within combinatorial optimization, as they have been shown to be equally efficient with regard to automating large workflows and have been shown to be excellent in terms of algorithm development, sometimes surpassing human-level performance. This study implements a novel agentic framework for the CCPO and explores several concrete architectures. In benchmark problems, the implemented agentic framework matches state-of-the-art algorithms. Furthermore, complex workflows and algorithm development efforts are alleviated, while in the worst case, lower but acceptable error is reported.\n\n\n\n1 Introduction\n\n\n1.1 Context\n\nAgentic Large Language Models (LLM) are emerging as critical elements in automating large workflows and decision support systems in many fields, such as logistics (logistics), management (management), healthcare (healthcare), urban planning (urban), and transportation (transportation). Hence, LLM agents have consequently been cast as tools for algorithm development in relevant combinatorial optimization problems such as scheduling (funsearch). They have been studied extensively in natural language processing for optimization (NL4Opt), where natural-language problem descriptions have been effectively translated into valuable mathematical formulations. Language model agents are equally proficient at generating algorithmic solutions to optimization problems when presented with natural-language descriptions and mathematical formulations (CoE), and their performance has also been shown to exceed that of human experts in time-constrained scenarios (COBench).\n\n\nResearchers and industry alike have been very interested in these frameworks, as they serve as valuable benchmarks for some of the foremost applications of LLMs. These applications stimulate two crucial facets of LLM performance: Natural-Language Processing (NLP) and coding (agentic). However, application of language model agents to combinatorial optimization problems has been limited to academic cases, where problem framing and descriptions are taken directly or inspired by textbooks used in human education (ORQA). Although these studies present structured benchmarks for LLM agents, they are limited to problems with single objectives and are tractable to exact solution approaches.\n\n\nLimited work has been conducted on combinatorial optimization that reflects real life. Problems that reflect real life are rarely transcribed into textbooks and can seldom be solved exactly, either due to computational resource constraints or problem uncertainty. Furthermore, real-life problems rarely come without trade-offs (MOOP), and real-life decision makers often require knowledge of those trade-offs‚Äô implications, i.e., the Pareto fronts resulting from multi-objective optimization tasks. Studies have applied LLM agents to develop heuristic algorithms for problems intractable to exact solvers (disc_heur). Still, limited work has been conducted on LLM agent solutions for multi-objective optimization problems.\n\n\n\n\n1.2 Rationale\n\nThis study‚Äôs focus is on the development of a language model framework capable of generating algorithm solutions to combinatorial optimization problems, reflecting real-life worst-case scenarios (opposite to several benchmark studies, where problem framing is a best-case scenario). Combinatorial optimization problems are frequently intractable due to their NP-hardness and due to the combinatorial explosion of subsets (comb_np), rendering exact solutions exploring all subsets intractable. Furthermore, real-life problems are often multi-objective, where decision makers are faced with competing business needs, etc.\n\n\nAn agentic framework capable of heuristic algorithm development presents itself as a valuable tool in such instances. Problems intractable to exact solvers often require approximate solutions from metaheuristics (exact_heuristic). Furthermore, multi-objective optimization problems have been shown to sometimes greatly benefit from the pooling of heuristic solutions, where pooled heuristic solutions form non-dominated frontiers with greater convergence and coverage (alg_port). For example, the Cardinality-Constrained Mean-Variance Portfolio Optimization (CCPO) (CCPO) fits this description very well. Unlike standard Markowitz mean-variance portfolio optimization (MVPO), which can be solved trivially with exact dynamic programming, CCPO is an NP-hard problem (CCPO_NP) with a non-convex and discontinuous efficient frontier. The subject of metaheuristic CCPO solutions has been studied extensively in the literature (MVPO_review), and the performance of pooled heuristics in this case has been shown to greatly improve performance beyond singular heuristics (CCPO_hybrid_pool).\n\n\n\n\n1.3 Contributions\n\nFollowing this rationale, this study contributes several findings:\n\n\n‚Ä¢\n\nThis study presents an agentic language model framework that serves in the construction of algorithm portfolios for multi-objective combinatorial optimization problems with NP-hardness. The agent framework not only trivializes the immense developmental burden associated with the construction of algorithm portfolios but also has the added benefit of the potential discovery of novel algorithms.\n\n\n\n‚Ä¢\n\nThis study validates the agentic framework, along with its produced algorithm portfolio, in a series of challenging multi-objective investment portfolio optimization benchmark problems studied extensively throughout the literature. The agent framework, measured against CCPO cases taken from OR-Library (OR-lib), is shown to produce algorithms on par with the state of the art. Furthermore, the pooling of algorithms from its derived algorithm portfolio is shown to greatly enhance solution performance.\n\n\n\n\n\n\n\n\n2 Preliminary\n\n\n2.1 LLM Agents\n\nCoding agents have received a lot of attention within the broader computer science and machine learning communities. They have been shown to be extremely promising in terms of coding ability and simplifying complex workflows. They have also received considerable attention in the domain of combinatorial optimization, given the large algorithm design burden in terms of required effort in solving intractable or NP-hard problems (HeuriGym). Several coding agent frameworks have been employed successfully in solving combinatorial optimization problems, namely Self-Refine (self-refine), FunSearch (funsearch), and ReEvo (ReEvo).\n\n\n\n2.1.1 Agent Framework\n\nThe coding agent frameworks employed in this study serve as the central element in the development of its algorithm portfolio. Given the successful usage of iterative agents in algorithm generation and discovery, this study will base its framework around their architectures. One-time generation using LLMs has been shown to most often lead to algorithms that frequently exhibit suboptimal performance or runtime/execution errors (self-refine). Hence, agent frameworks like the one used in this study rely on iterative refinement with external environments, formally referred to as reasoning-action iterations (react).\n\n\nThe language model, herein referred to as ‚Ñ≥\\mathcal{M}, will be framed in this study as a coding agent. Equation¬†1 describes the overview of one generation instance of algorithm ùíú\\mathcal{A} via coding agent ‚Ñ≥\\mathcal{M}, where ùê©\\mathbf{p} is the vector of engineered prompt templates, and aa, ff, and ss are the algorithm(s), feedback(s), and the score(s) from the previous iteration(s).\n\n\n\n‚Ñ≥‚Äã(ùê©,a,f,s)‚Ü¶ùíú\\displaystyle\\mathcal{M}(\\mathbf{p},a,f,s)\\;\\mapsto\\;\\mathcal{A}\n\n(1)\n\n\n\n\nThis study‚Äôs agent framework is based on a greedy refinement agent framework as described in (COBench), which itself is based on Self-Refine (self-refine), where greedy refinements are iteratively used to generate algorithms. Equation¬†2 describes the reasoning-action iterations of this study‚Äôs agent framework. Here, reasoning requires the vector of engineered prompt templates ùê©={p,pPF,pRA,pI/O}\\mathbf{p}=\\{p,p_{\\text{PF}},p_{\\text{RA}},p_{\\text{I/O}}\\}, including pp for general iteration instructions, pPFp_{\\text{PF}} for the problem formulation, pRAp_{\\text{RA}} for role assignment, and pI/Op_{\\text{I/O}} for formatting instructions. Furthermore, at‚àóa_{t}^{*}, ft‚àóf_{t}^{*}, and st‚àós_{t}^{*} are respectively the algorithm, feedback, and scores of the best-scoring previous iteration in ASCII format at an iteration tt, injected in the prompt templates where appropriate. Action requires problem parameters and inputs xx (constant over iterations), as well as the generated algorithm ùíú\\mathcal{A}.\n\n\n\nùíút‚àº‚Ñ≥‚Äã(ùê©,"
  },
  {
    "title": "Memory Bank Compression for Continual Adaptation of Large Language Models",
    "url": "https://arxiv.org/abs/2601.00756v1",
    "source": "arxiv",
    "summary": "Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, wh",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; cs &gt; arXiv:2601.00756v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Computer Science  Machine Learning\n    \n\n    \n      arXiv:2601.00756v1 (cs)\n    \n\n\n  \n    \n  [Submitted on 2 Jan 2026]\n    Title:Memory Bank Compression for Continual Adaptation of Large Language Models\n    Authors:Thomas Katraouras, Dimitrios Rafailidis            View a PDF of the paper titled Memory Bank Compression for Continual Adaptation of Large Language Models, by Thomas Katraouras and 1 other authors\n    View PDF\n\n\n\n    \n            Abstract:Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at this https URL.\n    \n\n    \n    \n              \n          Comments:\n          Accepted to the 41st ACM/SIGAPP Symposium on Applied Computing (SAC &#39;26)\n        \n\n          Subjects:\n          \n            Machine Learning (cs.LG); Computation and Language (cs.CL)\n                \n          ACM&nbsp;classes:\n          I.2.7; I.2.6\n        \n\n          Cite as:\n          arXiv:2601.00756 [cs.LG]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2601.00756v1 [cs.LG] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2601.00756\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite (pending registration)\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Thomas Katraouras [view email]          [v1]\n        Fri, 2 Jan 2026 17:22:34 UTC (138 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled Memory Bank Compression for Continual Adaptation of Large Language Models, by Thomas Katraouras and 1 other authorsView PDFTeX Source\n \n      \n          \n          view license\n        \n    \n        \n    Current browse context: cs.LG\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-01\n  \n    Change to browse by:\n    \n        cs\n        cs.CL\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n                    \n            \n              \n                \n                \n                IArxiv recommender toggle\n              \n            \n            \n              IArxiv Recommender\n              (What is IArxiv?)\n            \n          \n\n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n            Both individuals and organizations that work with arXivLabs"
  },
  {
    "title": "A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football",
    "url": "https://arxiv.org/abs/2601.00748v1",
    "source": "arxiv",
    "summary": "Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help ext",
    "full_text": "\n\n\n\n\n\nA Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football\n\n\nSean Groom\n\nSchool of Computer Science, The University of Birmingham, Birmingham, UK\n\nNottingham Forest Football Club, Nottingham, UK\n\n\nFrancisco Belo\n\nNottingham Forest Football Club, Nottingham, UK\n\n\nAxl Rice\n\nNottingham Forest Football Club, Nottingham, UK\n\n\nLiam Anderson\n\nSchool of Sport, Exercise and Rehabilitation Sciences, The University of Birmingham, Birmingham, UK\n\n\nShuo Wang\n\n\n\n\n\nAbstract\nEvaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating ‚Äùaverage‚Äù behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.\n\n\nIntroduction\n\nElite sporting organizations are increasingly leveraging machine learning to inform tactical planning and player evaluation. This advancement is fueled by rich datasets, including event data (e.g., passes and shots) and player tracking data from multi-camera systems [Spatio-Temporal-Analysis-of-Team-Sports, match-analysis-big-data-and-tactics-current-trends-in-elite-soccer]. For instance, pitch control models [RN31, RN35, RN30] estimate a team‚Äôs probability of controlling different areas of the field. While these models are valuable for visualizing territorial dominance, they often fail to appraise the contextual value of those areas within a specific game state. Similarly, possession value models [Rudd2011MarkovSoccer, Singh2018xT, Cervone2016EPV, RN22, RN21], which appraise on-ball actions, face significant challenges when applied to defensive performance analysis [RN4]. This is because defensive play presents unique appraisal problems, player‚Äôs individual actions are not the only important consideration, but also their coordinated movements with teammates, which makes it difficult to isolate individual contributions. Furthermore, successful defensive play is often defined by actions that don‚Äôt occur, i.e. preventing a pass or a shot [Tuyls2020GamePWB, Merhej2021WhatHNA, Forcher2023TheSFB]. Traditional metrics like tackles and interceptions are insufficient as they don‚Äôt capture the subtle ways defenders constrain attacking options. Consequently, the analysis of defensive performance significantly lags behind that of offensive play.\n\n\nTo address the limitations of traditional metrics, recent research has explored counterfactual analysis as a means of evaluating defensive performance. A notable example is the use of ‚Äùghosting‚Äù models, which generate simulated player trajectories to analyze defensive behavior by measuring how a player‚Äôs actual movement alters offensive outcomes‚Äîsuch as pass completion or shot quality‚Äîwhen compared to a hypothetical ‚Äùghost‚Äù player [Le2017DataDrivenGUC, Yurko2024NFLGAA, Seidl0BhostgustersRD]. This approach provides a powerful way to quantify a defender‚Äôs impact beyond simple event counts. However, the application of these techniques in football remains limited [RN90], and they often rely on simulating ‚Äùaverage‚Äù behavior, which may not align with a team‚Äôs specific tactical system. More recent research has attempted to move beyond this by introducing latent role variables into generative or predictive models of player motion [Scofano_2024, Fassmeyer2025Interactive]. While these roles help the model represent coordinated team structures, they are designed to capture statistical regularities in movement rather than interpretable tactical categories familiar to coaches (e.g., man-marking or zonal defending). To date, such models have been primarily evaluated for predictive accuracy, not for counterfactual assessment of tactical performance. Therefore, conditioning counterfactual generation on interpretable tactical roles may offer more relevant insights for coaching and performance analysis.\n\n\nAttempts to value off-ball defence in football have historically been limited, due in part to the difficulty of linking defensive positioning to observable outcomes. Recently, graph-based deep learning approaches have begun to address this gap in open play. Everett et al. [everett2025gapp] introduce GAPP, an attention-based framework that estimates Defender Influence by predicting pass reception probabilities using Graph Attention Networks. By leveraging attention weights and node-masking interventions, their method provides local, instance-level explanations of which defenders most strongly affect specific attacking options.\n\n\nHowever, as established in prior work on model interpretability, attention mechanisms‚Äîwhile often predictive and locally faithful‚Äîdo not in themselves constitute explanations of causal or semantic structure [jain2019attention, wiegreffe2019attention]. In particular, attention weights are not guaranteed to correspond to uniquely meaningful roles or responsibilities unless such concepts are explicitly represented in the model. In the context of off-ball defending, this means that high attention or influence scores indicate that a defender affected an outcome, but not why this occured. Moreover, attention-masking-based influence measures implicitly compare observed behaviour to the absence of a defender‚Äôs contribution, rather than to a realistic alternative execution of the same defensive role, limiting their ability to support structurally grounded tactical reasoning.\n\n\nIn parallel, Kim et al. propose DEFCON [kim2025defcon], a probabilistic framework that assigns defensive credit by marginalising over learned action selection, success, and defender responsibility probabilities to estimate marginal reductions in Expected Possession Value (EPV). This formulation yields a principled and stable attribution of defensive value and avoids reliance on explicit attention masking, making it well-suited to aggregating player contributions across matches and contexts. Importantly, DEFCON evaluates defenders relative to the observed defensive organisation, attributing credit within a fixed tactical configuration.\n\n\nSet pieces, particularly corner kicks, offer a structured and valuable context for studying defensive behavior. Occurring roughly ten times per match and accounting for a significant percentage of goals (11% of all goals in the 2024/2025 English Premier League season, calculated from Statsbomb event data), corners are highly scripted, meaning that improvements in performance can lead to substantial gains without needing to acquire new personnel. Their impact is significant enough that many clubs now employ dedicated set-piece coaches. Defensive instructions during corners typically involve either tracking a specific opponent (man-marking) or zonal marking, where players guard predefined locations. Most teams adopt hybrid strategies that reflect their tactical identity. Prior work has largely focused on scheme identification and pattern discovery. For example, Shaw &amp; Gopaladesikan mapped recurring corner routines and inferred defender roles [routineInspection]. Bauer et al. [Bauer] developed an approach using a convolutional‚Äìrecurrent neural networks (CNN‚ÄìLSTM) to assign defenders various roles, including zonal defending and man-marking roles, yielding who was marking whom but at the cost of a hand-labelled dataset that is neither publicly nor commercially available. DeepMind and Liverpool FC‚Äôs TacticAI utilises D2-equivariant graph neural networks to predict reception and shot outcomes, as well as generating suggestions on how to improve these outcomes [RN8]. Although TacticAI‚Äôs suggestions were preferred by expert raters, they are not explicitly parameterized by interpretable tactical roles. Accordingly, we seek a framework that infers time-resolved tactical roles from tracking data without time-intensive labeling. This framework will be coupled with outcome prediction models to facilitate counterfactual evaluation and individual defensive performance evaluation.\n\n\nAddressing this gap, we introduce a covariate-dependent Hidden Markov Model (CDHMM) [Bishop, RN45] specifically tailored for the analysis of corner kicks. In our model, the latent states are designed to represent interpretable tactical roles, such as which defender is assigned to man-mark a specific opponent and which defenders occupy zonal positions. The model‚Äôs covariate-dependent transitions capture the dynamic nature of set-play behavior, allowing it to infer time-resolved tactical assignments and derive team- and delivery-specific zonal structures directly from tracking data without the need for manual labeling of roles.\n\n\nWe leverage these role assignments in two key ways. First, they provide coach-facing profiles of defender and attacker behaviour at set plays and extend existing outcome models (e.g., reception probability, expected threat, shot likelihood) to the off-ball domain by attributing defensive credit to specific players in specific roles. Second, we define role-conditioned ghosts, counterfactual baselines that replace a defender with an average counterpart from the same tactical role and team context, enabling situation-specific, role-aware off-ball performance analysis. We illustrate practical utility via a reception"
  },
  {
    "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
    "url": "https://arxiv.org/abs/2601.00747v1",
    "source": "arxiv",
    "summary": "State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this fai",
    "full_text": "\n\n\n\n\n1 Introduction\n\nDiversity collapse in modern training loops.\nWhy diversity matters: Creativity as a diverse portfolio for generalization.\nThe central question.\nOur answer: Distributional Creative Reasoning.\nContributions.\nRoad-map.\n\n\n\n2 Related Work\n\nFrom reward optimisation to reasoning monoculture.\nFirst attempts at diversity-aware objectives.\nTheoretical lenses on collapse.\nDistributional Creative Reasoning (DCR).\n\n\n\n3 Distributional Creative Reasoning\n\n3.1 The Landscape of Reasoning\n3.2 The DCR Objective\n3.3 The Diversity Energy Functional ùíü‚Äã[p]\\mathcal{D}[p]\n3.4 Learning Dynamics: Gradient Flow\n\n3.5 Parametric Realization and Scalability\n\nParametric Realization.\nScalability.\n\n\n\n\n\n4 Collapse Under Scalar Objectives\n\n4.1 Scalar-Driven Dynamics: The SRCT Framework\n4.2 Deterministic Diversity Decay (Small Œµ\\varepsilon)\n4.3 Stochastic Dynamics: Fixation Under Noise\n4.4 Synthesis: The Diversity Decay Theorem\n\n\n\n5 The Diversity Energy Effect on the Equilibrium Structure\n\n5.1 From Collapse to Structured Diversity\n5.2 The Dual Levers of Diversity Energy: Shaping p‚ãÜp^{\\star}\n5.3 Balancing Correctness and Structured Diversity at Equilibrium\n\n\n\n6 The Creativity Kernel\n\n6.1 Limitations of Entropic Diversity\n6.2 Sculpting Semantic Diversity\n6.3 Practical Design of the Semantic Kernel\n6.4 Implementation and Desiderata\n\n\n\n7 Concluding Insights\n\n\n7.1 Testable Predictions\n\nAcknowledgements.\n\n\n\n\n\nA Mathematical Foundations and Problem Formalism\n\n\nA.1 Preliminaries and Standing Assumptions\n\nScope &amp; conventions.\nStanding assumptions.\nNorm conventions.\n\n\n\nA.2 Spaces and Simplex Geometry\n\nA.2.1 Trace space, simplex, tangent.\nA.2.2 Floors: policy vs. effective.\nA.2.3 Canonical inequalities.\n\n\n\nA.3 Functionals: Entropy, KL, Kernel, and Diversity\n\nA.3.1 Entropy and KL calculus.\nA.3.2 Kernel quadratic form.\nA.3.3 Diversity functional.\n\n\n\nA.4 Barriers and Interiority\n\nA.4.1 Entropy/KL barriers exclude boundary maximizers.\nA.4.2 No finite‚Äìtime boundary hitting under bounded fitness.\n\n\n\nA.5 Shahshahani Geometry and Gradient Representation\n\nA.5.1 Metric and replicator form.\n\nA.5.2 Integrability of replicator fields.\n\nInstantiation.\n\n\n\n\n\nA.6 Gradient‚ÄìFlow Dynamics and Convergence\n\nA.6.1 ODEs and barrier strength.\nA.6.2 Lyapunov identity (with boundary continuity).\nA.6.3 Log‚Äìratio contraction; time‚Äìuniform floor and cap.\n\nA.6.4 Global convergence with explicit rate.\n\nRemarks.\n\n\n\n\nA.7 Special Case: Replicator Flow with Single‚ÄìSite Scores\n\nA.8 Barrier‚ÄìDominance (BD)\n\nScope.\nA.8.1 Entropy face gap LS‚Äã(Œ¥)L_{S}(\\delta).\nA.8.2 Deterministic BD conditions.\n\n\n\n\n\nB Parametric (Logit‚ÄëSpace) Geometry and Propagation Bounds\n\n\nB.1 Introduction and Notation\n\nNotation.\n\n\nB.2 Soft‚Äëmax Map: Gauge, Inverse, and Log‚Äëratio\n\nB.3 Geometry and Conditioning of the Soft‚Äëmax Jacobian\n\nBasic differential.\nBoundary behavior.\n\n\n\nB.4 Clip‚ÄìRenormalize and the Logit Lift\n\nDefinition and effective floor.\nLogit lift and normalization cancellation.\nDifferentials (a.e.).\nLocal no‚Äëclip criterion.\nPost‚Äëclipping deviation with a known floor.\nSmooth vs. hard clip; Lipschitz of D‚ÄãPDP.\n\n\n\nB.5 Composite Smoothness for Œ¶‚Äã(Œ∏):=J‚Äã(softmax‚Å°(P‚Äã(Œ∏)))\\Phi(\\theta):=J(\\operatorname{softmax}(P(\\theta)))\n\nDomain and Assumption (A).\nChain pieces and uniform bounds.\nStep‚Äësize guidance.\n\n\n\nB.6 Quadratic Approximation and Hessian Suprema\n\nSecond derivatives.\nSecond‚Äëorder expansion and remainders.\nŒ¥\\delta‚Äëinterior refinements.\n\n\n\nB.7 Reference table: Parametric Constants\n\nDomain reminder for composite bounds.\n\n\n\n\n\nC The Self-Reinforcing Correctness Training (SRCT) Framework\n\nC.1 Domain, notation, and canonical constants\nC.2 SRCT objective, correct variational derivative, and canonical drift\n\nC.3 Operator facts for SS and the entropic map EE\n\nSelection covariance S‚Äã(p)S(p).\nEntropic vector E‚Äã(p)E(p).\n\n\nC.4 Global Lipschitz of the SRCT drift and Carath√©odory regularity\nC.5 Mass balance and log-ratio calculus\nC.6 Positivity and face invariance on the closed simplex\n\nC.7 Barrier‚ÄìDominance and confinement on ŒîŒ¥‚ãÜK‚àí1\\Delta^{K-1}_{\\delta_{\\star}}\n\nCoarse sufficient BD.\n\n\nC.8 Existence/uniqueness on the mass hyperplane\n\nC.9 Single-site score fields: Lyapunov structure and convergence\n\nRegime A&gt;0A&gt;0: strong concavity, KKT, convergence.\nRegime A=0A=0: water-filling and support selection.\n\n\nC.10 Safe denominators (linear-functional floor)\n\n\n\nD STaR through the SRCT Lens\n\nD.1 Setting, notation, and basic aggregates\n\nD.2 The STaR score field: bounds, Jacobian, and Lipschitzness\n\nComponentwise and norm bounds (sharp).\nContinuity caveat (stiffness near faces).\n\n\n\nD.3 STaR as an SRCT flow: well‚Äëposedness, Lipschitz drift, and confinement\n\nDynamics.\nNo finite‚Äëtime boundary hitting and uniform floor.\nGlobal ‚Ñì2\\ell_{2} Lipschitz bound for the SRCT drift on ŒîŒ¥‚ãÜK‚àí1\\Delta^{K-1}_{\\delta_{\\star}}.\nForward invariance of a trimmed simplex (Barrier‚ÄìDominance).\nUniform linear growth.\nWell‚Äëposedness summary.\n\n\n\nD.4 Log‚Äëratio dynamics and asymptotics\n\nIncorrect vs. incorrect (i,j‚àà‚Ñêi,j\\in\\mathcal{I}).\nWithin ùíû\\mathcal{C} (a,b‚ààùíûa,b\\in\\mathcal{C}).\nCorrect vs. incorrect (c‚ààùíû,i‚àà‚Ñêc\\in\\mathcal{C},i\\in\\mathcal{I}).\nAsymptotics.\n\n\nD.5 Edge cases and remarks\n\n\n\nE GRPO through the SRCT Lens\n\n\nE.1 Setup and GRPO characteristic\n\nDomain and classes.\nGRPO characteristic.\n\n\n\nE.2 GRPO scores: envelopes and rank‚Äëone Lipschitz constants\n\nScores and centering.\nPointwise envelopes.\nRank‚Äëone Jacobian and exact norms.\n\n\n\nE.3 SRCT drift: global Lipschitzness and mass conservation\n\nDrift.\nEntropic Lipschitz bound on ŒîŒ¥‚ãÜK‚àí1\\Delta^{K-1}_{\\delta_{\\star}}.\nSelection Lipschitz bound and full modulus.\n\n\n\nE.4 Barrier‚ÄìDominance (BD) and forward invariance\n\nEntropy face gap.\nExact BD on facets.\nConvenient sufficient relaxations.\nWell‚Äëposedness and invariance.\n\n\n\nE.5 Log‚Äëratio dynamics, envelopes, and scalar reduction\n\nIntra‚Äëclass equalization.\nCross‚Äëclass envelopes.\nFeasibility band (under BD).\nScalar reduction, closure error, and fixation (under BD).\n\n\nE.6 Edge cases and checks\n\n\n\nF DPO through the SRCT Lens\n\nNotation.\nF.1 Setting and single-site map\nF.2 Uniform size and Lipschitz bounds for the DPO score\nF.3 Entropy map and drift Lipschitzness\nF.4 DPO‚ÄìSRCT ODE, mass conservation, and positivity\n\nF.5 Barrier‚ÄìDominance (BD)\n\nNumerical note.\n\n\n\nF.6 Intra-class contraction\n\nSlope Condition (SC).\n\n\n\nF.7 Cross-class envelopes, trimming sharpenings, and a static cap\n\nCompatibility under BD.\n\n\nF.8 Lyapunov structure and eventual trimming (under SC)\n\nF.9 Two-level equilibrium: existence, uniqueness, and global convergence\n\nEdge cases (no mixed preferences).\nChoosing a compatible floor.\n\n\n\n\n\nG Dynamics on Coarse-Grained ‚ÄúLumps‚Äù\n\nSimplex, solution concept, and entropy map.\nTrim and feasibility.\n\nG.1 Lumps\n\nAggregation operator.\n\n\nG.2 Technical facts used repeatedly\n\nG.3 Small-Œµ\\varepsilon perturbation: trace and lump bounds\n\nForward-invariance templates.\n\n\n\nG.4 Pure-score (Œµ=0\\varepsilon=0) lump dynamics\n\nG.4.1 STaR\nG.4.2 GRPO\nG.4.3 DPO (sign-pure lumps)\n\n\nG.5 Entropy deviation envelopes for the lump term\n\nG.6 Open problems\n\nFace-wise entropy minima (at fixed œÅ\\rho and pk=Œ¥p_{k}=\\delta).\nRemarks.\n\n\n\n\n\nH Analysis of Stochasticity in SRCT\n\n\nH.1 Domain, notation, and standing hypotheses\n\nScore field and SRCT drift.\n\n\n\nH.2 Global Lipschitz moduli and envelopes\n\nSize envelope.\n\n\nH.3 Discrete mini‚Äìbatch updates and noise statistics\nH.4 Continuous‚Äìtime limits (correct scaling)\n\nH.5 Boundary behavior: entropy gap and BD conditions\n\nBarrier‚ÄìDominance (facewise).\nUnreflected vs. reflected diffusions.\n\n\nH.6 Uniform ellipticity on the tangent bundle\nH.7 Gradient‚Äìfield drifts and stationary laws\n\nH.8 Small centred bias: concentration toward the fittest face\n\nExponential Lyapunov device (reflected model).\nRemark (no fixation under a positive floor).\n\n\n\nH.9 Log‚Äìratio SDEs (algorithm‚Äìspecific)\n\nGRPO (within‚Äìclass).\nSTaR (within‚Äìclass).\nDPO (same‚Äìsign pair).\n\n\nH.10 Regime dictionary (concise)\n\n\n\nI Kernel Design Strategies for SRCT\n\nSetting, notation, and standing assumptions.\nSRCT objective, Shahshahani flow, and gauge.\n\nI.1 Idealized Kernel for a Two‚ÄìLevel Equilibrium\n\nTwo‚Äìlevel target.\nCurvature, strict concavity, uniqueness, interiority.\nLog‚Äìratio dynamics, operator‚Äìnorm envelope, dynamic floor.\nExponential convergence.\nStationary structure and uniform suppression.\nBlock‚Äìconstant kernels: PSD, norms, gap realization, low‚Äìnorm choice.\n\n\n\nI.2 Practical Design with a Learnable Semantic Kernel\n\nGated effective kernel and objective.\nIncorrect suppression and equalization among correct traces.\nSupport‚Äìfunction identity (diversity pressure).\nGlobal Lipschitz modulus of the SRCT drift on a trimmed simplex.\nTuning guidance (concise).\nDesign‚Äìto‚Äìguarantee checklist (explicit constants).\nNotation hygiene and edge cases.\n\n\n\n\n\nJ Insight Experiments\n\n\nJ.1 Experimental Implementation and Reproducibility\n\nVerifier and rewards.\nMini‚Äëbatch sampling and noise.\n\n\nJ.2 Strategy‚Äìsimplex overview (Fig.¬†1)\nJ.3 Study¬†A: scalar‚Äìobjective dynamics (Fig.¬†2)\nJ.4 Study¬†B: overlays and alignment diagnostics (Figs.¬†3, 4, 5)\nJ.5 Study¬†C: DCR phase diagrams (Fig.¬†6) and ablations (Fig.¬†7)\nJ.6 Objective and safety trajectories (Fig 8)\nJ.7 Safety‚Äìmargin distribution (Fig.¬†9)\n\n\n\n\n\n\n¬†\n\nThe Reasoning‚ÄìCreativity Trade-off: \nToward Creativity-Driven Problem Solving\n\n¬†\n\n\n\n\n\nMax Ruiz Luyten\n\n‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚Äâ\n\n\n\nMihaela van der Schaar\n\n\n\n\n\n\n\n\n\nUniversity of Cambridge\n\n\n\n\n\nAbstract\nState-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops‚Äîsampling diverse chains of thought and reinforcing the highest-scoring ones‚Äîmainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model‚Äôs distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all c"
  },
  {
    "title": "An Agentic Framework for Neuro-Symbolic Programming",
    "url": "https://arxiv.org/abs/2601.00743v1",
    "source": "arxiv",
    "summary": "Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDom",
    "full_text": "\n\n\n\n1 Introduction\n2 Background: DomiKnowS\n\n3 System Overview\n\n3.1 RAG\n3.2 Knowledge Declaration\n3.3 Model Declaration\n\n\n\n4 User Interface Implementation\n\n4.1 Backend\n4.2 Frontend\n\n\n\n5 Experiments\n\n5.1 Datasets\n5.2 Language Models\n5.3 Evaluation of ADS Workflow\n5.4 Human Evaluation\n\n\n6 Related Work\n7 Conclusion and Future Work\n\nA DomiKnowS Selected Tasks\n\n\nA.1 Natural Language Processing Tasks\n\nA.1.1 Hierarchical News Classification\nA.1.2 Spam Classification\nA.1.3 Sentiment Analysis\nA.1.4 Procedural Text Understanding\nA.1.5 Causal Reasoning\nA.1.6 Belief-Consistent Question Answering\nA.1.7 Logical Reasoning Question Answering\n\n\n\nA.2 Vision Tasks\n\nA.2.1 Hierarchical Image Classification I\nA.2.2 Hierarchical Image Classification II\nA.2.3 Constrained Digit Classification\n\n\n\nA.3 Constraint Satisfaction Problem Tasks\n\nA.3.1 Sudoku Puzzle\nA.3.2 Eight Queens Puzzle\n\n\n\n\nB Instructions for the Human Study\nC Detailed Evaluation Results\n\n\n\n\n\nAn Agentic Framework for Neuro-Symbolic Programming\n\n\n\nAliakbar Nafar,\nChetan Chigurupati,\nDanial Kamali,\n\nHamid Karimian,\nParisa Kordjamshidi\n\nMichigan State University\n\n\nCorrespondence: nafarali@msu.edu\n\n\n\nAbstract\nIntegrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library‚Äôs specific syntax. We propose AgenticDomiKnowS (ADS)111Access the UI at https://hlr-demo.egr.msu.edu/ to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.\n\n\n\nAn Agentic Framework for Neuro-Symbolic Programming\n\n\n\n\n\nAliakbar Nafar,\nChetan Chigurupati,\nDanial Kamali,\n\nHamid Karimian,\nParisa Kordjamshidi\n\n\n\nMichigan State University\n\n\nCorrespondence: nafarali@msu.edu\n\n\n\n\n\n\n1 Introduction\n\nDeep learning models augmented with symbolic reasoning methods, often referred to as neuro-symbolic (NeSy) systems, aim to combine the strengths of deep learning with the structured, logically consistent symbolic formalisms¬†Feldstein et¬†al. (2024). NeSy systems could make the models more robust, interpretable, and data-efficient than purely neural approaches¬†Liang et¬†al. (2025). However, authoring NeSy programs remains challenging, as existing frameworks impose a steep learning curve, requiring users to know the syntax and semantics of the target formalism for each symbolic system they employ¬†Sinha et¬†al. (2025).\n\n\nThis complexity is exemplified by NeSy frameworks such as DomiKnowS¬†Rajaby¬†Faghihi et¬†al. (2021), a declarative Python library that integrates symbolic logic with deep learning models. DomiKnowS operates by allowing users to define a conceptual graph that encodes concepts, relations, and logical constraints, which are then coupled with deep learning models. While this conceptual graph offers significant flexibility, utilizing the library requires mastering its syntax and manually encoding every logical rule. Consequently, this process is both error-prone and time-consuming for those without prior experience with the framework.\n\n\nA previous attempt to generate DomiKnowS programs with LLM assistance¬†Faghihi et¬†al. (2024) focused solely on the creation of the conceptual graph and its constraints, and not a complete DomiKnowS program. Constrained by the capabilities of earlier LLMs, it is designed to provide a UI that primarily serves as a coding assistant, requiring significant intervention by users who are familiar with the library. While newer LLMs have improved at expressing logical constraints and high-level relational structures¬†Cheng et¬†al. (2025); Shi et¬†al. (2025); Lalwani et¬†al. (2025), they continue to struggle with mapping them into correct syntax for domain-specific libraries. Additionally, because NeSy libraries like DomiKnowS are underrepresented or non-existent in pre-training corpora, LLMs frequently fail to generate their programs ¬†Gu et¬†al. (2025); Abbassi et¬†al. (2025).\n\n\nFigure 1: Knowledge and model declarations of a DomiKnowS program for the WIQA task. The left side defines the conceptual graph and logical constraints, while the right side shows the sensor code, which specifies how properties and predictive models are attached to the graph‚Äôs concepts.\n\n\nIn this demo paper, we introduce AgenticDomiKnowS (ADS) to overcome these generation barriers and enable users to create NeSy programs using natural language instructions and task descriptions. Unlike coding assistants such as Codex¬†Chen et¬†al. (2021) or Gemini CLI¬†Google (2025)222These assistants proved incapable of generating DomiKnowS programs from documentation in our initial testing. that synthesize an entire program at once, ADS employs an agentic workflow that breaks the development process into distinct stages, generating, executing, and refining each code section independently. This allows ADS to isolate and fix errors within specific components. ADS uses an iterative loop to fix syntactic errors identified during code execution and semantic errors detected by an LLM-based reviewer in a self-refinement process¬†Madaan et¬†al. (2023). ADS supports an optional human-in-the-loop mechanism for user intervention.\n\n\nWe facilitate this human-in-the-loop mechanism through an interactive web interface that provides access to ADS and visualizes the information needed for verification or refinement. The interface generates the DomiKnowS program as a plug-and-play executable Jupyter notebook, utilizing general-purpose VLMs as pre-initialized learning models for immediate inference. We also show how ADS helps DomiKnowS users accelerate their programming and non-users adopt NeSy programming without prior implementation experience.\n\n\n\n\n2 Background: DomiKnowS\n\nDomiKnowS uses a domain-specific Python-based language to define concepts, relations, and logical operators that encode domain knowledge as logical constraints. We use a procedural question-answering task, WIQA¬†Tandon et¬†al. (2019), to illustrate a DomiKnowS program. The WIQA dataset consists of paragraphs and associated questions asking about the effect of a perturbation, labeled as is_more, is_less, or no_effect. Crucially, there exists a transitivity relation between the answers to these questions when they form a causal chain. For example, if one question asks about the effect of step AA on BB, and another about BB on CC, their answers logically constrain the answer to a third question regarding the effect of AA on CC. We consider this transitivity essential for solving the task because it allows us to inject domain knowledge into the model, ensuring that predictions across related questions remain globally consistent. Figure¬†1 shows how this task is represented in DomiKnowS, highlighting two main components of a DomiKnowS program: the Knowledge Declaration and the Model Declaration.\n\n\nIn the Knowledge Declaration, we specify a conceptual graph that includes the concepts and relations. Using the concepts of this graph, the logical constraints needed to model this task can be defined. For WIQA, we create a paragraph concept and a question concept. We define the answer classes, is_more, is_less, and no_effect, that serve as labels associated with the questions. We define a one-to-many containment relation between paragraphs and questions. To express the logical relations between questions, we introduce a transitivity concept that connects triplets of questions (t1,t2,t3t_{1},t_{2},t_{3}). Finally, we add a logical constraint using ifL and andL operators: if a transitivity relation exists for a triplet then if the first two question (t1,t2t_{1},t_{2}) both indicate an increase (is_more), then the third question (t3t_{3}) must also indicate an increase.\n\n\nIn the Model Declaration, we load the data elements from the dataset and attach them as properties to the corresponding concepts using predefined DomiKnowS sensors (e.g., ReaderSensor). We also assign trainable models here: an LLMLearner wrapping an LLM to predict the question labels. We populate the graph edges, such as the transitivity triplets provided by the dataset. After these steps, the program can be executed to infer the outputs while obeying the logical constraints using Integer Linear Programming (ILP)¬†Roth and Yih (2005). Moreover, we can train the models to learn to satisfy the constraints using the underlying algorithms proposed in related research¬†Lee et¬†al. (2019); Nandwani et¬†al. (2019); Guo et¬†al. (2020).\n\n\n\n\n3 System Overview\n\nFigure 2: ADS system workflow. The left panel groups components of the Knowledge Declaration phase and the right panel the Model Declaration phase. Rectangles denote LLM agents, dashed rectangles denote human actions, ellipses denote input/output, and diamonds denote decision points.\n\n\nADS is implemented as a LangGraph333https://www.langchain.com/langgraph workflow over a shared memory state between multiple agents. It stores the task description, code drafts, reviews, and outputs of code executions. As depicted in Figure¬†2, the workflow starts with a user-provided natural-language task description. Using this task description, examples of similar tasks are retrieved from a RAG database, and then ADS proceeds through the two main phases of Knowledge Declaration and Model Declaration.\n\n\n\n3.1 RAG\n\nThe process begins with a retrieval step in which, given the input task description, the Rag Selector agent searches a pool of 12 prior DomiKnowS programs and retrieves the five most similar on"
  },
  {
    "title": "Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty",
    "url": "https://arxiv.org/abs/2601.00737v1",
    "source": "arxiv",
    "summary": "Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncert",
    "full_text": null
  },
  {
    "title": "Exploring the Performance of Large Language Models on Subjective Span Identification Tasks",
    "url": "https://arxiv.org/abs/2601.00736v1",
    "source": "arxiv",
    "summary": "Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification lik",
    "full_text": "\n\n\n\n1 Introduction\n2 Related Work\n\n3 Datasets\n\nComplex Text Datasets\nSimple Text Datasets\n\n\n\n4 Experiments\n\nBaselines\nLLMs\nApproaches\nEvaluation Metrics\n\n\n5 Results\n\n6 Discussion\n\nRQ1:\nRQ2:\nRQ3:\n\n\n7 Conclusion\n\nA Appendix\n\nA.1 LLM Prompt\nA.2 Hyper-parameters\nA.3 Additional Results\nA.4 Task-Specific Outputs\nA.5 Progress Test\n\n\n\n\n\n\n\nExploring the Performance of Large Language Models on \nSubjective Span Identification Tasks\n\n\nAlphaeus Dmonte1, Roland Oruche2, Tharindu Ranasinghe3\n Marcos Zampieri1, Prasad Calyam2\n1George Mason University, VA, USA\n2University of Missouri, MO, USA \n3Lancaster University, UK \nadmonte@gmu.edu\n\n\n\n\nAbstract\nIdentifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.\n‚Ä†‚Ä†WARNING: This paper contains examples that are offensive in nature.\n\n\n\nExploring the Performance of Large Language Models on \nSubjective Span Identification Tasks\n\n\n\n\nAlphaeus Dmonte1, Roland Oruche2, Tharindu Ranasinghe3\n\nMarcos Zampieri1, Prasad Calyam2\n\n1George Mason University, VA, USA\n2University of Missouri, MO, USA\n\n3Lancaster University, UK\n\nadmonte@gmu.edu\n\n\n\n\n\n\n1 Introduction\n\nOffensive language identification, sentiment analysis, and claim verification are some of the most widely studied tasks at the intersection of social media analysis and NLP sandu2024bibliometric. Most of the research on these tasks focuses on predicting post-level categorical labels. In the case of sentiment analysis, for example, these are often expressed in terms of positive, neutral, and negative labels or a Likert-scale representing the positive to negative continuum birjali2021comprehensive.\n\n\nVarious studies have addressed model explainability by developing frameworks, datasets, and models to identify attributes in texts through token span prediction. For example, in the toxic spans detection task, models predict the spans of toxic posts that are indicative of toxic label prediction pavlopoulos2021semeval; mathew2021hatexplain. Going beyond independent token spans, researchers have also proposed more structured formulations to capture relationship between textual elements. One of the most well-established of these formulations is Aspect-Based Sentiment Analysis (ABSA) pontiki-etal-2014-semeval; pontiki-etal-2015-semeval, which aims to detect aspects and their associated sentiments within a text. This approach is particularly effective for cases with mixed sentiments, such as ‚ÄúThe food was delicious, but the service was extremely slow‚Äù in a restaurant review. In this example different parts of the text express opposing opinions. In the same vein, in this paper we consider both complex and simple texts and define them as follows:\n\n\n\n\nComplex Text - A text containing more than one type of interrelated spans, and these related spans belong to different categories, such as Target and Aspect in ABSA.\nSimple Text - A text with only one span category such as a toxic span or claim span containing a toxic expression and a claim respectively.\n\n\n\nLLMs have achieved state-of-the-art performance across various NLP tasks, including generation and prediction minaee2024large. Recent studies on evaluating LLMs for sequence labeling tasks such as Named Entity Recognition (NER) wang2023gpt; pang2023guideline suggest that BERT models still outperform LLMs in the in-context learning setting. li2023label and dukic2024looking proposed approaches that transform the objective of LLMs to improve their performance on classification tasks. While LLMs have been explored for NER and sentiment analysis tasks, they have been unexplored for other token classification tasks like offensive spans and claim spans identification, and our work aims to address this gap.\n\n\nThis paper addresses the following research questions:\n\n\n\n\n‚Ä¢\n\nRQ1: How does the complexity of the text affect the LLM‚Äôs ability to identify the different types of spans? Do the models identify specific span types more efficiently than others?\n\n\n\n‚Ä¢\n\nRQ2: How do the model size and modeling strategies influence the span identification capabilities of LLMs?\n\n\n\n‚Ä¢\n\nRQ3: Are LLMs efficient in a low-resource setting?\n\n\n\n\n\n\n\n2 Related Work\n\nOffensive language identification, sentiment analysis, and claim verification are some of the widely studied text classification tasks. Several datasets with post-level annotations have been released for offensive language¬†davidson2017automated; zampieri-etal-2019-predicting; ranasinghe2021mudes; mathew2021hatexplain, sentiment analysis¬†tan2023survey, as well as claim verification¬†wang2017liar; thorne2018fever; schlichtkrull2024averitec. Most of the approaches to these tasks rely on pre-trained transformer-based language models like BERT¬†caselli2020hatebert; sarkar2021fbert; tan2023survey; zhang2023sentiment; dmonte2024evaluation while, more recently, LLMs have also been explored pan2023fact; zampieri2023offenseval; dmonte2024claim.\n\n\nWhile most of the work on the aforementioned three tasks addresses post-level analysis, several datasets and approaches for token-level analysis have also been proposed. For offensive language, the TSD pavlopoulos2021semeval and HateXplain mathew2021hatexplain datasets were introduced to identify the token spans containing offensive or toxic content, or specific rationales contributing to the predicted labels while TBO zampieri2023target was created, to identify the offensive spans and their associated targets.\nSimilarly, ABSA pontiki-etal-2014-semeval aims to identify the aspects, which are token spans from the text describing the targets or entities, as well as the sentiment labels associated with these aspects. wang2016recursive; wang2017coupled further annotated this dataset to identify the opinion terms. Approaches like Relation-aware Collaborative Learning (RACL)¬†chen2020relation, which considers the relationship between the different types of spans, have showed promising results.\n\n\nWhile LLMs have not been used extensively for token span identification tasks, there are some works that have leveraged these models on a few similar tasks. han2023information leveraged GPT for four tasks, namely NER, Relation Extraction, Entity Extraction, and ABSA. The authors observe that LLMs achieve lower performance compared to smaller BERT-based models. To improve the LLM performance on token spans tasks like NER, ABSA, etc, approaches that remove the causal mask from the LLM layers have been proposed¬†li2023label; dukic2024looking. While these approaches improve the performance on the token spans identification tasks, removing the causal mask changes the training objective of the models, essentially transforming the model from autoregressive to a masked language model. In this work, we leverage the autoregressive capabilities of the LLMs to evaluate their performance using different approaches.\n\n\n\n\n3 Datasets\n\nWe acquire four English datasets for our experiments, two with complex text spans and two with simple text spans. The example instances from each dataset are presented in Table¬†2, while the data statistics are presented in Table 1.\n\n\n\n\n\n\nSpan Type\nDataset\nTrain\nTest\nTotal\n\n\n\n\nComplex Spans\nTBO\n4,000\n673\n4,673\n\n\nABSA\n3,041\n800\n3,841\n\n\nSimple Spans\nCSI\n3,953\n362\n4,315\n\n\nTSD\n8,629\n2,000\n10,629\n\n\n\n\nTable 1: Number of Train and Test instances in the datasets used for the experiments.\n\n\nComplex Text Datasets\n\nWe acquire Target Based Offensive Language (TBO) zampieri2023target and the Aspect Based Sentiment Analysis (ABSA) dataset by pontiki-etal-2014-semeval. The instances in the TBO dataset were annotated with Arguments, which are offensive phrases in the text, and Target representing the subject of the arguments. The ABSA dataset is annotated with Aspects and their corresponding Opinion spans.\n\n\n\nSimple Text Datasets\n\nWe use the Claim Spans Identification (CSI)¬†mittal2023lost and Toxic Span Detection (TSD)¬†pavlopoulos2021semeval datasets. CSI is annotated with claim spans from social media posts, while the TSD dataset is annotated for toxic and harmful spans.\n\n\n\n\n\n\nDataset\nType\n\n\nExample Instance\n\n\n\n\nAnnotation\n\n\n\n\n\n\nTBO\nComplex\n\n\n@USER Time to stop the voter fraud. These people are evil.\n\n\n\n\nTarget 1: None, Argument 1: voter fraud, Target 2: these people, Argument 2: are evil\n\n\n\n\nComplex\n\n\n@USER Imma wear my uggs until they turn inside out the hell!\n\n\n\n\nTarget 1: @USER, Argument 1: hell\n\n\n\n\nABSA\nComplex\n\n\nnot only was the food outstanding, but the little ‚Äôperks‚Äô were great\n\n\n\n\nAspect 1: food, Opinion 1: outstanding, Aspect 2: perks\n\n\n\n\nComplex\n\n\nraga‚Äôs is a romantic, cozy restaurant\n\n\n\n\nOpinion 1: romantic, Opinion 2: cozy\n\n\n\n\nCSI\nSimple\n\n\nIt‚Äôs not Rahul Khan, it\n\n\n\n\nSpan: It‚Äôs not Rahul Khan, it\n\n\n\n\nSimple\n\n\nThey will try everything to steal it. We will not let them!\n\n\n\n\nSpan: They will try everything to steal it.\n\n\n\n\nTSD\nSimple\n\n\n‚ÄôAnother violent and aggressive immigrant killing a innocent and intelligent US Citizen‚Ä¶. Sarcasm‚Äô\n\n\n\n\nArgument 1: violent and aggressive immigrant\n\n\n\n\nSimple\n\n\nWhat a knucklehead. How can anyone not know this would be offensive??\n\n\n\n\nArgument 1: knucklehead\n\n\n\n\n\n\nTable 2: Example instances fro"
  },
  {
    "title": "Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL",
    "url": "https://arxiv.org/abs/2601.00728v1",
    "source": "arxiv",
    "summary": "We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficien",
    "full_text": "\n\n\n\n1 Introduction\n2 Related Work\n\n3 A General RL Framework for Precision Selection\n\n3.1 Contextual Bandit Formulation\n3.2 Learning with Discretized State Space\n3.3 Action Space Reduction\n\n\n\n4 Case Study: GMRES-Based Iterative Refinement\n\n4.1 Mixed-Precision GMRES-based Iterative Refinement\n4.2 Contextual Bandit Formulation for Precision selection\n\n\n\n5 Experiments\n\n5.1 Problem Setup\n\n5.2 Simulations on Dense Systems\n\n\n5.3 Simulations on Sparse Systems\n\n\n6 Discussion\n\n\n7 Conclusion and Future Work\n\n.1 For Dense Linear Systems\n.2 For Sparse Linear Systems\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrecision Autotuning for Linear Solvers via Contextual Bandit‚ÄìBased RL‚Ä†‚Ä†thanks: This work is in progress and will be submitted soon.\n\n\n\n‚ÄÖErin Carson\nCharles University \nPrague, Czech \ncarson@karlin.mff.cuni.cz\n&amp;‚ÄÖXinye Chen\nSorbonne Universit√©, CNRS, LIP6 \nParis, France \nxinye.chen@lip6.fr\nSupported by the Charles University Research Centre program No. UNCE/24/SCI/005 and the European Union (ERC, inEXASCALE, 101075632). Views and opinions expressed are those of the authors only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them. \n\n\nAbstract\nWe propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems A‚Äãx=bAx=b. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an œµ\\epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.\n\n\nKeywords‚ÄÇinference reduced-precision configurations, reinforcement learning, precision tuning, linear solvers\n\n\n\n1 Introduction\n\nFloating-point arithmetic (8766229, ) is widely used in machine learning and scientific computing. With the rapid development of large language models (DBLP:journals/corr/abs-2005-14165, ; hu2022lora, ; touvron2023, ) as well as large-scale GPU computing (DBLP:journals/corr/abs-1710-03740, ; peng2023fp8lmtrainingfp8large, ), numerical calculations and algorithm deployment with extensive use of floating-point arithmetic are often accompanied by a substantial increase in energy use. Therefore, using reduced-precision arithmetic in algorithms is typically required in many intensive computing kernels due to its lower communication, faster arithmetic, and energy efficiency. Seven commonly-used floating-point formats are referenced in Table¬†1. The NVIDIA A100 achieves up to 312 TFLOPS with half precision (FP16/BF16), 156 TFLOPS with TF32, and 9.7 TFLOPS with FP64, yielding an approximate 32√ó32\\times speedup for low-precision formats. Further, the NVIDIA H100 (NVIDIA‚Äôs Hopper architecture) achieves up to 624 TFLOPS with fp8, offering an approximate 64√ó64\\times speedup versus FP64 (nvidia_a100, ; nvidia_fp8, ). The work nvidia_fp8  demonstrates that the FP8 formats E4M3 and E5M2 can in some cases match FP16 accuracy with reduced compute and memory costs.\n\n\nHowever, reduced-precision arithmetic often brings increased rounding errors and numerical instability, which can compromise the results of computations, especially at large scale (10.1177/1094342016652462, ). The idea behind mixed-precision algorithms is to design an algorithm that combines low and high precision arithmetic while retaining an acceptable level of accuracy, which remains a major obstacle in modern approximate computing paradigms (benkhalifa:hal-03978176, ; 7348659, ). Accordingly, many theoretical analyses on rounding error analysis and mixed-precision algorithms (doi:10.1137/17M1122918, ; doi:10.1137/17M1140819, ; doi:10.1137/20M1316822, ; doi:10.1137/17M1122918, ; abhl24, ) and precision tuning tools (6877460, ; 10.1145/3213846.3213862, ) have been developed, which aim to achieve a balance between precision loss and arithmetic speedup.\n\n\nTheoretical analyses of the use of multiprecision arithmetic and mixed-precision algorithms have been extensively conducted in the context of iterative refinement (doi:10.1137/20M1316822, ; abhl24, ), least squares problems (doi:10.1137/19M1298263, ; doi:10.1137/20M1316822, ), and GMRES (jang:hal-05163845, ). For example, iterative refinement can be executed in three precisions, but the convergence is only theoretically guaranteed for a limited range of problems, which can be overly restrictive in practice oktay2022multistage . As such, one can instead use to precision tuning tools to find a suitable mixed-precision approach. Existing tools typically require running the program multiple times via trial-and-error, and the scalability and general ability are not verified, so they are either limited to small or medium-scale programs or suffer from efficiency issues. An ideal case for a precision tuning tool or method is to fit the model in a limited number of training sets and learn the key features that can be used to infer mixed-precision configurations for new unseen data. These challenges need to be addressed to reduce the dependency on programmer efforts.\n\n\nTable 1: Key parameters of seven floating-point formats; uu denotes the unit-roundoff corresponding to the precision, xminx_{\\min} denotes the smallest positive normalized floating-point number, xmaxx_{\\max} denotes the largest floating-point number, tt denotes the number of binary digits in the significand (including the implicit leading bit), emine_{\\min} denotes exponent of xminx_{\\min}, and emaxe_{\\max} denotes exponent of xmaxx_{\\max}.\n\n\n\n\n‚ÄÇ‚ÄÉ‚ÄÉuu\n\n‚ÄÇ‚ÄÉxminx_{\\min}\n\n‚ÄÇ‚ÄÉxmaxx_{\\max}\n\ntt\nemine_{\\min}\nemaxe_{\\max}\n\n\nbfloat16 (BF16)\n3.91√ó10‚àí33.91\\times 10^{-3}\n1.18√ó10‚àí381.18\\times 10^{-38}\n3.39√ó10383.39\\times 10^{38}\n8\n-126\n127\n\n\nhalf precision (FP16)\n4.88√ó10‚àí44.88\\times 10^{-4}\n6.10√ó10‚àí56.10\\times 10^{-5}\n6.55√ó1046.55\\times 10^{4}\n11\n-14\n15\n\n\nTensorFloat-32 (TF32)\n9.77√ó10‚àí49.77\\times 10^{-4}\n1.18√ó10‚àí381.18\\times 10^{-38}\n1.70√ó10381.70\\times 10^{38}\n11\n-126\n127\n\n\nsingle (FP32)\n5.96√ó10‚àí85.96\\times 10^{-8}\n1.18√ó10‚àí381.18\\times 10^{-38}\n3.40√ó10383.40\\times 10^{38}\n24\n-126\n127\n\n\ndouble (FP64)\n1.11√ó10‚àí161.11\\times 10^{-16}\n2.23√ó10‚àí3082.23\\times 10^{-308}\n1.80√ó103081.80\\times 10^{308}\n53\n-1022\n1023\n\n\n\n\n\nA contextual bandit (also known as a multi-armed bandit with context) is a simplified RL problem where the agent makes decisions based on the current context (i.e., state) without considering the future contexts or rewards of its actions; in other words, the agent optimizes for one-step (immediate) reward rather than long-term cumulative reward. In this paper, we propose a general framework for applying reinforcement learning (RL) for precision selection in general numerical algorithms, formulated as a contextual bandit problem due to the independence of problem instances and the single decision per instance. This is the first work to formally define the use of RL for precision selection in any algorithm. The framework uses an epsilon-greedy strategy, controlled by a decaying epsilon determined by training episodes, to select precision levels for the prespecified algorithm steps, treating precision choices as a multi-armed bandit problem within a RL environment. The epsilon parameter balances exploration and exploitation, starting high to encourage diverse precision selections and decaying over time to favor optimal choices. We believe this framework enables at least two utility points:\n\n\n1.\n\nIdentifying the precision level required for user-specific computational steps in terms of hand-crafted features or low computational complexity features modeled from linear systems;\n\n\n\n2.\n\nFinding salient features of the linear systems (e.g., condition number, matrix norm, non-zero values, diagonal dominance) to determine the reduced-precision configurations;\n\n\n\n3.\n\nBeing able to inference reduced mixed-precision configurations of unseen datasets.\n\n\n\n\n\nWe apply this framework to the GMRES-based iterative refinement (GMRES-IR) method doi:10.1137/17M1122918  to verify the effectiveness and generalization ability of RL for precision selection, aiming to achieve a trade-off between the use of low precision and accuracy. The framework is particularly suited for scenarios with limited training data and is designed to generalize to new data, and can be easily implemented in an online learning routine to avoid model retraining.\n\n\nThe rest of the paper is structured as follows. Section¬†2 discusses the existing literature on precision autotuning as well as its pros and cons, and a comparison with our work. Section¬†3 presents our general framework for precision selection;\nTo verify its effectiveness, we use the iterative refinement method, a well-studied mixed-precision method, as a case study detailed in Section¬†4. Section¬†5 presents the experiments and empirical results on both dense and sparse matrices under varying condition numbers and sparsity. Section¬†7 discusses limitations as well as future work.\n\n\n\n\n2 Related Work\n\nThere exists a variety of theo"
  },
  {
    "title": "Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model",
    "url": "https://arxiv.org/abs/2601.00716v1",
    "source": "arxiv",
    "summary": "Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labele",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related Work\n\n2.1 Vision-Language Model\n\n2.2 Domain Shift Detection\n\n2.2.1 Distance-Based Methods\n2.2.2 Machine Learning-Based Methods\n2.2.3 Statistic-Based Methods\n\n\n\n\n\n3 Domain Shift Analysis Toolbox\n\n\n3.1 Toolbox Design and Workflow\n\n3.1.1 Overall\n3.1.2 Workflow\n\n\n3.2 Algorithms\n\n\n\n4 Explore Performance Degradation of Pathology VLM\n\n\n4.1 Dataset\n\n4.1.1 Overview\n4.1.2 Reference and OOD Sites\n\n\n4.2 Model\n4.3 Inference\n\n4.4 Data Shift and Performance Degradation Analysis\n\n4.4.1 Experimental Setting\n4.4.2 Results\n4.4.3 Analysis\n\n\n\n4.5 Output-based Indicator for Performance Degradation\n\n4.5.1 Motivation\n4.5.2 Output-Based Degradation Indicator\n4.5.3 Results\n4.5.4 Discussion\n\n\n\n\n5 Conclusion\n\n\n\n\n\nDetecting Performance Degradation under Data Shift in Pathology Vision-Language Model\n\n\nHao¬†Guan\n\n‚ÄÉ‚ÄÉ\n\n\n‚ÄÉ‚ÄÉ\nLi¬†Zhou\nH.¬†Guan and L.¬†Zhou are with the Division of General Internal Medicine and Primary Care, Brigham and Women‚Äôs Hospital, and Department of Medicine, Harvard Medical School, Boston, Massachusetts 02115, USA.\nCorresponding Author: H.¬†Guan (hguan6@bwh.harvard.edu).\n\n\nAbstract\nVision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data.\nIn this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation.\nMotivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection.\nExperiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.\n\n\n{IEEEkeywords}\nData Shift Detection, Medical AI Monitoring, Performance Degradation, Vision-Language Model, Digital Pathology, Scientific Software, AI Reliability\n\n\n\n1 Introduction\n\n\\IEEEPARstart\nRecent advances in Vision-Language Models (VLMs) have greatly expanded the capabilities of artificial intelligence in medicine¬†[1, 2, 3, 4]. By jointly encoding visual and textual information, VLMs (e.g., CLIP¬†[1]) and their medical adaptations have enabled flexible zero-shot classification, image-report retrieval, and caption generation across clinical imaging modalities. In digital pathology, VLMs offer a promising foundation for computational diagnosis in pathology.\n\n\nDespite these advantages, the long-term reliability of VLMs in clinical deployment remains uncertain. Once deployed, these models may encounter input data that significantly differ from the observed distribution, arising from variations in scanners, staining procedures, or acquisition sites. This is the well-known domain (data) shift problem¬†[5, 6, 7, 8]. Such data shifts, as shown in Fig.¬†1, can cause performance degradation, compromising the safety and trustworthiness of AI-assisted diagnostic systems¬†[9]. Detecting degradation is therefore critical to prevent clinical risks and guide model maintenance.\n\n\nFigure 1: Overview of domain (data) shift across different medical sites and its impact on performance of medical AI models. An AI model deployed in Site A operates well, but when applied to Site B, the model suffers degradation under data shift.\n\n\nHowever, detecting performance degradation in large pre-trained pathology VLMs presents several fundamental challenges. First, despite the rapid adoption of VLMs in medical imaging, their post-deployment reliability, particularly performance degradation under real-world data shift, has not been systematically studied. Second, in practical medical settings, ground-truth labels are often unavailable after deployment, making direct detection of performance degradation using standard metrics such as accuracy or AUC infeasible.\n\n\nTo address this challenge, we investigate performance degradation under data shift in a state-of-the-art pathology VLM by jointly analyzing input data shift and output-level prediction. To support systematic exploration of input data shift, we develop DomainSAT, a lightweight GUI-based toolbox that integrates representative shift-detection algorithms, enabling intuitive inspection of data shifts across datasets. Our analysis confirms that input-level shift detection plays an important role in identifying distributional changes and providing warning signals, but also shows that input data shifts alone are not always predictive of downstream performance degradation.\n\n\nMotivated by this observation, we further examine output-level signals and introduce a simple yet effective, label-free confidence-based performance degradation indicator. This indicator captures changes in the model‚Äôs predictive confidence under shifting data conditions. The underlying intuition is that as a VLM operates farther from its reliable regime, its output confidence distribution becomes less separable and more uncertain which is a sign of performance degradation.\n\n\nWe evaluate the proposed framework using a large-scale pathology dataset spanning multiple medical sites with scanner-induced variability. Experimental results demonstrate that output-based confidence indicators closely track performance degradation, while input-level shift detection provides complementary diagnostic context. Together, these signals enable more reliable monitoring and interpretation of performance degradation in pathology VLMs under data shift.\n\n\nThe main contributions of this study are threefold:\n\n\n‚Ä¢\n\nAn in-depth investigation of data-shift-induced performance degradation in a state-of-the-art pathology VLM.\n\n\n\n‚Ä¢\n\nA label-free Confidence-based Degradation Indicator (CDI), which provides an effective signal for VLM degradation without requiring ground-truth labels.\n\n\n\n‚Ä¢\n\nDomainSAT, a lightweight GUI toolbox that integrates representative shift-detection methods and facilitates intuitive visualization of data shift patterns.\n\n\n\n\n\nThese components provide a practical framework for reliability monitoring of foundation models in digital pathology, with the DomainSAT toolbox publicly available at https://github.com/guanharry/DomainSAT.\n\n\n\n\n2 Related Work\n\n\n2.1 Vision-Language Model\n\nVision-Language Models (VLMs) learn joint representations of images and text, enabling zero-shot classification and retrieval. General-purpose VLMs such as CLIP¬†[1], BLIP-2¬†[10], and LLaVA¬†[11] have demonstrated strong generalization across diverse visual domains.\nMotivated by their success, several medical VLMs have been developed to improve clinical outcomes. These include MedCLIP¬†[2], BiomedCLIP¬†[12], and LLaVA-Med¬†[3], which leverage paired medical image-text data to enhance medical understanding.\n\n\nIn digital pathology, domain-specific VLMs have recently emerged to address the unique challenges of high-resolution histopathology images and fine-grained tissue semantics. Notably, PathGen-CLIP¬†[13], the state-of-the-art model used in this study, is trained on 1.6 million pathology image-text pairs. PathGen-CLIP provides strong pathology-specific embeddings and has demonstrated very good performance in tumor classification tasks.\nDespite rapid progress, the reliability and performance degradation of pathology VLMs under real-world data shift remain largely unexplored, motivating this study.\n\n\n\n\n2.2 Domain Shift Detection\n\nDomain (data) shift detection methods can generally be categorized into three groups: distance-based, statistic-based, and machine learning-based, as shown in Table¬†1.\n\n\n\n2.2.1 Distance-Based Methods\n\nThese methods quantify discrepancies between reference and target data using distance metrics, where larger values typically indicate stronger domain shift and increased risk of performance degradation. In¬†[14], a pre-trained autoencoder extracts latent features from chest X-rays, and MMD distance is computed to detect subtle distributional changes, including those associated with emerging conditions such as COVID-19. Stacke¬†et al.‚Äâ[6] use CNN-derived features and apply Wasserstein and KL divergences to assess latent-space shifts in medical image analysis.\n\n\nTable 1: Representative Domain Shift Detection Algorithms Included in the DomainSAT Toolbox.\n\n\n\nCategory\nAlgorithm\nReference\n\n\nDistance-Based\nMMD\n[15]\n\n\nWasserstein Distance\n[16]\n\n\nMahalanobis Distance\n[17]\n\n\nJS Divergence\n[18]\n\n\nKL Divergence\n[19]\n\n\nStatistic-Based\nKolmogorov-Smirnov test\n[20]\n\n\nWilcoxon rank-sum test\n[21]\n\n\nCram√©r-von Mises test\n[22]\n\n\n\nœá2\\chi^{2} test\n[23]\n\n\nMachine Learning-Based\nDomain Classifier\n[24]\n\n\nC2ST (Logistic Classifier)\n[25]\n\n\nC2ST (Random Forest)\n[26]\n\n\nAutoencoder\n[27]\n\n\n\n\n\nFigure 2: Overview of the DomainSAT workflow. The toolbox comprises three main components: (1) a data loading module for importing and preprocessing data"
  },
  {
    "title": "BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting",
    "url": "https://arxiv.org/abs/2601.00698v1",
    "source": "arxiv",
    "summary": "Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \\textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithm",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related Work\n\nPatching in Time Series Transformers\nB-Splines\nNon-Integer Relative Positional Encoding\n\n\n\n3 Preliminaries\n\n3.1 B-Splines\n3.2 Transformers\n3.3 Rotary Positional Embeddings\n\n\n\n4 Methodology\n\n4.1 Problem Statement\n\n4.2 BSAT: B-Spline Adaptive Tokenizer\n\nModified Feature Function ff\nAdaptive Clip-Factor\nRidge Fallback\nCoefficient Clipping\nCache\n\n\n\n4.3 Positional Encoding for Non-Uniform Tokens\n\nL-RoPE: Per-Layer Learnable Frequency Base\nHybrid Additive Rotary Positional Encoding\n\n\n4.4 Model Architecture\n\n\n\n5 Experiments\n\nDatasets\nSetup and Baseline\nTuning and Training\nAblation Study\n\n\n\n6 Results and Discussion\n\nComparative Benchmark\n\n6.1 Ablation Results\n\nHybrid Additive Rotary Positional Encoding RoPE LPE\nL-RoPE as a Multi-Resolution Mechanism\n\n\n6.2 Limitations and Diagnostics\n6.3 Future Work\n\n\n7 Conclusion\n\nA Appendix\n\n\nA.1 Dataset Details\n\nDataset Analysis\n\n\n\nA.2 Reproducibility\n\n\nHyperparameter Tuning Configuration\n\nSearch Strategy:\nSearch Space:\n\n\nTraining Configuration\nPseudo Code\n\n\n\nA.3 Ablation\n\nLearned RoPE Base Heatmap\n\n\n\nA.4 Full Benchmark\n\nAdditional Visualizations\n\n\n\n\n1. General Paper Structure\n2. Theoretical Contributions\n3. Dataset Usage\n4. Computational Experiments\n\n\n\n\n\nBSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting\n\n\n\nMaximilian Reinwardt1,\nMichael Eichelbeck1,\nMatthias Althoff 1\n\n\n\nAbstract\nLong-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data‚Äôs semantic structure. In this paper, we introduce the B-Spline Adaptive Tokenizer (BSAT), a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position.\nFurther, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.\n\n\n\n1 Introduction\n\nLong-term time series forecasting plays a crucial role across many sectors (cirstea_towards_2022; perveen_handling_2020; pan_magicscaler_2023).\nDeep learning models, particularly transformers (vaswani_attention_2017), excel at capturing long-range dependencies (lara-benitez_evaluation_2021; li_deep_2024).\nHowever, as their point-wise self-attention scales quadratically in both computation and memory, they become impractical for very long sequences.\nPatchTST (nie_time_2023) improved efficiency by segmenting sequences into overlapping fixed-length sub-sequences, patches. Conversely, this uniform segmentation can inadvertently split meaningful patterns or waste computational capacity on less informative regions (huang_hdmixer_2024; liu_rethinking_2025; cao_mspatch_2025; pagnoni_byte_2024).\nTo overcome the rigidity of patching, we explore adaptive tokenization, where tokens are dynamically aligned with the structure of the series. This introduces new challenges:\n(i) defining semantically meaningful tokens;\n(ii) embedding tokens of varying lengths; and\n(iii) accurately encoding non-uniform positions.\n\n\nIn this paper, we address these challenges through two major contributions:\n(1) We introduce the B-Spline Adaptive Tokenizer (BSAT), a novel tokenization strategy that adaptively segments time series using a B-spline curve. BSAT algorithmically places more tokens where the series exhibits high complexity. Each token encodes one basis function and is composed of two scalars: coefficient and position.\n\n\n(2) To embed the positions of these variable-sized and overlapping tokens, we introduce a hybrid positional encoding strategy, applying a learnable positional encoding and Rotary Positional Embedding (RoPE) (su_roformer_2023): Hybrid Additive Rotary Positional Encoding. Additionally, we propose L-RoPE, a layer-wise learnable RoPE frequency base, enabling the model to capture dataset-specific temporal patterns.\n\n\nOur experiments show that BSAT achieves strong performance against common baseline models and notably, performs particularly well on low token budgets.\nWe argue that, the layer-wise learnable RoPE base acts as a multi-resolution attention mechanism.\n\n\n\n\n2 Related Work\n\nPatching in Time Series Transformers\n\nSegmentation of large input sequences has proven successful across domains (devlin_bert_2019; pagnoni_byte_2024; dosovitskiy_image_2021). In the long-term time series forecasting domain, PatchTST (nie_time_2023) segments time series into uniform-size patches, treating them as input tokens. This improved both performance and efficiency by capturing local semantic information and shrinking sequence length (wang_deep_2024).\n\n\nHowever, uniform patches create challenges (pagnoni_byte_2024; huang_hdmixer_2024; liu_rethinking_2025; cao_mspatch_2025):\n(1) They may segment semantic structures, peaks, and periodic patterns or fail to split short structures, causing information loss.\n(2) They produce uneven information density per token. As models assign an equal amount of compute to each token, a substantial share is spent inefficiently.\nTo address this, some Time Series Transformers (TSTs) leverage multiple fixed patch sizes in parallel (chen_pathformer_2024; cao_mspatch_2025; du_multiresformer_2024).\nStudies in MPLs have introduced adjustable patches (huang_hdmixer_2024; liu_rethinking_2025).\nIn large, pre-trained time series models, adaptive tokenization via a learnable selection from a fixed set of patch sizes (kamarthi_large_2024), and variable motif-based segmentation (gotz_byte_2025) have been proposed.\nThese approaches have limitations: Parallel patch sizes increase compute costs, the flexibility of adjustable patches is limited, and they are incompatible with TSTs. Pre-trained tokenizers transfer poorly across domains and require substantial data for training. Further embedding variate patch sizes is challenging. Existing Options (nie_time_2023; kamarthi_large_2024; du_multiresformer_2024; gotz_byte_2025), all result in information loss, wasted compute or added architectural complexity.\n\n\n\nB-Splines\n\nB-splines are piecewise polynomial functions for constructing flexible curves with local control and adjustable smoothness.\nThis is achieved by representing them as the linear combination of basis functions, weighted by coefficients.\nSome deep learning approaches have integrated splines into recurrent neural networks and multilayer perceptrons (hajiabotorabi_improving_2019; kong_nonlinear_2018; bilos_irregularly-sampled_2022; gasthaus_probabilistic_2019).\nNotably, BasisFormer, learns global basis vectors, and predicts based on similarity to global patterns (ni_basisformer_2024).\nTo the best of our knowledge, a TST with an input token representing B-spline basis functions, enabling adaptive token lengths, has not been proposed before.\n\n\n\nNon-Integer Relative Positional Encoding\n\nThe permutation-invariant self-attention mechanism necessitates an explicit encoding of sequence order and positions (huang_improve_2020). Many models use fixed or learned absolute positional embeddings (vaswani_attention_2017; devlin_bert_2019; nie_time_2023). For time series with long, complex dependencies, relative positional embeddings and hybrid positional embeddings (huang_improve_2020; ke_rethinking_2021; liutkus_relative_2021; zhang_exploring_2024) have improved performance (irani_positional_2025).RoPE (su_roformer_2023), a relative positional encoding method has been widely adopted in natural language processing (touvron_llama_2023) and applied to irregular time series (zivanovic_rotary_2025). RoPE Base modification can serve to control attention decay, biasing attention toward short- or long-range patterns (men_base_2024). Some studies have explored learning the RoPE base pair-wise (zhang_elastst_2024; heo_rotary_2024), to better adapt attention patterns to the data.\nMotivated by this, we propose two modifications: a layer-wise learnable base, allowing each layer to attend to distinct temporal patterns and a hybrid positional encoding that applies both additive and rotary embeddings.\n\n\n\n\n\n3 Preliminaries\n\n\n3.1 B-Splines\n\nB-splines offer a principled framework for adaptive time series segmentation, through their desirable mathematical properties (partition of unity, continuity, and provably optimal local approximations), computational advantages (linear basis structure and compact support enabling natural tokenization), and well-established signal-based knot placement algorithms from approximation theory.\nB-splines are defined as n=k‚àí(p+1)n=k-(p+1) piecewise polynomial functions defined over a non-decreasing knot sequence ùùâ=(œÑ0,‚Ä¶,œÑk‚àí1)\\boldsymbol{\\tau}=(\\tau_{0},\\dots,\\tau_{k-1}) with kk knots, parameterized by their degree pp and clamped by p+1p+1 boundary knots.\nFor Œæ‚àà[œÑp,œÑn]‚äÇ‚Ñù\\xi\\in[\\tau_{p},\\tau_{n}]\\subset\\mathbb{R}, the ii-th B-spline basis function Ni,p‚Äã(Œæ)N_{i,p}(\\xi) is defined recursively by the Cox‚Äìde Boor relation¬†(de_boor_practical_2001, Ch. 9):\n\n\n\nNi,p‚Äã(Œæ)=\\displaystyle N_{i,p}(\\xi)=\\;\nŒæ‚àíœÑiœÑi+p‚àíœÑi‚ÄãNi,p‚àí1‚Äã(Œæ)\\displaystyle\\frac{\\xi-\\tau_{i}}{\\tau_{i+p}-\\tau_{i}}N_{i,p-1}(\\xi)\n\n\n\n\n\n+œÑi+p+1‚àíŒæœÑi+p+1‚àíœÑi+1‚ÄãNi+1,p‚àí1‚Äã(Œæ).\\displaystyle+\\frac{\\tau_{i+p+1}-\\xi}{\\tau_{i+p+1}-\\tau_{i+1}}N_{i+1,p-1}(\\xi).\n\n(1)\n\n\nEach basis function has local support over the interval [œÑi,œÑi+p+1)[\\tau_{i},\\tau_{i+p+1}); therefore, it only affects a limited region of the curve. Given a set of coefficients {ci}i=0n‚àí1\\{c_{i}\\}_{i=0}^{n-1}, a B-spline curve is then defined as\n\n\n\nC‚Äã(Œæ)=‚àëi=0n‚àí1ci‚ÄãNi,p‚Äã(Œæ).C(\\xi)=\\sum_{i=0}^{n-1}c_{i}N_{i,p}(\\xi).\n\n(2)\n\n\nTo construct a B-spl"
  },
  {
    "title": "Bayesian Inverse Games with High-Dimensional Multi-Modal Observations",
    "url": "https://arxiv.org/abs/2601.00696v1",
    "source": "arxiv",
    "summary": "Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related Work\n\n2.1 Dynamic Games\n2.2 Inverse Dynamic Games\n2.3 Multi-Modal VAEs\n\n\n3 Preliminaries\n\n4 Approach\n\n\n4.1 A Bayesian View on Inverse Games\n\n4.1.1 Observation Modalities\n\n\n\n4.2 Auto-Encoding Bayesian Inverse Games\n\n4.2.1 Introducing a Latent Variable Model\n4.2.2 Properties of the Latent Variable Model\n4.2.3 Connection to Variational Autoencoders\n\n\n\n4.3 Training a Game-Theory-Informed Variational Autoencoder\n\n4.3.1 High-Level Training Process\n4.3.2 Gradient Propagation Through the Game-Theory-Informed Observation Model\n4.3.3 Remark on Inference Time.\n\n\n\n\n\n5 Experiments\n\n\n5.1 Experiment Setup and Baselines\n\n5.1.1 Baselines\n\n\n\n5.2 Intersection Scenario with Partial-State-Only Observations\n\n5.2.1 Observability challenge of MLE inverse games\n5.2.2 Monte Carlo Evaluation\n\n\n5.3 Highway Scenario with Partial-State-Only Observations\n\n5.4 Intersection Scenario with Multi-Modal Observations\n\n\n5.4.1 Color-Encoded Agent Intents\n\nQualitative Behavior.\nMonte Carlo Evaluation.\n\n\n\n5.4.2 Agent Type Encoded Intents\n\nQualitative Behavior.\nMonte Carlo Evaluation.\n\n\n\n\n\n\n6 Conclusions\n\n\n\n\n\n\n\\corrauth\nXinjie Liu,\nThe University of Texas at Austin, Austin, TX 78712, USA.\n\nBayesian Inverse Games with High-Dimensional Multi-Modal Observations\n\n\n\nYash Jain1*1*affiliationmark: \n\n‚ÄÉ‚ÄÉ\n\nXinjie Liu1*1*affiliationmark: \n\n‚ÄÉ‚ÄÉ\n\nLasse Peters2*2*affiliationmark: \n\n‚ÄÉ‚ÄÉ\n\nDavid Fridovich-Keil11affiliationmark: \n\n‚ÄÉ‚ÄÉ\n and\nUfuk Topcu11affiliationmark: \n\n**affiliationmark:  Equal contribution\n11affiliationmark:  The University of Texas at Austin, Austin, TX 78712, USA\n22affiliationmark:  Delft University of Technology, Delft, 2600 AA, Netherlands\n\n\nxinjie-liu@utexas.edu\n\n\n\nAbstract\nMany multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent‚Äôs decisions depend on others‚Äô future actions.\nHowever, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents‚Äô objectives.\nTo circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data.\nUnfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions.\nWe present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time.\nConcretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents‚Äô true objectives.\nExtensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.\n\n\nkeywords: Probabilistic Inference, Planning under Uncertainty, Machine Learning for Robot Control, Game Theory, Integrated Planning and Learning, Model Learning for Control\n\n\n\n1 Introduction\n\nNoncooperative game theory¬†(Ba≈üar and Olsder, 1999) provides a principled framework for modeling multi-agent interactive decision-making and has become a powerful tool for interaction-aware motion planning in autonomous robots.\nModern numerical methods¬†(Fridovich-Keil et¬†al., 2020; Zhu and Borrelli, 2023; Cleac‚Äôh et¬†al., 2022; Li et¬†al., 2023a) have significantly accelerated the solution of game-theoretic planning problems, enabling real-time application and increasing their practical appeal¬†(Spica et¬†al., 2020; Wang et¬†al., 2021).\n\n\nIn game-theoretic planning, an ego agent (e.g., an autonomous robot) models its own and others‚Äô decision-making processes as coupled optimization problems with potentially conflicting objectives.\nWhen each agent‚Äôs decision is unilaterally optimal, the joint decision is a Nash equilibrium.\nFor example, Figure¬†1 illustrates this type of noncooperative interaction in an intersection scenario between a red ego robot and a green opponent (e.g., a human driver), where they both seek to reach their goals efficiently while avoiding collisions.\n\n\nIn real-world deployments, however, such methods are typically used in a decentralized fashion, where each agent only knows its own objective; thus, to compute interaction-aware Nash equilibrium motion plans, the ego robot must reason about unknown game parameters, such as the objectives of other agents. In the example of Figure¬†1,\nto interact safely while still efficiently reaching its goal, the ego must, within split seconds, infer whether the opponent will go straight or turn left from their observed opponent behavior and, when available, visual cues such as turn signals.\n\n\nFigure 1: \nA robot interacts with an opponent driver whose goal position is unknown. We embed a differentiable game solver within a structured variational autoencoder to infer the distribution of opponent intent from observed trajectories, jointly with image observations of the opponent.\n\n\n\nThe problem of inferring unknown game parameters from observations is known as an inverse game¬†(Molloy et¬†al., 2022). Standard approaches typically pose a maximum likelihood estimation (MLE) problem¬†(Peters et¬†al., 2023a; Liu et¬†al., 2023; Armstrong et¬†al., 2025; Mehr et¬†al., 2023; Hu et¬†al., 2025; Sun et¬†al., 2025) with the first-order Nash equilibrium conditions as constraints. However, MLE yields inherently overconfident point estimates: it lacks uncertainty quantification and often ignores important prior knowledge, which can lead to unsafe decisions. For example, when an opponent has just entered the intersection and has not yet committed to a turning maneuver, an MLE approach may confidently conclude that the opponent will go straight, whereas an experienced human driver would remain cautious, understanding the potential for an aggressive left turn¬†(Liu et¬†al., 2024).\n\n\nBayesian inverse games instead cast parameter inference as a Bayesian inference problem, which can be approximately solved by online filtering methods such as particle filtering¬†(Peters, 2020) or unscented Kalman filtering¬†(Le¬†Cleac‚Äôh et¬†al., 2021). More recently, Liu et¬†al. (2024) proposed a structured variational autoencoder (VAE) framework that approximately solves the Bayesian inverse game problem via amortized, offline training on datasets of interaction trajectories without parameter labels. The resulting generative belief model infers posterior distributions over unknown opponent objectives in noncooperative games from observed trajectories, runs in real time, and captures multimodal posteriors, providing uncertainty quantification which improves downstream motion planning safety.\n\n\nHowever, prior inverse game methods operate almost exclusively on low-dimensional observations, i.e., state trajectories. In real-world interactions, other observation modalities‚Äîsuch as visual cues (turn signals, vehicle type, etc.)‚Äîcan carry crucial information about an opponent‚Äôs intent, especially when a new agent has just entered the scene and little or no trajectory history is available. In highly dynamic, interactive settings, the ability to exploit such contextual information beyond pure behavior observations can be safety-critical, motivating inverse game approaches that operate on high-dimensional, multimodal observations from multiple sensors.\n\n\nTo this end, this article substantially extends the conference paper by Liu et¬†al. (2024) (in press; to appear in Algorithmic Foundations of Robotics XVI, Springer Nature) and contributes a tractable Bayesian inverse game framework that embeds a differentiable Nash game solver into a VAE. The proposed framework:\n\n\n‚Ä¢\n\n(Tractability and interpretability) leverages analytical gradients from a differentiable Nash game solver to learn a structured generative belief model, making multimodal posterior inference tractable while preserving interpretability for downstream motion planners;\n\n\n\n‚Ä¢\n\n(Multi-modal observation fusion) fuses visual cues from raw images with partial-state observations of agent interactions to perform amortized Bayesian inference, reducing uncertainty when trajectory data are unavailable or uninformative;\n\n\n\n‚Ä¢\n\n(Downstream decision-making) enables safer and more efficient uncertainty-aware decision-making than MLE-based inverse game approaches, while running in real time.\n\n\n\n\n\nBeyond the conference version, the present work:\n\n\n‚Ä¢\n\ngeneralizes the original Bayesian inverse game framework and architecture to handle multiple observation modalities, including high-dimensional raw images;\n\n\n\n‚Ä¢\n\nintroduces new experimental studies in CARLA simulations¬†(Dosovitskiy et¬†al., 2017) with photorealistic visual observations and low-level tracking controllers;\n\n\n\n‚Ä¢\n\nsystematically evaluates the impact of multimodal observations on Bayesian inference quality and downstream motion planning performance.\n\n\n\n\n\nThroughout the manuscript, we use ‚Äúmulti-modal‚Äù to denote either (i) multi-peaked prior/posterior distributions or (ii) multiple observation modalities (e.g., trajectories and images); the intended meaning is clear from context.\n\n\n\n\n2 Related Work\n\nThis section provides an overview of the literature on dynamic game theory, focusing on both forward games (Section¬†2.1) and inverse games (Section¬†2.2).111Sections¬†2.1 and¬†2.2 are largely reproduced from our earlier conference publication¬†(Liu et¬†al., 2024).\n\n\n\n2.1 Dynamic Games\n\nThis work focuses on noncooperative dynamic games where agents can have arbitrary, potentially conflicting objectives, do not c"
  },
  {
    "title": "A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference",
    "url": "https://arxiv.org/abs/2601.00694v1",
    "source": "arxiv",
    "summary": "Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adap",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; cs &gt; arXiv:2601.00694v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Computer Science  Artificial Intelligence\n    \n\n    \n      arXiv:2601.00694v1 (cs)\n    \n\n\n  \n    \n  [Submitted on 2 Jan 2026]\n    Title:A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference\n    Authors:Qingwen Pu, Kun Xie, Hong Yang, Guocong Zhai            View a PDF of the paper titled A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference, by Qingwen Pu and 3 other authors\n    View PDF\n\n\n\n    \n            Abstract:Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.\n    \n\n    \n    \n      \n          Subjects:\n          \n            Artificial Intelligence (cs.AI)\n        \n          Cite as:\n          arXiv:2601.00694 [cs.AI]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2601.00694v1 [cs.AI] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2601.00694\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Kun Xie [view email]          [v1]\n        Fri, 2 Jan 2026 14:13:28 UTC (3,055 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference, by Qingwen Pu and 3 other authorsView PDF\n      \n          \n          view license\n        \n    \n        \n    Current browse context: cs.AI\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-01\n  \n    Change to browse by:\n    \n        cs\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n          \n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n            Both individuals and organizations that work with arXivLabs have embraced and accepted our values o"
  },
  {
    "title": "ARISE: Adaptive Reinforcement Integrated with Swarm Exploration",
    "url": "https://arxiv.org/abs/2601.00693v1",
    "source": "arxiv",
    "summary": "Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate p",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related Work\n\n2.1 Population-Based and Evolutionary Reinforcement Learning\n2.2 Multi-Agent and Swarm-Inspired Methods\n2.3 Where does ARISE stand?\n\n\n\n3 Methodology\n\n3.1 Agent Architecture\n3.2 Particle‚ÄìSwarm Action Mixing\n3.3 Novelty-Driven Reward Augmentation\n3.4 On-Policy PPO Optimization\n3.5 Performance-Variance‚ÄìAdaptive PSO Updates\n3.6 Policy Broadcasting for Exploitation\n3.7 Training Pipeline Overview\n\n\n\n4 Experimental Setup\n\n4.1 Environments\n4.2 Baselines\n4.3 ARISE Configuration\n4.4 Training Protocol\n4.5 Ablation Studies\n\n\n\n5 Experimental Results\n\n5.1 Classic Control Tasks\n5.2 Continuous Control Tasks\n5.3 Non-Stationary Tasks\n5.4 Ablation Studies\n\n\n6 Discussion\n7 Conclusion\n\n\n\n\n11institutetext: Undergraduate Student, Dept. of Computer Science and Engineering \nDayananda Sagar College of Engineering, Bangalore, India \n11email: rajiv.muttur@gmail.com\nhttps://orcid.org/0009-0007-7159-5610\n22institutetext: Professor, Dept. of Computer Science and Engineering \nDayananda Sagar College of Engineering, Bangalore, India\n\nARISE: Adaptive Reinforcement Integrated with Swarm Exploration\n\n\n\nRajiv Chaitanya M\n\n‚ÄÉ‚ÄÉ\nD R Ramesh Babu\n\n\n\nAbstract\nEffective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.\n\n\n\n1 Introduction\n\nReinforcement learning (RL) has achieved significant progress across control, robotics, and decision-making domains [sutton2018reinforcement, mnih2015human]. In spite of advancements in function approximation, exploration remains a limitation. Standard methods such as œµ\\epsilon-greedy exploration, entropy bonuses, intrinsic curiosity, and count-based schemes [bellemare2016unifying, pathak2017curiosity, schulman2017proximal] often fail in environments with sparse, deceptive, or multi-modal reward structures. As a result, single-agent RL pipelines frequently converge to suboptimal local optima and fail to uncover broader solution structures.\n\n\nPopulation-based and evolutionary RL methods attempt to address these challenges through distributed exploration. Strategies such as Evolution Strategies (ES) [salimans2017evolution], MAP-Elites and quality-diversity algorithms [cully2015robots, mouret2015illuminating], and Population-Based Training (PBT) [jaderberg2017population] demonstrate the importance of maintaining behavioral diversity. However, these approaches typically introduce substantial computational overhead, or rely on evolutionary updates rather than gradient-based improvements. Even multi-agent RL frameworks often lack mechanisms that enable agents to coordinate exploration while preserving diversity.\n\n\nWe introduce ARISE, Adaptive Reinforcement Integrated with Swarm Exploration, a lightweight, gradient-based RL framework that leverages multiple agents exploring distinct policy regions, augmented with selective information sharing and adaptive coordination. ARISE is built on three core mechanisms.\n\n\n\n\n1.\n\nNovelty-driven exploration: Each agent receives a novelty bonus based on policy-space or trajectory-space deviation, encouraging diverse behaviors and preventing early homogenization.\n\n\n\n2.\n\nKnowledge broadcasting: High-performing agents periodically disseminate their policy parameters, while recipients blend these weights through a controlled mixing coefficient, enabling information sharing without mode collapse.\n\n\n\n3.\n\nVariance-based adaptive coordination: The swarm dynamically shifts between exploration and exploitation using a coordination-temperature derived from the inter-agent performance variance.\n\n\n\n\n\nIn contrast with either evolutionary or simply population-based methods, ARISE preserves the sample efficiency of gradient-based actor-critic architectures while gaining the robustness and versatility of behavior of distributed exploration. The method only slightly modifies the architecture and effortlessly functions alongside the common continuous-control RL baselines, such as PPO [schulman2017proximal] and SAC [haarnoja2018soft].\n\n\nTo summarize, our contributions are:\n\n\n‚Ä¢\n\nA novel unified framework in swarm-based RL that efficiently integrates traditional and cutting-edge coordination approaches along with novelty incentives and multi-agent exploration.\n\n\n\n‚Ä¢\n\nThe dynamic broadcasting mechanism we developed allows for diversity to be preserved while the rapid propagation of useful policy information is enabled.\n\n\n\n‚Ä¢\n\nOur empirical results based on standard continuous-control benchmarks illustrate that ARISE not only boosts sample efficiency but also secures the final performance through robustness in reward deception scenarios and surpassing strong baselines.\n\n\n\n\n\nARISE proves that coordinated exploration, which is scalable, does not entail long evolutionary runs or complicated population-control methods. A tailored mix of diversity, communication, and adaptation can significantly increase the exhaustiveness of the exploration done by gradient-based RL systems.\n\n\n\n\n2 Related Work\n\nExploration has always been a fundamental challenge in reinforcement learning. Classical approaches rely on stochastic action selection, or value-based uncertainty, or intrinsic rewards to encourage the agents to visit unseen states. Methods such as œµ\\epsilon-greedy exploration, entropy regularization, and count-based exploration [bellemare2016unifying, strehl2008analysis] offer simple and effective heuristics, but they often fail when rewards are sparse or when suboptimal attractors dominate early training. Curiosity-driven methods, including prediction-error‚Äìbased intrinsic motivation [pathak2017curiosity] and information-gain formulations [houthooft2016vime], improve exploration by rewarding agents for reducing uncertainty. However, these methods can be unstable in high-dimensional observation spaces and exhibit exploration drift unrelated to task success.\n\n\n\n2.1 Population-Based and Evolutionary Reinforcement Learning\n\nPopulation-based methods address exploration by maintaining multiple agents that evolve over time. Evolution Strategies (ES) [salimans2017evolution] use gradient-free black-box optimization to explore policy landscapes at scale, while MAP-Elites and quality-diversity (QD) algorithms [cully2015robots, mouret2015illuminating] explicitly search for a diverse archive of behaviors. These methods provide strong global exploration but sacrifice fine-grained gradient updates and often incur substantial computational cost. Population-Based Training (PBT) [jaderberg2017population] improves the hyperparameter adaptation by periodically replacing some weaker agents with stronger ones, but it relies on evolutionary selection pressure that can rapidly collapse diversity without careful tuning.\n\n\nRecent hybrid approaches combine policy gradients with evolutionary concepts. For instance, ERL and CERL frameworks [khadka2018evolutionary, pourchot2018cem] use evolutionary populations to augment gradient-based learners. Though effective, these systems often employ complex message-passing structures or auxiliary processes that add unnecessary system complexity and computational overhead.\n\n\n\n\n2.2 Multi-Agent and Swarm-Inspired Methods\n\nMulti-agent RL frameworks introduce coordination among agents to improve exploration. Decentralized and centralized training paradigms (e.g., MADDPG [lowe2017multi] and QMIX [rashid2018qmix]) improve cooperative and competitive learning but focus primarily on multi-agent tasks rather than using multi-agent structure as a tool for exploration. Swarm-based optimization methods, such as Particle Swarm Optimization [kennedy1995particle], uses simple communication rules to propagate useful information within a population, demonstrating the power of distributed local updates. But, these approaches are rarely ever integrated directly with gradient-based RL.\n\n\n\n\n2.3 Where does ARISE stand?\n\nARISE lies at the intersection of gradient-based RL, population diversity, and adaptive information sharing. Unlike the evolutionary methods, ARISE retains full backpropagation-based optimization. And unlike the traditional population-based training, ARISE does not rely on replacement or evolutionary selection, enabling the population to maintain a stable diversity. Finally, unlike a standard multi-agent RL, ARISE does not focus on multi-agent environments; instead, it uses multiple agents as a mechanism for structured exploration within one single-agent task.\n\n\nBy integrating novelty-driven behavior, controlled policy broadcasting, and variance-based adaptive coordination, ARISE offers a lightweight yet powerful alternative to evolutionary and population-based RL, preserving sample efficiency while expanding the reach of exploration.\n\n\n\n\n\n3 Methodology\n\nARISE (Adaptive Reinforcement Integrated with Swarm Exploration) is a hybrid learning framework that couples on-policy reinforcement learning with particle swarm exploration in the action space. The system consists of MM parallel actor"
  },
  {
    "title": "TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications",
    "url": "https://arxiv.org/abs/2601.00691v1",
    "source": "arxiv",
    "summary": "Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related work\n\n2.1 Ticket Troubleshooting\n2.2 Domain-specific LLMs\n\n\n3 Problem Statement\n\n4 TeleDoCTR: Ticket Troubleshooting System\n\n4.1 Domain-Specific Rankers\n4.2 Ticket Routing\n\n4.3 Multiple Fault Analysis Generation and Ranking\n\n4.3.1 Finetuning domain-specific LLM for fault analysis generation\n4.3.2 Response-ranking method for fault analysis reports\n4.3.3 Model alignment using RL from automated feedback\n\n\n\n4.4 Enhanced RAG-based Fault Analysis Generation with Demonstrations Selection\n\n4.4.1 Demonstrations Selection\n4.4.2 RAG-based Fault Analysis Generation\n\n\n\n\n\n5 Evaluation\n\n\n5.1 Telecom Troubleshooting Dataset\n\n5.1.1 Troubleshooting Tickets\n5.1.2 Fault Analysis Reports\n5.1.3 Team Labels\n\n\n\n5.2 Experimental Setup\n\n5.2.1 Domain-specific Rankers\n5.2.2 Domain-specific Generative Models\n\n\n\n5.3 Experimental Results\n\n5.3.1 Domain-specific Rankers\n5.3.2 Ticket Routing\n5.3.3 Fault Analysis Generation\n\n\n\n\n6 Conclusions\n\n\n\n\n\n\n\\useunder\n\\ul\n\n\nTeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications\n\n\nMohamed Trabelsi\n\nmohamed.trabelsi@nokia-bell-labs.com\n\nNokia Bell LabsMurray HillNJUSA\n\n and \nHuseyin Uzunalioglu\n\nhuseyin.uzunalioglu@nokia-bell-labs.com\n\nNokia Bell LabsWestfordMAUSA\n\n\n\nAbstract.\nTicket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.\n\nticket troubleshooting, large language models, retrieval models, instruction-tuning\n\n‚Ä†‚Ä†ccs: Computing methodologies¬†Natural language generation‚Ä†‚Ä†ccs: Computing methodologies¬†Ranking‚Ä†‚Ä†ccs: Computing methodologies¬†Learning from demonstrations\n\n\n1. Introduction\n\nService management systems are widely used across industries to ensure the reliable delivery and operation of complex services. A notable example is the telecommunications (telecom) sector, where services such as mobile voice, messaging, data, and home internet are provided through complex infrastructures that rely on wireless, optical, and internet protocol (IP)-based networks. Analogous service management systems are prevalent in other domains as well, including information technology, industrial automation, energy, and transportation. These service management systems typically consist of two main components: (1) monitoring and logging systems that continuously collect health and performance data from the service infrastructure, and (2) diagnostic tools that analyze the monitoring data to infer the health of the system, detect anomalies, and identify potential faults. Historically, the process of resolving service problems, known as ticket troubleshooting, has relied heavily on human expertise. When a ticket is created, it generally includes a brief title, a natural-language description of the problem, and metadata specifying the affected system components. Engineers then retrieve and analyze system diagnostics and logs to investigate the issue and determine a resolution strategy. Ticket troubleshooting is a critical operation, as it directly impacts customer satisfaction and service reliability. However, it remains a time-intensive process, not only due to the complexity of resolving each issue, but also because of the delays it introduces to other engineering tasks.\n\n\nMany existing methods in ticket troubleshooting (feng2022tadaa; liu2023ticket; bosch2022fine; sample2018predicting; ferland2020automatically) focus on the ticket classification task in terms of assigned class, resolution class, or resolution time as part of the ticket troubleshooting process. Other methods (cristian2019study; bosch2022fine) aim to identify duplicate or contextually similar tickets to aid in problem resolution. Some techniques also provide solution recommendations based on historical data (ferland2020automatically; grimalt2022berticsson). Additionally, large language model (LLM)-based solutions (arici2023llm; JainGN24; RoyZBBLFR24) have been introduced to offer real-time, conversational assistance for troubleshooting common technical issues. While effective for frequently asked questions and general-purpose support, these LLMs often fall short in specialized domains such as telecom, where domain-specific knowledge, expertise, and reasoning are essential. Moreover, most existing methods address only a single component of the troubleshooting process, classification, retrieval, or generation, without offering an integrated and unified troubleshooting solution. This fragmented approach creates a significant burden when attempting to build end-to-end systems that can fully automate and support the ticket troubleshooting workflow in complex and domain-specific environments.\n\n\nInspired by the recent progress of domain-specific LLMs\n(BloombergGPT; WizardMath; AlphaGeometry; MedPaLM-2; ChatLaw), we introduce a novel Telecom-related Domain-specific and Contextual TRoubleshooting (TeleDoCTR) system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate the full troubleshooting process composed of routing tickets to the appropriate expert team responsible for resolving the given ticket, retrieving contextually and semantically similar historical tickets to the given ticket for broader contextual information incorporation, and finally generating a detailed fault analysis report outlining the issue, root cause, and potential solutions. The TeleDoCTR architecture comprises four key components: (1) domain-specific rankers for ticket similarity and generated fault analysis report evaluation, (2) a classification module for predicting the responsible resolution team of the ticket, (3) a fault analysis generation module using finetuning, multi-response generation, and multi-response ranking, and (4) a Retrieval-Augmented Generation (RAG) conversational module enhanced with demonstrations selection. To enable efficient domain adaptation, TeleDoCTR employs Parameter-Efficient Fine-Tuning (PEFT) via QLoRA (hu2022lora; DettmersPHZ23) for both ticket classification and fault analysis generation. The generative model produces multiple candidate fault analysis reports, and finetuned domain-specific rankers evaluate their semantic relevance to the input ticket. The top-ranked reports are then returned to the user. Additionally, the domain-specific rankers are used to select relevant demonstrations for the RAG module, enabling more accurate and context-aware multi-turn fault analysis generation. We train and evaluate TeleDoCTR using a large-scale telecom-related troubleshooting dataset that reflects the inherent complexity and diversity of telecom troubleshooting scenarios. Experimental results show that TeleDoCTR significantly outperforms general-purpose LLMs and isolated solutions, delivering more effective and efficient ticket resolution in real-world telecom environments.\n\n\nIn summary, we make the following contributions:\n\n\n\n\n‚Ä¢\n\nWe propose a new telecom-related, domain-specific, and contextual troubleshooting system (TeleDoCTR) that combines domain-adapted ranking and generative models to automate the three key steps of ticket troubleshooting in a unified and integrated solution.\n\n\n\n‚Ä¢\n\nWe finetune specialized ranking models on the troubleshooting dataset to measure semantic relevance for ticket similarity and fault analysis evaluation. We also perform instruction-tuning using QLoRA to finetune a domain-specific LLM for both ticket classification and fault analysis generation.\n\n\n\n‚Ä¢\n\nWe develop a response-ranking mechanism in which multiple fault analysis reports are generated by the finetuned LLM and ranked using the domain-specific rankers to identify the most relevant fault analysis reports.\n\n\n\n‚Ä¢\n\nWe leverage the domain-specific ranking models to select demonstrations (ticket-fault analysis pairs), which are incorporated into a RAG conversational module for improved multi-turn fault analysis generation.\n\n\n\n‚Ä¢\n\nWe use large-scale telecom-based troubleshooting data for training and evaluation, and demonstrate that our new system outperforms baselines in all three key steps.\n\n\n\n\n\n\n\n2. Related work\n\n\n2.1. Ticket Troubleshooting\n\nTicket troubleshooting involves analyzing and resolving issues submitted through a ticketing system, which is a critical process in industries such as telecom, information technology, industrial automation, energy, and transportation. Existing methods (feng2022tadaa; arici2023llm; liu2023ticket; bosch2022fine; sample2018predicting; ferland2020automatically) have primarily focused on classification"
  },
  {
    "title": "Cost Optimization in Production Line Using Genetic Algorithm",
    "url": "https://arxiv.org/abs/2601.00689v1",
    "source": "arxiv",
    "summary": "This paper presents a genetic algorithm (GA) approach to cost-optimal task scheduling in a production line. The system consists of a set of serial processing tasks, each with a given duration, unit execution cost, and precedence constraints, which must be assigned to an unlimited number of stations subject to a per-station duration bound. The objective is to minimize the total production cost, mod",
    "full_text": null
  },
  {
    "title": "Sigmoid Head for Quality Estimation under Language Ambiguity",
    "url": "https://arxiv.org/abs/2601.00680v1",
    "source": "arxiv",
    "summary": "Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high p",
    "full_text": null
  },
  {
    "title": "QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models",
    "url": "https://arxiv.org/abs/2601.00679v1",
    "source": "arxiv",
    "summary": "Large Language Models (LLMs) have been emerging as prominent AI models for solving many natural language tasks due to their high performance (e.g., accuracy) and capabilities in generating high-quality responses to the given inputs. However, their large computational cost, huge memory footprints, and high processing power/energy make it challenging for their embedded deployments. Amid several tiny",
    "full_text": "\n\n\n\n\nI Introduction\n\nI-A State-of-the-art of SLMs and Their Limitations\nI-B A Case Study and Associated Research Challenges\nI-C Our Novel Contributions\n\n\n\nII Background\n\nII-A SNN Quantization\n\n\n\nIII The QSLM Framework\n\nIII-A Network Model Analysis\nIII-B Tiered Search Strategy for Quantization\nIII-C Quantization Setting Selection\n\n\nIV Evaluation Methodology\n\nV Results and Discussion\n\nV-A Reducing Memory while Maintaining High Performance\nV-B Reduction of Power Consumption\nV-C Impact of Different Œ±\\alpha Values on the Model Selection\n\n\nVI Conclusion\n\n\n\n\n\nQSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models\n\n\n\n\nRachmad Vidya Wicaksana Putra, Pasindu Wickramasinghe, Muhammad Shafique\n\n\n\nAbstract\nLarge Language Models (LLMs) have been emerging as prominent AI models for solving many natural language tasks due to their high performance (e.g., accuracy) and capabilities in generating high-quality responses to the given inputs.\nHowever, their large computational cost, huge memory footprints, and high processing power/energy make it challenging for their embedded deployments.\nAmid several tinyLLMs, recent works have proposed spike-driven language models (SLMs) for significantly reducing the processing power/energy of LLMs.\nHowever, their memory footprints still remain too large for low-cost and resource-constrained embedded devices.\nManual quantization approach may effectively compress SLM memory footprints, but it requires a huge design time and compute power to find the quantization setting for each network, hence making this approach not-scalable for handling different networks, performance requirements, and memory budgets.\nTo bridge this gap, we propose QSLM, a novel framework that performs automated quantization for compressing pre-trained SLMs, while meeting the performance and memory constraints.\nTo achieve this, QSLM first identifies the hierarchy of the given network architecture and the sensitivity of network layers under quantization, then employs a tiered quantization strategy (e.g., global-, block-, and module-level quantization) while leveraging a multi-objective performance-and-memory trade-off function to select the final quantization setting.\nExperimental results indicate that our QSLM reduces memory footprint by up to 86.5%, reduces power consumption by up to 20%, maintains high performance across different tasks (i.e., by up to 84.4% accuracy of sentiment classification on the SST-2 dataset and perplexity score of 23.2 for text generation on the WikiText-2 dataset) close to the original non-quantized model while meeting the performance and memory constraints.\nHence, QSLM framework advances the efforts in enabling efficient design automation for embedded implementation of SLMs.\n\n\n\nI Introduction\n\n\nTransformer-based networks¬†[Ref_Vaswani_Attention_NIPS17] have achieved state-of-the-art performance (e.g., accuracy) in diverse machine learning (ML)-based applications, including solving diverse natural language tasks¬†[Ref_Zhao_LLMsurvey_arXiv23, Ref_Minaee_LLMsurvey_arXiv24, Ref_Chang_LLMsurvey_TIST24, Ref_Han_SurveyViT_TPAMI22, Ref_Khan_SurveyViT_CSUR22, Ref_Putra_QSViT_IJCNN25].\nIn recent years, transformer-based large language models (LLMs) have demonstrated significant improvements in extending the capabilities of natural language models¬†[Ref_Zhao_LLMsurvey_arXiv23, Ref_Minaee_LLMsurvey_arXiv24, Ref_Chang_LLMsurvey_TIST24], thereby making it possible to produce high-quality language-based understanding and responses to the given inputs.\nTherefore, their adoption in resource-constrained embedded devices is highly in demand and actively being pursued for enabling customized and personalized systems¬†[Ref_ElMir_LLM4Healthcare_ICIPCW24].\nHowever, their large compute costs, huge memory footprints, and high processing power/energy make it challenging for their embedded deployments.\n\n\nIn the other domain, the advancements of spiking neural networks (SNNs) have demonstrated promising power/energy-efficient alternative to artificial neural network (ANN) algorithms, because of their sparse spike-driven operations¬†[Ref_Bartolozzi_EmbodiedNeuroIntel_Nature22][Ref_Putra_SNNonCNP_IJCNN25].\nTherefore, recent works leveraged spike-driven operations for LLMs to reduce the processing power/energy requirements, i.e., so-called Spike-driven Language Models (SLMs); see Fig.¬†1.\nHowever, their memory footprints are still too large for embedded deployments.\nTo reduce memory footprints of spike-driven models, quantization is one of the prominent methods¬†[Ref_Putra_FSpiNN_TCAD20, Ref_Rathi_PruneQuantizeSNN_TCAD18, Ref_Putra_QSpiNN_IJCNN21], because it can effectively reduce memory footprints with slightly yet acceptable accuracy degradation.\nHowever, manually determining an appropriate quantization setting for any given SLM requires huge design time and large power/energy consumption.\nTherefore, this approach is laborious and not scalable for compressing different SLMs for different possible performance and memory constraints.\nMoreover, existing ANN quantization frameworks cannot be employed directly for SLMs due to the fundamental differences in synaptic and neuronal operations between ANNs and SNNs.\n\n\nSuch conditions lead us to the research problem targeted in this paper, i.e., how can we efficiently quantize any given pre-trained SLM, while maintaining high performance (e.g., accuracy) and meeting the memory constraint?\nA solution to this problem may advance the design automation for efficient embedded implementation of SLMs.\n\n\nFigure 1: Current trends of performance (i.e., accuracy), number of weight parameters (note, M denotes millions [106] of parameters), and energy consumption of SLMs¬†[Ref_Xing_SpikeLM_ICML24, Ref_Bal_SpikingBERT_AAAI24, Ref_Su_SNNBERT_NeuNet24, Ref_Xing_SpikeLLM_ICLR24, Ref_Chu_SpikeGPT_TMLR24] on the sentiment analysis task with the SST-2 dataset¬†[Ref_Wang_GLUE_ICLR2019].\n\n\n\nI-A State-of-the-art of SLMs and Their Limitations\n\n\nSLM development is a relatively new research avenue, hence the state-of-the-art works still focus on achieving high performance (e.g., accuracy), such as SpikeBERT¬†[Ref_Lv_SpikeBERT_arXiv24], SpikingBERT¬†[Ref_Bal_SpikingBERT_AAAI24], SNN-BERT¬†[Ref_Su_SNNBERT_NeuNet24], SpikeLM¬†[Ref_Xing_SpikeLM_ICML24], SpikeLLM¬†[Ref_Xing_SpikeLLM_ICLR24], and SpikeGPT¬†[Ref_Chu_SpikeGPT_TMLR24].\nSpecifically, spike-driven BERTs¬†[Ref_Bal_SpikingBERT_AAAI24][Ref_Su_SNNBERT_NeuNet24][Ref_Lv_SpikeBERT_arXiv24] leverage BERT networks from ANN domain and apply spiking neuronal dynamics on them, while employing different techniques, such as knowledge distillation¬†[Ref_Bal_SpikingBERT_AAAI24] and input coding enhancements¬†[Ref_Su_SNNBERT_NeuNet24].\nSpikeLM¬†[Ref_Xing_SpikeLM_ICML24] and SpikeLLM¬†[Ref_Xing_SpikeLLM_ICLR24] target to scale up spiking neuronal dynamics to large models (e.g., up to 70 billions of weight parameters for SpikeLLM).\nMeanwhile, SpikeGPT¬†[Ref_Chu_SpikeGPT_TMLR24] targets at reducing the computational complexity in SLMs by replacing the spike-driven transformer modules with the spike-driven receptance weighted key value (SRWKV) modules, while maintaining the high performance.\nThese state-of-the-art highlight that the efforts for quantizing SLMs have not been comprehensively explored.\n\n\n\n\nI-B A Case Study and Associated Research Challenges\n\n\nFigure 2: Performance profiles of the pre-trained SpikeGPT-216M after uniformly quantizing its weight parameters in its attention blocks across different precision levels for different tasks: (a) sentiment classification on the SST-2 dataset¬†[Ref_Wang_GLUE_ICLR2019], and (b) perplexity on the WikiText-2 dataset¬†[Ref_Merity_WikiText_ICLR17].\nNote, a lower perplexity score represents a better text generation performance.\n\n\nTo show the potentials and challenges in quantizing SLMs, we perform an experimental case study.\nHere, we apply uniform quantization on the weight parameters of the pre-trained SpikeGPT-216M¬†[Ref_Chu_SpikeGPT_TMLR24] with the same precision level across its attention blocks, then employ the quantized model for solving the sentiment analysis on the SST-2 dataset¬†[Ref_Wang_GLUE_ICLR2019] and evaluating the perplexity on the WikiText-2 dataset¬†[Ref_Merity_WikiText_ICLR17].\nFurther details of experiments are provided in Sec.¬†IV, and the experimental results are presented in Fig.¬†2.\nThese results show that, the post-training quantization (PTQ) scheme leads to significant memory reduction, while preserving high performance (e.g., accuracy and perplexity) when employed with appropriate quantization.\nOtherwise, it leads to notable performance degradation.\n\n\nFurthermore, these observations also expose several research challenges, as follows.\n\n\n‚Ä¢\n\nQuantization process should handle different network complexity levels (e.g., number of layers) efficiently.\n\n\n\n‚Ä¢\n\nQuantization process should be able to meet different possible performance (e.g., accuracy) and memory constraints, thus making it practical for diverse applications.\n\n\n\n‚Ä¢\n\nQuantization process should minimize manual intervention to increase its scalability for handling different networks, performance requirements, and memory budgets.\n\n\n\n\n\n\n\nI-C Our Novel Contributions\n\n\nTo address the targeted problem and research challenges, we propose QSLM, a novel framework that performs automated Quantization for compressing pre-trained Spike-driven Language Model (SLM) to meet the performance (e.g., accuracy) and memory constraints.\nTo achieve this, QSLM performs the following key steps; see an overview in Fig.¬†3.\n\n\n‚Ä¢\n\nNetwork Model Analysis (Sec.¬†III-A):\nIt aims to identify the structure of the given pre-trained model, determine the network hierarchy to be considered for quantization search, and investigate the sensitivity of each block of the network under quantization on the performance (e.g., accuracy).\n\n\n\n‚Ä¢\n\nTiered Search Strategy for Quantization (Sec.¬†III-B):\nIt aims to perform automated quantization and evaluation fo"
  },
  {
    "title": "IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2601.00677v1",
    "source": "arxiv",
    "summary": "Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises ",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related Work\n\nBradley-Terry (B-T) Models.\nGenerative Reward Models.\nReinforcement Learning for LLM Alignment.\nPairwise Reward Models for RL Training.\n\n\n\n3 Intergroup Relative Preference Optimization\n\n3.1 Scaling the B-T Model\n\n3.2 Reward Design\n\nArithmetic Mean (Point Estimation).\nMedian (Point Estimation).\nInterval Estimation.\nFormat Reward.\n\n\n\n\n\n4 Experiments\n\n\n4.1 Experimental Setup\n\n4.1.1 Training Dataset\n4.1.2 Benchmarks\n4.1.3 Implementation Details\n\n\n\n4.2 Results\n\nIRPO achieves state-of-the-art performance among pointwise GRMs.\nInference-time scaling significantly enhances performance.\nIRPO outperforms the B-T model on the same dataset.\nEffectiveness under equal computational cost.\nComparison with the backbone model.\n\n\n\n4.3 Additional Studies\n\n4.3.1 Different Reward Design Methods\n4.3.2 Ablations of CoT Reasoning and Score\n\n\n\n4.4 Discussions\n\nWhy does IRPO work?\n\n\n\n\n5 IRPO for Post-training\n6 Conclusion\nA PROMPT TEMPLATE\nB EXPERIMENTAL SETUP\nC Group Relative Policy Optimization\n\n\n\n\n\nIRPO: Scaling the Bradley-Terry Model via Reinforcement Learning\n\n\nHaonan Song\n\n‚ÄÉ‚ÄÉ\nQingchen Xie\n\n‚ÄÉ‚ÄÉ\nHuan Zhu\n\n‚ÄÉ‚ÄÉ\nFeng Xiao\n\n‚ÄÉ‚ÄÉ\nLuxi Xing\n\n‚ÄÉ‚ÄÉ\nFuzhen Li\n\n‚ÄÉ‚ÄÉ\nLiu Kang\n\n‚ÄÉ‚ÄÉ\nFeng Jiang\n\n‚ÄÉ‚ÄÉ\nZhiyong Zheng\n\n‚ÄÉ‚ÄÉ\nFan Yang\n\n\n\nAbstract\nGenerative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL).\nHowever, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO).\nThis bottleneck arises from two factors: (i) the ùí™‚Äã(n2)\\mathcal{O}(n^{2}) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance.\nTo address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO.\nBy generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals.\nExperimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs.\nFurthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.\n\nReward Model, LLMs, Generative Reward Models, IRPO, Reinforcement Learning, LLM-as-a-judge\n\n\n\nFigure 1: \nDifferent reward generation paradigms and scoring patterns for reward modeling, including the Bradley-Terry model, pointwise GRMs, pairwise GRMs and listwise GRMs. We compare these modeling approaches based on the following criteria: interpretability; inference-time scalability (i.e., the ability to improve performance by allocating more computation at inference time); input flexibility (i.e., whether the method natively supports a variable number of inputs); mapping-free (whether the method must convert relative preference signals into an absolute scalar reward) and fine-grained reward capability.\n\n\n\n\n1 Introduction\n\nLarge Language Models (LLMs) have achieved impressive performance across a wide range of applications (openai2024gpt4; guo2025deepseek).\nHowever, reliably aligning their behavior with human preferences remains a central challenge (long2022instructgpt; christiano2023deeprl).\nReward Models (RMs) are a key component of modern alignment pipelines, providing training signals for reinforcement learning from human feedback (RLHF).\nExplicit reward modeling approaches are typically categorized into two types: scalar reward models and critique-based reward models (wu2025survey).\nScalar reward models are trained on human preference data, typically in the form of pairwise comparisons between chosen and rejected responses.\nThese reward models typically use an LLM with a value head that outputs a scalar score and are trained using an objective based on the Bradley-Terry (B-T) (bradley1952rank) model.\nAlthough B-T models are elegant and effective, they exhibit several practical limitations:\n(i) limited interpretability;\n(ii) poor generalization under distribution shift (wang2024secrets);\nand (iii) limited potential for performance gains from increased inference-time computation, because predictions are produced in a single forward pass.\n\n\nCritique reward models, often implemented using an LLM-as-a-judge paradigm, generate natural-language rationales along with an associated score (li2023autoj; cao2024compassjudger; ye2024conj; mahan2024generative).\nThis paradigm is inherently more interpretable and naturally supports inference-time scaling, for example by allocating more computation to deliberation (guo2025rrm) or to sampling-based aggregation (liu2025deepseekgrm).\nNevertheless, many existing applications of LLM judges remain effectively pairwise, focusing on determining which of two responses is better.\nDirect integration of pairwise reward models into RL training is impeded by a significant computational bottleneck.\nThis challenge stems from the standard evaluation protocol, which requires all-pairs comparisons among a set of candidate responses.\nThis process has quadratic time complexity, ùí™‚Äã(n2)\\mathcal{O}(n^{2}), which renders it computationally prohibitive for large-scale applications and poses a significant obstacle to efficient training.\nFurthermore, pairwise judging makes it difficult to derive fine-grained, calibrated rewards over variable-sized candidate sets.\n\n\nWe argue that an ideal reward model should satisfy five key properties:\n(1) the ability to be incorporated into the RL training loop with manageable computational overhead;\n(2) the capacity to assign fine-grained, pointwise scores to a variable-sized set of candidates;\n(3) the provision of interpretable rationales;\n(4) robustness to distribution shift (cao2024compassjudger);\n(5) the potential for inference-time scaling to trade computation for improved judgments.\n\n\nTo this end, we introduce Intergroup Relative Preference Optimization (IRPO), a novel reinforcement learning framework designed to satisfy all five of these criteria.\nIRPO trains pointwise Generative Reward Models (GRMs), retaining Bradley‚ÄìTerry‚Äìstyle scoring while enabling evaluation of an arbitrary number of candidates.\nIRPO inherits interpretability, strong generalization, and inference-time scalability from GRMs.\nCrucially, IRPO achieves linear time complexity, ùí™‚Äã(n)\\mathcal{O}(n), during RL training.\nIn contrast to the ùí™‚Äã(n2)\\mathcal{O}(n^{2}) time complexity of pairwise methods, IRPO substantially reduces the computational cost of deploying GRMs within RL training.\nExperimental results show that IRPO outperforms prior state-of-the-art (SOTA) pointwise GRMs by an average of 4.2% across four benchmarks.\nFurthermore, its performance on several of these benchmarks is competitive with and approaches that of leading pairwise GRMs.\n\n\nThe primary contributions of this work are as follows:\n\n\n‚Ä¢\n\nWe introduce IRPO, a method that satisfies the five key properties for reward models discussed above and achieves competitive performance across multiple benchmarks.\n\n\n\n‚Ä¢\n\nWe investigate practical strategies for improving GRMs via reinforcement learning with chain-of-thought (CoT) reasoning and find that CoT reasoning plays a pivotal role in model performance.\n\n\n\n‚Ä¢\n\nWe present a systematic comparison of pointwise and pairwise GRMs as reward signals for policy optimization.\nOur findings indicate that pointwise GRMs can match or outperform pairwise GRMs in subsequent training phases while significantly reducing computational costs.\n\n\n\n\n\n\n\n2 Related Work\n\nBradley-Terry (B-T) Models.\n\nGiven a preference dataset,\n\n\n\nùíü={(x(i),yc(i),yr(i))}i=1N,\\mathcal{D}=\\{(x^{(i)},y_{c}^{(i)},y_{r}^{(i)})\\}_{i=1}^{N},\n\n(1)\n\n\nwhere xx denotes the prompt, ycy_{c} the chosen response, and yry_{r} the rejected response.\nFollowing the B-T model (bradley1952rank), the preference distribution is formulated using the reward function rŒ∏r_{\\theta} as follows:\n\n\n\n\npŒ∏‚Äã(yc‚âªyr‚à£x)\\displaystyle p_{\\theta}(y_{c}\\succ y_{r}\\mid x)\n=exp‚Å°(rŒ∏‚Äã(x,yc))exp‚Å°(rŒ∏‚Äã(x,yc))+exp‚Å°(rŒ∏‚Äã(x,yr))\\displaystyle=\\frac{\\exp\\!\\big(r_{\\theta}(x,y_{c})\\big)}{\\exp\\!\\big(r_{\\theta}(x,y_{c})\\big)+\\exp\\!\\big(r_{\\theta}(x,y_{r})\\big)}\n\n(2)\n\n\n\n\n=œÉ‚Äã(rŒ∏‚Äã(x,yc)‚àírŒ∏‚Äã(x,yr)).\\displaystyle=\\sigma\\!\\big(r_{\\theta}(x,y_{c})-r_{\\theta}(x,y_{r})\\big).\n\n\n\n\nwhere œÉ\\sigma denotes the logistic function. Treating the task as a binary classification problem yields the negative log-likelihood objective:\n\n\n\n‚Ñí‚Äã(rŒ∏)=‚àíùîº(x,y)‚àºùíü‚Äã[log‚Å°œÉ‚Äã(rŒ∏‚Äã(x,yc)‚àírŒ∏‚Äã(x,yr))].\\mathcal{L}(r_{\\theta})=-\\mathbb{E}_{(x,y)\\sim\\mathcal{D}}\\!\\left[\\log\\sigma\\!\\big(r_{\\theta}(x,y_{c})-r_{\\theta}(x,y_{r})\\big)\\right].\n\n(3)\n\n\n\n\n\nGenerative Reward Models.\n\nTraining reward models (RMs) to capture human preferences is central to aligning LLMs.\nA foundational development in this area was the validation of using powerful LLMs as scalable and accurate judges of response quality, demonstrating the feasibility of AI-driven feedback loops (10.5555/3666122.3668142).\nSubsequent research has explored more advanced architectures and training methodologies for RMs.\nFor instance, Generative Verifiers (zhang2024generative) reformulate reward modeling as a next-token prediction task, generating explanations or critiques to justify a given score.\nAnother significant line of inquiry has focused on integrating explicit reasoning capabilities into the reward modeling process.\nWorks such as Critic-RM (yu-etal-2025-self) and RM-R1 (chen2025rmr1) have shown that endowing RMs with reasoning abilities can substantially improve their evaluative accuracy, particularly for complex tasks.\nFurthermore, RRM (guo2025rrm) investigates the impact of scaling inference-time reasoning on reward model pe"
  },
  {
    "title": "Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs",
    "url": "https://arxiv.org/abs/2601.00672v1",
    "source": "arxiv",
    "summary": "In this paper, we study the finite element operator network (FEONet), an operator-learning method for parametric problems, originally introduced in J. Y. Lee, S. Ko, and Y. Hong, Finite Element Operator Network for Solving Elliptic-Type Parametric PDEs, SIAM J. Sci. Comput., 47(2), C501-C528, 2025. FEONet realizes the parameter-to-solution map on a finite element space and admits a training proced",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; math &gt; arXiv:2601.00672v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Mathematics  Numerical Analysis\n    \n\n    \n      arXiv:2601.00672v1 (math)\n    \n\n\n  \n    \n  [Submitted on 2 Jan 2026]\n    Title:Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs\n    Authors:Seungchan Ko, Jiyeon Kim, Dongwook Shin            View a PDF of the paper titled Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs, by Seungchan Ko and 2 other authors\n    View PDF\n\n\n\n    \n            Abstract:In this paper, we study the finite element operator network (FEONet), an operator-learning method for parametric problems, originally introduced in J. Y. Lee, S. Ko, and Y. Hong, Finite Element Operator Network for Solving Elliptic-Type Parametric PDEs, SIAM J. Sci. Comput., 47(2), C501-C528, 2025. FEONet realizes the parameter-to-solution map on a finite element space and admits a training procedure that does not require training data, while exhibiting high accuracy and robustness across a broad class of problems. However, its computational cost increases and accuracy may deteriorate as the number of elements grows, posing notable challenges for large-scale problems. In this paper, we propose a new sparse network architecture motivated by the structure of the finite elements to address this issue. Throughout extensive numerical experiments, we show that the proposed sparse network achieves substantial improvements in computational cost and efficiency while maintaining comparable accuracy. We also establish theoretical results demonstrating that the sparse architecture can approximate the target operator effectively and provide a stability analysis ensuring reliable training and prediction.\n    \n\n    \n    \n      \n          Subjects:\n          \n            Numerical Analysis (math.NA); Machine Learning (cs.LG)\n        \n          Cite as:\n          arXiv:2601.00672 [math.NA]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2601.00672v1 [math.NA] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2601.00672\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite (pending registration)\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Seungchan Ko [view email]          [v1]\n        Fri, 2 Jan 2026 12:39:33 UTC (10,759 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs, by Seungchan Ko and 2 other authorsView PDFTeX Source\n \n      view license\n    \n        \n    Current browse context: math.NA\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-01\n  \n    Change to browse by:\n    \n        cs\n        cs.LG\n        cs.NA\n        math\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n          \n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n            Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n            Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n          \n          \n            \n          \n        \n      \n\n    \n\n\n  \n    Which authors of this paper are endorsers? |\n    Disable MathJax (What is MathJax?)\n    \n  \n  mathjaxToggle();\n\n      \n    \n\n    \n      \n        \n        \n          \n            \n              \n                Abo"
  },
  {
    "title": "Fast-weight Product Key Memory",
    "url": "https://arxiv.org/abs/2601.00671v1",
    "source": "arxiv",
    "summary": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by tran",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Product Key Memory\n\nTop-kk Key-value Memory\nProduct Key Memory\n\n\n\n3 Fast-weight Product Key Memory\n\n3.1 Fast Weights\n\n3.2 Memorization Optimization\n\n3.2.1 MSE loss\n\n3.2.2 Loss aggregation and gradient shaping\n\nReducing MSE losses to a scalar by summation\nWeighting gradient by row contribution\nWeighting MSE loss by token importance\nNo gradient clipping\n\n\n\n\n\n3.3 Addressing Optimization\n\n3.3.1 Marginal entropy loss\n3.3.2 IDW score\n\n\n\n3.4 Target Value Construction\n\n3.4.1 Value residual\n3.4.2 Lookahead value\n3.4.3 Target value normalization\n3.4.4 Gating\n\n\n3.5 FwPKM Summary\n\n\n\n4 Experiments\n\n\n4.1 Training Setting\n\nModel\nData\n\n\n\n4.2 PPL Evaluation\n\nFinding 1: FwPKM and PKM serve distinct, complementary roles\nFinding 2: FwPKM competes with Full Attention\nFinding 3: Restricting full attention facilitates FwPKM use.\n\n\n\n4.3 NIAH Evaluation\n\nFinding 4: Iterative reading boosts retrieval accuracy.\nFinding 5: FwPKM generalizes to 128K contexts.\nFinding 6: Longer context requires more memorization iterations.\n\n\n\n\n\n5 Interpretability Analyses\n\n\n5.1 Case Study: Probing Memory in NIAH\n\nHigh-precision retrieval\nError analysis\nRobust aggregation\n\n\n\n5.2 Case Study: Selective Gating\n\nLayer specialization\nNovelty detection\n\n\n\n\n6 Cost Analyses\n7 Related Work\n8 Conclusion\n\nA Detailed Training Settings\n\nFwMLP\nLaCT\n\n\nB Ablation Study\nC More Visualization Examples\n\n\n\n\n\n\n\\sidecaptionvpos\nfiguret\n\\correspondingauthorTianyu Zhao (tianyu@sakana.ai)\n\nFast-weight Product Key Memory\n\n\nTianyu Zhao\n\nSakana AI\n\n\nLlion Jones\n\nSakana AI\n\n\n\nAbstract\nSequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, ‚Äúfast-weight‚Äù episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.\n\n\nAbstract\nSequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, ‚Äúfast-weight‚Äù episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.\n\n\nContents\n\n\n\n\n1 Introduction\n\nSequence modeling layers, or token mixers, are the foundational components in modern language models. The most successful architectures today can be fundamentally understood as forms of associative memory (Transformer; ParallelDeltaNet; GDN; RWKV7; Mamba2), characterized by their ability to maintain key-value associations, execute retrieval, and perform memorization (KVMemInBrain).\n\n\nWithin this framework, existing layers lie on a spectrum defined by the trade-off between storage capacity and computational efficiency. Standard softmax attention (Transformer) acts as an associative memory with unbounded storage, yet its computational cost becomes increasingly prohibitive as the sequence length grows (TransformerAssocMem). Conversely, linear attention variants (LinearAttention; DeltaNetLSTM; Mamba; Mamba2; GDN; TTT; Titans) provide efficient, sub-quadratic mechanisms but rely on fixed storage capacities that often struggle to capture the same depth of information.\n\n\nWe focus our investigation on resolving this specific tension: balancing large-scale storage with low computational overhead. We posit that an ideal associative memory should satisfy four key properties:\n\n\nnosep\n\nKey-value Association: The ability to link keys to values.\n\n\n\nnosep\n\nLarge Storage: Capacity that is extensive, if not unbounded.\n\n\n\nnosep\n\nLow Cost: Sub-quadratic computational complexity w.r.t. input length.\n\n\n\nnosep\n\nRetrieval and Memorization: The capability to retrieve information and, crucially, memorize new key-value pairs from inputs at any time.\n\n\n\n\n\nProduct Key Memory (PKM, PKM) is an architecture that elegantly satisfies the first three properties. Its sparse key-value design handles an enormous number of memory slots (e.g., N=106N=10^{6}) with fixed and low computation. However, PKM was originally designed as a ‚Äúslow-weight‚Äù channel mixer ‚Äì similar to Feed-Forward Networks (FFN) ‚Äì meaning it is updated only during training and remains frozen during inference. Consequently, it lacks the ability to rapidly adapt to new inputs during deployment, failing property 4.\n\n\nIn this paper, we propose to convert PKM from a static, slow-weight module into Fast-weight Product Key Memory (FwPKM). By redesigning PKM to update its parameters dynamically at both training and inference time, we enable it to function as a high-fidelity episodic memory. FwPKMcan store ‚Äúepisodes‚Äù directly from input sequences and carry that memory across different contexts, offering a promising new path for continual learning and personalized AI agents.\n\n\nTable 1: Comparison of PKM and FwPKM\n\n\n\n\n\n\n\n\n\nPKM\n\n\n\n\nFwPKM\n\n\n\n\n\n\nWeight Type\n\n\n\n\nSlow Weights\n\n\n\n\nFast Weights\n\n\n\n\n\n\nSimilar Modules\n\n\n\n\nFFN, MoE-FFN, PKM\n\n\n\n\nSoftmax Attn., Linear Attn., DeltaNet\n\n\n\n\n\n\nRole\n\n\n\n\nChannel Mixer. Mixes features within a single token representation.\n\n\n\n\nToken Mixer. Mixes information across time steps (sequence positions).\n\n\n\n\n\n\nParameter Update\n\n\n\n\nUpdated at training; Frozen at inference.\n\n\n\n\nUpdated at both training and inference.\n\n\n\n\n\n\nMemory Horizon\n\n\n\n\nLong-term (Semantic). Stores dataset-wide facts and general rules (e.g., world knowledge).\n\n\n\n\nShort-term (Episodic). Stores context-specific variable bindings (the Context Window).\n\n\n\n\n\n\nLearning Objective\n\n\n\n\nGlobal Objective of next token prediction\n\n\n\n\nLocal Objective of memorization\n\n\n\n\n\n\n\n\n2 Product Key Memory\n\nTop-kk Key-value Memory\n\nA standard key-value memory consists of a key matrix K‚àà‚ÑõN√óDKK\\in\\mathcal{R}^{N\\times D_{K}} and a value matrix V‚àà‚ÑõN√óDVV\\in\\mathcal{R}^{N\\times D_{V}}, where NN represents the number of memory slots and D{K,V}D_{\\{K,V\\}} are the hidden dimensions. A common approach to learning a large memory without sacrificing computation efficiency is to exploit sparsity via a Top-kk operation (MemNet-JW; SparseMemRae). Given an input query vector ùê™\\mathbf{q}, the model computes a score sis_{i} for each memory slot as the inner product between the query and the keys. A Top-kk operation ùíØk\\mathcal{T}_{k} then selects the indices of the kk slots with the highest scores. The selected scores are normalized via softmax to produce weights {si‚Ä≤}\\{s^{\\prime}_{i}\\}, and the retrieval output ùêØ^\\hat{\\mathbf{v}} is computed as the weighted sum of the corresponding value slots.\n\n\n\nsi\\displaystyle s_{i}\n=ùê™‚ä§‚ÄãKi\\displaystyle=\\mathbf{q}^{\\top}K_{i}\n\n(1)\n\n\n\n‚Ñê\\displaystyle\\mathcal{I}\n=ùíØk‚Äã(ùê¨)\\displaystyle=\\mathcal{T}_{k}(\\mathbf{s})\n\n(2)\n\n\n\n{si‚Ä≤}\\displaystyle\\{s^{\\prime}_{i}\\}\n=ùöúùöòùöèùöùùöñùöäùö°‚Äã({sj}j‚àà‚Ñê)\\displaystyle=\\mathtt{softmax}(\\{s_{j}\\}_{j\\in\\mathcal{I}})\n\n(3)\n\n\n\nùêØ^\\displaystyle\\hat{\\mathbf{v}}\n=‚àëi‚àà‚ÑêVi‚Äãsi‚Ä≤\\displaystyle=\\textstyle\\sum_{i\\in\\mathcal{I}}V_{i}s^{\\prime}_{i}\n\n(4)\n\n\n\n\n\nProduct Key Memory\n\nWhile the Top-kk operation restricts the number of accessed memory slots, it still requires computing scores for all NN key rows to find the top candidates. This O‚Äã(N)O(N) complexity prohibits scaling to enormous memory sizes (e.g. N=106N=10^{6}). PKM proposed Product Key Memory (PKM) to address this problem. In PKM, the query vector ùê™\\mathbf{q} is decomposed into two sub-queries ùê™1\\mathbf{q}^{1} and ùê™2\\mathbf{q}^{2} as shown below in Equation 5, where [‚ãÖ;‚ãÖ][\\cdot;\\cdot] is concatenation. Instead of a single large key matrix, PKM maintains two smaller sub-key matrices K{1,2}K^{\\{1,2\\}} each of size N√óDK\\sqrt{N}\\times D_{K}. The memory slots are arranged in a Cartesian grid of size N√óN\\sqrt{N}\\times\\sqrt{N}, and the slot at index (i,j)(i,j) corresponds to the interaction between the ii-th sub-key from K1K^{1} and the jj-th sub-key from K2K^{2}. The score for this slot is defined as the sum of the scores of its corresponding sub-queries: s(i,j)=si1+sj2s_{(i,j)}=s_{i}^{1}+s_{j}^{2}. Importantly, under this formulation, the Top-kk elements of this Cartesian product can be obtained without computing all NN scores. Instead, it first identifies the Top-kk indices for each sub-query independently and then searches within the smaller length-k2k^{2} Cartesian product of these selected sets.\n\n\n\n[ùê™1;ùê™2]\\displaystyle[\\mathbf{q}^{1};\\mathbf{q}^{2}]\n=ùê™\\displaystyle=\\mathbf{q}\n\n(5)\n\n\n\nsi{1,2}\\displaystyle s^{\\{1,2\\}}_{i}\n=ùê™{1,2}‚ä§‚ÄãKi{1,2}\\displaystyle=\\mathbf{q}^{\\{1,2\\}\\top}K^{\\{1,2\\}}_{i}\n\n(6)\n\n\n\n‚Ñê{1,2}\\displaystyle\\mathcal{I}^{\\{1,2\\}}\n=ùíØk‚Äã(ùê¨{1,2})\\displaystyle=\\mathcal{T}_{k}(\\ma"
  },
  {
    "title": "Three factor delay learning rules for spiking neural networks",
    "url": "https://arxiv.org/abs/2601.00668v1",
    "source": "arxiv",
    "summary": "Spiking Neural Networks (SNNs) are dynamical systems that operate on spatiotemporal data, yet their learnable parameters are often limited to synaptic weights, contributing little to temporal pattern recognition. Learnable parameters that delay spike times can improve classification performance in temporal tasks, but existing methods rely on large networks and offline learning, making them unsuita",
    "full_text": "\n\n\n\nI Introduction\n\nII Background\n\nII-A Delay learning\nII-B Online learning\n\n\n\nIII Proposed Methods\n\n\nIII-A Neuron dynamics\n\nIII-A1 Surrogate gradient\n\n\nIII-B Neural network architecture and loss function\nIII-C Online learnable delays\nIII-D Spike train kernel\n\n\n\nIV Experiments\n\nIV-A Dataset\nIV-B Experimental Setup\n\n\nV Results\n\nVI Comparison and Discussion\n\nVI-A Efficacy of delay learning\nVI-B Relevance for on-chip implementation\n\n\nVII Conclusion\n\n\n\n\n\nThree-Factor Delay Learning Rules Spiking Neural Networks\n\n\nLuke Vassallo and Nima Taherinejad\n\n\n\nAbstract\nSpiking Neural Networks (SNNs) are dynamical systems that operate on spatiotemporal data, yet their learnable parameters are often limited to synaptic weights, contributing little to temporal pattern recognition. Learnable parameters that delay spike times can improve classification performance in temporal tasks, but existing methods rely on large networks and offline learning, making them unsuitable for real-time operation in resource-constrained environments. In this paper, we introduce synaptic and axonal delays to leaky integrate and fire (LIF)-based feedforward and recurrent SNNs, and propose three-factor learning rules to simultaneously learn delay parameters online. We employ a smooth Gaussian surrogate to approximate spike derivatives exclusively for the eligibility trace calculation, and together with a top-down error signal determine parameter updates. Our experiments show that incorporating delays improves accuracy by up to 20% over a weights-only baseline, and for networks with similar parameter counts, jointly learning weights and delays yields up to 14% higher accuracy. On the SHD speech recognition dataset, our method achieves similar accuracy to offline backpropagation-based approaches. Compared to state-of-the-art methods, it reduces model size by 6.6√ó\\times and inference latency by 67%, with only a 2.4% drop in classification accuracy. Our findings benefit the design of power and area-constrained neuromorphic processors by enabling on-device learning and lowering memory requirements.\n\n\n\nI Introduction\n\n\nSpiking Neural Networks (SNNs) are continuous time dynamical systems that integrate a weighted sum of action potentials and emit a spike when sufficiently stimulated. Unlike Artificial Neural Networks (ANNs), which perform static data transformations without an explicit temporal component, SNNs inherently operate in the time domain. However, despite this fundamental difference, SNNs still rely primarily on synaptic weights for learning [1, 2]. The absence of dedicated mechanisms for capturing temporal dynamics often leads to lower task performance, as shown by state-of-the-art methods for learning temporal delays [3, 4, 5]. Alternatively, achieving competitive performance often requires significantly larger models with orders of magnitude more parameters [1]. Recently improved techniques for training SNNs such as surrogate gradient methods [6] [7], have allowed learning of time-dependent parameters on a large scale such as synaptic delay learning.\n\n\nLearnable delays add a degree of freedom that facilitates temporal pattern detection. For instance, in Figure¬†1 the green plots shows the effect two incident spikes have on the membrane potential. The first spike at t1t_{1} increases the membrane potential in proportion to the strength of the synaptic weight and decays towards zero. A second spike at a later time t=t2t=t_{2} has a similar effect, but since the two do not coincide in time, the membrane potential does not exceed the threshold and thus, the neuron does not fire. However, if t1t_{1} is delayed to t12t_{12} by Dj‚ÄãiD_{ji}, then the spikes co-incide and, as the bold trace shows, a spikes it emitted. The converse can also be useful, increasing the separation of temporally local spikes can suppress firing.\n\n\nFigure 1: Illustration of coinciding pre-synaptic spikes leading to post-synaptic. Two distinct pre-synaptic neurons emit spikes at t=t1t=t_{1} and t=t2t=t_{2}, respectively. Introducing a delay to the first spike shifts its effect to t=t12t=t_{12}, where it coincides with the second spike and thereby triggering downstream effects.\n\n\nOur work introduces three-factor delay learning rules for updating synaptic and axonal delays in a gradient-equivalent manner. We explore the application of these rules to keyword spotting (KWS) tasks using feedforward SNNs and spiking recurrent neural networks (SRNNs). Our results highlight the contribution of each delay type to classification accuracy and demonstrate the advantages of heterogeneous spatiotemporal parameters over homogeneous spatial ones. Our proposed method, along with its systematic evaluation, provides insights for chip designers balancing model versatility and efficiency in size weight and power (SWaP)-constrained neuromorphic processors.\n\n\n\n\nII Background\n\n\nDelays in point neurons can be categorized based on morphology. At the synapse, delays arise from the complex chemical reactions triggered by the arrival of an action potential at the pre-synaptic site, which later initiates the post-synaptic response [8]. If the postsynaptic response causes the neuron to fire, the resulting spike propagates along the axon introducing an axonal delay [9]. Before reaching the synapse of a downstream neuron, the signal must also traverse the dendritic arbor, leading to a dendritic delay that depends on dendritic morphology, membrane properties, and the presence of active ion channels [10].\n\n\n\nII-A Delay learning\n\n\nSeveral approaches exist to embed and learn delays in neural networks. Spike layer error reassignment in time (SLAYER) [11] addresses the temporal credit assignment problem in SNNs, enabling learning both synaptic weights and delays in multi-layer networks. Sun et¬†al. [12] introduces axonal delays by extending the underlying spike response model (SRM) with temporal convolutions through rectified axonal delay (RAD) or the neurophysiologically inspired variable axonal delay (VAD) [5]. In both cases, the delay kernel gradient was calculated numerically using the finite difference approximation and demonstrated an accuracy improvement of up to 18.7% on KWS datasets [7]. Deckers et al. [3] further adapts SLAYER‚Äôs [11] axonal delay mechanism to individual synapses and when combined with a constrained adaptive leaky integrate and fire (ADLIF) neuron model [1], this approach achieves accuracy comparable to temporal convolution methods [4].\n\n\nHowever since in principle the adaptive neuron model and synaptic delays both facilitate temporal pattern recognition, it is unclear how much each feature contributes to classification accuracy. An alternative approach, implemented in PyTorch uses dilated convolution with learnable spacings (DCLS) [13, 4]. It employs a Gaussian kernel parameterized by weight and delay parameters, that is convolved with the incident spike train, to generate the spatiotemporal response of a synapse.\n\n\nBy leveraging automatic differentiation, it achieves state-of-the-art accuracy even on challenging KWS datasets. Recognizing the benefits of this method in sparse settings, M√©sz√°ros et al. [14] introduces dynamic pruning to enforce sparsity.\n\n\nEvent propagation [15] provides an alternative training algorithm that uses spike times to compute exact gradients without surrogates. Applied to keyword spotting and related tasks, event propagation has achieved state-of-the-art performance [16], with subsequent experiments highlighting the importance of loss shaping [17].\n\n\n\n\nII-B Online learning\n\n\nBackpropagation is update-locked [18], preventing parameter updates until the full input sequence is processed. For sequence data, this results in linearly increasing memory demands, which restricts real-time and on-chip implementation. Online learning releases this constraint and traces its origins to Real-Time Recurrent Learning (RTRL) [19]. By accumulating the gradients of the hidden states, RTRL eliminated the need to unroll the network over some time window TT. However, its cubic memory complexity (ùí™‚Äã(n3)\\mathcal{O}(n^{3})) is prohibitive compared to backpropagation through time (BPTT) (ùí™‚Äã(n‚ÄãT)\\mathcal{O}(nT)). Subsequent research has focused on approximating RTRL to reduce computational costs [20, 21] or developing biologically plausible three-factor learning rules [22] that aim to retain BPTT ‚Äôs performance guarantees.\n\n\nThree-factor learning rules mitigate the biological implausibility of BPTT-like algorithms [23, 15] by addressing the weight transport [24] and update locking [18] problems. They rely on eligibility traces, composed of pre- and post-synaptic factors that capture temporal activity. However, unlike two-factor learning rules [25], synaptic changes occur only when these traces are modulated by a third factor, for instance, a top-down learning signal spatially propagating task-relevant error information (see [26] for a comprehensive survey). Superspike [27] constructs an eligibility trace by combining a low-pass filtered trace of pre-synaptic activity with a nonlinear function of post-synaptic activity, while the error signal serves as the third factor. By contrast, Eligibility Propagation (e-prop) [28] reformulates BPTT as the three-factor learning rule framework, demonstrating equivalence for feedforward networks and approximating it for recurrent architectures. Dynamics for Deep Continuous Local Learning (DECOLLE) [29] computes local synthetic gradients using per-layer readout functions. [30] decouples spatial gradients (top-down learning signals within the same timestep) and temporal gradients (eligibility traces spanning timesteps). It is equivalent to BPTT for shallow SRNNs and approximates its performance for deeper architectures.\n\n\n\n\n\nIII Proposed Methods\n\n\nWe present the neural dynamics for point neurons, network architecture and three-factor delay learning rules using e-prop [28] as a basis for online learning.\n\n\n\nIII-A Neuron dynamics\n\n\nThe leaky integrate and fire "
  },
  {
    "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
    "url": "https://arxiv.org/abs/2601.00664v1",
    "source": "arxiv",
    "summary": "Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and",
    "full_text": null
  },
  {
    "title": "Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability",
    "url": "https://arxiv.org/abs/2601.00655v1",
    "source": "arxiv",
    "summary": "This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) pro",
    "full_text": null
  },
  {
    "title": "Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations",
    "url": "https://arxiv.org/abs/2601.00647v1",
    "source": "arxiv",
    "summary": "Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and i",
    "full_text": null
  },
  {
    "title": "Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs",
    "url": "https://arxiv.org/abs/2601.00641v1",
    "source": "arxiv",
    "summary": "Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Existence of correct answers\n\n2.1 Specific tasks\n2.2 Repetition Lemma\n\n\n\n3 Identification of correct answers\n\n3.1 Judging model\n3.2 Reliability of judged existence\n3.3 Identification via ensemble judging\n3.4 Ensemble judge accuracy\n3.5 Algorithmic formulation\n\n\n4 Experiments\n5 Conclusion\nA Task prompts\n\n\n\n\n\nProbabilistic Guarantees for Reducing Contextual Hallucinations in LLMs\n\n\n\n\n\n\nNils Rautenberg111contact: nils.rautenberg@rub.de\nSven Schippkus¬†\n\n\n\nDeutsche Aktuarvereinigung e.V.\nUniversity of Hamburg\n\n\n\n\n(January 2, 2026)\n\nAbstract\nLarge language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model‚Äëagnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.\nWe formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge‚Äôs true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.\nExperiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.\n\n\nKey Points\n\n\n‚àô\\bullet\n\nIndependent prompt repetition makes it overwhelmingly likely that a correct answer appears.\n\n\n\n‚àô\\bullet\n\nAn LLM-as-a-judge identifies correct answers; majority vote improves reliability when needed.\n\n\n\n‚àô\\bullet\n\nTogether, these give explicit probabilistic guarantees with exponentially decreasing error rates.\n\n\n\n\n\n\n1 Introduction\n\nLarge language models (LLMs) are increasingly capable of solving complex tasks, following instructions, and synthesizing information across long chains of reasoning. Yet even the most advanced models still fail in a surprisingly human way: they occasionally assert things that are not true, not implied, or directly contradicted by the information they were given. These hallucinations pose a challenge for automated pipelines that require deterministic correctness.\n\n\nA growing body of work has shown that hallucinations take many forms rather than one. Comprehensive reviews [undefg, undefaa] map out diverse error types‚Äîfrom contradictions with world knowledge to logical slips or instruction confusion‚Äîrevealing that hallucination is a structural property of present-day models rather than a rare glitch [undefi]. Summarization studies further demonstrate that even conditioned generation systems often produce unsupported claims [undefr, undefe, undefk], and retrieval-augmented models continue to introduce content not present in the retrieved passages [undef]. Contextual hallucinations, where the model contradicts or ignores information that is explicitly provided in the prompt, have proven particularly difficult to eliminate. Prior work attributes these failures to long‚Äëcontext degradation [undefb, undefj, undefm], competition between contextual and parametric knowledge [undefo], and the inherent difficulty of reliable evidence tracking in autoregressive generation.\n\n\n\n\n\nFigure 1: The repetition-judge pipeline gives probabilistic guarantees for reducing contextual hallucinations. Left: For a given specific task, the likelihood that all answers are hallucinated is reduced by repeating the task NN times and judging the output XnX_{n} of each for correctness. The pipeline fails (‚Äùall answers are judged as incorrect‚Äù) exponentially decreasing with NN. Right: From the judged-correct answers, a true correct answer can be found at guaranteed rates. If the judge is perfect (q++=1,q‚àí+=0q^{++}=1,\\,q^{-+}=0), any XnX_{n} with Yn=1Y_{n}=1 is a correct answer. If the judge is noisy but better than random (q‚àí+&lt;0.5q^{-+}&lt;0.5), an ensemble judge selects a hallucination exponentially decreasing with the number of judges KK.\n\n\nOngoing efforts have sought to detect and mitigate hallucinations. Techniques such as FactCC [undefk], AlignScore [undefz], REFChecker [undeff], and VeriFastScore [undefs] attempt to identify unsupported content post‚Äëhoc, while contrastive decoding strategies [undefu, undefa] and faithfulness-inspired heuristics [undefw] aim to reduce hallucinations during inference. Multi-agent refinement and LLM-as-a-judge systems [undefh, undefp, undefc, undefn, undefq, undefv, undefd, undefx] combine several model calls to improve reliability, but empirical studies show that judges can themselves be inconsistent or biased in challenging cases [undefl, undefj]. Despite substantial progress, existing mitigation strategies do not provide explicit quantitative guarantees on the likelihood of residual hallucinations.\n\n\nIn this paper, we focus on a restricted but practically important setting: a class of tasks that we call specific tasks. A specific task is one where: (i) the input is fixed, (ii) the prompt is issued only once per run, (iii) and correctness can be evaluated by a deterministic criterion. Typical examples include slot extraction, reference lookup, formatting tasks, or locating a particular word or number in a known text. Such tasks are common in automated workflows and provide a clean setting where correctness is unambiguous. In this setting, reliability decomposes naturally into two independent questions: (i) how likely is that at least one correct answer appears among the model outputs, and (ii) how reliably a judge can identify such an answer when it exists. These two stages-existence and identification-can be improved separately through repetition and judged selection.\n\n\nTwo simple observations motivate our framework:\n\n\n\n\n1.\n\nRepetition amplifies correctness.\nEven if a model sometimes answers incorrectly, running the same task several times independently, for example by issuing each call in a fresh context window, makes it very likely that at least one of the answers will be correct. This is a direct probabilistic consequence of independence, and we formalize it as the Repetition Lemma.\n\n\n\n2.\n\nIdentification requires a judge.\nRepetition alone does not tell us which of the responses is correct. Selecting an answer uniformly at random from the repeated runs yields the same correctness probability as a single run. To select a correct answer among all that appear, we need a secondary mechanism to filter out hallucinations: an LLM-as-a-judge. Even if the judge is imperfect, its reliability can itself be improved through repetition.\n\n\n\n\n\nFigure¬†1 illustrates the repetition‚Äìjudge pipeline based on these core concepts. Repetition makes it overwhelmingly likely that at least one correct answer appears among the model outputs, and an appropriate judge‚Äìstrengthened via majority vote if necessary‚Äîidentifies such an answer with task‚Äëdependent true‚Äë and false‚Äëpositive rates. Taken together, these components form a lightweight, model‚Äëagnostic pipeline for achieving arbitrarily low error rates on fixed‚Äëinput tasks without modifying model weights or relying on complex decoding schemes.\n\n\nThe remainder of the paper develops these ideas in a simple formal setting. Section 2 introduces specific tasks and shows how independent repetitions sharply reduce the chance that all responses are wrong. Section 3 then explains how a judge can be used to identify a correct answer once repetition makes its existence likely, and how ensemble judging provides explicit bounds on hallucination-selection probability even for imperfect judges. Section 4 presents controlled experiments validating both effects, and Section 5 concludes.\n\n\n\n\n2 Existence of correct answers\n\nAt the heart of our framework lies a simple but powerful modelling assumption: independent LLM calls made in fresh context windows behave as independent samples from a fixed output distribution. This assumption is the mathematical basis for all existence guarantees in this paper. It reflects the practical reality that each model call carries its own sampling randomness and that starting from an empty, uncontaminated context eliminates cross‚Äërun interference. Under this independence assumption, repeated executions of the same prompt provide statistically independent ‚Äúattempts‚Äù at solving a fixed task.\n\n\nWe now formalize the setting in which our analysis applies. At this stage, we focus solely on the probability that a correct answer appears among repeated calls to the model. The identification step (‚Äùfind a correct answer‚Äù) is developed separately in Section¬†3, where we incorporate a judge and, when needed, majority‚Äëvote aggregation.\n\n\nA specific task is one where the input is fixed, the prompt is issued only once per run, and correctness can be evaluated by a deterministic rule. In this setting, each call to the LLM behaves as a random draw from a fixed distribution. Running the same task independently multiple times therefore produces a sequence of independent and identically distributed random variables. This structure is all we need to derive explicit pro"
  }
]