[
  {
    "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System",
    "url": "https://arxiv.org/abs/2601.08829v1",
    "source": "arxiv",
    "summary": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation resu",
    "full_text": "\n\n\n\n1 Introduction\n2 Related Work\n\n3 Method\n\n\n3.1 Overview\n\nReviewer.\nArea Chair.\n\n\n\n3.2 Review Process\n\nInitial Review.\nSecond Review.\nAC Decision.\nMemory Update.\n\n\n3.3 Data Collection\n\n3.4 Reviewer Persona\n\nExpert.\nCritic.\nBluffer.\nOptimist.\nHarmonizer.\nSkimmer.\n\n\n3.5 Elo-ranked System\n\n\n\n4 Experiments\n\n\n4.1 Setup\n\nBaseline.\nAC Access.\nFull Access.\n\n\n\n4.2 Elo Rating Dynamics Analysis\n\nLimited Differentiation in Baseline.\nElo Introduces Stratification.\nExpert Dominance in Elo Rating.\nPenalty on Low-effort Behavior.\nVisible Elo Incentivizes Adaptation.\n\n\n4.3 Decision Performance Analysis\n\n\n5 Conclusion\n6 Limitations\n7 Ethical Considerations\n\n\n\n\n\nModeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System\n\n\n\nHsiang-Wei Huang ‚ÄÉJunbin Lu11footnotemark: 1 ‚ÄÉKuang-Ming Chen ‚ÄÉJenq-Neng Hwang\nUniversity of Washington\nEqual contribution\n\n\nAbstract\nIn this work, we explore the Large Language Model¬†(LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers‚Äô adaptive review strategy that exploits our Elo system without improving review effort. Our code is available at https://github.com/hsiangwei0903/EloReview.\n\n\n\\useunder\n\\ul\n\n\n\n\nModeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System\n\n\n\n\n\nHsiang-Wei Huang‚Ä†‚Ä†thanks: Equal contribution ‚ÄÉ‚ÄäJunbin Lu11footnotemark: 1 ‚ÄÉ‚ÄäKuang-Ming Chen ‚ÄÉ‚ÄäJenq-Neng Hwang\n\nUniversity of Washington\n\n\n\n\n\n\n1 Introduction\n\nPeer review is the cornerstone of scientific evaluation, yet substantial inconsistencies and biases persist in the process.\nPrior work has documented low inter-reviewer agreement and highly variable review quality¬†Stelmakh et al. (2021), unclear or strategic reviewer motivations¬†Zhang et al. (2022a), calibration noise in numerical ratings¬†Lu and Kong (2023), and systematic biases related to author identity or institutional prestige¬†Sun et al. (2022); Fox et al. (2023).\nThese challenges have been exacerbated by the rapid growth of submissions in recent AI conferences, which strains reviewer pools and increases variance in expertise and effort.\n\n\nWhile analyses of historical review data have yielded valuable insights, direct empirical study of reviewer behavior remains fundamentally constrained. Many influential factors, including reviewer intent, bias, and adaptation over time, are difficult to observe directly, while privacy concerns limit experimental manipulation of real review processes¬†Stelmakh et al. (2021); Zhang et al. (2022a).\n\n\nFigure 1: Our work explores the LLM agent dynamic of Elo-ranked Review System where reviewer is able to adjust their review strategy across review rounds.\n\n\nFigure 2: Four stages of our proposed Elo-ranked paper review process.\n\n\nRecently, simulation-based approaches provide a promising alternative for studying social interaction and even peer review process. The advancement in large language models (LLMs) have enabled agent-based simulations that exhibit increasingly realistic professional and social behaviors¬†Wu et al. (2024); Chen et al. (2024); Park et al. (2023) as well as simulating peer review dynamics in AI conference¬†Jin et al. (2024).\nHowever, existing studies largely overlook a growing practical concern in modern AI conferences. The expansion of reviewer pools has been accompanied by irresponsible and low-effort reviewing behaviors, which are currently addressed only through single-round, conference-specific penalties.\n\n\nMotivated by this gap, we introduce a LLM agent reviewer simulation framework that incorporates reviewer Elo rating across review rounds, as shown in Figure.¬†1. Our design enables longitudinal accountability beyond one-time review. Using six archetypal reviewer personas, we show that Elo-ranked system largely improves Area Chair¬†(AC) decision accuracy, and further offer insights via our study on the LLM agents‚Äô review dynamics. Together, these findings demonstrate the potential benefits and challenges of an Elo-ranked system can face in the real-world peer review process.\n\n\n\n\n2 Related Work\n\nPeer review has long been studied as a complex socio-technical system, with prior work analyzing biases, conflicts of interest, reviewer quality, and fairness using real-world conference data¬†Zhang et al. (2022b); Stelmakh et al. (2021); Ugarov (2023); Verharen (2023); McIntosh and Vitale (2023); Stephen (2023); Zhang et al. (2022a). Other studies examine operational components such as reviewer assignment strategies¬†Jovanovic and Bagheri (2023); Saveski et al. (2023); Kousha and Thelwall (2024) and the impact of author rebuttals¬†Huang et al. (2023). Recent advances in LLMs¬†OpenAI (2023); Team et al. (2023); Comanici et al. (2025) have enabled growing interest in agent-based modeling frameworks that simulate complex social processes¬†Wu et al. (2023); Yin et al. (2023); Li et al. (2024); Chan et al. (2024); Jin et al. (2024).\n\n\n\n\n3 Method\n\n\n3.1 Overview\n\nIn this work, we design a framework which simulates a multi round¬†(conference) review process of the current AI conference peer review procedure. Our framework incorporates multiple roles of LLM agents, including Reviewers and Area Chairs¬†(AC). As our work mainly focus on the reviewer and AC interaction in the Elo-ranked system, we remove the author role and rebuttal stage, and adopt real-world conference submission for our simulation. We introduce our designed role as follows:\n\n\nReviewer.\n\nThe simulation consists of six independent reviewers, each possess a carefully designed persona with an initial Elo rating with same value across all reviewers. The reviewers are required to provide paper review with review style strictly following their persona. Additionally, to simulate the reviewer‚Äôs dynamic in the Elo-ranked system, we design a memory module that can be updated after each review round, which enables them to update their review strategy.\n\n\n\nArea Chair.\n\nThe area chair¬†(AC) makes acceptance final decision. Besides paper decision, inspired by the recent AI conferences‚Äô policy of rating the review, the AC is also required to provide quality rating for each reviewer, which will be used to adjust each reviewer‚Äôs Elo rating.\n\n\n\n\n\n3.2 Review Process\n\nThe review round consists of four stages, including initial review, second review, the AC decision, and reviewer memory update, as illustrated in Figure.¬†2.\n\n\nInitial Review.\n\nEach submission consists of three independent LLM agent reviewers with different personas, each reviewer generates an initial review for the assigned paper.\n\n\n\nSecond Review.\n\nIn this stage, reviewers are provided with other agents‚Äô reviews and may revise their initial assessments accordingly.\nAuthor rebuttals are omitted from the context, as our focus is on peer-to-peer reviewer interaction and prior work has shown that rebuttals play a limited role in LLM peer review simulation¬†Jin et al. (2024).\n\n\n\nAC Decision.\n\nAfter the post review stage, the AC takes the three generated reviews and makes the final decision. When making the final decision, the AC can access the reviewer‚Äôs Elo rating, and use that as an auxiliary meta information to assess the quality of review and make better final decision.\n\n\n\nMemory Update.\n\nAfter each round, the reviewer receives their Elo rating adjustment and updates their memory accordingly.\nThis memory does not override the reviewer‚Äôs persona, but is represented as a brief textual summary prepended to the review prompt, enabling the reviewer to adjust their review strategy with the goal of improving Elo.\n\n\n\n\n\n3.3 Data Collection\n\n150 papers were sampled from the ICLR 2025 submission uniformly from different average rating intervals. Additionally, we also filter papers with high rating variance. For each round, two papers are randomly selected, each paper is assigned with a reviewer randomly formed triplet to encourage interaction between different personas.\n\n\n\n\n3.4 Reviewer Persona\n\nWe design a set of six reviewer personas to capture common and recurring patterns of reviewer behavior observed in large-scale conference review corpora and prior studies on peer review bias. We introduce our six designed persona as follows.\n\n\nExpert.\n\nProvides careful, professional assessments with full engagement with the paper.\n\n\n\nCritic.\n\nApplies strict standards, emphasizing flaws and often defaulting to skeptical evaluations.\n\n\n\nBluffer.\n\nDisplays high confidence and authoritative tone while relying on partial reading.\n\n\n\nOptimist.\n\nFocuses on paper contributions and strengths, gives positive ratings most of the time.\n\n\n\nHarmonizer.\n\nBalances strengths and weaknesses with a consensus-seeking perspective, avoiding extreme judgments unless strongly justified.\n\n\n\nSkimmer.\n\nSuperficial, low-effort reviewer with limited engagement with the paper‚Äôs content.\n\n\n\n\n\n3.5 Elo-ranked System\n\nTo model persistent, rank-based feedback for reviewers, we adopt a simplified Elo-style adjustment mechanism driven by relative reviewer ranking within each review round.\nAfter each round, reviewers are ranked in descending order according to the AC‚Äôs evaluation scores.\nWe assign fixed base rewards to the top, middle, and bottom ranks as +100+100, 0, and ‚àí100-100, respectively, ensuring that the total Elo adjustment within each group sums to zero. This simple design yields a stable ranking mechanism that emphasizes comparative performance, and enables the study of strategic reviewer adaptation under persistent feedback.\n\n\n\n\n\n4 Experiments\n\nFigure 3: Elo rating dynamics of different reviewer personas across three experiment setups.\n\n\n\n4.1 Setup\n\nWe adopt Gemini-2.5-Flash¬†Comanici et al. (2025) as our LLM for all agents. In each round, two papers are"
  },
  {
    "title": "Motion Attribution for Video Generation",
    "url": "https://arxiv.org/abs/2601.08828v1",
    "source": "arxiv",
    "summary": "Despite the rapid progress of video generation models, the role of data in influencing motion is poorly understood. We present Motive (MOTIon attribution for Video gEneration), a motion-centric, gradient-based data attribution framework that scales to modern, large, high-quality video datasets and models. We use this to study which fine-tuning clips improve or degrade temporal dynamics. Motive iso",
    "full_text": null
  },
  {
    "title": "MemRec: Collaborative Memory-Augmented Agentic Recommender System",
    "url": "https://arxiv.org/abs/2601.08816v1",
    "source": "arxiv",
    "summary": "The evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Yet existing agents rely on isolated memory, overlooking crucial collaborative signals. Bridging this gap is hindered by the dual challenges of distilling vast graph contexts without overwhelming reasoning agents with cognitive load, and evolving the ",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Methodology\n\nProblem Formulation\nMemory in Agentic RS\n\n2.1 The MemRec Pipeline\n\n\n2.1.1 Collaborative Memory Retrieval\n\nLLM-Guided Context Curation\nCollaborative Memory Synthesis\n\n\n2.1.2 Grounded Reasoning\n2.1.3 Async. Collaborative Propagation\n\n\n\n\n\n3 Empirical Evaluation\n\n\n3.1 Experimental Setup\n\nDatasets\nBaselines\nExperimental Setup\n\n\n3.2 Main Results (RQ1)\n3.3 Impact of Cognitive overload (RQ2)\n3.4 Flexibility and Cost-Effectiveness (RQ3)\n\n3.5 Ablation Studies (RQ4)\n\nRationale Quality Analysis.\nHyperparameter Sensitivity.\nQualitative Analysis.\n\n\n\n\n4 Related Works\n5 Conclusion\n6 Limitations\n\nA Experimental Setup and Implementation Details\n\n\nA.1 Dataset Details\n\nBooks\nGoodreads\nMovieTV\nYelp\n\n\n\nA.2 Baseline Model Details\n\nA.2.1 Traditional Pre-LLM Methods (Latent Embeddings)\n\nA.2.2 Memory-based Approaches (Post-AgentRS Era)\n\n(1) Models with No Explicit Memory\n(2) Static Memory Agents\n(3) Dynamic Memory Agents (Isolated Updates)\n\n\n\n\n\nA.3 Implementation Details\n\nModel Deployment\nHardware Environment\nHyperparameters\nNeighbor Representation Strategy\n\n\nA.4 LLM-Generated Curation Rules\nA.5 Cost Estimation Methodology\n\n\n\nB Detailed Related Works\n\nB.1 Memory Architectures for LLM Agents\nB.2 Memory in Agentic RS\n\n\nC Extended Efficiency and Modularity Analysis\n\nD Additional Experimental Results\n\nD.1 Results for Larger Candidate Set\nD.2 Rationale Quality Analysis\nD.3 Latency and Token Breakdown Analysis\nD.4 Hyperparameter Analysis\nD.5 Full Metrics for Architectural Analysis\n\n\nE Qualitative Case Study: A Complete Collaborative Journey\n\nF Prompt Templates and Contexts\n\nF.1 Meta-Prompt Template\nF.2 Domain-Specific Prompt Contexts\nF.3 Stage-R Memory Synthesis Prompt\nF.4 Stage-ReRank Scoring Prompt\nF.5 Stage-W Propagation Prompts\nF.6 Rationale Quality Evaluation Protocol\n\n\n\nG Methodology Analysis\n\nG.1 Comparison of Curation Approaches\n\n\n\n\n\n\n\nMemRec: Collaborative Memory-Augmented Agentic Recommender System\n\n\n\nWeixin Chen1,2 ‚ÄÉYuhan Zhao2 ‚ÄÉJingyuan Huang1 ‚ÄÉZihe Ye1\nClark Mingxuan Ju3‚Ä† ‚ÄÉTong Zhao3‚Ä† ‚ÄÉNeil Shah3‚Ä† ‚ÄÉLi Chen2 ‚ÄÉYongfeng Zhang1‚Ä°\n1Rutgers University ‚ÄÉ2Hong Kong Baptist University ‚ÄÉ3Snap Inc. \n{cswxchen, csyhzhao, lichen}@comp.hkbu.edu.hk\n{chy.huang, zihe.ye, yongfeng.zhang}@rutgers.edu\n{mju, tzhao, nshah}@snapchat.com\n\n\n\nAbstract\nThe evolution of recommender systems has shifted preference storage from rating matrices and dense embeddings to semantic memory in the agentic era. Yet existing agents rely on isolated memory, overlooking crucial collaborative signals. Bridging this gap is hindered by the dual challenges of distilling vast graph contexts without overwhelming reasoning agents with cognitive load, and evolving the collaborative memory efficiently without incurring prohibitive computational costs. To address this, we propose MemRec, a framework that architecturally decouples reasoning from memory management to enable efficient collaborative augmentation. MemRec introduces a dedicated, cost-effective LMMem\\text{LM}_{\\text{Mem}} to manage a dynamic collaborative memory graph, serving synthesized, high-signal context to a downstream LLMRec\\text{LLM}_{\\text{Rec}}. The framework operates via a practical pipeline featuring efficient retrieval and cost-effective asynchronous graph propagation that evolves memory in the background. Extensive experiments on four benchmarks demonstrate that MemRec achieves state-of-the-art performance. Furthermore, architectural analysis confirms its flexibility, establishing a new Pareto frontier that balances reasoning quality, cost, and privacy through support for diverse deployments, including local open-source models.\nCode: https://github.com/rutgerswiselab/memrec\nHomepage: https://memrec.weixinchen.com\n\n\n\nMemRec: Collaborative Memory-Augmented Agentic Recommender System\n\n\n\n\n\nWeixin Chen1,2 ‚ÄÉ‚ÄäYuhan Zhao2 ‚ÄÉ‚ÄäJingyuan Huang1 ‚ÄÉ‚ÄäZihe Ye1\n\nClark Mingxuan Ju3‚Ä† ‚ÄÉTong Zhao3‚Ä† ‚ÄÉNeil Shah3‚Ä† ‚ÄÉLi Chen2 ‚ÄÉYongfeng Zhang1‚Ä°\n\n1Rutgers University ‚ÄÉ2Hong Kong Baptist University ‚ÄÉ3Snap Inc.\n\n\n\n{cswxchen, csyhzhao, lichen}@comp.hkbu.edu.hk\n\n{chy.huang, zihe.ye, yongfeng.zhang}@rutgers.edu\n\n{mju, tzhao, nshah}@snapchat.com\n\n\n\n\n22footnotetext: Authors affiliated with Snap Inc. served in advisory roles only for this work.33footnotetext: Corresponding author.\n\n\n1 Introduction\n\nMemory has long served as a foundational component in Recommender Systems (RS). The field has evolved from capturing preferences through sparse rating matrices in conventional collaborative filtering era¬†Sarwar et al. (2001); Koren et al. (2009) to using dense latent embeddings in the deep learning era¬†Covington et al. (2016); He et al. (2017). Recently, the emergence of agentic RS, powered by Large Language Models (LLMs), has ushered in a new paradigm, i.e., semantic memory¬†Wu et al. (2024); Zhang et al. (2025).\n\n\nIn agentic RS, memory is transformed into a semantic format, enabling LLMs to perform complex reasoning and use tools with natural language as the substrate¬†Zhao et al. (2024). For an agent to be more than a stateless function, it must utilize this persistent memory to retain and evolve its user understanding through ongoing interactions¬†Xi et al. (2025); Park et al. (2023). The evolution of memory mechanisms in this context can be delineated into three key milestones: (1) No explicit memory, relying solely on the LLM‚Äôs inherent knowledge¬†Liu et al. (2023); Lyu et al. (2024); (2) Static memory, characterized by retrieving context from fixed storage¬†Xu et al. (2025b); Gao et al. (2023); and recently (3) Dynamic, self-reflective memory, where agents iteratively update their understanding over time¬†Tang et al. (2025); Zhang et al. (2024b).\n\n\n\n\n\n(a) \n\n\n\n\n\n(b) \n\n\n\nFigure 1: \n(a) Existing Agents interact with user and item memories through separate, isolated read/write channels. (b) MemRec performs collaborative operations on memory graph, enabling global connectivity.\n\n\n\nHowever, these approaches predominantly represent non-collaborative paradigms. As illustrated in Figure 1(a), current agents typically reflect only on their siloed history with a user (MuM_{u}) or item (MiM_{i})¬†Xu et al. (2025b); Zhang et al. (2024b). This isolates them from the most potent signal in recommender systems, i.e., global collaboration. The high-order connectivity of the broader user-item graph, essential for capturing community trends and serendipitous discoveries, remains largely untapped by existing agentic frameworks¬†Wang et al. (2019); He et al. (2020).\n\n\nA seemingly intuitive solution for bridging this gap is to inject raw collaborative neighborhoods directly into the agent‚Äôs memory. However, this na√Øve brute-force approach proves inadequate for at least two critical reasons:\n\n\n‚Ä¢\n\nCognitive Overload. While the agent may be able to access large quantities of neighbor memories, it struggles to effectively distill pertinent information from this abundance. The sheer volume of textual and structural signals increases difficulty for the reasoning agent to identify salient knowledge¬†Liu et al. (2024), as validated in ¬ß3.3.\n\n\n\n‚Ä¢\n\nProhibitive Collaborative Updates. Our system requires propagating dynamic updates throughout the graph neighborhood. However, this naive approach that synchronously updates every user- or item-related neighborhood graph necessitates redundant, independent LLM calls for each interaction, resulting in an intractable computational bottleneck within the primary reasoning loop.\n\n\n\nConsequently, a core challenge emerges: How can we distill extensive collaborative knowledge into memory to empower the reasoning agent, while ensuring efficient evolution of the graph?\n\n\nTo address these challenges, we introduce MemRec (Figure 1(b)), a framework built upon architectural decoupling to shift from isolated to collaborative memory. By dedicating a separate Memory Manager (LMMem\\text{LM}_{\\text{Mem}}) to manage a dynamic graph and synthesize compact grounding, this architecture systematically resolves both cognitive overload and update bottlenecks.\nFirstly, addressing cognitive overload during retrieval, our Collaborative Memory Retrieval method overcomes the limitations of isolated memory paradigms. Instead of relying solely on siloed user or item memory, it leverages LLM-guided domain-adaptive rules to curates neighbor signals to synthesize a compact, high-utility collaborative memory.\nSecondly, overcoming update bottlenecks, we develop an Asynchronous Collaborative Propagation mechanism inspired by Label Propagation¬†Zhu and Ghahramani (2002). It efficiently batches self-reflection and neighbor updates into a single asynchronous operation and achieves constant-time (O‚Äã(1)O(1)) interaction complexity, ensuring continuous graph evolution without incurring the computational penalties of redundant, independent updates.\n\n\nExtensive evaluations on four benchmarks show that MemRec achieves state-of-the-art performance. Furthermore, our architectural analysis demonstrates MemRec‚Äôs flexibility, establishing a new Pareto frontier that balances reasoning quality, computational cost, and deployment constraints, supporting diverse setups from cloud-native APIs to on-premise local models.\n\n\nFigure 2: The overall framework of MemRec, decoupling reasoning (LLMRec\\text{LLM}_{\\text{Rec}}) from memory management (LMMem\\text{LM}_{\\text{Mem}}). The three-stage pipeline consists: Collaborative Memory Retrieval, synthesizing high-order connectivity context from memory graph; Grounded Reasoning, scoring items based on instruction and context; and Asynchronous Collaborative Propagation, evolving the semantic memory graph in the background.\n\n\n\n\n2 Methodology\n\nProblem Formulation\n\nLet ùí∞\\mathcal{U} and ‚Ñê\\mathcal{I} denote the sets of users and items, respectively. For each user u‚ààùí∞u\\in\\mathcal{U}, we denote their historical interactions as HuH_{u}. Given a target user uu, a natural language instruction ‚Ñêu\\mathcal{I}_{u} requiring semantic interpretation (e.g., specific constraints, complex goals), and a set of candidate items C‚äÜ‚ÑêC\\subseteq\\mathcal"
  },
  {
    "title": "Agent Contracts: A Formal Framework for Resource-Bounded Autonomous AI Systems",
    "url": "https://arxiv.org/abs/2601.08815v1",
    "source": "arxiv",
    "summary": "The Contract Net Protocol (1980) introduced coordination through contracts in multi-agent systems. Modern agent protocols standardize connectivity and interoperability; yet, none provide formal, resource governance-normative mechanisms to bound how much agents may consume or how long they may operate. We introduce Agent Contracts, a formal framework that extends the contract metaphor from task all",
    "full_text": "\n\n\n\n1 Introduction\n2 Theoretical Foundations\n\n3 Related Work\n\n3.1 Agent Architectures and Coordination\nProtocols\n3.2 Budget-Aware Reasoning and Resource\nManagement\n3.3 Agent Safety and Formal\nVerification\n3.4 Multi-Agent Coordination\nFrameworks\n\n\n\n4 The Agent Contract\nFramework\n\n4.1 Contract Definition\n4.2 Contract Components\n4.3 Contract Lifecycle\n\n\n\n5 Resource Tracking and\nMonitoring\n\n5.1 Token Budget\nDecomposition\n5.2 Runtime Monitoring\n\n\n\n6 Multi-Agent Coordination Under\nContracts\n\n6.1 Conservation Laws and Budget\nAllocation\n6.2 Coordination Patterns Through a Contract\nLens\n\n\n\n7 Fundamental Limitations and Practical\nEnforcement\n\n7.1 Single-Call Enforcement\nConstraints\n7.2 Enforcement Capabilities\n7.3 Future Infrastructure\nRequirements\n\n\n\n8 Empirical Evaluation\n\n8.1 Experimental Overview\n8.2 Runaway Prevention in Iterative\nWorkflows\n8.3 Conservation Laws in Multi-Agent\nCoordination\n8.4 Quality-Resource Tradeoffs via Contract\nModes\n\n\n9 Conclusion\n10 References\n\n\n\n\n11institutetext: Independent Researcher 11email: yeqi519@gmail.com 22institutetext: Independent Researcher 22email: jtan@live.de\nAgent Contracts: A Formal Framework for Resource-Bounded\nAutonomous AI Systems (Full)\n\n\nQing Ye\n\n‚ÄÉ‚ÄÉ\nJing Tan\n\n‚ÄÉ‚ÄÉ\nQing Ye\n\n‚ÄÉ‚ÄÉ\nJing Tan\n\n\n\nAbstract\nThe Contract Net Protocol (1980) introduced coordination through\ncontracts in multi-agent systems. Modern agent protocols standardize\nconnectivity and interoperability, yet none provide formal resource\ngovernance‚Äînormative mechanisms to bound how much agents may\nconsume or how long they may operate. We introduce Agent\nContracts, a formal framework that extends the contract metaphor from\ntask allocation to resource-bounded execution. An Agent Contract\nC=(I,O,S,R,T,Œ¶,Œ®)C=(I,O,S,R,T,\\Phi,\\Psi) unifies input/output specifications, multi-dimensional\nresource constraints, temporal boundaries, and success criteria into a\ncoherent governance mechanism with explicit lifecycle semantics. For\nmulti-agent coordination, we establish conservation laws ensuring\ndelegated budgets respect parent constraints, enabling hierarchical\ncoordination through contract delegation. Empirical validation across\nfour experiments demonstrates 90% token reduction with 525√ó\\times lower\nvariance in iterative workflows, zero conservation violations in\nmulti-agent delegation, and measurable quality-resource tradeoffs\nthrough contract modes. Agent Contracts provide formal foundations for\npredictable, auditable, and resource-bounded autonomous AI deployment.\n\n\n\n1 Introduction\n\nIn late 2025, an engineering team deployed a multi-agent research system\nwith four specialized agents. Two agents fell into a recursive\nclarification loop, running undetected for eleven days. When the invoice\narrived, the team discovered a $47,000 API bill\n[26]. The system had no stop conditions, no budget\nlimits, and no real-time cost monitoring. This incident encapsulates a\nfundamental problem‚Äîwe have built AI agents capable of autonomous\naction but lack formal mechanisms to bound their behavior.\n\n\nSuch failures reflect systemic gaps, not implementation bugs\n[10]. Gartner predicts that over 40% of agentic\nAI projects will be canceled by 2027 due to escalating costs or\ninadequate risk controls [15], even as agentic AI\nis projected to appear in 33% of enterprise software by 2028\n[14]. A recent MIT Sloan study finds that 35% of\norganizations already deploy agentic AI, with leaders citing the tension\nbetween supervision and autonomy as a core challenge requiring\ncentralized governance infrastructure [40].\nAgents are becoming capable of sustained autonomous operation spanning\nhours or days [42, 6], yet\nthe protocols governing them address connectivity and\ninteroperability but not resource governance‚Äîhow much an\nagent may consume or how long it may operate.\n\n\nAgent Contracts address this gap by extending the contract\nmetaphor from task allocation to resource governance. Where the Contract\nNet Protocol [51] asks ‚Äúwho should do this\ntask?‚Äù, Agent Contracts ask ‚Äúwithin what bounds may this task be\nperformed?‚Äù We draw on contract theory from economics, coordination\ntheory from distributed systems, and resource-bounded computation from\nreal-time systems to form a formal framework for resource-bounded\nautonomous AI.\n\n\nThis paper makes two contributions. First, we define an Agent Contract\nas a formal tuple C=(I,O,S,R,T,Œ¶,Œ®)C=(I,O,S,R,T,\\Phi,\\Psi) that unifies\ninput/output specifications, resource constraints, temporal boundaries,\nand success criteria into a coherent governance mechanism. Second, we\nestablish conservation laws for multi-agent systems that ensure budget\ndiscipline across delegation hierarchies, enabling composable\ncoordination patterns where contracting itself becomes an agent\ncapability. We validate these contributions across four experiments\ndemonstrating 90% token reduction in iterative workflows, zero\nconservation violations in multi-agent delegation, and measurable\nquality-resource tradeoffs. Together, these contributions provide formal\nfoundations for explicit resource governance in autonomous AI systems.\n\n\n\n\n2 Theoretical Foundations\n\nAgent Contracts draw on three theoretical traditions: contract theory\nfrom economics, multi-agent coordination from computer science, and\nresource-bounded computation from real-time systems.\n\n\nContract Theory. Bolton and Dewatripont (2005)\n[8] formalize how agreements are constructed\nunder asymmetric information. Three concepts apply to agent governance:\nmoral hazard (hidden actions; in LLM agents, unpredictable\nresource consumption), incomplete contracts (separating success\ncriteria from execution strategies) [21], and\nmechanism design (specifications that elicit desired behavior).\nRecent work [45, 60] identifies\nprincipal-agent dynamics in LLM systems but provides conceptual rather\nthan operational frameworks.\n\n\nMulti-Agent Coordination. Classical MAS research\n[57, 48] established\nfoundations for agent coordination. The Contract Net Protocol\n[51] demonstrated that explicit contracting could\ncoordinate distributed systems. Coordination theory\n[37] identifies fundamental problems\n(managing shared resources, producer-consumer relationships, and\nsimultaneity constraints), each corresponding to challenges in\nmulti-agent LLM systems. Research on normative multi-agent systems\n[7] formalizes how norms govern agent\nbehavior through obligations, prohibitions, and permissions. Agent\nContracts operationalize this perspective: resource constraints function\nas prohibitions (agents must not exceed budgets), success\ncriteria as obligations (agents must achieve quality thresholds),\nand the contract lifecycle provides regimented enforcement where\nviolations trigger automatic termination.\n\n\nA key insight from MAS theory is that coordination mechanisms must\nrespect conservation laws‚Äîresources allocated to subtasks\ncannot exceed parent resources. This principle requires explicit\nenforcement in LLM systems where token consumption is stochastic and\nobservable only after the fact.\n\n\nResource-Bounded Computation. Simon‚Äôs theory of bounded\nrationality [49, 50] established\nthat agents with limited cognitive resources must satisfice\nrather than maximize. Agent Contracts operationalize satisficing by\ndefining acceptable quality thresholds within resource budgets.\n\n\nThe algorithmic foundation comes from contract algorithms\n[63], which specify computation budgets\nbefore activation. Unlike anytime algorithms\n[64] that can be interrupted arbitrarily,\ncontract algorithms enable strategic resource allocation. An Agent\nContract transforms an LLM agent into a contract algorithm where bounds\nRR are known in advance. Real-time systems theory\n[9] contributes the distinction between hard\nconstraints (violation causes termination) and soft constraints\n(permitting graceful degradation).\n\n\n\n\n3 Related Work\n\n\n3.1 Agent Architectures and Coordination\nProtocols\n\nThe development of LLM-based agents has accelerated rapidly since 2022.\nReAct [59] introduced the paradigm of synergizing\nreasoning and acting. Chain-of-Thought prompting [56]\nestablished that computational depth correlates with output quality,\nmotivating explicit resource governance. Toolformer\n[47] showed that language models can learn to\nuse external tools, expanding the resource consumption profile of\nagents. Fully autonomous systems like AutoGPT\n[19] and Generative Agents\n[44] revealed both the potential and governance\nchallenges of unbounded execution.\n\n\nCoordination protocols have evolved to address different concerns. The\nContract Net Protocol [51] established task\nallocation through bidding; MCP [4] standardizes\ntool connectivity between models and external resources; A2A\n[16] enables discovery and interoperability across\nheterogeneous agent systems. The recent formation of the Agentic AI\nFoundation [33] under the Linux Foundation‚Äîwith\ncontributions including MCP, OpenAI‚Äôs AGENTS.md, and Block‚Äôs\ngoose‚Äîsignals industry consensus on connectivity and documentation\nstandards. However, resource governance remains outside this scope; none\nof these initiatives formalize how much agents may consume.\n\n\n\n\n3.2 Budget-Aware Reasoning and Resource\nManagement\n\nA growing body of work addresses resource efficiency in LLM reasoning.\nThe TALE framework [11] introduces token-budget-aware\nreasoning, achieving 68% reduction in token usage with less than 5%\naccuracy degradation. Critically, the authors identify ‚Äútoken\nelasticity‚Äù: LLMs often exceed specified budgets when constraints are\ntight, demonstrating that prompting alone is insufficient for strict\nenforcement. BudgetThinker [35] addresses this\nthrough control tokens injected during inference, coupled with\nreinforcement learning to achieve precise budget adherence. SelfBudgeter\n[55] enables models to predict required token\nbudgets based on task complexity. Liu et al.¬†(2025) [34]\ndemonstrate that simply granting larger tool-call budgets fails to\nimprove agent performance; their Budget-Aware Tool Selection (BATS)\nframework shows that explicit budg"
  },
  {
    "title": "Reasoning Matters for 3D Visual Grounding",
    "url": "https://arxiv.org/abs/2601.08811v1",
    "source": "arxiv",
    "summary": "The recent development of Large Language Models (LLMs) with strong reasoning ability has driven research in various domains such as mathematics, coding, and scientific discovery. Meanwhile, 3D visual grounding, as a fundamental task in 3D understanding, still remains challenging due to the limited reasoning ability of recent 3D visual grounding models. Most of the current methods incorporate a tex",
    "full_text": "\n\n\n\n1 Introduction\n2 Related Work\n\n3 Method\n\n3.1 3D Scene Generation\n3.2 Four Stages Reasoning\n3.3 Reasoning Data Collection\n3.4 3D Visual Grounding LLM Fine-tuning\n3.5 Inference Pipeline\n\n\n\n4 Experiments\n\n4.1 Implementation Details\n\n4.2 Benchmarks\n\nScanRefer.\nNR3D.\n\n\n4.3 Comparison with Non-fine-tuned Methods\n4.4 Comparison with Fine-tuned Methods\n\n4.5 Ablation Studies\n\nEffectiveness of fine-tuning.\nImportance of reasoning supervision.\nGeneralization to out-of-domain queries.\nFine-tuning with varied data scale.\n\n\n4.6 Qualitative Results\n\n\n5 Limitations and Future Work\n6 Conclusion\n7 Training configurations\n8 Scene generation details\n9 Training data statistics\n10 Spatial relationship templates\n11 Data collection and inference prompt\n\n\n\n\n\nReasoning Matters for 3D Visual Grounding\n\n\n\nHsiang-Wei Huang‚ÄÉKuang-Ming Chen‚ÄÉWenhao Chai‚ÄÉCheng-Yen Yang‚ÄÉ\nJen-Hao Cheng‚ÄÉJenq-Neng Hwang‚ÄÉ\nUniversity of Washington\n{hwhuang,kmchen,wchai,cycyang,andyhci,hwang}@uw.edu\n\n\n\nAbstract\nThe recent development of Large Language Models¬†(LLMs) with strong reasoning ability has driven research in various domains such as mathematics, coding, and scientific discovery. Meanwhile, 3D visual grounding, as a fundamental task in 3D understanding, still remains challenging due to the limited reasoning ability of recent 3D visual grounding models. Most of the current methods incorporate a text encoder and visual feature encoder to generate cross-modal fuse features and predict the referring object. These models often require supervised training on extensive 3D annotation data. On the other hand, recent research also focus on scaling synthetic data to train stronger 3D visual grounding LLM, however, the performance gain remains limited and non-proportional to the data collection cost. In this work, we propose a 3D visual grounding data pipeline, which is capable of automatically synthesizing 3D visual grounding data along with corresponding reasoning process. Additionally, we leverage the generated data for LLM fine-tuning and introduce Reason3DVG-8B, a strong 3D visual grounding LLM that outperforms previous LLM-based method 3D-GRAND using only 1.6% of their training data, demonstrating the effectiveness of our data and the importance of reasoning in 3D visual grounding.\n\n\nFigure 1: Our method outperforms 3D-GRAND on the ScanRefer benchmark when using only 1.6% amount of their training data scale. Compared with 3D-GRAND, our proposed data pipeline features lower data collection cost, incorporate extra reasoning supervision for LLM, and achieve 25% better grounding accuracy.\n\n\n\n1 Introduction\n\n3D Visual Grounding is a fundamental task in 3D understanding, aiming to identify a target object within a 3D scene based on a given textual query. Recent supervised-training models¬†[16, 25, 21, 26, 28, 35] integrate a text encoder and a visual encoder to generate cross-modal features for target object prediction. These supervised methods rely on large-scale, real-world annotated 3D visual grounding datasets for supervised training. To mitigate this, some recent research also explores approaches that leverage proprietary Large Language Models¬†(LLMs) and Vision Language Models¬†(VLMs) for the 3D visual grounding task via an agentic workflow¬†[30, 18] or through in-context examples and code generation¬†[33]. Despite these methods somewhat demonstrating success in the 3D visual grounding task, they heavily rely on proprietary LLMs and VLMs to achieve the best visual grounding performance, which introduce extensive inference cost during test time.\n\n\nFigure 2: We propose a fully automatic data pipeline that can generate visual grounding queries and reasoning responses. The collected data are used to conduct LLM fine-tuning, which results in Reason3DVG-8B, a powerful LLM with strong 3D visual grounding ability.\n\n\nTo advance open-source models for improved performance on 3D visual grounding, recent work also investigates the direction of collecting 3D visual grounding data for open-source LLM fine-tuning. 3D-GRAND¬†[29] collects a million-scale 3D visual grounding dataset and fine-tunes open-source LLM on this large-scale data. Despite showing performance improvements on public benchmarks, several new challenges emerge. First, 3D-GRAND relies on human-expert-designed 3D scenes, which require extensive manual labor. In addition, the dense object-level annotations introduce further cost. Furthermore, their experimental results also indicate that the performance improvement achieved through fine-tuning on such large-scale data is moderate and not proportional to the significant data collection effort. These challenges motivate us to rethink 1) a more cost-efficient, fully automatic data pipeline that can generate 3D visual grounding data in a human-free and cost-efficient fashion, and 2) the actual key beyond data scale towards improving the performance of open-source LLM on the challenging 3D visual grounding task.\n\n\nIn this work, we explore the direction of improving the LLM‚Äôs 3D visual grounding performance using fully automatically generated synthetic data, featuring detailed, structured reasoning supervision for LLM fine-tuning. Our proposed automated data collection pipeline introduces minimal cost, featuring detailed, structured reasoning supervision. LLM fine-tuned on our data outperforms previous LLM-based method 3D-GRAND that trained on 60√ó\\times more data, as shown in Fig.¬†1.\n\n\nOur work first introduces a fully automatic, 3D visual grounding data pipeline, which aims to address the dependency on extensive human-annotated 3D visual grounding data. We use our collected data and conduct LLM fine-tuning, resulting in Reason3DVG, an LLM with strong reasoning ability and advanced 3D visual grounding accuracy. We perform extensive evaluation and show that Reason3DVG¬†achieves superior grounding accuracy than SOTA zero-shot methods and LLM-based method 3D-GRAND on multiple 3D visual grounding benchmarks including ScanRefer and NR3D. We summarize the main contribution of our work as follows:\n\n\n\n\n‚Ä¢\n\nWe propose a fully automatic 3D visual grounding data pipeline for LLM fine-tuning. Our data pipeline does not require any human annotation, which largely reduces the data collection cost compared to previous works.\n\n\n\n‚Ä¢\n\nWe conduct LLM fine-tuning on our collected data and introduce Reason3DVG, an LLM for 3D visual grounding task that achieves strong accuracy on multiple 3D visual grounding benchmarks including ScanRefer and NR3D.\n\n\n\n‚Ä¢\n\nOur model outperforms previous 3D visual grounding LLM 3D-GRAND when using only 1.6% of training data, demonstrating the importance of reasoning supervision in the 3D visual grounding task, and serves as a cornerstone for future 3D understanding LLM development with stronger reasoning and understanding ability.\n\n\n\n\n\n\n\n2 Related Work\n\nFigure 3: An illustration of our 3D scene layout generation pipeline, which includes 5 steps:¬†1) Set up an empty 3D scene with certain dimension. 2) Choose a spatial relationship and decide the anchor and distractor objects as well as their dimension and location. 3) Place them in the 3D scene. 4) Determine the target object from the distractors and query. 5) Generate more distractor objects to enrich 3D scene.\n\n\n3D visual grounding is a fundamental 3D understanding task that aims to predict the target object in the 3D scene based on a given language query. Most of the recent 3D visual grounding methods¬†[28, 16, 19, 14] adopt separate encoders for each input modality such as text and point cloud to generate cross-modal features and conduct prediction. Some end-to-end methods like SAT¬†[32], LanguageRefer¬†[22], and UniT3D¬†[5] utilized a unified multi-modal transformer to conduct 3D visual grounding. Most of these methods utilize supervised training on human collected 3D data, which incur extensive annotation efforts. Recent works started to focus on the LLM-based approaches¬†[30, 33], which leverage proprietary LLM to solve the 3D visual grounding task, but introduce extensive inference costs. 3D-GRAND¬†[29] attempts to scale-up the training data for small-scale, open-source LLM training, yet it still requires extensive 3D scene layout annotation, and only achieve sub-optimal grounding performance. In this work, we explore using an open-source LLM to solve the 3D visual grounding task through our fully automatic data collection pipeline, which does not require any human expert annotations, and outperforms existing LLM-based methods on multiple 3D visual grounding benchmarks.\n\n\n\n\n3 Method\n\nWe illustrate our proposed framework in Fig.¬†2. We design an automatic 3D visual grounding data pipeline that features detailed, structured reasoning responses for LLM fine-tuning. We fine-tuned open-source LLM Llama-3.1-8B on our collected data. During test time, we utilize an object detector Mask3D to generate object proposals, which are transformed to text format and sent to the LLM along with the query. The LLM then predicts the referring target object by performing multi-stage structured reasoning.\n\n\n\n3.1 3D Scene Generation\n\nThe collection of 3D scene data requires a huge effort, including extensive human expert annotations and indoor 3D scan collection. To address this, we propose to generate synthetic 3D scene data for LLM-based model training and enable the model to conduct 3D visual grounding in real-world 3D scenes. There are many existing methods for 3D scene generation¬†[9, 31], but they mostly focus on generating scene layout with realistic object arrangements or following the specified room style from users‚Äô prompt, while our goal is to collect object-centric 3D scene that focuses on objects‚Äô spatial arrangements as well as the target object‚Äôs corresponding grounding query, which is an important component of 3D visual grounding data.\n\n\nIn this work, we design a program-based 3D scene data pipeline that can generate an object-centric 3D scene following several common spatial relationships between objects¬†(shown in Fig.¬†3-St"
  },
  {
    "title": "Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge",
    "url": "https://arxiv.org/abs/2601.08808v1",
    "source": "arxiv",
    "summary": "Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate token",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; cs &gt; arXiv:2601.08808v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Computer Science  Computation and Language\n    \n\n    \n      arXiv:2601.08808v1 (cs)\n    \n\n\n  \n    \n  [Submitted on 13 Jan 2026]\n    Title:Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge\n    Authors:Yao Tang, Li Dong, Yaru Hao, Qingxiu Dong, Furu Wei, Jiatao Gu            View a PDF of the paper titled Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge, by Yao Tang and 5 other authors\n    View PDF\n\n\n\n    \n            Abstract:Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, Multiplex Thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, Multiplex Thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at this https URL.\n    \n\n    \n    \n              \n          Comments:\n          21 pages. Code available at this https URL\n        \n\n          Subjects:\n          \n            Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\n        \n          Cite as:\n          arXiv:2601.08808 [cs.CL]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2601.08808v1 [cs.CL] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2601.08808\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite (pending registration)\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Jiatao Gu [view email]          [v1]\n        Tue, 13 Jan 2026 18:48:00 UTC (952 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge, by Yao Tang and 5 other authorsView PDFTeX Source\n \n      view license\n    \n        \n    Current browse context: cs.CL\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-01\n  \n    Change to browse by:\n    \n        cs\n        cs.AI\n        cs.LG\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n          \n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n            Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n            Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n          \n          \n            \n          \n        \n      \n\n    \n\n\n  \n    Which authors of this paper are endorsers? |\n    Disable MathJax (What is MathJax?)\n    \n  \n  mathjaxToggle();\n\n      \n    \n\n    \n      \n        \n        \n          \n            "
  },
  {
    "title": "S3-CLIP: Video Super Resolution for Person-ReID",
    "url": "https://arxiv.org/abs/2601.08807v1",
    "source": "arxiv",
    "summary": "Tracklet quality is often treated as an afterthought in most person re-identification (ReID) methods, with the majority of research presenting architectural modifications to foundational models. Such approaches neglect an important limitation, posing challenges when deploying ReID systems in real-world, difficult scenarios. In this paper, we introduce S3-CLIP, a video super-resolution-based CLIP-R",
    "full_text": null
  },
  {
    "title": "APEX-SWE",
    "url": "https://arxiv.org/abs/2601.08806v1",
    "source": "arxiv",
    "summary": "We introduce the AI Productivity Index for Software Engineering (APEX-SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX-SWE assesses two novel task types that reflect real-world software engineering work: (1) Integration tasks (n=100), which require const",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; cs &gt; arXiv:2601.08806v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Computer Science  Software Engineering\n    \n\n    \n      arXiv:2601.08806v1 (cs)\n    \n\n\n  \n    \n  [Submitted on 13 Jan 2026]\n    Title:APEX-SWE\n    Authors:Abhi Kottamasu, Akul Datta, Aakash Barthwal, Chirag Mahapatra, Ajay Arun, Adarsh Hiremath, Brendan Foody, Bertie Vidgen            View a PDF of the paper titled APEX-SWE, by Abhi Kottamasu and 7 other authors\n    View PDF\n\n\n\n    \n            Abstract:We introduce the AI Productivity Index for Software Engineering (APEX-SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX-SWE assesses two novel task types that reflect real-world software engineering work: (1) Integration tasks (n=100), which require constructing end-to-end systems across heterogeneous cloud primitives, business applications, and infrastructure-as-code services, and (2) Observability tasks (n=100), which require debugging production failures using telemetry signals such as logs and dashboards, as well as unstructured context. We evaluated eight frontier models on APEX-SWE. Gemini 3 Pro (Thinking = High) performs best, with a Pass@1 score of 25\\%. Our analysis shows that strong performance is primarily driven by epistemic reasoning, defined as the ability to distinguish between assumptions and verified facts, combined with agency to resolve uncertainty prior to acting. We open-source the APEX-SWE evaluation harness and a dev set (n=50).\n    \n\n    \n    \n      \n          Subjects:\n          \n            Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)\n        \n          Cite as:\n          arXiv:2601.08806 [cs.SE]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2601.08806v1 [cs.SE] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2601.08806\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite (pending registration)\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Bertie Vidgen Dr [view email]          [v1]\n        Tue, 13 Jan 2026 18:44:08 UTC (8,932 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled APEX-SWE, by Abhi Kottamasu and 7 other authorsView PDFTeX Source\n \n      \n          \n          view license\n        \n    \n        \n    Current browse context: cs.SE\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-01\n  \n    Change to browse by:\n    \n        cs\n        cs.AI\n        cs.CL\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n          \n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n            Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n            Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n          \n          \n            \n          \n        \n      \n\n    \n\n\n  \n    Which authors of this paper are endorsers? |\n    Disable MathJax (What is MathJax?)\n    \n  \n  mathjaxToggle();\n\n      \n    \n\n    \n      \n        \n        \n          \n            \n              \n                About\n                Help\n              \n            \n            \n              \n                \n                  contact arXivClick here to contact arXiv\n                   Contact\n                \n                \n                  subscribe to arXiv mailingsClick here"
  },
  {
    "title": "Uncovering Political Bias in Large Language Models using Parliamentary Voting Records",
    "url": "https://arxiv.org/abs/2601.08785v1",
    "source": "arxiv",
    "summary": "As large language models (LLMs) become deeply embedded in digital platforms and decision-making systems, concerns about their political biases have grown. While substantial work has examined social biases such as gender and race, systematic studies of political bias remain limited, despite their direct societal impact. This paper introduces a general methodology for constructing political bias ben",
    "full_text": null
  },
  {
    "title": "On the use of graph models to achieve individual and group fairness",
    "url": "https://arxiv.org/abs/2601.08784v1",
    "source": "arxiv",
    "summary": "Machine Learning algorithms are ubiquitous in key decision-making contexts such as justice, healthcare and finance, which has spawned a great demand for fairness in these procedures. However, the theoretical properties of such models in relation with fairness are still poorly understood, and the intuition behind the relationship between group and individual fairness is still lacking. In this paper",
    "full_text": "\n\n\n\n\n1 Introduction\n\n1.1 Contributions\n1.2 Structure\n\n\n\n2 Related work\n\n2.1 Fairness\n2.2 Sheaf models\n2.3 Network topologies\n\n\n\n3 Theoretical background\n\n3.1 Fair classification\n\n3.2 Group Fairness metrics\n\n3.2.1 Independence\n3.2.2 Separation\n3.2.3 Sufficiency\n\n\n\n3.3 Individual Fairness Metrics\n\n3.3.1 Lipschitz constant\n3.3.2 Consistency\n3.3.3 Generalized entropy\n\n\n\n3.4 Cellular sheaf theory\n\n3.4.1 Cellular sheaves\n3.4.2 Sheaf Diffusion\n\n\n\n\n\n4 Fair Sheaf Diffusion\n\n4.1 Sheaves\n\n4.2 Towards topological fairness\n\n4.2.1 Fairness induced by a graph\n4.2.2 Subset topology\n4.2.3 k-Nearest Neighbor topology\n4.2.4 Unit ball topology\n4.2.5 Combining sheaves\n\n\n\n\n\n5 Experiments\n\n5.1 Experimental setup\n5.2 Simulation study\n5.3 Effect of the hyper-parameters\n\n5.4 Case study\n\n5.4.1 The cost of fairness\n5.4.2 Results of the grid search\n5.4.3 Understanding fairness\n\n\n\n\n6 Conclusion\nA Training procedure\n\nB Extended results\n\nB.1 Simulation study\n\nB.2 Sensitivity analysis\n\nB.2.1 Effect of Œ±\\alpha, nn and tt\nB.2.2 Effect of kk and Œ¥\\delta on local topologies\nB.2.3 Effect of convex weights on mixed topologies\n\n\nB.3 The cost of fairness\nB.4 Results of the grid search\nB.5 Understanding fairness\n\n\n\n\n\n\n\nOn the use of graph models to achieve individual and group fairness\n\n\nArturo P√©rez-Peralta\n\n\nSandra Ben√≠tez-Pe√±a\n\n\nRosa E. Lillo\n\n\n\nAbstract\nMachine Learning algorithms are ubiquitous in key decision-making contexts such as justice, healthcare and finance, which has spawned a great demand for fairness in these procedures. However, the theoretical properties of such models in relation with fairness are still poorly understood, and the intuition behind the relationship between group and individual fairness is still lacking. In this paper, we provide a theoretical framework based on Sheaf Diffusion to leverage tools based on dynamical systems and homology to model fairness. Concretely, the proposed method projects input data into a bias-free space that encodes fairness constrains, resulting in fair solutions. Furthermore, we present a collection of network topologies handling different fairness metrics, leading to a unified method capable of dealing with both individual and group bias. The resulting models have a layer of interpretability in the form of closed-form expressions for their SHAP values, consolidating their place in the responsible Artificial Intelligence landscape. Finally, these intuitions are tested on a simulation study and standard fairness benchmarks, where the proposed methods achieve satisfactory results. More concretely, the paper showcases the performance of the proposed models in terms of accuracy and fairness, studying available trade-offs on the Pareto frontier, checking the effects of changing the different hyper-parameters, and delving into the interpretation of its outputs.\n\n\nkeywords: \nalgorithmic fairness , machine learning , bias mitigation , sheaf diffusion , fair topology , topological deep learning\n\n\n\n\\affiliation\n[inst2]organization=Department of Statistics. Universidad Carlos III de Madrid,country=Spain\n\\affiliation[inst3]organization=uc3m-Santander Big Data Institute. Universidad Carlos III de Madrid,country=Spain\n\n\n\n\n1 Introduction\n\nIn recent years, advances in Artificial Intelligence (AI) and Machine Learning (ML) have unleashed unprecendented improvements in automation, becoming a key tool in tasks like speech recognition (Hinton et al., 2012), computer vision (Chai et al., 2021) and recommendation (Batmaz et al., 2019). However, the use of these automated systems in critical decision-making contexts such as personnel selection (Kuncel et al., 2014) or healthcare (Park et al., 2020) raises concerns about the negative impact they might have on certain demographic groups or individuals (ProPublica, 2016), leading to a widespread demand from both a social and legal perspective for fair models aware of these issues (Birzhandi and Cho, 2023; office of the president, 2016). This is the fundamental goal of fair Machine Learning: to demonstrate that it is possible to build accurate models while mitigating harmful biases through careful data processing (Barocas et al., 2023). Significant progress has been made across multiple domains, including tabular data (He and Li, 2025), images (Yang et al., 2022), text (Zmigrod et al., 2019) and policy-making (Viviano and Bradic, 2024). This work delves into the relation between relational data and bias motivated by the recent successes found in graph-based classifiers, whose foundation lies on the relationship between combinatorial data and true reasoning (Battaglia et al., 2018), providing astonishing results in various tasks such as fraud detection (Hu et al., 2023), recommendation (He et al., 2020), and social modeling (Kumar et al., 2022).\nIn particular, this paper investigates the use of graph models in fair ML, offering a unified framework that encompasses both group and individual fairness and introducing tools with demonstrable practical effectiveness and deep theoretical implications as a consequence of the underlying object of study. In short, sheaves are algebraic geometric objects that provide a link between topology and abstract algebra, assigning algebraic objects to the open sets of a topological space. This work focuses on their application to combinatorial data in the form of cellular sheaves and Sheaf Diffusion (SD), which has led to the development of a rich theory capable of modeling complex phenomena such as opinion dynamics (Hansen and Ghrist, 2021), and provides a useful framework capable of answering certain fundamental questions about relational models linked to topics ranging from oversmothing to heterophily while achieving state-of-the-art results on common benchmarks (Bodnar et al., 2022). In light of these results, this paper defines sheaf models capable of addressing and mitigating bias, being, to our knowledge, the first study relating cellular sheaves to algorithmic prejudice.\n\n\n\n\n1.1 Contributions\n\nWe provide a unifying framework based on network topology and cellular sheaves capable of tackling both individual and group bias by codifying fairness constraints as a set of algebraic equations that determine the kernel of a linear map. Concretely, this paper defines a collection of graphs encoding fairness constraints from non-graph data, and sheaves which encourage the minimization of said metrics, both at the individual and group level. The resulting model is flexible enough to fulfill the role of pre-processor, in-processor, and post-processor, and is capable of tackling intersectional bias. The intuitions presented are backed by a series of theoretical results which we reproduce for easier availability. Furthermore, the resulting model has interesting interpretability properties in the form of closed-form SHAP values (Lundberg and Lee, 2017), thus achieving another dimension of responsible AI. Finally, we achieve notable results both in terms of bias and performance on common fairness benchmarks, consolidating the approach introduced in the work. Moreover, we perform an extensive analysis of the available trade-offs between fairness and accuracy by studying the Pareto frontiers resulting from a grid search, the effect of different hyper-parameters on the used metrics, and the difference between the SHAP values of the proposed models and the benchmark.\n\n\n\n\n\n1.2 Structure\n\nThis work is organized as follows: Section¬†2 begins with a review of related work in fairness and graph literature. This exposition is followed by Section¬†3, which presents the theoretical background, delving into the details of fair classification both at the group and individual level, and presenting the theory behind cellular sheaves and Sheaf Diffusion. Section¬†4 introduces the concrete models for Fair Sheaf Diffusion (FSD), which are built over a collection of fairness-encouraging network topologies presented in Section¬†4.2. Finally, Section¬†5 explains the experimental setup and discusses the results, and Section¬†6 recapitulates the most important ideas synthetizing our conclusions.\n\n\n\n\n\n2 Related work\n\nThis section is devoted to introducing the most significant aspects of the state of the art in three topics that will be linked in this work: fairness, sheaf models, and network topologies.\n\n\n\n2.1 Fairness\n\nBarocas et al. (2023) provide a comprehensive compilation on group fairness on tabular data, explaining the motivation, metrics, and methods behind bias mitigation. In practical terms, Kozodoi et al. (2022) compare fairness processors in the setting of credit scoring, analyzing profit-fairness trade-offs. By comparison, individual fairness is still relatively underdeveloped with debate over even the most fundamental metrics. Dwork et al. (2012) attempted a first stab at this problem by formalizing a notion of bias at the individual level through the notion of the Lipschitz condition, while Zemel et al. (2013) propose a definition based on the kk nearest neighbors. Finally, we attempt to provide a unified perspective on these matters, which is similar to Speicher et al. (2018), who propose a framework to address and quantify the individual-group bias trade-offs. \n\n\n\n\n\n2.2 Sheaf models\n\nSheaf Neural Networks were first introduced by Hansen and Gebhart (2020) and then gained a certain degree of notoriety thanks to Bodnar et al. (2022). Our approach is similar to Hansen and Gebhart (2020) in that we propose a set of hand-crafted sheaves, leaving the question on how to extend our methodology to an end-to-end framework like Bodnar et al. (2022) for future research. Related work could have applications in fairness, including non-linear sheaf diffusion (Zaghen et al., 2024), using higher-order connection Laplacians (Pfau et al., 2020), or considering sheaf models based on the wave equation (Suk et al., 2022). Finally, readers interested in more comprehensive treatments of sheaf theory are encouraged to consult Chapter 2 of Vakil (2025), while Curry (2014) provides a de"
  },
  {
    "title": "Fast and explainable clustering in the Manhattan and Tanimoto distance",
    "url": "https://arxiv.org/abs/2601.08781v1",
    "source": "arxiv",
    "summary": "The CLASSIX algorithm is a fast and explainable approach to data clustering. In its original form, this algorithm exploits the sorting of the data points by their first principal component to truncate the search for nearby data points, with nearness being defined in terms of the Euclidean distance. Here we extend CLASSIX to other distance metrics, including the Manhattan distance and the Tanimoto ",
    "full_text": null
  },
  {
    "title": "Pervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards",
    "url": "https://arxiv.org/abs/2601.08778v1",
    "source": "arxiv",
    "summary": "Researchers have proposed numerous text-to-SQL techniques to streamline data analytics and accelerate the development of database-driven applications. To compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. Since these benchmarks heavily rely on human annotations during question construction and answer evaluation, the v",
    "full_text": "\n\n\n\n1 Introduction\n\n2 EXPERIMENT DESIGN\n\n2.1 Benchmark Selection\n2.2 Toolkit for Annotation Error Detection and Correction\n2.3 Evaluation Overview\n\n\n\n3 Toolkit\n\n3.1 SAR-Agent\n3.2 SAPAR\n\n\n\n4 BIRD and Spider 2.0 Have Pervasive Annotation Errors\n\n4.1 Experimental Settings\n4.2 Three-step Examination\n4.3 Evaluation Results\n4.4 Analysis of Annotation Errors\n\n\n\n5 Annotation Errors Break the BIRD Leaderboard\n\n5.1 Data Settings\n5.2 Experimental Settings\n5.3 Evaluation Results\n5.4 Analysis of Performance Changes\n5.5 Analysis of Ranking Correlations\n\n\n\n6 SAR-Agent helps experts detect 42% more incorrect examples\n\n6.1 Experimental Settings\n6.2 Evaluation Results\n\n\n7 ablation study\n8 Related work\n9 Conclusion\n10 Acknowledgements\n\nA Appendix\n\nA.1 Example\nA.2 Configurations of Text-to-SQL Agents\nA.3 Correction Settings on the BIRD Dev Subset\nA.4 Case study\n\n\n\n\n\n\n\n\nPervasive Annotation Errors Break Text-to-SQL Benchmarks and Leaderboards\n\n\nTengjun Jin\n\nUniversity of Illinois (UIUC)UrbanaUSA\n\ntengjun2@illinois.edu\n\n, \nYoojin Choi\n\nUniversity of Illinois (UIUC)UrbanaUSA\n\nyoojinc3@illinois.edu\n\n, \nYuxuan Zhu\n\nUniversity of Illinois (UIUC)UrbanaUSA\n\nyxx404@illinois.edu\n\n and \nDaniel Kang\n\nUniversity of Illinois (UIUC)UrbanaUSA\n\nddkang@illinois.edu\n\n\n\nAbstract.\nResearchers have proposed numerous text-to-SQL techniques to streamline data analytics and accelerate the development of database-driven applications.\nTo compare these techniques and select the best one for deployment, the community depends on public benchmarks and their leaderboards. Since these benchmarks heavily rely on human annotations during question construction and answer evaluation, the validity of the annotations is crucial.\nIn this paper, we conduct an empirical study that (i) benchmarks annotation error rates for two widely used text-to-SQL benchmarks, BIRD and Spider 2.0-Snow, and (ii) corrects a subset of the BIRD development (Dev) set to measure the impact of annotation errors on text-to-SQL agent performance and leaderboard rankings.\nThrough expert analysis, we show that BIRD Mini-Dev and Spider 2.0-Snow have error rates of 52.8% and 62.8%, respectively. We re-evaluate all 16 open-source agents from the BIRD leaderboard on both the original and the corrected BIRD Dev subsets. We show that performance changes range from ‚àí7-7% to 3131% (in relative terms) and rank changes range from ‚àí9-9 to +9+9 positions. We further assess whether these impacts generalize to the full BIRD Dev set. We find that the rankings of agents on the uncorrected subset correlate strongly with those on the full Dev set (Spearman‚Äôs rsr_{s}=0.85, pp=3.26e-5), whereas they correlate weakly with those on the corrected subset (Spearman‚Äôs rsr_{s}=0.32, pp=0.23). These findings show that annotation errors can significantly distort reported performance and rankings, potentially misguiding research directions or deployment choices. Our code and data are available at https://github.com/uiuc-kang-lab/text_to_sql_benchmarks.\n\n\n\n1. Introduction\n\nAs text-to-SQL techniques become increasingly important for data analytics and database-driven applications¬†(Gao et al., 2025; Pourreza and Rafiei, 2023a; Pourreza et al., 2024, 2025; Xie et al., 2025; Gao et al., 2023, 2023; Talaei et al., 2024), researchers and practitioners have introduced a variety of text-to-SQL benchmarks¬†(Yaghmazadeh et al., 2017; Iyer et al., 2017; Price, 1990; Lee et al., 2021; Yu et al., 2019; Li et al., 2024b; Yavuz et al., 2018; Lei et al., 2024; Chen et al., 2025; Li et al., 2025c). These benchmarks guide researchers in improving text-to-SQL techniques and help practitioners select the best text-to-SQL technique for downstream applications in real-world scenarios.\n\n\nUnfortunately, current text-to-SQL benchmarks are unreliable due to annotation errors.\nAs reported in prior work, BIRD¬†(Li et al., 2024b) has annotation errors in 32% of examples in the mini development set (Mini-Dev)¬†(Arcwise, 2024) and 49% of financial domain examples¬†(Wretblad et al., 2024). Such errors can distort reported performance and rankings of agents and mislead researchers and practitioners.\n\n\nTo understand how we can build reliable text-to-SQL benchmarks with minimal annotation errors, we conduct an in-depth analysis of annotation errors in text-to-SQL benchmarks.\nWe design our analysis based on four recurring text-to-SQL annotation error patterns.\nGiven a target database ùíü\\mathcal{D}, human annotators curate text-to-SQL examples, each comprising a natural language input ùíØ\\mathcal{T} and a ground-truth SQL query ùí¨\\mathcal{Q}.111Input ùíØ\\mathcal{T} consists of a user question and, optionally, external knowledge. Annotation errors can arise within any individual component or from inconsistencies across components, including:\n\n\nE1.\n\nMismatches between the semantics of ùí¨\\mathcal{Q} and the logic of ùíØ\\mathcal{T}.\n\n\n\nE2.\n\nMismatches between the semantics of ùí¨\\mathcal{Q} and ùíü\\mathcal{D} due to a limited understanding of the data or the schema.\n\n\n\nE3.\n\nMismatches between the semantics of ùí¨\\mathcal{Q} and the domain knowledge relevant to ùíØ\\mathcal{T}, or misannotated domain knowledge in ùíØ\\mathcal{T}.\n\n\n\nE4.\n\nAmbiguity in ùíØ\\mathcal{T}, such as multiple possible interpretations or an unclear output format.\n\n\n\nFigure¬†1(a) illustrates a misuse of a Snowflake function (E1). Figure¬†1(b) presents an incorrect annotation from BIRD due to the annotator‚Äôs lack of domain knowledge (E3). We present additional representative examples for each error pattern in Section¬†4.4.\n\n\n\n\n\n\nAnnotated user question:\nCan you provide a daily weather summary for July 2019 within a 5 km radius of latitude 26.75 and longitude 51.5? ‚Ä¶\nAnnotated SQL\n‚¨á\n... ST_DWITHIN(ST_GEOGFROMWKB(\"TRI\".\"geography\"),\n\nST_POINT(26.75, 51.5), 5000) ...\n\n\nIssue: Snowflake‚Äôs ST_POINT expects (longitude, latitude). The query passes ST_POINT(26.75, 51.5), which inverts the order.\n\n(a) sf_bq291 of Spider 2.0-Snow. Annotators mistakenly swapped the longitude‚Äìlatitude order in the ST_POINT arguments (E1).\n\n\n\n\n\n\nAnnotated user question: Which state special schools have the highest number of enrollees from grades 1 through 12?\nAnnotated external knowledge: State Special Schools refers to DOC = 31; Grades 1 through 12 means K-12\nAnnotated SQL\n‚¨á\nSELECT T2.School\n\nFROM frpm AS T1 INNER JOIN schools AS T2\n\nON T1.CDSCode = T2.CDSCode WHERE T2.DOC = 31\n\nORDER BY T1.\"Enrollment‚ê£(K-12)\" DESC LIMIT 1\n\n\nIssue: ‚ÄòEnrollment (K-12)‚Äô includes kindergarten and is therefore not equivalent to enrollment for grades 1 through 12.\n\n(b) Example 46 of BIRD Mini-Dev. Annotators had limited understanding of ‚ÄúK-12‚Äù (E3).\n\n\n\nFigure 1. Two examples from existing text-to-SQL benchmarks that demonstrate incorrect annotations.\n\n\nWe conducted a human-in-the-loop, three-stage audit, with all final decisions made by human SQL experts, to benchmark annotation error rates for two widely used benchmarks, BIRD ¬†(Li et al., 2024b) and Spider 2.0-Snow¬†(Lei et al., 2024). To facilitate the audit, we developed SAR-Agent (SQL Annotation Reviewer agent), the first AI agent that assists SQL experts in detecting annotation errors in text-to-SQL benchmarks. Our three-stage audit consisted of: (1) SAR-Agent producing per-annotation diagnostic reports; (2) human SQL experts adjudicating all agent-flagged cases, verifying the stated error reasons and assigning final correctness labels; and (3) human SQL experts extending manual review to additional examples based on the recurring error patterns.\n\n\nWe manually corrected a subset of the BIRD Dev set to measure the impact of annotation errors on text-to-SQL agent performance and leaderboard rankings. To support manual corrections by SQL experts, we introduced SAPAR (SQL Annotation Pipeline with an AI Agent Reviewer), which integrated SAR-Agent into the standard text-to-SQL annotation pipeline (Li et al., 2024b). We randomly sampled 100 of the 1,534 BIRD Dev examples and, guided by SAPAR, manually corrected all identified errors. We then re-evaluated all 16 open-source text-to-SQL agents from the BIRD leaderboard on both the original and the corrected Dev subsets.\n\n\nBelow, we (i) quantify annotation error rates in BIRD Mini-Dev (an official subset of the BIRD Dev set) (Li et al., 2024b) and Spider 2.0-Snow (Lei et al., 2024), (ii) analyze their impact on agent performance and leaderboard rankings, and (iii) evaluate SAR-Agent‚Äôs error-detection capability to demonstrate its utility for improving benchmark quality.\n\n\nHigh error rates in existing text-to-SQL benchmarks.  Our analysis reveals a wider range of annotation errors in text-to-SQL benchmarks than previously recognized. We executed SAR-Agent on BIRD Mini-Dev and Spider 2.0-Snow to generate diagnostic reports for each example. After manual verification, we find that 52.8% of the examples in BIRD Mini-Dev¬†(Li et al., 2024b) contain annotation errors, which is 20.5% higher than the previously reported rate of 32.3%¬†(Arcwise, 2024). In addition, we are the first to comprehensively examine annotation errors in Spider 2.0-Snow ¬†(Lei et al., 2024), a recently released benchmark and successor to the widely used Spider 1.0 ¬†(Yu et al., 2019). The Spider 2.0 team applied large language models (LLMs) to paraphrase user questions for clarity and corrected 45% of examples in the first validation round and 5% in the second¬†(Lei et al., 2024). Nevertheless, across all 121 problems for which ground-truth SQL is publicly available, we still identify an annotation error rate of 62.8%.\n\n\nThe unreliability of the BIRD leaderboard. \nThese annotation errors cause severe misestimation and misranking of agents‚Äô performance. Through our re-evaluation of 16 agents on both the original and the corrected BIRD Dev subsets, we identify significant performance changes ranging from ‚àí7-7% to 3131% in relative terms and ranking position changes ranging from ‚àí9-9 to +9+9. For instance, we find the performance of CHESS¬†(Talaei et al., 2024), an agent previously ranked 7th among our 16 selected agents, inc"
  },
  {
    "title": "Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling",
    "url": "https://arxiv.org/abs/2601.08777v1",
    "source": "arxiv",
    "summary": "Aligning large language models (LLMs) to serve users with heterogeneous and potentially conflicting preferences is a central challenge for personalized and trustworthy AI. We formalize an ideal notion of universal alignment through test-time scaling: for each prompt, the model produces $k\\ge 1$ candidate responses and a user selects their preferred one. We introduce $(k,f(k))$-robust alignment, wh",
    "full_text": null
  },
  {
    "title": "Translating Light-Sheet Microscopy Images to Virtual H&E Using CycleGAN",
    "url": "https://arxiv.org/abs/2601.08776v1",
    "source": "arxiv",
    "summary": "Histopathology analysis relies on Hematoxylin and Eosin (H&E) staining, but fluorescence microscopy offers complementary information. Converting fluorescence images to H&E-like appearance can aid interpretation and integration with standard workflows. We present a Cycle-Consistent Adversarial Network (CycleGAN) approach for unpaired image-to-image translation from multi-channel fluorescence micros",
    "full_text": null
  },
  {
    "title": "Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs",
    "url": "https://arxiv.org/abs/2601.08773v1",
    "source": "arxiv",
    "summary": "Retrieval-Augmented Generation for software engineering often relies on vector similarity search, which captures topical similarity but can fail on multi-hop architectural reasoning such as controller to service to repository chains, interface-driven wiring, and inheritance. This paper benchmarks three retrieval pipelines on Java codebases (Shopizer, with additional runs on ThingsBoard and OpenMRS",
    "full_text": "\n\n\n\n\n1 Introduction\n\n1.1 Contributions\n1.2 Paper Organization\n\n\n\n2 Background and Preliminaries\n\n2.1 RAG for Software Engineering\n2.2 Program Structure Graphs\n2.3 Knowledge Graphs and Ontologies in Code\n\n\n3 Related Work\n\n4 Problem Formulation and Research Questions\n\n4.1 Task Definition\n4.2 Graph-Based Retrieval Formalization\n4.3 Research Questions\n\n\n\n5 System Overview\n\n5.1 Compared Pipelines\n5.2 Graph Artifacts\n\n\n\n6 Methodology\n\n6.1 Strategy A: Naive Vector Retrieval (No-Graph)\n6.2 Strategy B: LLM-Generated Knowledge Graph (LLM-KB)\n6.3 Strategy C: Deterministic AST Graph (DKB - Proposed)\n6.4 Graph-Aware Retrieval Algorithm\n\n6.5 Implementation Snippets and Instrumentation\n\n6.5.1 DKB: Deterministic ontology extraction (Tree-sitter)\n6.5.2 DKB: Bidirectional traversal + interface-consumer expansion\n6.5.3 LLM-KB: Batch extraction, truncation, and explicit skip detection\n\n\n\n\n\n7 Experimental Setup\n\n7.1 Dataset\n7.2 Task Set\n\n\n\n8 Evaluation Metrics\n\n8.1 Latency\n8.2 Correctness Labels\n8.3 Indexing Reliability and Coverage\n\n\n\n9 Results\n\n\n9.1 Quantitative Performance Benchmarks\n\nInterpreting DB build time under corpus shrinkage.\n\n\n9.2 Cost Analysis (Normalized)\n9.3 Cost Analysis on Multi-Repository Runs (OpenMRS + ThingsBoard)\n\n9.4 Indexing Reliability and Corpus Coverage\n\nEdge-count comparability.\nCross-repository reliability summary.\n\n\n9.5 Answer Correctness on Full 15-Question Suite\n\n9.6 Generalization Across Repositories\n\n9.6.1 ThingsBoard\n9.6.2 OpenMRS Core\n\n\n9.7 Correctness Summary\n9.8 Comparative Analysis\n\n\n10 Discussion\n\n11 Threats to Validity\n\n11.1 Internal Validity\n11.2 External Validity\n11.3 Construct Validity\n\n\n\n12 Reproducibility and Artifact Availability\n\n12.1 Artifacts Provided\n12.2 Target Codebase and Version Pinning\n12.3 Environment and Dependencies\n12.4 Running the Benchmarks\n12.5 Outputs, Logs, and Metric Extraction\n12.6 Reproducing Summary Tables\n12.7 Notes on Stochasticity\n\n\n13 Ethical Considerations\n14 Limitations and Future Work\n15 Conclusion\n\nA Per-question correctness tables\n\nA.1 Shopizer\nA.2 ThingsBoard\nA.3 OpenMRS Core\n\n\n\nB Prompts\n\nB.1 No-Graph (Vector-only) RAG: Answer Prompt\nB.2 DKB (Tree-sitter AST Graph RAG): Answer Prompt\nB.3 LLM-KB (LLM-Generated Graph): Index-Time Extraction Prompt\nB.4 LLM-KB (LLM-Generated Graph): Answer Prompt\n\n\n\nC Graph Schema and Edge Types (Implemented)\n\n\nC.1 DKB (Tree-sitter) Ontology Graph\n\nC.1.1 Node Types\nC.1.2 Edge Types (Relation Labels)\nC.1.3 Inheritance Extraction Rules\nC.1.4 Query-time Expansion Semantics (Bidirectional + Interface-Consumer Expansion)\nC.1.5 Context Assembly Budgeting\n\n\n\nC.2 LLM-KB (LLM-extracted) Dependency Graph\n\nC.2.1 Node Types\nC.2.2 Edge Types\nC.2.3 Indexing Completeness Signals\nC.2.4 Query-time Expansion Semantics\n\n\nC.3 Summary: Why the Schema Matters\n\n\n\n\n\n\n\nReliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs\n\n\n\nManideep Reddy Chinthareddy\nSoftware Engineer, Centerville, USA \nchmanideepreddy@gmail.com\n\n\n(January 2026)\n\nAbstract\nRetrieval-Augmented Generation (RAG) for software engineering often relies on vector similarity search, which captures topical similarity but frequently fails on multi-hop architectural reasoning (e.g., controller ‚Üí\\rightarrow service ‚Üí\\rightarrow repository chains, interface-driven wiring, and inheritance-based behavior)¬†[2, 5].\nThis paper benchmarks three retrieval pipelines on Java codebases (detailed on Shopizer; additional runs on ThingsBoard and OpenMRS Core): (A) No-Graph Naive RAG (vector-only), (B) an LLM-Generated Knowledge Graph RAG (LLM-KB), and (C) a deterministic AST-derived Knowledge Graph RAG (DKB) built via Tree-sitter parsing with bidirectional traversal¬†[20].\nUsing a fixed suite of 15 architecture and code-tracing queries per repository (The questions are same for all the 3 approaches while they differ per repository to make it relevant to the code bases), we report indexing overhead, query-time latency, corpus coverage signals, and end-to-end cost.\nAcross repositories, DKB builds its ontology graph in seconds (2.81s on Shopizer; 13.77s on ThingsBoard; 5.60s on OpenMRS Core), whereas LLM-KB requires substantially longer LLM-mediated graph generation (200.14s on Shopizer; 883.74s on ThingsBoard; 222.17s on OpenMRS Core).\nCritically, LLM-KB exhibits probabilistic indexing incompleteness: on Shopizer, the extraction log flags 377 files as SKIPPED/MISSED by LLM, yielding a per-file success rate of 0.688 (833/1210) and shrinking the embedded corpus to 3465 chunks (0.641 coverage vs. the No-Graph baseline of 5403 chunks), compared to deterministic indexing at 4873 chunks (0.902 coverage).\nThis incompleteness also reduces the extracted graph footprint: LLM-KB produces 842 nodes versus 1158 nodes for DKB (0.727 node coverage), even though all approaches scan the same discovered files; however, LLM-KB fails to produce structured records for a subset, and those files consequently do not contribute to embeddings/graph.\nWhile batching strategies, prompt tuning, and retries can reduce omissions, completeness remains mediated by stochastic model behavior and schema-bound extraction failure modes in tool-mediated indexing pipelines¬†[21, 27].\nWe also quantify end-to-end execution cost (indexing + answering the full 15-question suite) and report relative cost normalized to the No-Graph baseline.\nOn Shopizer, representative costs were $0.04 (No-Graph), $0.09 (DKB), and $0.79 (LLM-KB), corresponding to ‚àº\\sim2.25√ó\\times for DKB and ‚àº\\sim19.75√ó\\times for LLM-KB.\nOn a larger combined OpenMRS-core + ThingsBoard workload, costs increase to $0.149 (No-Graph), $0.317 (DKB), and $6.80 (LLM-KB), yielding ‚àº\\sim2.13√ó\\times for DKB and ‚àº\\sim45.64√ó\\times for LLM-KB, indicating that LLM-mediated graph construction can dominate total cost as repository scale increases.\nFor query-time latency, the No-Graph baseline remains competitive but less stable across workloads: on Shopizer it achieves 9.52¬±\\pm2.98s (mean¬±\\pmstd), compared to 10.51¬±\\pm4.17s for DKB and 13.36¬±\\pm7.87s for LLM-KB.\nOn ThingsBoard, mean latencies increase to 10.92¬±\\pm1.43s (No-Graph), 11.17¬±\\pm1.97s (DKB), and 15.29¬±\\pm4.94s (LLM-KB), while on OpenMRS Core we observe 11.82¬±\\pm2.79s (No-Graph), 12.21¬±\\pm6.96s (DKB), and 11.94¬±\\pm4.88s (LLM-KB), with LLM-KB and DKB showing higher worst-case outliers in several settings.\nWe additionally validate answer correctness on the full 15-question Shopizer suite: DKB attains the highest correctness (15/15), LLM-KB follows closely (13/15; 2 partial), while No-Graph degrades on upstream architectural queries and exhibits the highest hallucination risk (6/15). Across repositories, correctness gains are largest on suites that emphasize multi-hop architectural tracing and upstream discovery; in some suites (e.g., ThingsBoard) DKB ties the vector-only baseline while maintaining higher coverage and lower indexing overhead than LLM-mediated graph construction.\n\n\nKeywords:\nRetrieval-Augmented Generation (RAG), Static Code Analysis, Abstract Syntax Trees (AST), Knowledge Graphs, Multi-Hop Reasoning, Software Maintenance.\n\n\nNomenclature\n\n\n\n\nG=(V,E)G=(V,E)\n\n\nCode knowledge graph with nodes VV and edges EE\n\n\n\n\nqq\n\n\nNatural language query\n\n\n\n\nR‚Äã(‚ãÖ)R(\\cdot)\n\n\nVector retriever returning top-kk items\n\n\n\n\nNd‚Äã(v)N_{d}(v)\n\n\nGraph neighborhood within depth dd around node vv\n\n\n\n\nùíû‚Äã(q)\\mathcal{C}(q)\n\n\nContext assembled for query qq\n\n\n\n\nQQ\n\n\nNumber of benchmark questions (here Q=15Q=15)\n\n\n\n\nCC\n\n\nNumber of embedded text chunks\n\n\n\n\nNfilesN_{\\text{files}}\n\n\nNumber of Java files discovered during scanning\n\n\n\n\n\n\n\n\n\n1 Introduction\n\nAs Large Language Models (LLMs) transition from generic assistants to enterprise reasoning engines built on Transformer architectures¬†[1], the context window remains a primary constraint.\nRetrieval-Augmented Generation (RAG) mitigates this constraint by retrieving relevant context from a codebase prior to answer generation¬†[2, 5].\nIn software engineering settings, however, vector similarity often introduces context flattening: the retrieved chunks share lexical or semantic overlap with the query, but do not reliably preserve structural dependencies such as inheritance, dependency injection, and call relationships.\n\n\nIn complex systems, many questions are inherently multi-hop.\nFor example, answering ‚ÄúWhich controllers use the shopping cart logic¬ø‚Äò requires traversing upstream consumers from services to controllers, and frequently crossing interface boundaries.\nVector-only retrieval may retrieve the shopping-cart implementation class but omit the controllers that depend on it, producing incomplete or ungrounded answers.\nThis failure mode is consistent with known limitations of dense retrieval pipelines (e.g., DPR-style retrievers) when evidence is distributed across multiple non-local contexts¬†[3, 4].\n\n\nThis paper compares three retrieval paradigms for code analysis:\n(A) No-Graph Naive RAG (vector-only),\n(B) LLM-KB Graph RAG (LLM-generated dependency graph during indexing),\nand (C) DKB, a deterministic compiler-inspired approach that parses code via ASTs and performs bidirectional graph expansion at query time¬†[20, 9].\nOur motivation aligns with repository-level code understanding needs highlighted by recent benchmark suites and surveys¬†[14, 15, 10, 11].\n\n\n\n1.1 Contributions\n\nThis paper makes the following contributions:\n\n\n1.\n\nBenchmarking framework for graph-aware retrieval: We provide an end-to-end comparison of vector-only, LLM-extracted graph RAG, and AST-derived graph RAG under shared hyperparameters and identical question sets¬†[5, 19].\n\n\n\n2.\n\nMeasured indexing and query-time costs: We report concrete build times and latency distributions; notably, LLM-based graph construction introduces large indexing overhead compared to deterministic AST parsing¬†[6, 20].\n\n\n\n3.\n\nIndexing reliability analysis: We instrument and report coverage/consistency signals from run logs (files scanned, nodes/edges built, chunks embedded), and show that LLM-KB can skip files during extraction, shrinking both gra"
  },
  {
    "title": "AI as Entertainment",
    "url": "https://arxiv.org/abs/2601.08768v1",
    "source": "arxiv",
    "summary": "Generative AI systems are predominantly designed, evaluated, and marketed as intelligent systems which will benefit society by augmenting or automating human cognitive labor, promising to increase personal, corporate, and macroeconomic productivity. But this mainstream narrative about what AI is and what it can do is in tension with another emerging use case: entertainment. We argue that the field",
    "full_text": null
  },
  {
    "title": "Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs",
    "url": "https://arxiv.org/abs/2601.08763v1",
    "source": "arxiv",
    "summary": "Reinforcement learning (RL) has become a central paradigm for post-training large language models (LLMs), particularly for complex reasoning tasks, yet it often suffers from exploration collapse: policies prematurely concentrate on a small set of dominant reasoning patterns, improving pass@1 while limiting rollout-level diversity and gains in pass@k. We argue that this failure stems from regulariz",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; cs &gt; arXiv:2601.08763v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Computer Science  Machine Learning\n    \n\n    \n      arXiv:2601.08763v1 (cs)\n    \n\n\n  \n    \n  [Submitted on 13 Jan 2026]\n    Title:Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs\n    Authors:Zhiyuan Hu, Yucheng Wang, Yufei He, Jiaying Wu, Yilun Zhao, See-Kiong Ng, Cynthia Breazeal, Anh Tuan Luu, Hae Won Park, Bryan Hooi            View a PDF of the paper titled Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs, by Zhiyuan Hu and 9 other authors\n    View PDF\n\n\n\n    \n            Abstract:Reinforcement learning (RL) has become a central paradigm for post-training large language models (LLMs), particularly for complex reasoning tasks, yet it often suffers from exploration collapse: policies prematurely concentrate on a small set of dominant reasoning patterns, improving pass@1 while limiting rollout-level diversity and gains in pass@k. We argue that this failure stems from regularizing local token behavior rather than diversity over sets of solutions. To address this, we propose Uniqueness-Aware Reinforcement Learning, a rollout-level objective that explicitly rewards correct solutions that exhibit rare high-level strategies. Our method uses an LLM-based judge to cluster rollouts for the same problem according to their high-level solution strategies, ignoring superficial variations, and reweights policy advantages inversely with cluster size. As a result, correct but novel strategies receive higher rewards than redundant ones. Across mathematics, physics, and medical reasoning benchmarks, our approach consistently improves pass@$k$ across large sampling budgets and increases the area under the pass@$k$ curve (AUC@$K$) without sacrificing pass@1, while sustaining exploration and uncovering more diverse solution strategies at scale.\n    \n\n    \n    \n              \n          Comments:\n          Work in Progress\n        \n\n          Subjects:\n          \n            Machine Learning (cs.LG); Computation and Language (cs.CL)\n        \n          Cite as:\n          arXiv:2601.08763 [cs.LG]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2601.08763v1 [cs.LG] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2601.08763\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite (pending registration)\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Zhiyuan Hu [view email]          [v1]\n        Tue, 13 Jan 2026 17:48:43 UTC (267 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs, by Zhiyuan Hu and 9 other authorsView PDFTeX Source\n \n      \n          \n          view license\n        \n    \n        \n    Current browse context: cs.LG\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-01\n  \n    Change to browse by:\n    \n        cs\n        cs.CL\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n                    \n            \n              \n                \n                \n                IArxiv recommender toggle\n              \n            \n            \n              IArxiv Recommender\n              (What is IArxiv?)\n            \n          \n\n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n            Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n            Have an idea for a project that will add value for "
  },
  {
    "title": "Adaptive Requesting in Decentralized Edge Networks via Non-Stationary Bandits",
    "url": "https://arxiv.org/abs/2601.08760v1",
    "source": "arxiv",
    "summary": "We study a decentralized collaborative requesting problem that aims to optimize the information freshness of time-sensitive clients in edge networks consisting of multiple clients, access nodes (ANs), and servers. Clients request content through ANs acting as gateways, without observing AN states or the actions of other clients. We define the reward as the age of information reduction resulting fr",
    "full_text": null
  },
  {
    "title": "Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit",
    "url": "https://arxiv.org/abs/2601.08753v1",
    "source": "arxiv",
    "summary": "The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, the effective management of mixed fleets consisting of both electric and diesel buses poses significant operational challenges. One major challenge is coping with dynamic electricity pricing, where charging costs var",
    "full_text": null
  },
  {
    "title": "Spatial Context Improves the Integration of Text with Remote Sensing for Mapping Environmental Variables",
    "url": "https://arxiv.org/abs/2601.08750v1",
    "source": "arxiv",
    "summary": "Recent developments in natural language processing highlight text as an emerging data source for ecology. Textual resources carry unique information that can be used in complementarity with geospatial data sources, thus providing insights at the local scale into environmental conditions and properties hidden from more traditional data sources. Leveraging textual information in a spatial context pr",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Materials and Methods\n\n2.1 Preliminaries\n2.2 Text and image encoding\n2.3 Location encoding\n2.4 Multi-modal fusion with the attention-based module\n\n2.5 Dataset\n\n2.5.1 EcoWikiRS\n2.5.2 SWECO25\n\n\n2.6 Experimental setup\n\n\n\n3 Results\n\n3.1 Combining text and images in a spatial context\n3.2 Specific contribution of text and images for different types of environmental variables\n\n3.3 Ablation studies\n\n3.3.1 Integrating text\n3.3.2 Integrating location\n\n\n\n\n4 Discussion and Conclusion\n4.1 Spatial statistics of the EcoWikiRS dataset\n4.2 Additional results\n\n\n\n\n\nSpatial Context Improves the Integration of Text with Remote Sensing for Mapping Environmental Variables\n\n\nValerie Zermatten\n\n\nChiara Vanalli\n\n\nGencer Sumbul\n\n\nDiego Marcos\n\n\nDevis Tuia\n\nECEO, Ecole Polytechnique F√©d√©rale de Lausanne (EPFL), 1951 Sion, Switzerland.\n\nINRIA, University of Montpellier, Montpellier 34090, France.\n\n\n\nAbstract\n1. Recent developments in natural language processing highlight text as an emerging data source for ecology. Textual resources carry unique information that can be used in complementarity with geospatial data sources, such as remote sensing imagery, thus providing insights at the local scale into environmental conditions and properties hidden from more traditional data sources.\n2. Leveraging textual information in a spatial context presents several challenges. First, the contribution of textual data remains poorly defined in an ecological context, and it is unclear for which tasks it should be incorporated. Unlike ubiquitous satellite imagery or environmental covariates, the availability of textual data is sparse and irregular; its integration with geospatial data is not straightforward. Moreover, text descriptions, typically those about environmental conditions, can be relevant for areas of variable size, sometimes over vast regions, introducing a high variability in the size of the spatial context to be integrated.\n3. In response to these challenges, this work proposes an attention-based approach that combines aerial imagery and geolocated text within a spatial neighbourhood, i.e. integrating contributions from several nearby observations. Our approach combines vision and text representations with a geolocation encoding, allowing it to explicitly take into account the spatial structure of the original observations. The attention-based module dynamically selects spatial neighbours that are useful for predictive tasks, enabling the processing of a flexible range of inputs, with a spatial context of dynamic size.\n4. The proposed approach is applied to the EcoWikiRS dataset, which combines high-resolution aerial imagery with sentences extracted from Wikipedia describing local environmental conditions across Switzerland. Our model is evaluated on the task of predicting 103 environmental variables from the SWECO25 data cube. Our approach consistently outperforms single-location or unimodal, i.e. image-only or text-only, baselines. When analysing variables by thematic groups, results show a significant improvement in performance for climatic, edaphic, population and land use/land cover variables, underscoring the benefit of including the spatial context when combining text and image data. Overall, our findings demonstrate an advantage of injecting knowledge through text when spatially modelling environmental variables with remote sensing imagery.\n\n\nkeywords: Remote Sensing, Spatial Context, Spatial Interpolation, Switzerland, Text, Vision-Language Models, Wikipedia.\n\n\n\nFigure 1: We study how to effectively combine remote sensing images and geolocated text for predicting a variety of environmental variables with a single deep learning model. For a location of interest (x0x_{0}), we use the geolocation of species observations in crowdsourcing platforms as a way to introduce geolocated text: We combine aerial images (I0I_{0} to I3I_{3}) with text describing the species habitat extracted from its Wikipedia article (T0T_{0} to T3T_{3}) and encode them with pretrained vision and text encoders, respectively. We incorporate several spatial neighbours that are in the vicinity of the location of interest and keep the spatial organisation of the observation by encoding geolocation (x0x_{0} to x3x_{3}). We fuse all the textual and visual inputs through an attention-based fusion module that dynamically selects which neighbours are useful.\n\n\n\n\n1 Introduction\n\nRecent advances in machine learning applied to remote sensing images have enabled large-scale, cost-effective monitoring of the natural environment, supporting a variety of applications such as terrestrial plant diversity mapping (Wang and Gamon, 2019), canopy height estimation (Lang et al., 2023), species distribution modelling (Deneu et al., 2022), offshore industrial activities mapping (Paolo et al., 2024), population estimation (Metzger et al., 2022), bioclimatic variables regression (Waltari et al., 2014) or water quality monitoring (Sun et al., 2022).\n\n\nThe whole complexity of natural environments is rarely captured by a single data source. The use of heterogeneous data sources is often essential for a comprehensive understanding of ecological dynamics, with approaches that combine remote sensing with additional sources such as bioclimatic variables, in situ observations or laboratory measurements (Cavender-Bares et al., 2022; Miao et al., 2024; Liu et al., 2024; Abdelwahed et al., 2025; Zbinden et al., 2025). These heterogeneous data sources provide complementary perspectives on natural processes, each contributing unique information revealing details possibly not available in other sources. Integration of heterogeneous data sources can be challenging, particularly for those that are not available regularly, i.e. following a sparse sampling process, but recent approaches show first successes for this type of multimodal logic.\n\n\nA new promising ecological data modality is text. The integration of textual information in environmental modelling pipelines holds promises and could bring significant contributions to applications at the intersection of natural language processing and ecology (Xue and Zhu, 2025; Miao et al., 2024). Of particular interest is the possibility of injecting knowledge through text into machine learning models. Automatic methods to process text enable information retrieval and structuring that would otherwise require several time-consuming, manual pre-processing steps (Castro et al., 2024). Various textual resources have been exploited to obtain specialised knowledge for a variety of applications, such as collecting plant traits systematically from the web (Marcos et al., 2025; Domazetoski et al., 2023; Paz-Argaman et al., 2020), monitoring illegal wildlife trade from online trade platforms (Stringham et al., 2021), or quantifying temporal ecological patterns from social media posts (Hart et al., 2018; Mi≈Çodrowski et al., 2025). The emergence of Large Language Models (LLMs) has also facilitated the filtering and rephrasing of the information coming from text, enabling an easier integration into machine learning models (Hamilton et al., 2024; Wen et al., 2025; Castro et al., 2024). Given the risks of LLMs to produce hallucinations and to introduce spurious biases in modelling pipelines, the relevance and correctness of the collected text content have also been assessed in recent works (Castro et al., 2024; Miao et al., 2024; Dorm et al., 2025).\n\n\nThe integration of text with other modalities has been significantly improved with Vision-Language Models (VLMs). CLIP¬†(Radford et al., 2021), one well known VLMs, leverages the rich language semantics of image‚Äìtext pairs extracted from the web for predicting image labels in zero-shot settings, i.e. predicting an image label without being explicitly trained for it.\nCLIP-like models have been widely leveraged: On the one hand, language semantics facilitate the transferability of annotations for real-world applications by harmonising different nomenclatures. One the other hand, the use of free-form text can be used as a supervision to introduce human expertise in a flexible manner in visual recognition tasks. For instance, WildCLIP (Gabeff et al., 2024) adapts the CLIP model to retrieve scenic, behavioural, and species attributes from camera trap images with user-defined queries expressed with language. BioCLIP (Gu et al., 2025; Stevens et al., 2024) leverages the natural hierarchy between species taxonomic names to improve fine-grained species recognition. INQUIRE (Vendrow et al., 2024) introduces a challenging text-to-image retrieval benchmark with textual descriptions that reflect real-world scientific queries, encouraging the development of retrieval systems that can support ecological and biodiversity research. \n\n\n\nTo study ecological geospatial processes, texts need to be associated with a geographic location. Geotagged social media posts (H√§berle et al., 2022; Sathianarayanan et al., 2024; Yang et al., 2022), volunteered geographic information (VGI) such as OpenStreetMap (Wang et al., 2024; de Arruda et al., 2024; Fonte et al., 2018), or web content associated with geographic coordinates (Uzkent et al., 2019) are frequently used as a mean to associate a text with geographic coordinates. Alternatively, some texts can be associated with a geolocation by exploiting information explicitly present in the text (e.g. addresses, toponyms), or a relative description of the place, and also by identifying specific language features, such as dialects and idioms, to infer the location of the speaker (Derungs and Purves, 2014; Stock et al., 2022).\n\nIn ecology, a creative way to attach text to geographic coordinates is to exploit geo-tagged wildlife observations from crowd-sourcing platforms, where geolocations are paired with textual descriptions of the species (Daroya et al., 2025; Hamilton et al., 2024; Zermatten et al., 2025; Lange et al., 2025). Species descriptions, such as those coming from Wikipedia, provide va"
  },
  {
    "title": "To Retrieve or To Think? An Agentic Approach for Context Evolution",
    "url": "https://arxiv.org/abs/2601.08747v1",
    "source": "arxiv",
    "summary": "Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks.However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step. This indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise. T",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Methodology\n\n2.1 Notation and Initialization\n\n2.2 Interleaved Retrieve-Think Cycle\n\nCollective Decision-Making.\nRETRIEVE Action.\nTHINK Action.\n\n\n2.3 Context-evolved Answer Generation\n\n\n\n3 Experiments\n\n3.1 Main Results\n3.2 Impact of Iteration Depth\n\n\n4 Conclusion\n\n\n\n\n\n\nTo Retrieve or To Think? An Agentic Approach for Context Evolution\n\n\n\nRubing Chen,\n¬† Jian Wang,\n¬† Wenjie Li,\n¬† Xiao-Yong Wei,\n¬† Qing Li\nDepartment of Computing, The Hong Kong Polytechnic University \nrubing.chen@connect.polyu.hk ¬† jian51.wang@polyu.edu.hk\ncswjli@comp.polyu.edu.hk ¬† {cs007.wei,qing-prof.li}@polyu.edu.hk\nCorresponding author.\n\n\nAbstract\nCurrent context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks.\nHowever, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step.\nThis indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise.\nTo address these limitations, we introduce Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge.\nACE employs a central orchestrator agent to make decisions strategically via majority voting.\nIt aims to alternate between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement.\nBy eliminating redundant retrieval steps, ACE maintains a concise and evolved context.\nExtensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption.\nOur work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.\n\n\n\nTo Retrieve or To Think? An Agentic Approach for Context Evolution\n\n\n\n\n\nRubing Chen,\n¬† Jian Wang,\n¬† Wenjie Li,\n¬† Xiao-Yong Wei‚Ä†‚Ä†thanks: Corresponding author.,\n¬† Qing Li\n\nDepartment of Computing, The Hong Kong Polytechnic University\n\nrubing.chen@connect.polyu.hk ¬† jian51.wang@polyu.edu.hk\n\ncswjli@comp.polyu.edu.hk ¬† {cs007.wei,qing-prof.li}@polyu.edu.hk\n\n\n\n\n\n\n1 Introduction\n\nLarge language models (LLMs) have demonstrated remarkable capabilities by conditioning generation on specific contexts, which blend user queries with auxiliary information such as instructions, few-shot demonstrations, or retrieved documents.\nConsequently, recent paradigms, including retrieval-augmented generation (RAG)¬†Lewis et al. (2020), in-context learning (ICL)¬†Song et al. (2023), and chain-of-thought (CoT) reasoning¬†Wei et al. (2022), can be viewed through a unified lens: context augmentation and refinement.\nFrom this perspective, the efficacy of an LLM-based system hinges not merely on the volume of available context, but critically on how this information is curated, synthesized, and evolved throughout the solution generation process, particularly in knowledge-intensive tasks.\n\n\nAs a dominant strategy, conventional context augmented-generation approaches enhance LLMs via a single-step retrieval.\nHowever, this ‚Äúretrieve-then-generate‚Äù paradigm often fails in complex, multi-hop scenarios where the information need is non-evident at the outset.\nTo bridge this gap, iterative context-augmented generation methods¬†Thompson et al. (2025); Verma et al. (2024) have been proposed to perform retrieval and generation across multiple steps.\nDespite their improvements, these approaches often fall into the trap of blind accumulation, where they rigidly execute retrieval at every step¬†Trivedi et al. (2022); Shao et al. (2023); Yue et al. (2024).\nSuch indiscriminate expansion leads to ‚Äúcontextual saturation,‚Äù where irrelevant noise and redundant snippets distract the model, increase inference latency, and ultimately result in reasoning hallucinations.\n\n\nTo address these limitations, we draw inspiration from metacognition in human problem-solving¬†Simon (1983); Ackerman and Thompson (2017).\nHumans do not gather information in a vacuum; they dynamically evaluate their own internal knowledge gaps.\nThey alternate between seeking external evidence and pausing to think, synthesizing existing clues to decide whether further searching is even necessary.\nThis suggests that a robust LLM system should adopt context evolution, treating context augmentation and refinement as a sequence of deliberate strategic decisions rather than a rigid, pre-defined schedule.\n\n\nMotivated by this principle, we propose Agentic Context Evolution (ACE), a multi-agent framework that transforms context management from a static pipeline into an autonomous, state-aware process.\nACE employs a central orchestrator agent to manage the context‚Äôs life cycle by strategically selecting between two specialized actions:\n(i) RETRIEVE: Activating a retriever agent to bridge specific knowledge gaps only when the current context is insufficient;\n(ii) THINK: Activating a reasoner agent to distill internal insights and refine the context window, preventing information bloat.\nThrough this interleaved ‚ÄúRetrieve-or-Think‚Äù loop, ACE ensures that the context evolves in both depth and relevance, rather than just growing in size.\nThis avoids the pitfalls of noise accumulation from over-retrieval or hallucinations from under-reasoning.\n\n\nOur main contributions are as follows:\n\n\n‚Ä¢\n\nWe introduce the concept of context evolution, moving beyond brute-force retrieval toward a metacognitive, decision-based strategy for context augmentation and refinement.\n\n\n\n‚Ä¢\n\nWe propose Agentic Context Evolution (ACE), a multi-agent framework that dynamically balances external knowledge acquisition with internal reasoning, maintaining a compact yet high-utility context.\n\n\n\n‚Ä¢\n\nExperiments on multi-hop QA benchmarks show that ACE significantly outperforms state-of-the-art baseline methods in accuracy while achieving a significant reduction in token costs by bypassing redundant retrieval calls.\n\n\n\n\n\n\n\n2 Methodology\n\n\n\n\n\n\nMultiHop-RAG\nHotpotQA\n2WikiQA\n\n\nMethod\nAcc. (%)\nAvg. Tokens\nAcc. (%)\nAvg. Tokens\nAcc. (%)\nAvg. Tokens\n\n\nVanilla\n36.1\n333\n25.7\n194\n28.2\n155\n\n\nRAG\n49.2\n1,127\n38.9\n723\n28.8\n639\n\n\nIterDRAG\n47.0\n18,196\n38.9\n723\n27.2\n9,760\n\n\nACE (Ours)\n57.9\n10,653\n62.8\n3,271\n47.9\n2,945\n\n\n\n\nTable 1: Main results across three challenging multi-hop QA datasets. We report accuracy (Acc.) and average token consumption (Avg. Tokens). The best accuracy scores are highlighted in bold.\n\n\nIn this section, we present the Agentic Context Evolution (ACE) framework, with an overview provided in Figure¬†1.\nUnlike static RAG pipelines that follow a fixed retrieve-then-generate sequence, ACE adopts a dynamic, multi-agent paradigm.\nAt each reasoning step, a committee of agents decides whether to retrieve new information from an external knowledge base or to deepen reasoning over the current context by generating a sub-query.\nThis iterative process enables ACE to adaptively balance knowledge acquisition and internal reasoning, progressively constructing a richer, focused context from which to derive the final answer.\n\n\nFigure 1: Overview of the proposed Agentic Context Evolution (ACE) framework. In each of the NN iterative rounds, multiple agents vote to either retrieve external context or think by generating a sub-query. The selected action updates a shared context, which is then used in subsequent rounds and for final answer generation.\n\n\n\n2.1 Notation and Initialization\n\nThe state of the ACE process at the beginning of the ii-th round can be formulated as a tuple given by:\n\n\n\nùíÆi=(‚Ñ≥i,Q,ùíú,ùí™,ùí¶)\\mathcal{S}_{i}=(\\mathcal{M}_{i},Q,\\mathcal{A},\\mathcal{O},\\mathcal{K})\n\n(1)\n\n\nwhere each element is defined as follows:\n\n\n‚Ä¢\n\n‚Ñ≥i\\mathcal{M}_{i} is the working memory, a set containing the accumulated contexts and thoughts from previous rounds.\n\n\n\n‚Ä¢\n\nQQ is the initial user query.\n\n\n\n‚Ä¢\n\nùíú={a1,a2,‚Ä¶,ak}\\mathcal{A}=\\{a_{1},a_{2},\\dots,a_{k}\\} is the set of kk agents.\n\n\n\n‚Ä¢\n\nùí™={RETRIEVE,THINK}\\mathcal{O}=\\{\\texttt{RETRIEVE},\\texttt{THINK}\\} is the set of candidate actions.\n\n\n\n‚Ä¢\n\nùí¶\\mathcal{K} is the external document corpus, serving as the knowledge source for retrieval.\n\n\n\nThe process iterates for a total of NN rounds.\n\n\nTo begin the process, we initialize the working memory ‚Ñ≥0\\mathcal{M}_{0} with the user‚Äôs query. This ensures that the agents‚Äô first decision is based on the initial question, given by:\n\n\n\n‚Ñ≥0={Q}.\\mathcal{M}_{0}=\\{Q\\}.\n\n(2)\n\n\n\n\n\n\n2.2 Interleaved Retrieve-Think Cycle\n\nAt each round, the ACE framework executes a decision-action cycle. This cycle consists of two main phases: collective decision-making and action execution.\n\n\nCollective Decision-Making.\n\nGiven the current working memory ‚Ñ≥i\\mathcal{M}_{i} and the initial query QQ, each agent aj‚ààùíúa_{j}\\in\\mathcal{A} independently decides on the optimal next action. This decision function, fdecidef_{\\text{decide}}, for a single agent is:\n\n\n\nfd:(‚Ñ≥i,Q)‚Ü¶oj‚ààùí™f_{\\text{d}}:(\\mathcal{M}_{i},Q)\\mapsto o_{j}\\in\\mathcal{O}\n\n(3)\n\n\nwhere ojo_{j} is the vote of agent aja_{j}.\nThe formulated prompt template for fdf_{\\text{d}} is given below:\n\n\n\n\nfd‚Äã(‚Ñ≥i,Q)f_{\\text{d}}(\\mathcal{M}_{i},Q): You are an expert question-answering system. Based on the original question {QQ}, the current context, and the sub-queries {‚Ñ≥i\\mathcal{M}_{i}}, decide whether to: (1) THINK: continue asking one sub-query which is needed to answer the question; (2) RETRIEVE: retrieve more external documents from the context to gain more information.\n\n\n\nThe collective decision for the round, oi‚àóo_{i}^{*}, is determined by a majority voting among all agents:\n\n\n\noi‚àó=MajorVote‚Äã({fd‚Äã(‚Ñ≥i,Q)‚Äã¬†for each¬†‚Äãaj‚ààùíú}).o_{i}^{*}=\\text{MajorVote}(\\{f_{\\text{d}}(\\mathcal{M}_{i},Q)\\text{ for each }a_{j}\\in\\mathcal{A}\\}).\n\n(4)\n\n\nOnce the collective decision oi‚àóo_{i}^{*} is made, the framework executes the chosen action.\n\n\n\n\nRETRIEVE Action.\n\nIf oi‚àó=Ro_{i}^{*}=\\text{R}, the system executes a retrieval function, fRf_{\\text{R}}, to fetch re"
  },
  {
    "title": "TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL",
    "url": "https://arxiv.org/abs/2601.08743v1",
    "source": "arxiv",
    "summary": "In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. While user queries typically focus on recurrent table sets-offering an opportunity for KV cache sharing across queries-current inference engines, such as SGLang and vLLM, generate redundant prefix cache copies when processing user q",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related Work\n\n2.1 KV Cache Management\n2.2 Text-to-SQL\n\n\n3 Problem Setup\n\n4 Method\n\n\n4.1 Offline KV Cache Precomputation\n\n4.1.1 Primary Foreign Key Guided Table Representation.\n4.1.2 Table Trie Construction\n\n\n\n4.2 Table KV Cache Management\n\n4.2.1 Query Reranking\n4.2.2 Computation Loading Pipeline\n\n\n\n\n\n5 Experiments\n\n5.1 Experiment Setup\n5.2 Implementation Details\n5.3 Main Results\n5.4 Ablation Study\n\n\n\n6 Discussion\n\n6.1 Why TableCache Works?\n6.2 Practical Feasibility\n6.3 System Time Complexity\n\n\n7 Conclusion\n8 Limitations\nA Cache Manager Details\nB Training Details\nC Prompt Template\nD Case Study\n\nE Time Complexity Analysis\n\nE.1 Primary Foreign Key Guided Table Representation.\nE.2 Table Trie Construction\nE.3 Query Reranking\nE.4 Overall Inference Time\n\n\n\n\n\n\n\nTableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL\n\n\nJinbo Su\n\nSchool of Information, Renmin University of China,Beijing, China\n\nKey Laboratory of Data Engineering and Knowledge Engineering, Beijing, China\n\n\nYuxuan Hu\n\nSchool of Information, Renmin University of China,Beijing, China\n\nKey Laboratory of Data Engineering and Knowledge Engineering, Beijing, China\n\n\nCuiping Li\n\nSchool of Information, Renmin University of China,Beijing, China\n\nEngineering Research Center of Database and Business Intelligence, Beijing, China\n\n\nHong Chen\n\nSchool of Information, Renmin University of China,Beijing, China\n\nEngineering Research Center of Database and Business Intelligence, Beijing, China\n\n\nJia Li\n\nAnt Group, Hangzhou, China\n\n\nLintao Ma\n\nAnt Group, Hangzhou, China\n\n\n\nJing Zhang\nCorresponding author\nSchool of Information, Renmin University of China,Beijing, China\n\nKey Laboratory of Data Engineering and Knowledge Engineering, Beijing, China\n\n\n\nAbstract\nIn Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. While user queries typically focus on recurrent table sets‚Äîoffering an opportunity for KV cache sharing across queries‚Äîcurrent inference engines, such as SGLang and vLLM, generate redundant prefix cache copies when processing user queries with varying table orders.\nTo address this inefficiency, we propose precomputing table representations as KV caches offline and querying the required ones online. A key aspect of our approach is the computation of table caches while preserving primary foreign key relationships between tables. Additionally, we construct a Table Trie structure to facilitate efficient KV cache lookups during inference.\nTo enhance cache performance, we introduce a cache management system with a query reranking strategy to improve cache hit rates and a computation loading pipeline for parallelizing model inference and cache loading.\nExperimental results show that our proposed TableCache achieves up to a 3.62√ó speedup in Time to First Token (TTFT) with negligible performance degradation.\n\n\n\nTableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL\n\n\n\n\n\n1 Introduction\n\nThe Text-to-SQL task endeavors to translate natural language (NL) queries into precise structured query language (SQL) statements, enabling efficient database execution. By providing a natural language interface, it empowers non-technical users to interact with databases effortlessly, unlocking seamless access to targeted data. Recently, this task has garnered growing interest from both the NLP and database research communities.\n\n\nModern Text-to-SQL approaches primarily utilize LLM-based multi-agent systems, where agents process user queries and database schemas (i.e., table metadata) as input, coordinating a series of complex steps to generate the desired SQL statement.\nAlthough current LLM-based agents achieve state-of-the-art performance on various benchmarks, they face significant deployment challenges. A major bottleneck arises from embedding extensive table metadata into prompts, leading to longer sequences and substantially increased prefill latency.\n\n\nFigure 1: An example of TableCache\n\n\nTo address the high latency commonly associated with LLM inference, advanced inference engines like SGLang¬†(Zheng et¬†al., 2023) and vLLM¬†(Kwon et¬†al., 2023) have become essential tools for improving inference efficiency. These systems enhance LLM deployment mainly through efficient KV cache management and have shown strong performance across a variety of tasks. A key mechanism they rely on is the use of structures such as RadixCache or PrefixCache, which organize previously computed KV cache to enable reuse‚Äîthough this requires exact prefix matches. However, as shown in Figure¬†1, the dynamic ordering of tables in user queries often leads to prefix matching failures, compelling the system to produce multiple independent KV cache paths and thereby reducing cache efficiency. Another limitation is that this strategy does not fully leverage distinctive attributes of Text-to-SQL workloads: while the static structure of database schemas allows for table-level KV cache reuse, query trends often generate localized data hotspots. Together, these characteristics highlight the potential to accelerate the LLM prefill phase by exploiting shared table information.\n\n\nBased on these observations, we propose TableCache, a method to accelerate LLM inference for Text-to-SQL tasks by precomputing KV caches for tables offline. Specifically, we proactively identify all tables in the database schemas that users may query, represent these tables as KV cache values offline, and store the results in CPU memory. The core idea is to represent tables while preserving primary foreign key relationships, preventing performance degradation caused by the loss of cross-attention when encoding tables individually. To achieve this, we construct a primary foreign key graph from the database, apply topological sorting to determine the sequence of tables, and use causal attention based encoding with LLMs to represent the tables. This approach restores essential relationships between tables, maintaining both efficiency and system performance.\n\n\nTo streamline the online query process, all tables are organized into a trie structure, referred to as the Table Trie. When a user query arrives, the system iteratively matches table positions within the Table Trie. Upon finding an exact match for a table, the corresponding KV cache is loaded from CPU memory to GPU memory. The offline KV caches are then concatenated and passed to the LLM for SQL generation.\n\n\nTo further optimize cache performance, we introduce a cache management system that implements CPU-GPU cache eviction and loading policies, such as FIFO and LRU. More importantly, we propose two strategies to enhance system efficiency: (1) a query reranking strategy that improves cache hit rates by leveraging user query similarities, and (2) a computation loading pipeline that parallelizes model inference with cache loading by asynchronously transferring the KV cache required for subsequent user queries from CPU to GPU during the computation of the current query.\n\n\nIn summary, the contributions of this paper are delineated as follows:\n\n\n\n\n‚Ä¢\n\nWe propose TableCache, a method that recomputes KV caches for tables while preserving primary foreign key relationships and builds a Table Trie for efficient table matching, ensuring high performance and efficiency for Text-to-SQL LLMs.\n\n\n\n‚Ä¢\n\nWe enhance cache performance with a query reranking strategy to improve hit rates and a computation loading pipeline to parallelize model inference and cache loading.\n\n\n\n‚Ä¢\n\nExperimental results demonstrate that our proposed TableCache achieves a speedup of up to 3.62√ó\\times in TTFT while maintaining the original model‚Äôs performance.\n\n\n\n\n\n\n\n2 Related Work\n\n\n2.1 KV Cache Management\n\nOn the system side, KV cache optimization focuses on memory management and scheduling. Both vLLM and SGLang employ PrefixCache to reuse shared prefixes across sequences.\n\n\nFor retrieval-augmented generation(RAG) scenarios, methods like PromptCache¬†(Gim et¬†al., 2023), TurboRAG¬†(Lu et¬†al., 2024), and BlockAttention¬†(Ma et¬†al., 2024) utilize block-based pre-encoding but neglect inter-block attention relationships, causing performance degradation. In response, CacheBlend¬†(Yao et¬†al., 2024), KVLink¬†(Yang et¬†al., 2025), KVZip¬†(Kim et¬†al., 2025), and EPIC¬†(Hu et¬†al., 2024) introduce selective recomputation for more accurate cache reuse. Unlike RAG, Text-to-SQL provides explicit attention reconstruction guidance through primary foreign key, inspiring our primary foreign key guided attention reconstruction mechanism.\n\n\nOn the algorithmic side, research focuses on eliminating redundant or less useful KV cache entries to improve efficiency. Methods such as H2O¬†(Zhang et¬†al., 2023), QUEST¬†(Tang et¬†al., 2024), Ada-KV¬†(Feng et¬†al., 2024), snapKV¬†(Li et¬†al., 2024b), and PyramidKV¬†(Cai et¬†al., 2024) have designed various KV cache eviction and compensation schemes to accelerate inference. In contrast to them, our TableCache preserves all KV caches to suit the high-reuse setting of Text-to-SQL.\n\n\nFigure 2: Overview of TableCache. KV caches are precomputed and organized into a hierarchical Table Trie during offline preprocessing. Inference utilizes cache management system, including query reranking for cache-friendly sequencing and a computation loading pipeline to reduce latency and improve efficiency.\n\n\n\n\n2.2 Text-to-SQL\n\nMainstream LLM-based approaches for Text-to-SQL fall into two paradigms: prompt engineering and supervised fine-tuning (SFT).\nPrompt engineering methods often leverage few-shot prompting strategies¬†(Cheng et¬†al., 2023; Nan et¬†al., 2023). Examples include DIN-SQL(Pourreza and Rafiei, 2023) and CHESS(Talaei et¬†al., 2024), which decompose the task into subtasks like Schema Linking and SQL Generation with a self-correction mechanism.\nIn contrast, SFT-based approaches¬†(Gao et¬†al., 2024b; Pourreza and Rafiei, 2024), such as CODES¬†(Li et¬†al., 2024a), DA"
  },
  {
    "title": "Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents",
    "url": "https://arxiv.org/abs/2601.08742v1",
    "source": "arxiv",
    "summary": "Attributional inference, the ability to predict latent intentions behind observed actions, is a critical yet underexplored capability for large language models (LLMs) operating in multi-agent environments. Traditional natural language inference (NLI), in fact, fails to capture the nuanced, intention-driven reasoning essential for complex interactive systems. To address this gap, we introduce Attri",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Attributional Natural Language Inference\n\n\n2.1 Attributional Inference as an Abductive-Deductive Process\n\nStage 1: Intention Selection (Abduction).\nStage 2: Conclusion Inference (Deduction).\nExample.\n\n\n2.2 Definition of Attributional NLI\n\n\n\n3 Undercover-V: Evaluating Att-NLI via Textual Games\n\n\n3.1 Agent Types\n\n\n3.1.1 Standard NLI Agent\n\nDescription Phase.\nVoting Phase.\n\n\n\n3.1.2 Standard Att-NLI Agent\n\nDescription Phase.\nVoting Phase.\n\n\n\n3.1.3 Neuro-Symbolic Att-NLI Agent\n\nDescription Phase.\nVoting Phase.\n\n\n\n\n\n\n\n4 Empirical Evaluation\n\n\n4.1 Metrics\n\nAttributional Score.\n(i) Attributional Soundness\n(ii) Attributional Alignment\n\n\n\n4.2 Fixed LLM Opponent Contest\n\nLLMs exhibit various NLI and Att-NLI ability.\nAtt-NLI ability is critical in Undercover-V performance.\n\n\n\n4.3 Round-Robin Tournament\n\nAtt-NLI players infer others‚Äô intentions and produce more sound and valid inferences than standard NLI players.\nNeuro-symbolic approach further enhances the Att-NLI ability.\nFeedback from external TP and refinement in the guess word significantly advances the Att-NLI ability.\n\n\n\n\n\n5 Related Work\n\nNeuro-symbolic Reasoning.\nMulti-agent LLM Social Deduction Games.\n\n\n6 Conclusion\nA Undercover-V Game Rules\n\nB Implementation of External Theorem Prover in Neuro-Symbolic Player\n\n\nB.1 Mechanism of integrating external theorem prover for verification and refinement\n\nB.1.1 Verification\nB.1.2 Refinement\n\n\nB.2 Constructing the Knowledge Base\nB.3 Autoformalization\nB.4 Verification\nB.5 Scalability of the theorem prover\n\n\n\nC Formalization and Proof of Testability in Undercover-V\n\n\nD Metrics\n\n\nE On the impact of Word Selection\n\n\nF Case Study\n\n\nG Model implementation details\n\n\nH Prompt\n\nH.1 System Prompt\n\nH.2 Naive Player‚Äôs Prompts\n\nH.2.1 Naive Player Description Prompt\nH.2.2 Naive Player Voting Prompt\n\n\n\nH.3 Standard Att-NLI Player‚Äôs Prompts\n\nH.3.1 Standard Att-NLI Player Description Prompt\nH.3.2 Standard Att-NLI Player Voting Prompt\n\n\n\nH.4 Neuro-Symbolic Player\n\nH.4.1 Generating Rules\nH.4.2 Guessing Words\nH.4.3 Neuro-Symbolic Player Description Prompt\nH.4.4 Neuro-Symbolic Player Voting Prompt\nH.4.5 Neuro-Symbolic Player Updating Guess Words Prompt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInferring Latent Intentions:\nAttributional Natural Language Inference in LLM Agents\n\n\nXin Quan1, Jiafeng Xiong111footnotemark: 1, Marco Valentino2, Andr√© Freitas1,3,4\n1Department of Computer Science, University of Manchester, UK \n2School of Computer Science, University of Sheffield, UK \n3Idiap Research Institute, Switzerland \n4National Biomarker Centre, CRUK-MI, University of Manchester, UK\nxin.quan@manchester.ac.uk‚ÄÉjiafeng.xiong@manchester.ac.uk\nm.valentino@sheffield.ac.uk‚ÄÉandre.freitas@idiap.ch\nEqual contribution. They jointly implemented the player-type design; Xin Quan designed and implemented the neuro-symbolic component, while Jiafeng Xiong designed and implemented the game framework and evaluation metrics.\n\n\nAbstract\nAttributional inference, the ability to predict latent intentions behind observed actions, is a critical yet underexplored capability for large language models (LLMs) operating in multi-agent environments. Traditional natural language inference (NLI), in fact, fails to capture the nuanced, intention-driven reasoning essential for complex interactive systems.\nTo address this gap, we introduce Attributional NLI (Att-NLI), a framework that extends NLI with principles from social psychology to assess an agent‚Äôs capacity for abductive intentional inference (generating hypotheses about latent intentions), and subsequent deductive verification (drawing valid logical conclusions).\nWe instantiate Att-NLI via a textual game, Undercover-V, experimenting with three types of LLM agents with varying reasoning capabilities and access to external tools: a standard NLI agent using only deductive inference, an Att-NLI agent employing abductive-deductive inference, and a neuro-symbolic Att-NLI agent performing abductive-deductive inference with external theorem provers.\nExtensive experiments demonstrate a clear hierarchy of attributional inference capabilities, with neuro-symbolic agents consistently outperforming others, achieving an average win rate of 17.08%. Our results underscore the role that Att-NLI can play in developing agents with sophisticated reasoning capabilities, highlighting, at the same time, the potential impact of neuro-symbolic AI in building rational LLM agents acting in multi-agent environments.\n\n\n\nInferring Latent Intentions:\nAttributional Natural Language Inference in LLM Agents\n\n\n\n\nXin Quan1‚Ä†‚Ä†thanks: Equal contribution. They jointly implemented the player-type design; Xin Quan designed and implemented the neuro-symbolic component, while Jiafeng Xiong designed and implemented the game framework and evaluation metrics., Jiafeng Xiong111footnotemark: 1, Marco Valentino2, Andr√© Freitas1,3,4\n\n1Department of Computer Science, University of Manchester, UK\n\n2School of Computer Science, University of Sheffield, UK\n\n3Idiap Research Institute, Switzerland\n\n4National Biomarker Centre, CRUK-MI, University of Manchester, UK\n\nxin.quan@manchester.ac.uk‚ÄÉjiafeng.xiong@manchester.ac.uk\n\nm.valentino@sheffield.ac.uk‚ÄÉandre.freitas@idiap.ch\n\n\n\n\n\nFigure 1: Multi-agent LLM interactions often require inferring latent intentions beyond surface-level propositions, exposing a gap in traditional NLI evaluation. We propose Attributional NLI, a two-stage abductive-deductive framework grounded in attribution theory, consisting of intention selection followed by conclusion verification. We operationalise Att-NLI with Undercover-V, a verifiable social-deduction game that makes latent-intent attribution empirically testable.\n\n\n\n1 Introduction\n\nNatural Language Inference (NLI), determining whether a hypothesis is entailed, contradicted, or neutral given a premise, is a standard benchmark for evaluating textual reasoning in language models¬†(Bowman et al., 2015; Camburu et al., 2018). A key aspect of NLI is constructing logically coherent arguments from factual premises to support a hypothesis¬†(Jansen et al., 2018; Thayaparan et al., 2021; Bostrom et al., 2022; Weir et al., 2023). Recent work explores improving reasoning control in large language models (LLMs) for NLI¬†(Chen et al., 2021; Valentino et al., 2022; Quan et al., 2024a, 2025b, 2025a), focusing on eliciting factual, logical, or semantic consistency to enhance explicit inference.\n\n\nHowever, traditional NLI is fundamentally limited to single-agent, purely textual reasoning and overlooks the critical role of latent intentions in multi-agent settings. Many real-world scenarios, such as online debates, collaborative reasoning, or social deductive games, inherently require an understanding of underlying motivations beyond surface-level propositions¬†(Wang et al., 2019; Chen et al., 2024; Serrino et al., 2019). While some studies have explored LLMs capabilities in multi-agent settings via social deductive games¬†(Tanaka et al., 2024; Costarelli et al., 2024; Wang et al., 2023), they primarily focus on game metrics, overlooking the underlying NLI capabilities. Similarly, other multi-agent studies¬†(Dong et al., 2024) rely on explicit belief modeling rather than logic-based reasoning. Furthermore, existing NLI-based and multi-hop reasoning methods, like Chain-of-Thought or hybrid approaches¬†(Hu et al., 2025; Wei et al., 2023; Madaan et al., 2023), tend to address explicit logical reasoning but lack quantitative metrics for evaluating intention-aware capabilities in multi-agent dialogues¬†(Sileo et al., 2022).\n\n\nAttributional inference principles in social psychology describe the process of interpreting intentions through a two-stage process composed of intuitive inference and subsequent criticism¬†(Lieberman et al., 2005; Bargh, 1989).\nInspired by these principles, we propose attributional NLI (Att-NLI), a framework that extends standard NLI by incorporating a two-stage reasoning process in a multi-agent setting (example in Fig.¬†1): (1) an initial abductive stage required to infer the latent intention of other agents, and (2) a subsequent deductive stage to draw logical conclusions based on the intentions. This abductive-deductive framework allows assessing LLMs‚Äô reasoning and their applicability to complex, interactive multi-agent systems.\n\n\nTo empirically evaluate Att-NLI and assess the attributional inference capabilities of LLM agents, we first introduce three types of LLM agents, namely NLI, Att-NLI, and Neuro-Symbolic Att-NLI, each endowed with distinct reasoning capabilities and access to external tools. We then empirically assess these agents using a representative deductive‚Äìabductive textual game, Undercover-V, which is specifically designed to be empirically testable for Att-NLI, together with a novel metric, the Attributional Score, which quantitatively evaluates Att-NLI proficiency and augments standard game performance metrics.\n\n\nUndercover-V provides a setting where agents must infer others‚Äô roles (intentions) based on their actions (premises). The standard NLI agent performs only conventional deductive textual inference without considering intentions. The Standard Att-NLI agent extends this with an abductive-deductive pipeline, first inferring each agent‚Äôs intention and then revising its judgment. The Neuro-Symbolic Att-NLI agent further enhances this process with an external theorem prover, ensuring logically sound inference and external-feedback-guided refinement for deductive reasoning. We use standard game metrics (win rate, elimination rate) to provide a holistic view of reasoning capacity, while the new Attributional Score, measuring soundness and alignment, quantifies the Att-NLI performance across different LLM agents.\n\n\nExtensive evaluations using four widely adopted LLMs (GPT-4o-mini, GPT-4o, Mixtral-8x22B, and Mistral-Medium) led to the following conclusions:\n(1) We introduce Attributional NLI (Att-NLI), a mechanism that enables LLM agents to infer latent intentions via abductive-deductive reaso"
  },
  {
    "title": "From Rows to Reasoning: A Retrieval-Augmented Multimodal Framework for Spreadsheet Understanding",
    "url": "https://arxiv.org/abs/2601.08741v1",
    "source": "arxiv",
    "summary": "Large Language Models (LLMs) struggle to reason over large-scale enterprise spreadsheets containing thousands of numeric rows, multiple linked sheets, and embedded visual content such as charts and receipts. Prior state-of-the-art spreadsheet reasoning approaches typically rely on single-sheet compression or full-context encoding, which limits scalability and fails to reflect how real users intera",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related Work\n\n2.1 LLMs for Tables and Spreadsheets\n2.2 Long Context, Retrieval, and Hybrid Search\n2.3 Multimodal Spreadsheet Understanding and Document VQA\n2.4 Benchmarks for Spreadsheet Interaction\n\n\n\n3 Framework Overview\n\n3.1 Motivation and Design Goals\n3.2 Architecture Overview\n3.3 Retrieval and Fusion Layer\n3.4 Multimodal Embedding Layer\n3.5 Reasoning and Output Generation\n\n\n\n4 FRTR-Bench: Benchmark for Spreadsheet Reasoning\n\n4.1 Dataset Construction\n4.2 Evaluation Protocol\n4.3 Benchmark Statistics and Examples\n\n\n\n5 Evaluation\n\nMetrics.\nLLMs.\n\n5.1 Experiment 1 - FRTR-Bench Evaluation\n\n5.1.1 Goal\n5.1.2 Experimental Setup\n5.1.3 Results Analysis\n5.1.4 Discussion\n\n\n\n5.2 Experiment 2 - SpreadsheetLLM Benchmark Evaluation\n\n5.2.1 Goal\n\n5.2.2 Experimental Settings\n\nDataset.\nBaselines.\n\n\n5.2.3 Results\n5.2.4 Results Analysis\n5.2.5 Discussion\n\n\n\n\n6 Conclusion\n\nAppendix¬†A Experiment 1 - FRTR-Bench Evaluation\n\nAppendix¬†B Token Usage Visualization\n\n\nAppendix¬†C Prompt Template: explain_prompt\n\n\n\n\n11institutetext: Commercial Technology and Innovation Office, PricewaterhouseCoopers, U.S.\nFrom Rows to Reasoning: A Retrieval-Augmented Multimodal Framework for Spreadsheet Understanding‚Ä†‚Ä†thanks: FRTR-Bench dataset: https://github.com/AnmolGulati6/FRTR-bench\n\n\n\nAnmol Gulati\n\n‚ÄÉ‚ÄÉ\nSahil Sen\n\n‚ÄÉ‚ÄÉ\nWaqar Sarguroh\n\n‚ÄÉ‚ÄÉ\nKevin Paul\n\n\n\nAbstract\nLarge Language Models (LLMs) struggle to reason over large-scale enterprise spreadsheets containing thousands of numeric rows, multiple linked sheets, and embedded visual content such as charts and receipts. Prior state-of-the-art spreadsheet reasoning approaches typically rely on single-sheet compression or full-context encoding, which limits scalability and fails to reflect how real users interact with complex, multimodal workbooks. We introduce FRTR-Bench, the first large-scale benchmark for multimodal spreadsheet reasoning, comprising 30 enterprise-grade Excel workbooks spanning nearly four million cells and more than 50 embedded images. To address these challenges, we present From Rows to Reasoning (FRTR), an advanced, multimodal retrieval-augmented generation framework that decomposes Excel workbooks into granular row, column, and block embeddings, employs hybrid lexical-dense retrieval with Reciprocal Rank Fusion (RRF), and integrates multimodal embeddings to reason over both numerical and visual information. We tested FRTR on six LLMs, achieving 74% answer accuracy on FRTR-Bench with Claude Sonnet 4.5, a substantial improvement over prior state-of-the-art approaches that reached only 24%. On the SpreadsheetLLM benchmark, FRTR achieved 87% accuracy with GPT-5 while reducing token usage by roughly 50% compared to context-compression methods.\n\n\n\n1 Introduction\n\nSpreadsheets remain the foundational medium for analytical work at an enterprise level, and modern workbooks routinely contain thousands of cells, span multiple sheets, and embed diverse media such as charts, receipts, and scanned tables [17, 14]. While Large Language Models (LLMs) promise intuitive natural-language interaction with such documents, directly serializing entire sheets into a prompt is inefficient and brittle. Spreadsheet semantics hinge on spatial layout, structural dependencies, and cross-sheet relationships rather than text alone. Moreover, recent work shows that long-context LLMs suffer positional degradation, as accuracy declines when relevant information appears far from the prompt boundaries [25]. This motivates retrieval-focused approaches that surface small, relevant subsets rather than streaming full spreadsheets into the context window.\n\n\nA prominent direction by Haoyu Dong et al., SpreadsheetLLM [10], introduced encoding schemes SheetEncoder and SheetCompressor that compress cell content, positional addresses, and formatting to fit within an LLM‚Äôs context window. While effective for single-sheet reasoning, such compression assumes all relevant data can fit within a single prompt and fails to scale to multi-sheet or multimodal settings. In practice, enterprise workbooks exceed these boundaries, incorporating thousands of rows, inter-sheet references, and embedded images. Retrieval-augmented generation approaches provide a complementary path: combining database-style retrieval with hybrid lexical‚Äìdense retrieval to fetch only the minimal, most relevant evidence for reasoning [6, 18, 19]. Empirical studies demonstrate that retrieval-augmented generation (RAG) can match or surpass long-context models at significantly lower computational cost and latency [22, 13, 3, 18]. Simple rank fusion methods, such as Reciprocal Rank Fusion (RRF), further enhance stability and performance across retrieval modalities [7].\n\n\nFigure 1: Excel workbooks are decomposed into rows, columns, sliding context windows, and embedded images during indexing. These components are stored in a multimodal hybrid vector database supporting lexical and dense fields. Hybrid lexical‚Äìdense retrieval (RRF) fetches relevant evidence for LLM reasoning.\n\n\nIn this work, we make three novel contributions:\n\n\n\n\n‚Ä¢\n\nRetrieval-first framework: We present an advanced, multimodal retrieval-augmented generation approach to spreadsheet understanding that integrates hybrid lexical‚Äìdense retrieval search to overcome full-context limitations and improve scalability.\n\n\n\n‚Ä¢\n\nMulti-granular and multimodal indexing: We introduce a fine-grained indexing scheme for Excel workbooks at the row, column, and block levels, and extend it to multimodal settings using joint text‚Äìvision embeddings. Hybrid rank-fusion retrieval ensures robust and reproducible performance across both textual and image-bearing spreadsheets.\n\n\n\n‚Ä¢\n\nFRTR-Bench benchmark: We release FRTR-Bench, the first large-scale, multimodal spreadsheet reasoning benchmark, spanning 30 enterprise-grade workbooks with nearly four million cells and over fifty embedded images, to support reproducible evaluation of retrieval-augmented spreadsheet understanding.\n\n\n\nBy reframing spreadsheet analysis as a three-part pipeline composed of retrieval, verification, and composition, FRTR incorporates information-retrieval principles, emphasizing minimal access and explicit evidence grounding for LLM-spreadsheet interaction. The result is a scalable, auditable, and cost-efficient framework for reasoning in finance, analytics, and auditing.\n\n\n\n\n2 Related Work\n\n\n2.1 LLMs for Tables and Spreadsheets\n\nEarly neural models such as TAPAS [15] learned to answer questions directly over tables by encoding cell values jointly with queries, while TUTA [32] extended this paradigm by modeling hierarchical and spatial cues. OmniTab [8] further improved few-shot table QA by combining natural and synthetic supervision. These approaches focus on in-context reasoning within a single table and do not scale to multi-sheet or multimodal workbooks.\n\n\nMore recent work such as SpreadsheetLLM [10] compresses spreadsheet structure and content to fit within LLM context limits, achieving notable gains on single-sheet reasoning. Complementary methods, including Table-GPT [5] and TableLLM [4], improve general table manipulation and code generation capabilities. However, these approaches are not capable of handling cross-sheet and multimodal reasoning. In contrast, FRTR emphasizes hybrid lexical-dense retrieval and multimodal embedding [11, 34, 1, 29, 28].\n\n\n\n\n2.2 Long Context, Retrieval, and Hybrid Search\n\nDespite advances in long-context modeling, evidence retrieval remains a bottleneck: simply extending context windows does not guarantee that models attend effectively to mid-range information [25]. Retrieval-augmented generation approaches address this by selecting relevant evidence before generation, improving both performance and interpretability [21, 13]. Hybrid lexical-dense retrieval, fused through methods such as Reciprocal Rank Fusion (RRF) [6, 7], offers robustness and simplicity across tasks. However, basic chunking and retrieval methodologies do not take into account the complicated spatial relationships in spreadsheets, where logic can apply across rows, columns, and even sheets.\n\n\n\n\n2.3 Multimodal Spreadsheet Understanding and Document VQA\n\nSpreadsheets often convey semantics through visual layout, including bold headers, merged cells, and shaded totals, as well as through embedded images such as charts or scanned receipts. Vision‚Äìlanguage models (VLMs) still struggle to interpret such spatial and structural cues [24, 30, 16, 23]. Parallel research in chart and document VQA (e.g., ChartQA [26], DocVQA [27]) highlights the challenges of numerically grounded visual reasoning. These methods typically treat visual and textual modalities in isolation, without integrating multimodal embeddings that unify text, layout, and image semantics.\n\n\n\n\n2.4 Benchmarks for Spreadsheet Interaction\n\nBeyond table QA, recent benchmarks target spreadsheet interaction directly. SpreadsheetLLM [10] performs reasoning on encoded spreadsheets, while SpreadsheetBench [20] introduces realistic, forum-based spreadsheet questions. InstructExcel [33] focuses on natural-language-to-OfficeScript translation. No existing benchmarks offer assessment involving cross-sheet reasoning, multimodal queries, and large-scale evaluation, reflecting the real-world challenges of enterprise workbooks.\n\n\n\n\n\n3 Framework Overview\n\n\n3.1 Motivation and Design Goals\n\nReal-world Excel workbooks exhibit three intertwined challenges: scale, multimodality, and cross-sheet dependency. Workbooks can span thousands of rows across multiple worksheets, include embedded charts or receipts, and encode meaning through layout and formatting. Existing approaches either compress entire files into an LLM‚Äôs context, trading precision for token cost, or rely on text-only embeddings that ignore visual cues.\n\n\nFRTR addresses these challenges through three guiding principles:\n\n\n1.\n\nScalability: Decompose workbooks into granular, retrievable units such as rows, columns, blocks, and images to bypass conte"
  },
  {
    "title": "PrivGemo: Privacy-Preserving Dual-Tower Graph Retrieval for Empowering LLM Reasoning with Memory Augmentation",
    "url": "https://arxiv.org/abs/2601.08739v1",
    "source": "arxiv",
    "summary": "Knowledge graphs (KGs) provide structured evidence that can ground large language model (LLM) reasoning for knowledge-intensive question answering. However, many practical KGs are private, and sending retrieved triples or exploration traces to closed-source LLM APIs introduces leakage risk. Existing privacy treatments focus on masking entity names, but they still face four limitations: structural ",
    "full_text": "\n\n\n\n1 Introduction\n2 Related Work\n3 Preliminaries\n\n4 Method\n\n4.1 Privacy-Aware Initialization\n4.2 Dual-LLM Hierarchical Reasoning\n\n4.3 Evidence Retrieval and Pruning\n\n4.3.1 Evidence exploration\n4.3.2 Evidence pruning\n\n\n4.4 Privacy-Aware Memory\n\n\n\n5 Experiment\n\n5.1 Main Results\n5.2 Ablation Study\n\n\n6 Conclusion\n7 Limitation\n\nA Algorithm\n\nA.1 Privacy-Aware Initialization\nA.2 Dual-LLM Hierarchical Reasoning\nA.3 Evidence Retrieval and Pruning\nA.4 Privacy-Aware Memory\n\n\nB Workflow Diagram\n\nC Additional Experiment\n\nC.1 Effectiveness Evaluation\nC.2 Reasoning Faithfulness Analysis\nC.3 Error Analysis\n\nC.4 Efficiency Analysis\n\nC.4.1 LLM calls cost analysis\nC.4.2 Cost-Performance analysis\n\n\n\n\nD Experiment Details\nE Case study: privacy-preserving interpretable reasoning\nF Prompts\n\n\n\n\n\nPrivGemo: Privacy-Preserving Dual-Tower Graph Retrieval for Empowering LLM Reasoning with Memory Augmentation\n\n\n\nXingyu Tan1,2,\nXiaoyang Wang1,\nQing Liu2,\nXiwei Xu2,\n\nXin Yuan2,\nLiming Zhu2,\nWenjie Zhang1\n1University of New South Wales, Australia\n2Data61, CSIRO, Australia\n\n{xingyu.tan, xiaoyang.wang1, wenjie.zhang}@unsw.edu.au\n{q.liu, xiwei.xu, xin.yuan, liming.zhu}@data61.csiro.au\n\n\n\nAbstract\nKnowledge graphs (KGs) provide structured evidence that can ground large language model (LLM) reasoning for knowledge-intensive question answering.\nHowever, many practical KGs are private, and sending retrieved triples or exploration traces to closed-source LLM APIs introduces leakage risk.\nExisting privacy treatments focus on masking entity names, but they still face four limitations:\nstructural leakage under semantic masking, uncontrolled remote interaction, fragile multi-hop and multi-entity reasoning, and limited experience reuse for stability and efficiency.\nTo address these issues, we propose PrivGemo, a privacy-preserving retrieval-augmented framework for KG-grounded reasoning with memory-guided exposure control.\nPrivGemo uses a dual-tower design to keep raw KG knowledge local while enabling remote reasoning over an anonymized view that goes beyond name masking to limit both semantic and structural exposure.\nPrivGemo supports multi-hop, multi-entity reasoning by retrieving anonymized long-hop paths that connect all topic entities, while keeping grounding and verification on the local KG.\nA hierarchical controller and a privacy-aware experience memory further reduce unnecessary exploration and remote interactions.\nComprehensive experiments\non six benchmarks show that PrivGemo achieves overall state-of-the-art results, outperforming the strongest baseline by up to 17.1%. Furthermore, PrivGemo enables smaller models (e.g., Qwen3-4B) to achieve reasoning performance comparable to that of GPT-4-Turbo.\n\n\n\n\\useunder\n\\ul\n\n\n\n\nPrivGemo: Privacy-Preserving Dual-Tower Graph Retrieval for Empowering LLM Reasoning with Memory Augmentation\n\n\n\n\nXingyu Tan1,2,\nXiaoyang Wang1,\nQing Liu2,\nXiwei Xu2,\n\nXin Yuan2,\nLiming Zhu2,\nWenjie Zhang1\n\n1University of New South Wales, Australia\n\n2Data61, CSIRO, Australia\n\n{xingyu.tan, xiaoyang.wang1, wenjie.zhang}@unsw.edu.au\n\n{q.liu, xiwei.xu, xin.yuan, liming.zhu}@data61.csiro.au\n\n\n\n\n\n1 Introduction\n\nFigure 1: Representative workflow of three LLM reasoning paradigms.\n\n\nLarge Language Models (LLMs) have achieved remarkable performance by scaling up to billions of parameters and pre‚Äëtraining on vast and diverse corpora\nBrown (2020); Chowdhery et al. (2023).\nHowever, the prohibitive expense of full-model training for LLMs makes continual retraining infeasible, causing static parametric knowledge to quickly become obsolete and resulting in factual gaps and hallucinations Touvron et al. (2023).\n\n\nRetrieval-Augmented Generation (RAG) mitigates this issue by retrieving external evidence at inference time and conditioning generation on retrieved context¬†Baek et al. (2023); Gao et al. (2023).\nAmong external sources, Knowledge Graphs (KGs) provide structured facts and explicit relations, making them a reliable grounding source for multi-hop question answering and interpretable reasoning¬†Sun et al. (2024); Luo et al. (2023).\nKG-based RAG systems commonly identify topic entities from the question, retrieve candidate triples or reasoning paths, and then generate an answer supported by the retrieved evidence Tan et al. (2025b).\n\n\nHowever, KGs are private in many modern applications Bellomarini et al. (2024).\nDirectly prompting a closed-source LLM with private KG content introduces a leakage risk, especially in sensitive domains such as enterprise knowledge, healthcare, and internal security graphs Ning et al. (2025).\nThis motivates a privacy-protected KG-based RAG, where the system answers with KG evidence while restricting what a remote model can observe.\n\n\nLimitations of existing methods.\nCurrent approaches focus on semantic anonymization, e.g., replacing entity names with pseudonyms or meaningless identifiers, and then performing a ‚Äúretrieve-and-select‚Äù routine on the anonymized KG Ma et al. (2025b).\nFor example, as shown in Figure¬†1(b), ARoG operates on an entity-warped KG, retrieves one-hop triples around question keywords, and prompts LLM to select an answer Ning et al. (2025).\nWhile effective for shallow queries, this strategy suffers from four limitations.\n\n\nL1: Semantic masking insufficient.\nMost privacy adaptations focus on replacing entities with pseudonyms.\nHowever, unique connectivity patterns and repeated exploration traces can cause structural leakage,\nenabling linkage and re-identification without raw semantics.\nFor example, in Figure¬†1(b), MID_B connects to two election events via [winner_of], forming a rare structural pattern that enables re-identification.\n\n\nL2: Uncontrolled remote interaction.\nRemote LL-Ms are often used for question analysis and candidate selection.\nIn Figure¬†1 (a-b), the system retries one-hop expansion and selection around topic entities, each extra call exposes more neighbors, partial paths, and selection traces, especially when depth is increased or the model backtracks after a failure.\n\n\nL3: Multi-hop and multi-entity reasoning.\nCurrent methods typically explore topic entities separately, retrieve only one-hop relations per step, and rely on semantic pruning.\nAs in Figure¬†1(a-b), greedy choices drift to locally plausible branches (e.g., party/served_as) and fail to pass through the unnamed intermediate (Unknown Type), so the evidence does not form a single connected path between the two topic entities.\nThis local-optimal process can prune the correct long-hop chain prematurely and miss cross-entity linking facts.\n\n\nL4: Lack of reasoning experience management.\nMost pipelines remain memoryless, discarding successful traces after each run.\nIn Figure¬†1(a-b), similar questions repeatedly trigger the same failing exploration pattern (e.g., expansion and greedy selection), causing redundant exploration and remote calls, increasing both cost and exposure.\n\n\nContributions.\nWe present PrivGemo, shown in Figure 1(c), a privacy-preserving RAG framework for multi-hop reasoning over private graphs with memory augmentation.\nPrivGemo jointly limits semantic and structural exposure, keeping raw KG evidence local and exposing only an anonymized view to a remote model for analysis, with local verification gating exploration and answering.\nA privacy-aware experience memory further reduces redundant exploration and remote calls.\n\n\nTo mitigate semantic and structural leakage,\nPriv-Gemo constructs a question-specific working subgraph GQrawG^{\\mathrm{raw}}_{Q} locally and derives an anonymized view G~Q\\tilde{G}_{Q} for remote processing.\nBeyond session-specific entity and relation anonymization œïQ\\phi_{Q}, PrivGemo applies structure-level sanitization (structural de-uniqueness) on G~Q\\tilde{G}_{Q} to reduce leakage from uniquely identifying subgraph signatures and from repeated exploration traces across iterations.\n\n\nTo control remote usage,\nPrivGemo separates a remote Brain LLM from a local Hand LLM, and uses experience memory to gate remote calls.\nThe brain only performs anonymized question analysis and anonymized candidate-path selection.\nHand controls exploration, performs controlled de-anonymization, and question answering on GQrawG^{\\mathrm{raw}}_{Q}.\n\n\nTo improve multi-hop and multi-entity reasoning,\nPrivGemo introduces an indicator-guided long-hop path retrieval that explicitly enforces a coherent path covering all topic entities.\nThis avoids greedy hop-by-hop selection that may discard globally correct chains, and prevents inconsistent evidence merging by requiring joint coverage of all topic entities within one verified reasoning path.\n\n\nTo manage and reuse reasoning experience,\nPriv-Gemo maintains a continuously evolving experience memory that records successful records.\nEach entry stores embeddings of the anonymized question Q~\\tilde{Q} and indicator II, enabling efficient similarity-based retrieval under privacy-mode constraints.\nDuring inference, Hand retrieves relevant exemplars to guide reasoning and to skip unnecessary Brain calls, while after termination, verified artifacts are encrypted and written back for future reuse.\nIn summary, the advantages of PrivGemo can be abbreviated as:\n\n\nSemantic-structural privacy protection.\nPriv-Gemo goes beyond name masking by sanitizing subgraph structure and limiting what a remote model can infer from repeated exploration traces.\n\n\nDual-LLM hierarchical reasoning.\nA hierarchical controller with physical knowledge isolation to execute, locally verify, and refine questions, enabling faithful and interpretable reasoning.\n\n\nExperience-guided exploration and pruning.\nA retrieval tree controller manages mode and depth transitions to support multi-hop and multi-entity reasoning with bounded exposure.\n\n\nSelf-evolving privacy-aware memory.\nVerified reasoning responses are continuously organized in an adaptive experience pool to reduce unnecessary exploration and remote calls, forming a closed feedback loop for continual improvement.\n\n\nEfficiency and adaptability:\na) PrivGemo "
  },
  {
    "title": "TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback",
    "url": "https://arxiv.org/abs/2601.08734v1",
    "source": "arxiv",
    "summary": "Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, a",
    "full_text": "\n\n\n\n1 Introduction\n2 Related Work\n3 Preliminaries and Problem Formulation\n4 TF-Gen and TF-Mutn: A Systematic Dataset Curation Pipeline with LLMs and Verification\n5 Fine-Tuning Methodology\n6 Experimental Results\n7 Quality Assessment of TF-Gen &amp; TF-Mutn\n8 Conclusion\nA Reproducibility\nB Description of LLM Prompts\n\n\n\n\n\n\n\\setcctype\nby-nc-nd\n\n\n\n\n\n\n\nTerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback\n\n\nPrithwish Jana\n\npjana7@gatech.edu\n\n0000-0003-1967-4665\nGeorgia Institute of TechnologyAtlantaUSA\n\n, \nSam Davidson\n\nssdavid@amazon.com\n\n0000-0003-1160-2683\nAmazon Web ServicesSeattleUSA\n\n, \nBhavana Bhasker\n\n0009-0006-9605-5525\nAmazon Web ServicesSeattleUSA\n\n, \nAndrey Kan\n\n0000-0002-2432-0047\nAmazon Web ServicesSeattleUSA\n\n, \nAnoop Deoras\n\n0009-0007-4566-8767\nAmazon Web ServicesSeattleUSA\n\n and \nLaurent Callot\n\n0000-0002-0756-8120\nAmazon Web ServicesSeattleUSA\n\n\n(2026)\n\nAbstract.\nAutomating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including ‚àº\\sim50√ó\\times larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen (Test), and 19.60% on TF-Mutn (Test). It outperforms larger models on both TF-Gen (Test) and TF-Mutn (Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance.\n\nInfrastructure as Code (IaC), IaC generation, IaC mutation, Neuro-symbolic AI, Large language models, Formal Verification\n\n‚Ä†‚Ä†journalyear: 2026‚Ä†‚Ä†copyright: cc‚Ä†‚Ä†conference: 2026 IEEE/ACM 48th International Conference on Software Engineering; April 12‚Äì18, 2026; Rio de Janeiro, Brazil‚Ä†‚Ä†booktitle: 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE-SEIP ‚Äô26), April 12‚Äì18, 2026, Rio de Janeiro, Brazil‚Ä†‚Ä†doi: 10.1145/3786583.3786898‚Ä†‚Ä†isbn: 979-8-4007-2426-8/2026/04‚Ä†‚Ä†ccs: Software and its engineering¬†Orchestration languages‚Ä†‚Ä†ccs: Software and its engineering¬†Formal software verification‚Ä†‚Ä†ccs: Computing methodologies¬†Natural language processing‚Ä†‚Ä†ccs: Computing methodologies¬†Reinforcement learning\n\n\n1. Introduction\n\nCloud computing has become the backbone of modern IT systems, with over 96% of organizations using public cloud services and the market projected to exceed $940 billion by 2026¬†(Michalowski, 2025). Cloud-native development involves orchestrating diverse infrastructure components such as compute, storage, networking, databases, and identity management, across multiple environments. To ensure reproducibility and support iterative changes, these resources must be provisioned consistently and automatically. As a result, Infrastructure-as-Code (IaC)¬†(Morris, 2020) has emerged as a core DevOps practice, enabling infrastructure to be deployed and managed via high-level, machine-readable code (configuration). Broadly, IaC tools fall into two categories: configuration management systems (e.g., Puppet, Chef, Ansible) that manage already-provisioned systems‚Äô state, and infrastructure provisioning frameworks (e.g., CloudFormation, Terraform, Pulumi) that declaratively define, provision, and manage resources. Among these, Terraform¬†(HashiCorp, 2014) is one of the most widely used IaC tools on GitHub, with its declarative HashiCorp Configuration Language (HCL) experiencing over 30% growth every year¬†(Daigle, 2023; GitHub, 2024). Backed by a strong community, Terraform‚Äôs modular, platform-agnostic definitions and plugin system enable integration with major cloud providers like AWS, Azure, and Google Cloud.\n\n\nAlthough Terraform‚Äôs HCL offers a readable, declarative syntax, authoring IaC configurations requires deep knowledge of cloud provider APIs, provider-specific attributes, and complex inter-resource dependencies. Experienced engineers typically spend around 100 minutes creating a moderately complex multi-cloud setup¬†(Ragothaman et¬†al., 2024), and human-written configurations often contain critical security vulnerabilities¬†(Buehler et¬†al., 2025). These challenges highlight the need to automate IaC generation from high-level goals to reduce manual effort and security risks. Large language models (LLMs) are well-suited, having shown strong code generation across benchmarks. Notable examples include Claude 3.7¬†(Anthropic, 2025), GPT-4.1¬†(OpenAI, 2025), DeepSeek-R1¬†(Guo et¬†al., 2025), LLaMA-4¬†(Meta AI, 2025), and Qwen-3¬†(Yang et¬†al., 2025), which rank highly on HumanEval+¬†(Liu et¬†al., 2023a), MMLU-Pro¬†(Wang et¬†al., 2024), Open LLM v2¬†(Fourrier et¬†al., 2024), and Polyglot¬†(Aider, 2024). However, applying LLMs to IaC automation involves unique challenges.\n\n\n\n\n\nFigure 1. Learning Objectives. Task definitions for IaC generation, i.e., creating Terraform configurations from scratch, and IaC mutation, i.e., modifying existing configurations, both taking natural language (NL) prompts as input.\n\nLearning objectives showing task definitions for Infrastructure as Code generation, i.e., creating Terraform configurations from scratch, and Infrastructure as Code mutation, i.e., modifying existing configurations, both taking natural language prompts as input.\n\n\n\nIn this paper, we address two fundamental tasks in IaC automation using LLMs, focusing on Terraform and its native language HCL: (a) IaC generation, creating configurations from scratch given natural language (NL) prompts, and (2) IaC mutation, modifying existing configurations based on NL instructions (Figure¬†1). These use cases pose several challenges that limit the effectiveness of current LLMs in the IaC domain.\nFirst, there is a lack of high-quality labeled datasets, hindering model evaluation and the development of specialized ones. Due to privacy restrictions, real-world IaCs are rarely shared, limiting LLMs‚Äô exposure to diverse conventions and usage patterns in production.\nSecond, general-purpose LLMs struggle to satisfy the strict syntactic and semantic constraints of formal languages¬†(Jana, 2024; Ugare et¬†al., 2024) like HCL, frequently producing hallucinated or invalid code. This stems from their stochastic nature and is compounded by the lack of domain-specific supervision. The challenge is amplified in IaC, where tools like Terraform use a highly declarative, stateful language, and correctness depends on both syntax and semantic consistency with cloud provider APIs and inter-resource dependencies.\nThird, IaC mutation poses a distinct challenge from IaC generation, as it requires LLMs to accurately interpret existing infrastructure and make precise updates while preserving critical dependencies. Although a few recent studies¬†(Zhang et¬†al., 2025b; Palavalli et¬†al., 2024; Kon et¬†al., 2024; Lee et¬†al., 2024) have explored NL-to-IaC generation from scratch, the task of mutating or incrementally updating existing IaC via NL prompts (arguably more reflective of real-world development) remains largely underexplored.\nFourth, automated evaluation of IaC correctness is a major bottleneck. Actual cloud deployment is prohibitively slow¬†(Qiu et¬†al., 2023), cannot reliably verify user intent, and often requires credentials unavailable to the LLM, necessitating manual post-processing. Pre-deployment testing remains an open problem¬†(Sokolowski et¬†al., 2024), so prior IaC research relies on proxies like BLEU, exact match¬†(Srivatsa et¬†al., 2023), CodeBERTScore, LLM judges¬†(Kon et¬†al., 2024), linters¬†(Palavalli et¬†al., 2024), and static analyzers¬†(Buehler et¬†al., 2025). Without formal verifiers, these provide minimal guarantees for deployability or preservation of user intent.\n\n\nTo address the challenges of reliable IaC generation and mutation from NL prompts, we present TerraFormer, a neuro-symbolic framework that leverages an LLM fine-tuned with feedback from formal verification tools. We employ a comprehensive suite of verifiers that assess Terraform IaC for compilability, deployability, and policy compliance. Using these verifiers, we curate a high-quality NL-to-IaC dataset by processing a large collection of erroneous Terraform configurations from open-source repositories through multi-stage verification. Crucially, those failing verification enter a multi-turn repair loop, where an LLM iteratively refines them using verifier-generated error certificates. This self-correction process yields a large set of verified IaC, from which we derive NL prompts and policies that capture infrastructure intent. Though focused on Terraform, our automated data curation pipeline extends to other IaC tools (e.g., Pulumi, Ansible, CloudFormation) and general code generation or mutation. We use this dataset to fine-tune open-source LLMs for IaC generation and mutation. We warm-start with supervised fine-tuning (SFT), then apply reinforcement learning (RL) guided by fine-grained verifier feedback with progressively structured rewards, enabling the LLM to move beyond pattern imitation and produce deployable, functionally correct IaC.\n\n\nContributions:\n\n\n‚Ä¢\n\nWe present an automated data curation pipeline leveraging LLMs and formal verification to construct large-scale NL-to-IaC datasets: TF-Gen (152,475 generation instances; 330√ó\\times IaC-Eval¬†(Kon et¬†al., 2024), 1000√ó\\times DPIaC-Eval¬†(Zhang et¬†al., 2025b), 150√ó\\times CloudEval-YAML¬†(Xu et¬†al., 2024)) and TF-Mutn (52,516 mutation instances, the first IaC mutation dataset), both with more complex infrastructures than IaC-Eval. We validate prompt‚ÄìIaC‚Äìpolicy semantic alignment and mutation complexity via a cloud-expert sur"
  },
  {
    "title": "A Novel Approach to Explainable AI with Quantized Active Ingredients in Decision Making",
    "url": "https://arxiv.org/abs/2601.08733v1",
    "source": "arxiv",
    "summary": "Artificial Intelligence (AI) systems have shown good success at classifying. However, the lack of explainability is a true and significant challenge, especially in high-stakes domains, such as health and finance, where understanding is paramount. We propose a new solution to this challenge: an explainable AI framework based on our comparative study with Quantum Boltzmann Machines (QBMs) and Classi",
    "full_text": null
  },
  {
    "title": "ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning",
    "url": "https://arxiv.org/abs/2601.08732v1",
    "source": "arxiv",
    "summary": "Accurate delineation of acute ischemic stroke lesions in MRI is a key component of stroke diagnosis and management. In recent years, deep learning models have been successfully applied to the automatic segmentation of such lesions. While most proposed architectures are based on the U-Net framework, they primarily differ in their choice of loss functions and in the use of deep supervision, residual",
    "full_text": null
  },
  {
    "title": "Learning from Demonstrations via Capability-Aware Goal Sampling",
    "url": "https://arxiv.org/abs/2601.08731v1",
    "source": "arxiv",
    "summary": "Despite its promise, imitation learning often fails in long-horizon environments where perfect replication of demonstrations is unrealistic and small errors can accumulate catastrophically. We introduce Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that mitigates the brittle dependence on expert trajectories for direct imitation. Unlike prior methods that rely ",
    "full_text": "\n\n\n\n\nLearning from Demonstrations via Capability-Aware Goal Sampling\n\n1 Introduction\n2 Background and Problem Setup\n\n3 Method\n\n3.1 Observation Visit Tracking with Demonstration Alignment\n3.2 Capability-Aware Goal Sampling\n3.3 Learning Framework\n\n\n4 Experiments\n5 Related Work\n6 Conclusion\nA Proof of Theorem 1\n\nB Extended Background\n\nB.1 Dreamer World Model\nB.2 Temporal Distance Training in LEXA\n\n\nC Discussion\nD Limitations and Future Work\n\nE Environment Details\n\nE.1 MetaWorld\nE.2 Adroit\nE.3 Maniskill\n\n\n\nF More Experiments\n\nF.1 More Baselines\nF.2 Visual goal predictor\nF.3 Ablation on Number of Demonstration\n\nF.4 Ablation on Demonstration Quality\n\nSuboptimal Demonstrations.\nFailed Demonstrations.\n\n\nF.5 Ablation on Parameters\n\n\n\nG Runtime\n\nG.1 Experiment total runtimes\nG.2 Computation Time for Updating the Cago Visitation Record Dictionary\n\n\nH Hyperparameters\n\n\n\n\n\n\n\nLearning from Demonstrations via Capability-Aware Goal Sampling\n\n\nYuanlin Duan\nRutgers University\nyuanlin.duan@rutgers.edu\n&amp;Yuning Wang \nRutgers University \nyw895@cs.rutgers.edu\nWenjie Qiu \nRutgers University \nwq37@cs.rutgers.edu\n&amp;He Zhu \nRutgers University \nhz375@cs.rutgers.edu\n\n\n\n\nAbstract\nDespite its promise, imitation learning often fails in long-horizon environments where perfect replication of demonstrations is unrealistic and small errors can accumulate catastrophically. We introduce Cago (Capability-Aware Goal Sampling), a novel learning-from-demonstrations method that mitigates the brittle dependence on expert trajectories for direct imitation. Unlike prior methods that rely on demonstrations only for policy initialization or reward shaping, Cago dynamically tracks the agent‚Äôs competence along expert trajectories and uses this signal to select intermediate steps‚Äîgoals that are just beyond the agent‚Äôs current reach‚Äîto guide learning. This results in an adaptive curriculum that enables steady progress toward solving the full task. Empirical results demonstrate that Cago significantly improves sample efficiency and final performance across a range of sparse-reward, goal-conditioned tasks, consistently outperforming existing learning from-demonstrations baselines.\n\n\n\n1 Introduction\n\nImitation Learning (IL) provides a powerful paradigm for training agents using expert demonstrations, effectively alleviating the exploration challenges common in Deep Reinforcement Learning (DRL)¬†(Arulkumaran and Lillrank, 2024). The simplest form of IL is Behavior Cloning (BC), which directly supervises policy actions based on the states visited by the expert¬†(Bain and Sammut, 1995; Torabi et al., 2018). However, BC often suffers from compounding errors when the learned policy deviates from expert trajectories. To overcome this limitation, modern approaches such as GAIL¬†(Ho and Ermon, 2016), PWIL¬†(Dadashi et al., 2020), and AdRIL¬†(Eysenbach et al., 2021) seek to align the state‚Äìaction distributions of the agent and the expert through adversarial or distribution-matching objectives. In parallel, Inverse Reinforcement Learning (IRL) methods¬†(Ziebart et al., 2008) aim to infer underlying reward functions from demonstrations, which can then guide reinforcement learning. More recently, advances in offline and offline-to-online RL, such as CQL¬†(Kumar et al., 2020) and Cal-QL¬†(Nakamoto et al., 2023), integrate demonstrations as anchors to regularize policy learning. These methods penalize value estimates that diverge from demonstrated behavior, mitigating overestimation and instability caused by out-of-distribution actions.\n\n\nHowever, existing IL methods often struggle with complex, long-horizon tasks because they fail to reason about which parts of the task the agent has already mastered and which remain challenging. In particular, distribution-matching approaches perform flat matching‚Äîattempting to align occupancy measures over the entire trajectory distribution without considering the agent‚Äôs evolving capabilities. This leads to poor exploration guidance, especially in the early stages of training when the agent seldom reaches meaningful parts of the state space. As a result, the learned reward function tends to assign uniformly low rewards, yielding uninformative gradients and hindering effective policy improvement. Some prior work proposes demonstration-guided curriculum learning that trains agents to solve tasks by starting near the goal or high-reward states and gradually expanding to earlier parts of the trajectories¬†(Resnick et al., 2018; Salimans and Chen, 2018; Tao et al., 2024). However, these approaches rely on the ability to reset the agent to arbitrary demonstration states‚Äîan assumption impractical in real-world settings due to challenges in replicating physical conditions like joint velocities and angular momentum.\n\n\nWe propose Cago (Capability-Aware Goal Sampling), a new learning-from-demonstrations framework that explicitly aligns the agent‚Äôs learning process with its evolving capabilities. Unlike prior methods that use demonstrations for direct imitation, reward shaping, or offline pretraining, Cago treats demonstrations as structured roadmaps. It continuously monitors which parts of a demonstration the agent can already reach and leverages this signal to sample intermediate goal states in the demonstration, those at the boudary of the agent‚Äôs current goal-reaching capabilities. At each episode, a goal-conditioned agent¬†(Liu et al., 2022; Plappert et al., 2018) first attempts to reach the sampled goal and then explores forward from it, generating informative, task-relevant data for policy optimization. This iterative process of capability-aware goal selection and curriculum-aligned exploration enables steadily progress toward solving the full task.\n\n\nWe evaluate Cago across several sparse-reward environments and demonstrate substantial improvements in both sample efficiency and final task performance over existing imitation-based baselines. Our experiments highlight that capability-aware goal sampling provides a powerful signal for structuring learning, particularly in long-horizon tasks.\n\n\n\n\n2 Background and Problem Setup\n\nReinforcement learning (RL) aims to enable agents to learn optimal behaviors through trial-and-error interactions with an environment. An RL problem is formulated as a Markov Decision Process (MDP), represented as a tuple (ùíÆ,ùíú,ùíØ,ùí¢,Œ∑,R,œÅ0)(\\mathcal{S},\\mathcal{A},\\mathcal{T},\\mathcal{G},\\eta,R,\\rho_{0}). The agent operates within a state space ùíÆ\\mathcal{S} and takes actions from an action space ùíú\\mathcal{A}, transitioning between states according to the dynamics ùíØ‚Äã(s‚Ä≤|s,a)\\mathcal{T}(s^{\\prime}|s,a). R‚Äã(s,a)‚àà‚ÑùR(s,a)\\in\\mathbb{R} is the reward function and œÅ0\\rho_{0} is the initial state distribution. Given a policy œÄ\\pi, consider the trajectory œÑ={s0,a0,s1,a1,‚Ä¶}\\tau=\\{s_{0},a_{0},s_{1},a_{1},\\ldots\\} sampled by œÄ\\pi, i.e., s0‚àºœÅ0s_{0}\\sim\\rho_{0}, at‚àºœÄ(‚ãÖ|st)a_{t}\\sim\\pi(\\cdot|s_{t}), and st+1‚àºùíØ(‚ãÖ|st,at)s_{t+1}\\sim\\mathcal{T}(\\cdot|s_{t},a_{t}). The goal of RL is to learn a return-maximizing policy œÄ‚àó=arg‚Å°maxœÄ‚Å°ùîºœÑ‚àºœÄ‚Äã(at‚à£st)‚Äã[‚àët=0‚àûŒ≥t‚Äãr‚Äã(st,at)]\\pi^{*}=\\arg\\max_{\\pi}\\mathbb{E}_{\\tau\\sim\\pi(a_{t}\\mid s_{t})}\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})\\right] where Œ≥‚àà(0,1]\\gamma\\in(0,1] is the discount factor.\n\n\nLearning from Demonstrations. In imitation learning, the agent is provided a dataset of demonstrations ùíüdemo\\mathcal{D}_{\\text{demo}} collected from some expert policy œÄexpert\\pi_{\\text{expert}}. The objective is to learn a policy œÄ\\pi that reproduces the expert‚Äôs behavior by generalizing from these demonstrations. The simplest approach, behavioral cloning (BC), treats this as a supervised learning problem, minimizing the discrepancy between the agent‚Äôs predicted actions and the expert‚Äôs.\nAnother line of work, inverse reinforcement learning (IRL)¬†(Abbeel and Ng, 2004), aims to infer an underlying reward function that explains the expert‚Äôs behavior and then optimizes a policy through RL on this learned reward, thus decoupling reward inference from policy optimization.\nBuilding on ideas from IRL, Generative Adversarial Imitation Learning (GAIL)¬†(Ho and Ermon, 2016) bypasses explicit reward recovery by training a policy and a discriminator in an adversarial game: the discriminator distinguishes expert from agent trajectories, while its output serves as an implicit, learned reward signal guiding the policy.\nMore broadly, many recent imitation learning algorithms can be interpreted as minimizing a divergence between the expert and agent occupancy measures.\n\n\nState Reset. Several methods attempt to mitigate the exploration challenge in sparse-reward RL environments by resetting the agent to states from expert demonstrations, thereby bypassing the need to discover those states through the agent‚Äôs own exploration. These strategies include initializing the agent to states sampled uniformly from demonstration trajectories¬†(Nair et al., 2018; Peng et al., 2018; Hosu and Rebedea, 2016), employing a hand-crafted curriculum¬†(Zhu et al., 2018), or using a reverse curriculum that progressively trains the agent from goal or high-reward states backward¬†(Resnick et al., 2018; Salimans and Chen, 2018; Tao et al., 2024). These approaches assume the ability to reset the agent to arbitrary demonstration states‚Äîan assumption that is unrealistic in real-world settings.\n\n\nGoal-Conditioned RL (GCRL) extends the standard RL framework by conditioning policies on specific target goals, guiding agents toward desired goals. The MDPs are augmented with a goal space ùí¢\\mathcal{G} and are associated with states via a mapping Œ∑:ùíÆ‚Üíùí¢\\eta:\\mathcal{S}\\to\\mathcal{G}, ensuring that each state corresponds to an achieved goal. In GCRL, the reward signal from the environment is typically sparse and is defined as: R‚Äã(s,a,s‚Ä≤,g)=1‚Äã{Œ∑‚Äã(s‚Ä≤)=g}R(s,a,s^{\\prime},g)=1\\{\\eta(s^{\\prime})=g\\}.\nWe assume that each episode has a fixed horizon TT and ùíÆ=ùí¢\\mathcal{S}=\\mathcal{G}. The agent‚Äôs objective is to train a goal-conditioned policy œÄG(‚ãÖ|st,g)\\pi^{G}(\\cdot|s_{t},g) to achieve a"
  },
  {
    "title": "Model-Agnostic Solutions for Deep Reinforcement Learning in Non-Ergodic Contexts",
    "url": "https://arxiv.org/abs/2601.08726v1",
    "source": "arxiv",
    "summary": "Reinforcement Learning (RL) remains a central optimisation framework in machine learning. Although RL agents can converge to optimal solutions, the definition of ``optimality'' depends on the environment's statistical properties. The Bellman equation, central to most RL algorithms, is formulated in terms of expected values of future rewards. However, when ergodicity is broken, long-term outcomes d",
    "full_text": "\n\n\n\n1 Introduction\n2 Ergodicity in Reinforcement Learning Research\n\n3 Experiment design\n\n3.1 Toy model for an MDP\n3.2 Portfolio Assignment Optimisation\n\n\n\n4 Experiment results\n\n4.1 Deep Q-Network and the Toy Model\n4.2 Actor-Critic Model and Portfolio Assignment\n\n\n5 Conclusion\n\nA Appendix\n\nA.1 DQN model parameters\nA.2 Actor-Critic Model and Training Parameters\nA.3 Policy training result for AC model\n\n\n\n\n\n\n\nModel-Agnostic Solutions for Deep Reinforcement Learning in Non-Ergodic Contexts\n\n\n\nBert Verbruggen1, \n‚Äâ0000-0001-9776-2420\n&amp;Arne Vanhoyweghen1,2\n‚Äâ0000-0003-0103-4715\n&amp;Vincent Ginis1,3\n‚Äâ0009-0001-5086-2704\n\n\n‚ÄÉ‚ÄÉ\n1Data Analytics Lab, Vrije Universiteit Brussel, 1050 Brussel, Belgium \n2Mobilise, Vrije Universiteit Brussel, 1050 Brussel, Belgium \n3School of Engineering and Applied Sciences, Harvard University, Cambridge, Massachusetts 02138, USA\n\n\n\nAbstract\nReinforcement Learning (RL) remains a central optimisation framework in machine learning. Although RL agents can converge to optimal solutions, the definition of ‚Äúoptimality‚Äù depends on the environment‚Äôs statistical properties. The Bellman equation, central to most RL algorithms, is formulated in terms of expected values of future rewards. However, when ergodicity is broken, long-term outcomes depend on the specific trajectory rather than on the ensemble average. In such settings, the ensemble average diverges from the time-average growth experienced by individual agents, with expected-value formulations yielding systematically suboptimal policies. Prior studies demonstrated that traditional RL architectures fail to recover the true optimum in non-ergodic environments. We extend this analysis to deep RL implementations and show that these, too, produce suboptimal policies under non-ergodic dynamics. Introducing explicit time dependence into the learning process can correct this limitation. By allowing the network‚Äôs function approximation to incorporate temporal information, the agent can estimate value functions consistent with the process‚Äôs intrinsic growth rate.\nThis improvement does not require altering the environmental feedback, such as reward transformations or modified objective functions, but arises naturally from the agent‚Äôs exposure to temporal trajectories. Our results contribute to the growing body of research on reinforcement learning methods for non-ergodic systems.\n\n‚Ä†‚Ä†footnotetext:  Corresponding author: bert.verbruggen@vub.be\n\n\n1 Introduction\n\nReinforcement Learning (RL) is a powerful training method for agents to learn policies that optimise actions in decision-making contexts¬†[1]. An agent is set in a virtual environment with states st‚ààùíÆs_{t}\\in\\mathcal{S}, and available actions at‚ààùíúa_{t}\\in\\mathcal{A} for a time-step t‚àà‚Ñït\\in\\mathbb{N}. In traditional contexts, the state-action space, the set of all possible state-action pairs, is represented in a table, and a value function V‚Äã(st)V(s_{t}) is learned during training. This function determines a reference value for choosing a specific action from a given state. To find this function, an optimisation is implemented based on the Bellman Equation,\n\n\n\nV‚Äã(s)=ùîº‚Äã[rt+1+Œ≥‚ÄãV‚Äã(st+1)‚à£st=s].V(s)=\\mathbb{E}\\left[r_{t+1}+\\gamma V(s_{t+1})\\mid s_{t}=s\\right].\n\n(1)\n\n\nThis equation has an explicit dependence on the expected value (ùîº‚Äã[R]\\mathbb{E}[R]) of the rewards RR and resides at the core of traditional update rules such as SARSA¬†[2], Q-learning¬†[3] or the Monte Carlo (MC) methods¬†[1].\n\n\nDespite the effective implementations and results of RL over the past years, its reliance on expected values implicitly assumes ergodicity and restricts the standard implementation of RL to ergodic contexts. In an ergodic dynamic, the expected value is equal to the time growth of an agent, as indicated by Equation¬†2. When this equality does not hold, we say ergodicity is broken. For a generic optimiser function f‚Äã(œâ)f(\\omega), with f:Œ©‚Üí‚Ñùf:\\Omega\\to\\mathbb{R} an integrable observable evaluated along a trajectory œâ\\omega, this equation can be written as\n\n\n\nlimT‚Üí‚àû‚Äã1T‚Äã‚à´0Tf‚Äã(œâ‚Äã(t))‚Äãùëët=‚à´Œ©f‚Äã(œâ)‚ÄãP‚Äã(œâ)‚Äãùëëœâ.\\raisebox{2.15277pt}{\\scalebox{0.8}{$\\displaystyle\\lim_{T\\to\\infty}\\;$}}\\frac{1}{T}\\int^{T}_{0}f\\left(\\omega\\left(t\\right)\\right)dt=\\int_{\\Omega}f\\left(\\omega\\right)P\\left(\\omega\\right)d\\omega.\n\n(2)\n\n\nIn non-ergodic contexts, however, the optimal policy cannot be accurately inferred from expected values alone. Recent work¬†[4] demonstrated this effect in multiplicative dynamics, where path dependence requires optimisation with respect to time-average growth rather than ensemble averages. Prior studies focused primarily on tabular RL with finite, discrete action spaces. In the present work, we extend this analysis to Deep Reinforcement Learning (DRL) by employing function approximators to generalise over continuous and higher-dimensional spaces. Although neural networks, as function approximators, are designed to capture complex dependencies in the data, our findings show that this capability does not resolve the underlying limitation: when the learning signal is defined in terms of expected values, DRL agents remain unable to identify the true time-optimal policy.\n\n\n\n\n2 Ergodicity in Reinforcement Learning Research\n\nThe concept of ergodicity has broad relevance across scientific disciplines, from physics to social sciences. In the present work, we examine its implications within agent-based modelling, particularly in Economics and Finance, where a seminal contribution was made by¬†[5]. In this work, the author formalises the notion of ergodicity breaking and demonstrates its importance for understanding economic dynamics. The author‚Äôs initial critique focuses on the widespread use of ensemble averages in behavioural economics and the lack of motivation for the choice of specific utility functions. Peters illustrates this by investigating the multiplicative dynamic, a compounding process at the heart of many economic applications, in which wealth grows and shrinks with relative increments. Moreover, Peters shows that the multiplicative dynamic is non-ergodic and therefore well described by the time-average growth rate, but not by its expected value¬†[6]. Finally, the author demonstrates that, with the right transformation, non-ergodic dynamics can be rendered ergodic, allowing the expected values of the transformed variables to meaningfully represent long-term outcomes. This transformation, often referred to as the ergodic transform¬†[7], bears similarities to the notion of a utility function. However, whereas utility functions arise from idiosyncratic preferences, the ergodic transform follows from the objective structure of the underlying dynamics.\n\n\nSubsequent studies in Ergodicity Economics have demonstrated the far-reaching implications of the ergodic assumption across the behavioural and computational sciences. This ranges from findings that human decision-making, often labelled as irrational under classical expected-utility theory, can be re-interpreted as rational when evaluated through time-average growth¬†[8, 9, 10, 11], to analyses showing how non-ergodic dynamics can promote cooperation and collective stability in social and economic systems¬†[12, 13, 14, 15]. The influence of ergodicity-breaking extends further to reinforcement learning, where agents trained on expected-value criteria have been shown to develop sub-optimal policies in non-ergodic environments¬†[4, 16, 17].\n\n\nWhen combining decision-making and risk sensitivity, we often encounter RL and Markov decision processes (MDPs). Foundational work introduced risk into Markov Decision Processes (MDPs) as a selective parameter for value iteration and policy iteration¬†[18]. By embedding risk-sensitivity as a parameter in the objective function of the exponential expected utility, a similar notion to the ergodic transform was introduced. An alternative introduction to the value function is considered by¬†[19], which incorporates the variance of the return into the optimisation. This formulation is often referred to as the first risk-aware RL formulation. By including variance in the objective function, it diverges from optimising the expected value alone and also focuses on variance minimisation. In a random multiplicative process, whose central tendency depends on both the expected return and its variance, this approach can be interpreted as approximately optimising the time-average growth rate.\nSimilar conceptual introductions of parameters have been studied, using variance, entropy or other definitions to modulate the effects of the stochastic return signal as well¬†[20, 21, 22].\n\n\nA complexity analysis for mean-variance objectives, including variance-driven operators in the objective functions for agent-based modelling, shows that such objectives are non-additive and, as such, non-ergodic by design. Related to the specific use of actor-critic (AC) models,¬†[23] presents three approaches for incorporating variance into the optimisation of AC models and demonstrates their practical application in a dedicated experimental setting.\n\n\nA different approach from explicitely accounting for the variance in the value function, introduces the ergodic transform in the objective function during optimisation¬†[24]. For instance, using logarithmic utility directly resolves the broken ergodicity of the return signal in portfolio optimisation.\nIn recent research on RL under non-ergodic contexts,¬†[16] discusses how this transformation can be learned to make reward increments ergodic before computing the return signal. In recent work¬†[17], the optimisation itself is altered to focus on growth rates rather than expected values. By replacing the arithmetic mean with the geometric mean as an objective, the agents learn to optimise average time growth through proper dynamic optimisation.\n\n\nA solution that effectively handles a non-ergodic context is to use an actual distribution in the objective function formulation, rather than relying on a single or several statistical parameters. This re"
  }
]