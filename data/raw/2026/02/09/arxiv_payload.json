[
  {
    "title": "Learning a Generative Meta-Model of LLM Activations",
    "url": "https://arxiv.org/abs/2602.06964v1",
    "source": "arxiv",
    "summary": "Existing approaches for analyzing neural network activations, such as PCA and sparse autoencoders, rely on strong structural assumptions. Generative models offer an alternative: they can uncover structure without such assumptions and act as priors that improve intervention fidelity. We explore this direction by training diffusion models on one billion residual stream activations, creating \"meta-mo",
    "full_text": null
  },
  {
    "title": "InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning",
    "url": "https://arxiv.org/abs/2602.06960v1",
    "source": "arxiv",
    "summary": "Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to opt",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; cs &gt; arXiv:2602.06960v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Computer Science  Computation and Language\n    \n\n    \n      arXiv:2602.06960v1 (cs)\n    \n\n\n  \n    \n  [Submitted on 6 Feb 2026]\n    Title:InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning\n    Authors:Yuchen Yan, Liang Jiang, Jin Jiang, Shuaicheng Li, Zujie Wen, Zhiqiang Zhang, Jun Zhou, Jian Shao, Yueting Zhuang, Yongliang Shen            View a PDF of the paper titled InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning, by Yuchen Yan and 9 other authors\n    View PDF\n\n\n\n    \n            Abstract:Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to optimize when to summarize, what to preserve, and how to resume reasoning. We propose InftyThink+, an end-to-end reinforcement learning framework that optimizes the entire iterative reasoning trajectory, building on model-controlled iteration boundaries and explicit summarization. InftyThink+ adopts a two-stage training scheme with supervised cold-start followed by trajectory-level reinforcement learning, enabling the model to learn strategic summarization and continuation decisions. Experiments on DeepSeek-R1-Distill-Qwen-1.5B show that InftyThink+ improves accuracy by 21% on AIME24 and outperforms conventional long chain-of-thought reinforcement learning by a clear margin, while also generalizing better to out-of-distribution benchmarks. Moreover, InftyThink+ significantly reduces inference latency and accelerates reinforcement learning training, demonstrating improved reasoning efficiency alongside stronger performance.\n    \n\n    \n    \n              \n          Comments:\n          Project Page: this https URL Code: this https URL\n        \n\n          Subjects:\n          \n            Computation and Language (cs.CL); Artificial Intelligence (cs.AI)\n        \n          Cite as:\n          arXiv:2602.06960 [cs.CL]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2602.06960v1 [cs.CL] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2602.06960\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite (pending registration)\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Yuchen Yan [view email]          [v1]\n        Fri, 6 Feb 2026 18:59:27 UTC (3,636 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning, by Yuchen Yan and 9 other authorsView PDFTeX Source\n \n      \n          \n          view license\n        \n    \n        \n    Current browse context: cs.CL\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-02\n  \n    Change to browse by:\n    \n        cs\n        cs.AI\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n          \n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n            Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n            Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n          \n          \n            \n      "
  },
  {
    "title": "Improving Credit Card Fraud Detection with an Optimized Explainable Boosting Machine",
    "url": "https://arxiv.org/abs/2602.06955v1",
    "source": "arxiv",
    "summary": "Addressing class imbalance is a central challenge in credit card fraud detection, as it directly impacts predictive reliability in real-world financial systems. To overcome this, the study proposes an enhanced workflow based on the Explainable Boosting Machine (EBM)-a transparent, state-of-the-art implementation of the GA2M algorithm-optimized through systematic hyperparameter tuning, feature sele",
    "full_text": null
  },
  {
    "title": "DAWN: Dependency-Aware Fast Inference for Diffusion LLMs",
    "url": "https://arxiv.org/abs/2602.06953v1",
    "source": "arxiv",
    "summary": "Diffusion large language models (dLLMs) have shown advantages in text generation, particularly due to their inherent ability for parallel decoding. However, constrained by the quality--speed trade-off, existing inference solutions adopt conservative parallel strategies, leaving substantial efficiency potential underexplored. A core challenge is that parallel decoding assumes each position can be f",
    "full_text": null
  },
  {
    "title": "DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos",
    "url": "https://arxiv.org/abs/2602.06949v1",
    "source": "arxiv",
    "summary": "Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diver",
    "full_text": "\n\n\n\n1 Introduction\n2 Preliminary\n\n3 Approach\n\n3.1 Overview\n3.2 DreamDojo-HV Dataset\n\n3.3 DreamDojo Foundation World Model\n\n3.3.1 Model Architecture\n3.3.2 Pretraining from Human Videos\n3.3.3 Post-Training on Target Robots\n3.3.4 Distillation\n\n\n\n\n\n4 Experiments\n\n4.1 Experimental Setup\n4.2 Effects of Different Action Conditions\n4.3 Effects of Different Data Mixtures\n4.4 Generalization to Unseen Scenarios\n4.5 Ablations of Our Design Choices\n4.6 Benefits of Distillation\n4.7 Downstream Applications\n\n\n5 Conclusion\nA Acknowledgement\nB Related Work\nC Human Preference Evaluation\n\nD Additional Visualizations\n\nD.1 Effects of Our Data Mixtures\nD.2 Effects of Our Model Designs\nD.3 Benefits of Distillation\nD.4 DreamDojo-HV Samples\nD.5 PSNR Curves in Post-Training\nD.6 Value Model\n\n\n\n\n\n\n\nDreamDojo: A Generalist Robot World Model from Large-Scale Human Videos\n\n\n\nShenyuan Gao1,2‚Ä† ‚ÄÑ\nWilliam Liang1,3‚Ä† ‚ÄÑ\nKaiyuan Zheng1,4‚àó ‚ÄÑ\nAyaan Malik1,5‚àó ‚ÄÑ\nSeonghyeon Ye1,6 ‚ÄÑ \nSihyun Yu6 ‚ÄÑ\nWei-Cheng Tseng1,7 ‚ÄÑ\nYuzhu Dong1 ‚ÄÑ\nKaichun Mo1 ‚ÄÑ\nChen-Hsuan Lin1 ‚ÄÑ\nQianli Ma1 ‚ÄÑ \nSeungjun Nah1 ‚ÄÑ\nLoic Magne1 ‚ÄÑ\nJiannan Xiang8 ‚ÄÑ\nYuqi Xie1 ‚ÄÑ\nRuijie Zheng1 ‚ÄÑ\nDantong Niu1,3 ‚ÄÑ \nYou Liang Tan1 ‚ÄÑ\nK.R. Zentner1 ‚ÄÑ\nGeorge Kurian1 ‚ÄÑ\nSuneel Indupuru1 ‚ÄÑ\nPooya Jannaty1 ‚ÄÑ\nJinwei Gu1 ‚ÄÑ \nJun Zhang2 ‚ÄÑ\nJitendra Malik3 ‚ÄÑ\nPieter Abbeel3 ‚ÄÑ\nMing-Yu Liu1 ‚ÄÑ\nYuke Zhu1,9‚Ä° ‚ÄÑ\nJoel Jang1‚Ä° ‚ÄÑ\nLinxi ‚ÄúJim‚Äù Fan1‚Ä°\n1NVIDIA ‚ÄÇ‚ÄÑ‚Ää2HKUST ‚ÄÇ‚ÄÑ‚Ää3UC Berkeley ‚ÄÇ‚ÄÑ‚Ää4UW ‚ÄÇ‚ÄÑ‚Ää5Stanford ‚ÄÇ‚ÄÑ‚Ää6KAIST ‚ÄÇ‚ÄÑ‚Ää7UofT ‚ÄÇ‚ÄÑ‚Ää8UCSD ‚ÄÇ‚ÄÑ‚Ää9UT Austin \n‚Ä†Co-First Authors ‚ÄÇ‚ÄÑ‚Ää‚àóCore Contributors ‚ÄÇ‚ÄÑ‚Ää‚Ä°Project Leads \ndreamdojo-world.github.io\n\n\n\n\n\n\nAbstract\nBeing able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diverse interactions and dexterous controls from 44k hours of egocentric human videos. Our data mixture represents the largest video dataset to date for world model pretraining, spanning a wide range of daily scenarios with diverse objects and skills. To address the scarcity of action labels, we introduce continuous latent actions as unified proxy actions, enhancing interaction knowledge transfer from unlabeled videos. After post-training on small-scale target robot data, DreamDojo demonstrates a strong understanding of physics and precise action controllability. We also devise a distillation pipeline that accelerates DreamDojo to a real-time speed of 10.81 FPS and further improves context consistency. Our work enables several important applications based on generative world models, including live teleoperation, policy evaluation, and model-based planning. Systematic evaluation on multiple challenging out-of-distribution (OOD) benchmarks verifies the significance of our method for simulating open-world, contact-rich tasks, paving the way for general-purpose robot world models.\n\n\n\\abscontent\n\n\n\n1 Introduction\n\nWorld models, which predict futures based on actions, have emerged as a key component in the development of generalist robots (sutton1991dyna; lecun2022path; hu2023toward; richens2025general). Recent advances in video generation (ali2025world; team2025wan) have driven video world models, in which future states are represented as video frames (parker2025genie; russell2025gaia; sun2025worldplay). However, they primarily plateau at discrete controls, while the high-dimensional action spaces for contact-rich robot tasks have yet to make similar progress. Unlike game and driving data, robot data often has limited coverage due to hardware variability and collection cost. The nearly infinite variety of real-world environments can easily exceed the distribution of available robot data. Additionally, existing datasets predominantly consist of expert demonstrations, lacking the stochasticity in intentions necessary for learning strong action controllability. As a result, existing video world models remain confined to simulating observed setups and are often unresponsive to counterfactual actions, constraining their applicability for diverse scenarios and complex tasks.\n\n\nIn this work, we introduce DreamDojo, a foundation world model for open-world dexterous robot tasks. Unlike previous methods that typically rely on teleoperation data, we exploit human videos for pretraining. Despite the embodiment gap, the underlying physics during interactions is largely consistent between humans and robots, enabling effective knowledge transfer. Therefore, we curate the largest egocentric human video dataset to date, DreamDojo-HV (Human Videos), which comprises 44k hours of video sequences, surpassing the datasets used in prior works by several orders of magnitude. In addition to its scale, DreamDojo-HV incorporates an exceptionally diverse range of activities, encompassing approximately 96√ó\\times more skills and 2,000√ó\\times more scenes than the most diverse public datasets for robot learning (khazatsky2024droid; bu2025agibot). This provides us with a rich corpus for learning physics and dynamics about diverse interactions.\n\n\nNevertheless, fine-grained action labels are much scarcer than raw videos at scale. Naively training on passive videos overlooks the causality between video observations and actions, leading to inferior knowledge transfer for action-conditioned world simulation. Moreover, converting various action formats into a unified one entails inevitable engineering effort. To address these challenges, we introduce continuous latent actions (gao2025adaworld) as unified proxy actions for all videos. The proposed latent action model can extract semantically meaningful actions between frames in a self-supervised manner, ensuring effective transfer of both physics and controllability as the data scales to the internet level. Through rigorous designs of model architecture and training recipe, DreamDojo is able to acquire a comprehensive understanding of physics, achieving plausible simulations across diverse environments and fine-grained controllability over continuous robot actions.\n\n\nTo achieve real-time prediction without visual degradation, we further introduce a distillation pipeline following the Self Forcing paradigm (huang2025self). Our distillation also enhances the long-horizon consistency by efficiently modeling a short temporal context. The resulting model can autoregressively predict future frames at a resolution of 640√ó480640\\times 480 at 10.81 FPS for an arbitrary horizon, significantly reducing the cost for various downstream applications such as live teleoperation and model-based planning.\n\n\nIn summary, our main contributions include:\n\n\n\n\n‚Ä¢\n\nA large-scale video dataset, DreamDojo-HV, that accumulates 44k hours of egocentric experiences from a wide spectrum of daily activities. To the best of our knowledge, this is the largest and most diverse data corpus to date for world model learning.\n\n\n\n‚Ä¢\n\nA foundation world model for general-purpose robots. By scaling up human videos and introducing continuous latent actions as unified proxy, we present DreamDojo, the first world model of its kind that shows zero-shot generalization to unseen objects and novel environments.\n\n\n\n‚Ä¢\n\nA distillation pipeline that enables efficient autoregressive prediction and improves context consistency. The final model can be interacted with for more than 1 minute in real time without degradation.\n\n\n\n‚Ä¢\n\nMultiple downstream applications highlight the potential of DreamDojo in performing live teleoperation, policy evaluation, model-based planning, \\etc, accelerating the development of robot policies.\n\n\n\n\n\n\n\n2 Preliminary\n\nFigure 1: DreamDojo overview. DreamDojo acquires comprehensive physical knowledge from large-scale human datasets by utilizing latent actions as unified labels. After post-training and distillation on the target robots, our model can predict the future world in real time with continuous action controls. DreamDojo can robustly generalize to various objects and environments, facilitating large-scale policy evaluation without real-world deployment. It also enables live teleoperation and online model-based planning.\n\n\nInteractive world model. The objective of an interactive world model is to infer future states based on actions. Formally, given an action a‚ààùíúa\\in\\mathcal{A}, the interactive world model acts as a state transition function that samples the next state:\n\n\n\nst+1‚àºp(‚ãÖ|st,at),s_{t+1}\\sim p(\\cdot|s_{t},a_{t}),\n\n(1)\n\n\nwhere p:ùíÆ√óùíú‚ÜíŒî‚Äã(ùíÆ)p:\\mathcal{S}\\times\\mathcal{A}\\rightarrow\\Delta(\\mathcal{S}) is the transition distribution. In this paper, the term ‚Äúworld model‚Äù refers specifically to this category unless otherwise stated.\n\n\nCosmos-Predict2.5 model. We establish our world model on the pretrained Cosmos-Predict2.5 model (ali2025world), a latent video diffusion model that predicts future frames with text and conditional frame inputs. The Cosmos-Predict2.5 model operates in the continuous latent space produced by WAN2.2 tokenizer (team2025wan). It injects language and timestep conditions into each DiT block (peebles2022scalable). The text embedding is processed by cross-attention layers, while the timestep information is first encoded by sinusoidal embeddings, projected by a lightweight MLP, and then used by adaptive layer normalization for dynamic modulations (scale, shift, gate) (ali2025world). The whole network is trained using flow matching loss (lipman2022flow). Specifically, given the noise corrupted video latent ùê±t\\mathbf{x}_{t} at timestep tt, the flow matching loss minimizes the prediction error with the ground-truth velocity ùêØt\\mathbf{v}_{t}:\n\n\n\n‚Ñíflow‚Äã(Œ∏)=ùîºùê±,œµ,ùêú,t‚Äã‚ÄñùêÆ‚Äã(ùê±t,t,ùêú;Œ∏)‚àíùêØt‚Äñ2,\\mathcal{L}_{\\text{flow}}(\\theta)=\\mathbb{E}_{\\mathbf{x},\\epsilon,\\mathbf{c},t}\\left\\|\\mathbf{u}(\\mathbf{x}_{t},t,\\mathbf{c};\\theta)-\\mathbf{v}_{t}\\right\\|^{2},\n\n(2)\n\n\nwhere ùêØt\\mathbf{v}_{t} is a difference between the noise œµ\\"
  },
  {
    "title": "Agentic Uncertainty Reveals Agentic Overconfidence",
    "url": "https://arxiv.org/abs/2602.06948v1",
    "source": "arxiv",
    "summary": "Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination tha",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Methods\n\n2.1 Problem Setup\n\n2.2 Uncertainty Agents\n\n2.2.1 Pre-Execution Agent\n2.2.2 Mid-Execution Agent\n\n2.2.3 Post-Execution Agent\n\nAdversarial post-execution variant.\n\n\n\n\n\n\n\n3 Experiments\n\n3.1 Setup\n3.2 Pervasive Overconfidence\n3.3 Less Information, Better Discrimination\n3.4 Mid-Execution: Uninformative Doubt\n\n3.5 Adversarial Framing Reduces Overconfidence\n\nShift vs. signal decomposition.\n\n\n3.6 Ensemble Methods\n3.7 Self-Preference Ablation\n\n\n\n4 Related Work\n\nConcurrent work\nLLM uncertainty estimation.\nOverconfidence in LLMs.\nSelf-verification and self-correction.\nLLM-as-judge and self-preference.\nAI control.\nLearned verifiers.\n\n\n\n5 Limitations and Future Work\n\nBeyond software engineering.\nTrained verifiers for self-assessment.\nHybrid deployment strategies.\nMulti-agent uncertainty propagation.\nSample size.\nScaling laws for calibration.\n\n\n6 Conclusion\n\n\n\n\n\nAgentic Uncertainty Reveals Agentic Overconfidence\n\n\nJean Kaddour\n\n‚ÄÉ‚ÄÉ\nSrijan Patel\n\n‚ÄÉ‚ÄÉ\nGb√®tondji Dovonon\n\n‚ÄÉ‚ÄÉ\nLeo Richter\n\n‚ÄÉ‚ÄÉ\nPasquale Minervini\n\n‚ÄÉ‚ÄÉ\nMatt J. Kusner\n\n\n\nAbstract\nCan AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination than standard post-execution review, though differences are not always significant. Adversarial prompting reframing assessment as bug-finding achieves the best calibration.\n\nMachine Learning, ICML\n\n\n\n1 Introduction\n\nA software engineer needs to fix an auth service error. Before delegating to an AI coding agent, she asks: what are the chances this succeeds?\n\n\n\n\nPre-Exec.  P(success): 72%\nThe issue is clear and well-defined, the error message points directly to the problem, and the fix follows existing patterns in the codebase.\n\n\n\nFigure 1: Agentic overconfidence. We measure the overconfidence as the difference between the estimated success probability and the true success probability (true rates: GPT-5.2 Codex 35%, Gemini-3-Pro 22%, Opus 4.5 27%). We plot three strategies: pre-, post-, and adversarial-post-execution. All agents systematically overestimate their success.\n\n\n72% confidence before any code is written. As the coding agent works, she asks another agent to monitor progress:\n\n\n\n\nMid-Exec.  P(success): 78%\nThe agent has correctly diagnosed the problem and knows exactly what code to add. The probability of success is high.\n\n\n\nConfidence rises to 78%. The patch is now complete. She fires off a review agent:\n\n\n\n\nPost-Exec.  P(success): 92%\nThe patch is a correct and complete fix. It‚Äôs a minimal, focused change that adds the missing interface method.\n\n\n\nToo optimistic. Let‚Äôs spawn an adversarial agent.\n\n\n\n\nAdv. Post-Exec.  P(success): 85%\nMinor concerns don‚Äôt affect the main use case... the patch correctly resolves the reported issue.\n\n\n\nStill 85%. All four agents confidently predict success.\n\n\nBut the patch fails! And this agentic overconfidence is systematic. For example, GPT-5.2-Codex-based post-execution agents predict 73% success against a true rate of 35% averaged over 100 SWE-Bench-Pro (Deng et al., 2025) tasks.\n\n\nThis matters because the scope of autonomous work is expanding rapidly. The effective length of tasks that AI agents complete has doubled every 7 months for six years¬†(METR, 2025). As we increasingly delegate complex workflows to agents\n(Appel et al., 2025), we must develop scalable oversight protocols (Bowman et al., 2022).\n\n\nIn this work, we elicit agentic uncertainty at three points in a coding agent‚Äôs lifecycle: pre-, mid-, and post-execution. Each corresponds to a different oversight question: Can agents predict failure before committing resources? Can they recognize failure as it unfolds? Can they verify their own work? Importantly, we use the same underlying model for both the coding agent that produces patches and the uncertainty agent that assesses them, isolating the effect of information access from differences in model capability.\n\n\nOur experiments on 100 SWE-bench Pro tasks across three frontier models (GPT-5.2-Codex, Gemini-3-Pro, Claude Opus 4.5) reveal several striking findings:\n\n\n‚Ä¢\n\nPervasive overconfidence. Post-execution agents can predict 73% success on average against a 35% base rate (GPT), with similar gaps across all models.\n\n\n\n‚Ä¢\n\nMore context, uncalibrated doubt. Mid-execution agents develop ‚Äúcold feet‚Äù: confidence decreases as they observe their partial work, but this doubt is uninformative, occurring equally for successes and failures.\n\n\n\n‚Ä¢\n\nAdversarial framing helps. Prompting agents to ‚Äúfind bugs‚Äù rather than ‚Äúverify correctness‚Äù reduces overconfidence by up to 15 pp and tends to achieve the best calibration across models in our setup.\n\n\n\n\n\n0‚Äì25%25‚Äì75%100%\n\nPRE-EXECUTIONTask + repo\n\nMID-EXECUTIONTask + repo +partial trajectory\n\nPOST-EXECUTIONTask + repo+ patch\n\nADV. POST-EXEC.Task + repo + patch+ ‚Äúfind bugs‚Äù\n\nFigure 2: Agentic Uncertainty Regimes. Each regime observes different information. Post-execution and adversarial post-execution occur at the same point but use different prompts.\n\n\n\n\n2 Methods\n\n\n2.1 Problem Setup\n\nWe define agentic uncertainty as an agent‚Äôs estimate of the probability that an agent built on the same underlying model will successfully complete a task. The uncertainty (-estimating) agent may use a different system prompt or have access to different information than the task-solving agent, but shares the same base model.\n\n\nUnlike standard uncertainty quantification, which focuses on confidence in individual predictions or token probabilities, agentic uncertainty concerns the outcome of an entire multi-step trajectory: will this sequence of observations, reasoning, and actions culminate in task success?\n\n\nKadavath et al. (2022) introduced P(IK): ‚Äúprobability that I know,‚Äù measuring whether models can predict which questions they can answer correctly. We generalize this to agentic settings and call it P(IS): ‚Äúprobability that I succeed.‚Äù Formally, given a task tt, base model MM, and information state ‚Ñê\\mathcal{I} available at elicitation time:\n\n\n\nP(IS)‚âîP(agentM¬†succeeds on¬†t|‚Ñê)P(\\text{IS})\\;\\coloneqq\\;P\\!\\left(\\text{agent}_{M}\\text{ succeeds on }t\\;\\middle|\\;\\mathcal{I}\\right)\n\n(1)\n\n\nwhere ‚Ñê\\mathcal{I} may include the task description, repository state, partial trajectory, or proposed patch, depending on the elicitation regime.\nFor example, where P(IK) asks ‚Äúdo I know the capital of France?‚Äù, a question about factual recall, P(IS) asks ‚Äúcan I fix this bug through a sequence of file edits, shell commands, and test runs?‚Äù\n\n\n\n\n2.2 Uncertainty Agents\n\nWe consider three points in an agent‚Äôs life cycle to elicit uncertainty estimates: before attempting a solution, during execution, and after producing a solution.\n\n\nEach uncertainty agent interacts with a sandbox environment through tool use: reading files, searching code, and inspecting version history. This shared infrastructure means agents can actively gather evidence to inform their estimates. The key distinction is the information available at uncertainty estimation time.\n\n\n\n2.2.1 Pre-Execution Agent\n\nIn the pre-execution setting, an agent receives only the task description (e.g., a GitHub issue) and read-only access to the repository. Crucially, the agent cannot execute code, run tests, or modify files. If it could attempt solutions and observe test results, it might anchor on its own partial solution rather than reasoning abstractly about the task.\nThe agent must form an estimate based on cues, e.g., the complexity of the codebase, rather than through trial and error.\n\n\n\n\n2.2.2 Mid-Execution Agent\n\nMid-execution asks whether can we detect failure in progress?\nRather than eliciting estimates at a single point, we prompt the agent at 25%, 50%, and 75% of total agent steps (tool calls and reasoning turns) to estimate the success probability given the trajectory so far.\nIf these estimates reliably decrease as agents approach failure, we could implement early stopping or human escalation before resources are wasted on doomed approaches.\n\n\n\n\n2.2.3 Post-Execution Agent\n\nOnce a task solution has been proposed, can we trust an agent‚Äôs self-assessment that it is correct? This is the default scenario when ground-truth verification is unavailable. If post-execution agents are well-calibrated, we can use their success estimates to route submissions with low estimate of success to human reviewers while auto-accepting solutions with high estimates. If they are poorly calibrated, this delegation becomes dangerous.\n\n\nIn the post-execution setting, an agent receives both the task description and a proposed patch written by another agent. The repository is in its post-patch state, where the changes have already been applied, and the agent can explore the modified codebase. After assessment, the agent estimates whether the patch successfully solves the task.\n\n\nAdversarial post-execution variant.\n\nWe also evaluate a variant that explicitly prompts agents to find bugs before estimating confidence. Rather than asking ‚Äúis this correct?‚Äù, adversarial post-execution asks ‚Äúwhat bugs can you find?‚Äù This reframes the task from verification to falsification, potentially counteracting confirmation bias that is encouraged by the vanilla post-execution framing, asking whether a patch is correct.\n\n\n\n\n\n\n\n\n\n\nPre-Exec.\n\n\nExplore the repository to understand the issue, then estimate P(success).\n\nRead-only: cat, grep, find, git log/diff/blame\nBlocked: Modifications, code execution\n\n\n\n\n\n\n\n\n\n\n\nMid-Exec.\n\n\nEvaluate agent progress at 25/50/75% of execution.\n\nConsider:\n- Is the approach sound?\n- Root cause identified?\n- Signs of confusion?\n\n\n\n\n\n\n\n\n\n\n\nPost-Exec.\n\n\nReview the proposed patch:\n\n‚Äò‚Äò‚Äòdiff\n{{ patch }}\n‚Äò‚Äò‚Äò\n\nEstimate P(correct).\n\n\n\n\n\n\n\n\n\n\n\n\nAdv. Post-Exec.\n\n\nYour job is to find problems: edge ca"
  },
  {
    "title": "Optimal Derivative Feedback Control for an Active Magnetic Levitation System: An Experimental Study on Data-Driven Approaches",
    "url": "https://arxiv.org/abs/2602.06944v1",
    "source": "arxiv",
    "summary": "This paper presents the design and implementation of data-driven optimal derivative feedback controllers for an active magnetic levitation system. A direct, model-free control design method based on the reinforcement learning framework is compared with an indirect optimal control design derived from a numerically identified mathematical model of the system. For the direct model-free approach, a po",
    "full_text": null
  },
  {
    "title": "Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay",
    "url": "https://arxiv.org/abs/2602.06942v1",
    "source": "arxiv",
    "summary": "Tokenization is a pivotal design choice for neural language modeling in morphologically rich languages (MRLs) such as Turkish, where productive agglutination challenges both vocabulary efficiency and morphological fidelity. Prior studies have explored tokenizer families and vocabulary sizes but typically (i) vary vocabulary without systematically controlling the tokenizer's training corpus, (ii) p",
    "full_text": "\n\n\n\n1 Introduction\n2 Related Work\n\n3 Datasets\n\n\n3.1 Benchmarking\n\nSemantic (TrGLUE)\nNamed Entity Recognition (NER)\nSyntax and Morphology (BOUN Treebank)\n\n\n\n3.2 Morphological segmentation\n\n\n4 Tokenization Metrics\n\n\n4.1 Tokenization Granularity and Fragmentation Metrics\n\n4.1.1 Fertility\n4.1.2 Token continuation rate (cross-token span frequency)\n4.1.3 Interpreting the metric pair\n\n\n\n4.2 Morphology-Aware Tokenization Metrics\n\n4.2.1 Setup and Notation\n\n4.2.2 Core Metrics\n\n1) Mean subwords per word\n2) Boundary precision, recall, and micro-F1\n3) Boundary macro-F1\n4) Lemma boundary hit rate\n5) Lemma single-token rate\n6) Over-/Under-segmentation indices\n7) Sequence agreement: CER and WER\n\n\n\n4.2.3 Supporting Metrics\n\nAffix coverage and atomicity\n\n\n\n4.2.4 Worked examples\n\n\n5 Pre-Transformer Tokenization Benchmarks\n\n\nTokenization schemes\n\n\nModeling overview\n\n\n5.1 Character-Level Tokenization\n\n5.1.1 TrGLUE\n5.1.2 NER\n5.1.3 POS-DEP-Morph\n\n5.1.4 Key Findings\n\n\n5.2 Word-Level Tokenization\n\n\n5.2.1 TrGLUE\n\nCoLA\nSST-2\n\n\n5.2.2 NER\n5.2.3 POS-DEP-Morph\n5.2.4 Explainability\n\n5.2.5 Key Findings\n\n\n5.3 Morphology-Aware Subwords\n\n5.3.1 TrGLUE\n5.3.2 NER\n5.3.3 POS-DEP-Morph\n5.3.4 Explainability\n\n5.3.5 Key Findings\n\n\n6 WordPiece Tokenization\n\n6.1 Pretraining Corpus\n6.2 Training WordPiece Tokenizers\n\n6.3 Tokenization Behavior Across Corpora and Vocabulary Sizes\n\n6.3.1 Corpus Size, Vocabulary Size, and Fragmentation\n6.3.2 Tokenizer Morphology Diagnostics: Results and Discussion\n\n\n\n6.4 Transformer Benchmarking of WordPiece Tokenizers\n\n6.4.1 Pretraining the Transformers\n6.4.2 Pretraining Times\n\n6.4.3 Downstream Results and Analysis\n\nTrGLUE\nSubword statistics and downstream success\nMorphology alignment and downstream success\nTrGLUE Explainability\nNER\nNER Explainability\nPOS‚ÄìDEP‚ÄìMorph\nPOS-DEP-Morph Explainability\n\n\n\n\n\n6.5 Key Findings\n\n\n7 Optimal Ways of Tokenizing Turkish\n\n\n8 Conclusion\n\nAcknowledgments\nData Availability\n\nEthical Standards\n\nA Explainability Tools\nB Comprehensive Morphology Diagnostics by Vocabulary Size\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data‚ÄìVocabulary‚ÄìMorphology Interplay\n\n\nDuygu Altinok\n\nIndependent Researcher, Berlin, Germany\n\n[\n\n\n\nAbstract\nTokenization is a pivotal design choice for neural language modeling in morphologically rich languages (MRLs) such as Turkish, where productive agglutination challenges both vocabulary efficiency and morphological fidelity. Prior studies have explored tokenizer families and vocabulary sizes, but they typically (i) vary vocabulary without systematically controlling the tokenizer‚Äôs training corpus, (ii) provide limited intrinsic diagnostics of segmentation quality, and (iii) evaluate a narrow slice of downstream tasks. We present the first and only comprehensive, principled study of Turkish subword tokenization‚Äî a subwords manifest ‚Äîthat jointly varies vocabulary size and tokenizer training corpus size (data‚Äìvocabulary coupling), compares multiple tokenizer families under matched parameter budgets (WordPiece, morphology-level, and character baselines), and evaluates across semantic (NLI, STS, sentiment analysis, NER), syntactic (POS, dependency parsing), and morphology-sensitive probes. To explain why tokenizers succeed or fail, we introduce a morphology-aware diagnostic toolkit that goes beyond coarse aggregates to boundary-level micro/macro-F1 over gold morpheme boundaries, decoupled lemma atomicity vs·π°urface boundary hits, over-/under-segmentation indices, character/word edit distances (CER/WER), continuation rates, and affix-type coverage and token-level atomicity. Our contributions are fourfold: (i) a systematic investigation of the vocabulary‚Äìcorpus‚Äìsuccess triad for Turkish, including larger data regimes than prior work; (ii) a unified, morphology-aware evaluation framework linking intrinsic diagnostics to extrinsic outcomes; (iii) extensive, controlled comparisons that identify when character-level and morphology-level tokenization pay off; and (iv) full open-source release of evaluation code, tokenizer training pipelines, and interim Transformer checkpoints for reproducibility. As the first and only work of its kind, this subwords manifest delivers actionable, prescriptive guidance for building effective tokenizers in MRLs and establishes a reproducible foundation for future research and deployment.\n\n\nkeywords: Turkish subwords, Turkish morphology, Turkish subword tokenization, Turkish tokenizers, Turkish WordPiece, Turkish NLP\n\n\nF. Author]duygu@turkish-nlp-suite.com\n\n\n\n1 Introduction\n\nSince the advent of Transformer architectures‚Äîfrom encoder-only models like BERT undefg  to decoder-only large language modelsundefp , tokenizers have drawn sustained attention, especially their underlying algorithms. For non-English and, in particular, morphologically rich languages (MRLs), tokenization becomes even more consequential: how vocabularies are compressed, how subwords align with linguistic units (morphemes), and how compression choices affect downstream task performance are central design questions.\n\n\nTokenization is the first‚Äîand often most consequential‚Äîinterface between raw text and neural language models. Its design determines how linguistic structure is exposed to the model, how parameters are allocated, and how efficiently sequences are represented. For MRLs such as Turkish, where productive agglutination creates long and sparse surface forms undefq , tokenization is not merely a preprocessing choice but a core modeling decision. Word-level tokenization explodes the vocabulary and invites out-of-vocabulary failures; character- or byte-level tokenization lengthens sequences and obscures morpheme boundaries; and off-the-shelf subword tokenizers (e.g. BPE undefu , WordPiece undefg , Unigram undefm ) often fragment stems or smear affixes, weakening the model‚Äôs access to syntactic and morphological cues.\n\n\nIn Turkish specifically, the central practical question is how to represent and leverage morphology. Naturally Transformer type tokenizers such as WordPiece and BPE attracted attention from research side. Recent work has examined aspects of this problem in Turkish: suffix-preserving tokenizers have shown modest, consistent gains on select tasks; RoBERTa-scale comparisons have tied vocabulary size to downstream performance; and WordPiece/BPE have remained strong baselines. Yet, these studies largely vary vocabulary size without systematically controlling or scaling the tokenizer‚Äôs training corpus, provide limited intrinsic diagnostics of segmentation quality, and evaluate a narrower slice of tasks‚Äîoften omitting morphology- and syntax-sensitive settings where boundary fidelity matters most. As a result, practitioners lack prescriptive guidance on when to favor larger vocabularies, morphology-aware tokenizers, or byte/character regimes, and how tokenizer training data interacts with these choices.\n\n\nMotivated by these gaps, we argue that Turkish subword modeling and morphological structure have not been dissected in sufficient depth. This paper advances tokenization for Turkish from ad hoc exploration to principled design. We present the first comprehensive study that jointly varies vocabulary size and tokenizer training corpus size (data‚Äìvocabulary coupling), compares multiple tokenizer families under matched parameter budgets (WordPiece, morphology-level, and character baselines), and evaluates across a broad suite of downstream tasks spanning semantic (NLI, STS, NER, sentiment analysis), syntactic (POS, dependency parsing), and morphology-sensitive probes. To explain why tokenizers succeed or fail, we introduce a morphology-aware diagnostic toolkit that moves beyond coarse aggregates (e.g., fertility) to boundary-level micro/macro-F1 over gold morpheme boundaries, decoupled lemma atomicity etc·π°urface boundary hits, over-/under-segmentation indices, character/word edit distances (CER/WER), continuation rates, and affix-type coverage and token-level atomicity.\n\n\nOur contributions are fourfold:\n(i) A systematic investigation of the vocabulary‚Äìcorpus‚Äìsuccess triad for Turkish tokenization, including larger data regimes than prior work.\n(ii) A unified, morphology-aware evaluation framework that links intrinsic segmentation diagnostics to extrinsic task outcomes, enabling causal interpretation rather than post hoc correlation.\n(iii) Extensive, controlled comparisons across tokenizer families and parameter allocations, including conditions where character-level tokenization is competitive (e.g., NER) and when morphology-level tokenization pays off.\n(iv) Open-source release of all evaluation code, tokenizer training pipelines, and interim Transformer checkpoints to ensure full reproducibility and to facilitate further research and deployment in Turkish NLP.\n\n\nPositioned as a manifest in Turkish subwords, our study is the first and only of its kind to integrate large-scale tokenizer data sweeps, fine-grained morphological diagnostics, and the widest coverage of morphology- and syntax-sensitive tasks. We transform fragmented observations into actionable, prescriptive rules for building tokenizers that actually work for morphologically rich languages‚Äîgrounded in evidence, reproducible by design, and immediately useful to both researchers and practitioners. We offer all our work freely, all evaluation and training scripts under our Github repository 111https://github.com/turkish-nlp-suite/Turkish-subwords-research and Transformer models under our Hugging Face repository222https://huggingface.co/collections/turkish-nlp-suite/turkish-subwords-research.\n\n\n\n\n2 Related Work\n\nIn this section, we present works directly related to our study and compare them to our contributions.\n\n\nundefi  investigates how subword tokenization interacts with Turkish morphology and whether morphology-aware tokenization improves modeling and downstream tasks. The study compares BPE, WordPiece, and Unigram across corpus and vocabulary sizes on Tu"
  },
  {
    "title": "Endogenous Resistance to Activation Steering in Language Models",
    "url": "https://arxiv.org/abs/2602.06941v1",
    "source": "arxiv",
    "summary": "Large language models can resist task-misaligned activation steering during inference, sometimes recovering mid-generation to produce improved responses even when steering remains active. We term this Endogenous Steering Resistance (ESR). Using sparse autoencoder (SAE) latents to steer model activations, we find that Llama-3.3-70B shows substantial ESR, while smaller models from the Llama-3 and Ge",
    "full_text": null
  },
  {
    "title": "From Core to Detail: Unsupervised Disentanglement with Entropy-Ordered Flows",
    "url": "https://arxiv.org/abs/2602.06940v1",
    "source": "arxiv",
    "summary": "Learning unsupervised representations that are both semantically meaningful and stable across runs remains a central challenge in modern representation learning. We introduce entropy-ordered flows (EOFlows), a normalizing-flow framework that orders latent dimensions by their explained entropy, analogously to PCA's explained variance. This ordering enables adaptive injective flows: after training, ",
    "full_text": null
  },
  {
    "title": "Cochain Perspectives on Temporal-Difference Signals for Learning Beyond Markov Dynamics",
    "url": "https://arxiv.org/abs/2602.06939v1",
    "source": "arxiv",
    "summary": "Non-Markovian dynamics are commonly found in real-world environments due to long-range dependencies, partial observability, and memory effects. The Bellman equation that is the central pillar of Reinforcement learning (RL) becomes only approximately valid under Non-Markovian. Existing work often focus on practical algorithm designs and offer limited theoretical treatment to address key questions, ",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Preliminaries\n\n2.1 Occupancy Measures\n2.2 Cochain Spaces and Inner Products\n2.3 Discrete de Rham Differential and Hodge Laplacian\n\n\n\n3 Topological Bellman Decomposition\n\n3.1 Bellman Error as a 1-Cochain\n3.2 Topological integrability and exact 1-cochains\n3.3 Hodge-type decomposition\n3.4 Poisson characterization of the optimal potential\n3.5 Measuring Bellman non-integrability\n\n\n4 HodgeFlow Policy Search\n5 Sensitivity and Robustness Analysis\n\n6 Experiments\n\nSynthetic settings.\nControl benchmarks and the Nonmarkov regime.\nBaselines and reporting.\nSynthetic results: validating the topological decomposition\nControl benchmarks: Nonmarkov learning curves\nDerived diagnostics from learning-curve data\n\n\n7 Conclusion\n\nA Implementation of HodgeFlow Policy Search\n\nA.1 Common RL framework\nA.2 Shared neural architectures\nA.3 Stable HFPS with clipping and inner-loop updates\n\nA.4 Residual-adaptive and norm-preserving TD updates\n\nInstantiation in synthetic experiments.\nInstantiation in control benchmarks.\n\n\n\n\n\nB Additional regimes, full tables, and Nonmarkov construction\n\nB.1 Nonmarkov regime via hidden control-command memory\n\nB.2 Control benchmarks under Clean/Noisy/Sticky regimes\n\nLearning curves (Clean/Noisy/Sticky).\nDerived diagnostics (cAUC and Std).\n\n\nB.3 Aggregate summary table (all benchmark‚Äìregime pairs)\n\n\n\nC Proof\n\nC.1 Proof of Lemma¬†2.4\nC.2 Proof of Theorem¬†3.4\nC.3 Proof of Corollary¬†3.5\nC.4 Proof of Theorem¬†3.6\nC.5 Proof of Theorem¬†3.7\nC.6 Proof of Theorem¬†3.8\nC.7 Proof of Corollary¬†3.9\nC.8 Proof of Theorem¬†5.1\nC.9 Proof of Theorem¬†5.2\nC.10 Proof of Theorem¬†5.3\nC.11 Proof of Corollary¬†5.4\nC.12 Proof of Proposition¬†5.5\n\n\n\n\n\n\n\nCochain Perspectives on Temporal-Difference Signals for Learning Beyond Markov Dynamics\n\n\n\nZuyuan Zhang\nThe George Washington University\nzuyuan.zhang@gwu.edu\n&amp;Sizhe Tang\nThe George Washington University\ns.tang1@gwu.edu\n&amp;Tian Lan\nThe George Washington University\ntlan@gwu.edu\n\n\n\nAbstract\nNon-Markovian dynamics are commonly found in real-world environments due to long-range dependencies, partial observability, and memory effects. The Bellman equation that is the central pillar of Reinforcement learning (RL) becomes only approximately valid under Non-Markovian. Existing work often focus on practical algorithm designs and offer limited theoretical treatment to address key questions, such as what dynamics are indeed capturable by the Bellman framework and how to inspire new algorithm classes with optimal approximations. In this paper, we present a novel topological viewpoint on temporal-difference (TD) based RL. We show that TD errors can be viewed as 1-cochain in the topological space of state transitions, while Markov dynamics are then interpreted as topological integrability. This novel view enables us to obtain a Hodge-type decomposition of TD\nerrors into an integrable component and a topological residual, through a Bellman‚Äìde Rham projection. We further propose HodgeFlow Policy Search (HFPS) by fitting a potential network to minimize the non-integrable projection residual in RL, achieving stability/sensitivity guarantees. In numerical evaluations, HFPS is shown to significantly improve RL performance under non-Markovian.\n\n\n\n1 Introduction\n\nModern reinforcement learning (RL) systems are increasingly deployed in long-horizon, complex-dynamics environments, where long-range dependencies, partial observability, and memory effects are commonly found in these real-world processes¬†(Arulkumaran et al., 2017; Garcƒ±a and Fern√°ndez, 2015; possama√Ø2024policyiterationalgorithmnonmarkovian; Zhang et al., 2024; Qiao et al., 2024; Ravari et al., 2024; Zhang et al., 2025b, a). The classical Markov assumption is often violated. The Bellman equation that is the central pillar of RL becomes only approximately valid: Temporal-difference (TD) errors demonstrate non-markovian structures that cannot be removed by simply increasing function class representations or tuning optimization hyper-parameters\n(Sutton, 1988; Tsitsiklis and Van Roy, 1996; Baird and others, 1995; Sutton et al., 2009).\n\n\nExisting work often focuses on proposing RL algorithms with high-order Markov approximations by leveraging memory mechanisms to embed (or summarize) state/action histories. Classical treatments of partial observability introduce internal-state or finite-memory policy representations, e.g., finite-state controllers and internal-state policy gradients¬†(Meuleau et al., 2013; Aberdeen and Baxter, 2025; Zhang et al., 2026b; Zou et al., 2024; Kaelbling et al., 1998). In deep RL, recurrent and sequence-based architectures are widely used to encode dependence, including DRQN-style recurrent value learning¬†(Hausknecht and Stone, 2015), recurrent distributed replay (R2D2)¬†(Kapturowski et al., 2018), recurrent actor‚Äìcritic systems such as IMPALA with V-trace¬†(Espeholt et al., 2018), and attention/transformer memory architectures such as GTrXL¬†(Parisotto et al., 2020). In multi-agent RL, recurrent extensions such as R-MADDPG similarly leverage recurrency to handle partial observability and limited communication¬†(Wang et al., 2020). Recent efforts have also investigated efficient dependence representations via sliding windows¬†(Tasse et al., 2025) and approximations under certain conditional laws¬†(possama√Ø2024policyiterationalgorithmnonmarkovian). However, there has been very limited theoretical treatment to address the key questions regarding non-Markovian RL: What dynamics are mathematically capturable by the Bellman framework? How to obtain optimal Markov approximations? Can we go beyond memory approaches and inspire novel algorithm classes under non-Markovian?\n\n\nThis paper presents a novel topological viewpoint and framework for TD-based RL under non-Markovian. In particular, we show that TD errors can be viewed as 1-cochain in the topological space of state transitions. Markov dynamics are then interpreted as topological integrability: One-step discrepancies encoded by TD errors can be fully explained by a single global potential uu, moving along any transition simply increases the potential by u‚Äã(s‚Ä≤)‚àíŒ≥‚Äãu‚Äã(s)u(s^{\\prime})-\\gamma u(s)¬†(Desbrun et al., 2006; Jiang et al., 2011; Lim, 2020). This novel view enables us to obtain a Hodge-type decomposition of TD errors into an integrable component (which is Markov and capturable by Bellman equation) and a topological residual. We develop a Bellman‚Äìde Rham projection in the corresponding Hilbert space to minimize this non-integrability residual, thus achieving an optimal integrable approximation for solving non-Markovian problems. The residual quantifies how far the environment‚Äìpolicy pair departs from an ideal Markov model and thus serves as a principled diagnostic signal measuring by how much standard TD learning is fundamentally mismatched to the data\n¬†(Kaelbling et al., 1998; Tsitsiklis and Van Roy, 1996; Sutton et al., 2009).\n\n\nBuilding on this framework, we propose HodgeFlow Policy Search (HFPS), a simple two-network scheme that explicitly projects TD errors onto their integrable component and trains the value function using only this well-behaved part.\nRather than chasing state-of-the-art benchmark scores in our evaluation, we focus on specific regimes where standard TD learning is fragile: non-Markovian rewards, partially observed and dependent dynamics, and offline RL with dataset shift\n¬†(Bacchus and Kabanza, 2000; Icarte et al., 2022; Zhang et al., 2026a; Hausknecht and Stone, 2015; Fu et al., 2020; Kumar et al., 2020; Kostrikov et al., 2021).\nAcross these settings, HFPS delivers (i) a rigorous Hilbert-space formulation of TD integrability, (ii) a practical Topological Bellman Decomposition (TBD) algorithm that approximates the Hodge projection from data, and (iii) sensitivity and robustness guarantees that explain how the integrable update behaves under perturbations of rewards, discount factors, and approximation errors\n¬†(Sutton, 1988; Tsitsiklis and Van Roy, 1996; Sutton et al., 2009; Jiang et al., 2011; Lim, 2020).\n\n\nContributions.\n(i) We formulate TD error as a Hilbert-space 1-cochain and introduce the notion of topological Bellman integrability, together with a Hodge-type decomposition into integrable and residual components (Desbrun et al., 2006; Jiang et al., 2011; Lim, 2020).\n(ii) We derive a Poisson characterization of the optimal potential and show that in the ideal Markov setting the topological residual vanishes, while in non-Markovian regimes it provides a quantitative measure of Bellman non-integrability (Sutton, 1988; Tsitsiklis and Van Roy, 1996; Fang et al., 2026; Jiang et al., 2011).\n(iii) We propose the Topological Bellman Decomposition (TBD) algorithm, which realizes the Hodge projection using two function approximators trained from replay data (Sutton et al., 1998; Mnih et al., 2015; Schulman et al., 2017; Sutton et al., 2009).\n(iv) We provide theoretical guarantees on consistency, stability, and sensitivity of the decomposition, and empirically study HFPS in path-dependent and partially observed control tasks where conventional TD learning becomes brittle (Kaelbling et al., 1998; Hausknecht and Stone, 2015; Fu et al., 2020; Kumar et al., 2020; Kostrikov et al., 2021).\n\n\n\n\n2 Preliminaries\n\nIn this section we put the discounted MDP in a measure-theoretic and Hilbert-space form that will be used throughout the paper. We first define discounted occupancy measures over state‚Äìtransition triplets, and use them to build two Hilbert cochain spaces: a 0-cochain space C0C^{0} of state functions and a 1-cochain space C1C^{1} of functions on (s,a,s‚Ä≤)(s,a,s^{\\prime}) triplets. We then introduce a discrete de¬†Rham differential d:C0‚ÜíC1d:C^{0}\\to C^{1} that plays the role of a discounted temporal gradient, and define the associated zero-th order Hodge Laplacian Œî0=d‚àó‚Äãd\\Delta_{0}=d^{\\ast}d on C0C^{0}. All subsequent Hodge decompositions of TD errors will be formulated in terms of these objects.\n\n\nA discounted Markov decision process (MDP) is a tuple ‚Ñ≥=(ùíÆ"
  },
  {
    "title": "Reliable Mislabel Detection for Video Capsule Endoscopy Data",
    "url": "https://arxiv.org/abs/2602.06938v1",
    "source": "arxiv",
    "summary": "The classification performance of deep neural networks relies strongly on access to large, accurately annotated datasets. In medical imaging, however, obtaining such datasets is particularly challenging since annotations must be provided by specialized physicians, which severely limits the pool of annotators. Furthermore, class boundaries can often be ambiguous or difficult to define which further",
    "full_text": null
  },
  {
    "title": "Reciprocal Latent Fields for Precomputed Sound Propagation",
    "url": "https://arxiv.org/abs/2602.06937v1",
    "source": "arxiv",
    "summary": "Realistic sound propagation is essential for immersion in a virtual scene, yet physically accurate wave-based simulations remain computationally prohibitive for real-time applications. Wave coding methods address this limitation by precomputing and compressing impulse responses of a given scene into a set of scalar acoustic parameters, which can reach unmanageable sizes in large environments with ",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Related Work\n\n\n2.1 Impulse response generation\n\n2.1.1 Traditional methods\n2.1.2 Machine learning-based methods\n\n\n\n2.2 Simulating sound propagation in games\n\n2.2.1 Ray-tracing\n2.2.2 Rooms and portals systems\n2.2.3 Wave coding systems\n\n\n\n\n\n3 Parametric wave field coding for precomputed sound propagation\n\n3.1 Acoustic Simulation\n\n3.2 Parameter Estimation\n\n3.2.1 Path distance\n3.2.2 Direction of arrival\n3.2.3 Direct sound level\n3.2.4 Reflection levels\n3.2.5 Reflection decay times\n\n\n\n3.3 Rendering\n\n3.3.1 Reference IR selection\n3.3.2 Dry path\n3.3.3 Wet paths\n3.3.4 Runtime interpolation of parameters\n3.3.5 Spatialization\n\n\n\n\n\n4 The Reciprocal Latent Field Framework\n\n\n4.1 Reciprocal Latent Fields\n\n4.1.1 Euclidean RLF\n4.1.2 Riemannian RLF\n4.1.3 Distance field with MLPs\n\n\n\n4.2 Sound propagation specific fields\n\n4.2.1 Sound Levels\n4.2.2 Decay Times\n4.2.3 Direction of Arrival\n\n\n\n4.3 Practical setup\n\n4.3.1 Shared latent space\n4.3.2 Dataset Generation\n4.3.3 Training\n\n\n\n\n\n5 Results\n\n\n5.1 Experimental Setup\n\n5.1.1 Maps\n5.1.2 Models\n5.1.3 Training and evaluation\n\n\n5.2 Comparative study of model architectures\n5.3 Influence of latent space size\n5.4 Subjective test\n\n\n6 Conclusion\n\n\n\n\n\nReciprocal Latent Fields for Precomputed Sound Propagation\n\n\n\nHugo Seut√© \nUbisoft La Forge\nMontr√©al, Canada \nhugo.seute@ubisoft.com\n&amp;Pranai Vasudev \nAudiokinetic\nMontr√©al, Canada \npvasudev@audiokinetic.com\n&amp;Etienne Richan \nAudiokinetic\nMontr√©al, Canada \nerichan@audiokinetic.com\n&amp;Louis-Xavier Buffoni \nAudiokinetic\nMontr√©al, Canada \nxbuffoni@audiokinetic.com\n\n\n\n\nAbstract\nRealistic sound propagation is essential for immersion in a virtual scene, yet physically accurate wave-based simulations remain computationally prohibitive for real-time applications. Wave coding methods address this limitation by precomputing and compressing impulse responses of a given scene into a set of scalar acoustic parameters, which can reach unmanageable sizes in large environments with many source-receiver pairs. We introduce Reciprocal Latent Fields (RLF), a memory-efficient framework for encoding and predicting these acoustic parameters.\nThe RLF framework employs a volumetric grid of trainable latent embeddings decoded with a symmetric function, ensuring acoustic reciprocity. We study a variety of decoders and show that leveraging Riemannian metric learning leads to a better reproduction of acoustic phenomena in complex scenes. Experimental validation demonstrates that RLF maintains replication quality while reducing the memory footprint by several orders of magnitude. Furthermore, a MUSHRA-like subjective listening test indicates that sound rendered via RLF is perceptually indistinguishable from ground-truth simulations.\n\n\nFigure 1: Visualization of the 2D latent space from an Euclidean RLF trained to reproduce path distance, on two different 2D geometries\n\n\n\n1 Introduction\n\nIn interactive virtual environments, such as video games, audio is a primary driver of immersion and a critical tool for directing attention within a 3D space. Realistic auditory experiences require accurate modeling of complex wave phenomena, specifically diffraction around obstacles and reverberation. These effects are physically characterized by the impulse response (IR), which captures the spectral and temporal transformations a unit impulse undergoes as it propagates from source to receiver.\n\n\nBecause the IR changes with every movement of the source or receiver, accurately simulating these wave phenomena in real-time is beyond the computational budgets of game engines. As detailed in Sec. 2, geometric methods such as ray-tracing remain CPU-intensive for complex scenes, while rooms and portals systems require labor-intensive manual markup. Our work builds upon the wave coding method [26], which addresses these issues via precomputation of acoustic parameters (detailed in Sec. 3). However, this approach scales poorly to large environments, as it requires computing and storing data for all necessary source-receiver configurations.\n\n\nTo address this bottleneck, we introduce Reciprocal Latent Fields (RLF) in Sec. 4. While applied here to wave coding, RLF is a generalized framework that compresses reciprocal scalar fields into a grid of nn-dimensional embeddings forming a latent manifold. We employ decoders to predict field values as geodesic distances between arbitrary source and receiver embeddings, similar to [39]. By restricting these decoders to symmetric functions, our method guarantees acoustic reciprocity by design.\n\n\nWe summarize our main contributions as follows:\n\n\n‚Ä¢\n\nReciprocal Latent Fields (RLF). A novel method for encoding acoustic paths as metrics over a latent manifold, inherently enforcing physical reciprocity (Sec. 4.1).\n\n\n\n‚Ä¢\n\nRiemannian Decoder Architecture. A decoder that significantly improves reconstruction accuracy over simpler baselines with negligible computational overhead by including a local metric tensor to warp space (Sec. 4.1.2).\n\n\n\n‚Ä¢\n\nLightweight decoders for acoustic parameters. An extension of RLF to a complete set of acoustic parameters, including non-metric quantities such as energy levels and decay times, enabling real-time, memory-efficient acoustic rendering (Section 4.2).\n\n\n\n‚Ä¢\n\nBenchmark and study. In Sec. 5, we compare decoder designs and embedding dimensionality. In conjunction with a subjective study, our results demonstrate that the Riemannian RLF approach maintains high fidelity while compressing wave coding data by several orders of magnitude.\n\n\n\n\n\n\n\n2 Related Work\n\n\n2.1 Impulse response generation\n\nExisting methods for computing acoustics generally focus on predicting full IRs, either via physical simulation or machine learning approximation.\n\n\n\n2.1.1 Traditional methods\n\nPhysical approaches are split into geometrical and wave-based methods. Geometrical methods, such as image source [16] and acoustic radiance transfer [32, 22] are computationally tractable but require costly approximations to model diffraction [38, 29]. Conversely, wave-based solvers (e.g., FDTD [11], FEM [20], BEM [12]) inherently capture wave phenomena but remain too computationally intensive for real-time applications.\n\n\n\n\n2.1.2 Machine learning-based methods\n\nRecent work accelerates IR generation using mesh-based encoders [28, 17], neural operators [18, 4], or implicit neural representations [19]. However, predicting raw IRs remains ill-suited for video games. First, massive parameter counts lead to prohibitive inference costs [4, 15]. Second, raw IRs lack spatial smoothness, resulting in interpolation artifacts and wall leakage. Third, they lack the tunable parameters (e.g., loudness, decay) required by sound designers. Finally, generalization is often limited by training on residential datasets [5, 35] or simplified geometries [4, 14], restricting applicability in complex game environments.\n\n\n\n\n\n2.2 Simulating sound propagation in games\n\nThe common systems for sound propagation in games are ray-tracing, rooms and portals, and wave coding.\n\n\n\n2.2.1 Ray-tracing\n\nRay-tracing models propagation via specular reflections at boundary surfaces ignoring phase coherence and fails to inherently model diffraction [25]. Real-time performance is bottlenecked by the visibility tree, which defines the valid reflection paths between a source and receiver and requires expensive re-calculations whenever the source or receiver moves [3, 36]. While optimizations like diffuse rain exist [30, 23, 37], they do not resolve this computational bottleneck. Furthermore, valid reflection path finding is unstable in complex geometries, causing audio dropouts when ray density is insufficient [36, 29].\n\n\n\n\n2.2.2 Rooms and portals systems\n\nStemming from classical work on acoustically coupled rooms [16], rooms and portals systems decompose the virtual scene into discrete volumes (rooms) connected by openings (portals), allowing for simplified propagation modeling. [34] proposes a topological approach using reverberation graphs to model energy exchange between coupled volumes, achieving update rates (10‚Äì100 Hz) suitable for real-time use. A prominent commercial implementation is Wwise Rooms and Portals [13]. While computationally efficient, this approach is labor-intensive, requiring manual markup of room boundaries and reverberation parameters. Moreover, this abstraction breaks down in outdoor or hybrid environments where acoustic boundaries are ambiguous [25].\n\n\n\n\n2.2.3 Wave coding systems\n\nWave-coding [26] shifts the computational burden of wave-based sound propagation to an offline simulation. Simulations are run using a representative set of emitters and a dense grid of receiver probes. Compact acoustic parameters are then extracted from the IRs computed at each probe to drive runtime filters (loudness, reflection energy, decay times, direction). This method inherently accounts for diffraction without manual room definition, offering a physically accurate yet automated alternative to rooms and portals systems. The main limitation of this approach is the memory footprint which scales proportionally to the product of the number of emitters and receivers. Even with compression, the memory footprint scales poorly for large maps on memory-constrained devices. We address this memory bottleneck by replacing explicit parameter grids with our Reciprocal Latent Field framework.\n\n\n\n\n\n\n3 Parametric wave field coding for precomputed sound propagation\n\nAs there is no publicly available implementation of the wave coding pipeline [26], we describe our own.\n\n\n\n3.1 Acoustic Simulation\n\nWe perform wave-based acoustic simulations using the Pretty Fast FDTD (PFFDTD) solver [11]. Given the scene mesh, PFFDTD voxelizes the domain into a regular grid with spacing\nh=c/(fmax‚ãÖPPW)h=c/(f_{\\max}\\cdot\\mathrm{PPW}), where cc is the speed of sound, fmaxf_{\\max} the maximum simulated frequency, and PPW the number of points per wavelength.\nThe simulation time step is Œî‚Äãt=S‚Äãh/c\\Delta t=Sh/c, where SS is the Couran"
  },
  {
    "title": "Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI",
    "url": "https://arxiv.org/abs/2602.06934v1",
    "source": "arxiv",
    "summary": "Grassroots Logic Programs (GLP) is a concurrent logic programming language with variables partitioned into paired \\emph{readers} and \\emph{writers}, conjuring both linear logic and futures/promises: an assignment is produced at most once via the sole occurrence of a writer (promise) and consumed at most once via the sole occurrence of its paired reader (future), and may contain additional readers ",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Transition Systems and Implementations\n\n2.1 Transition Systems\n2.2 Implementations\n\n\n\n3 Concurrent GLP and Its Implementation\n\n3.1 Concurrent GLP\n3.2 Deterministic Implementation of GLP\n\n\n\n4 Multiagent Transition Systems\n\n4.1 Agents, Local States, and Configurations\n4.2 Multiagent Transition Systems\n\n\n\n5 Multiagent GLP and Its Implementation\n\n5.1 Multiagent GLP\n5.2 Implementing Multiagent GLP with Deterministic Agents\n\n\n6 Related Work\n7 Conclusion\n\nA Single-Agent GLP Details\n\nA.1 GLP Remarks\nA.2 dGLP Proofs\nA.3 dGLP Remarks\n\n\n\nB Multiagent GLP Details\n\nB.1 maGLP Proofs\nB.2 maGLP Remarks\n\n\n\nC madGLP Specification\n\nC.1 Global Variable Names\nC.2 Global Writers Table\nC.3 The global_send Predicate\nC.4 Index-0 Serializer for Cold-Calls\nC.5 Globalizing and Localizing Terms\nC.6 madGLP Transactions\nC.7 madGLP Remarks\nC.8 Variable Correspondence\nC.9 Correctness Proofs\n\n\n\nD madGLP is Grassroots\n\nD.1 Protocols and the Grassroots Property\nD.2 Transactions-Based Protocols\nD.3 madGLP is Grassroots\nD.4 Implementations Preserve Grassroots\n\n\n\nE Detailed madGLP Example Traces\n\n\nE.1 Example 1: Client-Monitor Communication\n\nGlobalization performed:\nLocalization performed:\nGlobalization performed:\nLocalization performed:\n\n\n\nE.2 Example 2: Friend-Mediated Introduction\n\nGlobalization at Bob for Alice:\nLocalization at Alice:\nGlobalization at Bob for Charlie:\nLocalization at Charlie:\nGlobal Link Summary after Stage 2:\nSummary:\n\n\n\nE.3 Example 3: Both Ends to Same Agent\n\nGlobalization at Bob:\nGlobalized term:\nLocalization at Alice:\nLocalized term:\nSummary:\n\n\n\n\n\n\n\n\n\n\nLondon School of Economics, UK, and Weizmann Institute of Science, Israelehud.shapiro@weizmann.ac.ilhttps://orcid.org/0000-0002-6030-106X\n\\CopyrightEhud Shapiro\\hideLIPIcs\\ArticleNo0\\ccsdesc[500]Theory of computation Operational semantics\n\\ccsdesc[500]Software and its engineering Concurrent programming languages\n\\ccsdesc[300]Software and its engineering Runtime environments\n\\ccsdesc[300]Theory of computation Distributed computing models\n\\ccsdesc[300]Computer systems organization Peer-to-peer architectures\n\nImplementing Grassroots Logic Programs with Multiagent Transition Systems and AI\n\n\nEhud Shapiro\n\n\n\nAbstract\nGrassroots Logic Programs (GLP) is a concurrent logic programming language with variables partitioned into paired readers and writers, conjuring both linear logic and futures/promises: an assignment is produced at most once via the sole occurrence of a writer (promise) and consumed at most once via the sole occurrence of its paired reader (future), and may contain additional readers and/or writers, enabling the concise expression of rich multidirectional communication modalities.\nGLP was designed as a language for grassroots platforms‚Äîdistributed systems with multiple instances that can operate independently of each other and of any global resource, and can coalesce into ever larger instances‚Äîwith its target architecture being smartphones communicating peer-to-peer. The operational semantics of Concurrent (single-agent) GLP and of multiagent GLP (maGLP) were defined via transition systems/multiagent transition systems, respectively.\nHere, we describe the mathematics developed to facilitate the workstation- and smartphone-based implementations of GLP by AI in Dart. We developed dGLP‚Äîimplementation-ready deterministic operational semantics for single-agent GLP‚Äîand proved it correct with respect to the Concurrent GLP operational semantics; dGLP was used by AI as a formal spec, from which it developed a workstation-based implementation of GLP. We developed madGLP‚Äîan implementation-ready multiagent operational semantics for maGLP‚Äîand proved it correct with respect to the maGLP operational semantics; madGLP is deterministic at the agent level (not at the system level due to communication asynchrony), and is being used by AI as a formal spec from which it develops a smartphone-based implementation of maGLP.\nThe development process employs three layers of abstraction‚Äîthe mathematical spec (this paper); an English+code fragments informal spec derived by AI from the math; and the Dart code derived by AI from the informal spec. While the authority is math‚Üíspec‚ÜíDart, the three layers were harmonized via back-and-forth communication, with programming in Dart revealing gaps and inconsistencies in the informal spec, which in turn revealed gaps and inconsistencies in the math. The latter resulted in several major redesigns of madGLP, the outcome of which is presented here.\n\n\nkeywords: concurrent logic programming, multiagent systems, transition systems, operational semantics, peer-to-peer, grassroots platforms\n\n\n\n1 Introduction\n\nGrassroots Logic Programs (GLP) [shapiro2025glp] is a concurrent logic programming language with variables partitioned into paired readers and writers, conjuring both linear logic [girard1987linear] and futures/promises [friedman1976impact]: an assignment is produced at most once via the sole occurrence of a writer (promise) and consumed at most once via the sole occurrence of its paired reader (future), and may contain additional readers and/or writers, enabling the concise expression of rich multidirectional communication modalities.\n\n\nGLP was designed as a language for grassroots platforms [shapiro2023grassrootsBA]‚Äîdistributed systems with multiple instances that can operate independently of each other and of any global resource, and can coalesce into ever larger instances‚Äîwith its target architecture being smartphones communicating peer-to-peer. The operational semantics of Concurrent (single-agent) GLP and of multiagent GLP (maGLP) were defined via transition systems/multiagent transition systems, respectively [shapiro2021multiagent, shapiro2025glp].\n\n\nHere, we describe the mathematics developed to facilitate the workstation- and smartphone-based implementations of GLP by AI (Claude) in Dart [dart2024] (a multi-platform smartphone programming language). We developed dGLP‚Äîimplementation-ready deterministic operational semantics for single-agent GLP‚Äîand proved it correct with respect to the Concurrent GLP operational semantics; dGLP was used by AI as a formal spec, from which it developed a workstation-based implementation of GLP. We developed madGLP‚Äîan implementation-ready multiagent operational semantics for maGLP‚Äîand proved it correct with respect to the maGLP operational semantics; madGLP is deterministic at the agent level (not at the system level due to communication asynchrony), and is being used by AI as a formal spec from which it develops a smartphone-based implementation of maGLP.\n\n\nThe development process employs three layers of abstraction‚Äîthe mathematical spec (this paper); an English+code fragments informal spec derived by AI from the math; and the Dart code derived by AI from the informal spec. While the authority is math‚Üíspec‚ÜíDart, the three layers were harmonized via back-and-forth communication, with programming in Dart revealing gaps and inconsistencies in the informal spec, which in turn revealed gaps and inconsistencies in the math. The latter resulted in several major redesigns of madGLP, the outcome of which is presented here. All remarks in the paper were generated by AI, to assist itself in better understanding the math while writing the spec.\n\n\nA key goal of this paper is to offer a precise interface between the human designer and the AI programmer: formal operational semantics serve as a specification language, constraining the space of legal implementations. The emerging discipline [fowler2025sdd, mundler2025type, blinn2024typed] we advocate and employ is for the human designer and AI to jointly develop and agree upon (1) formal semantics (this paper); (2) informal (English+code) specification (derived by AI); and only then let AI attempt to write (3) Dart code that complies with these formal and informal specs. The current madGLP English+code specification is available as supplementary material.\n\n\nPaper outline.\nSection 2 recalls transition systems, implementations, and correctness.\nSection 3 presents Concurrent GLP: syntax, operational semantics, and dGLP which correctly implements it.\nSection 4 recalls multiagent transition systems and atomic transactions.\nSection 5 defines multiagent GLP (maGLP), multiagent deterministic GLP (madGLP), and proves madGLP correctly implements maGLP.\nSection 6 discusses related work.\nSection 7 concludes.\nAppendix A contains single-agent GLP proofs and remarks.\nAppendix B contains multiagent GLP proofs and remarks.\nAppendix C provides the complete madGLP specification.\nAppendix D proves madGLP grassroots.\nAppendix E provides detailed example traces.\n\n\n\n\n2 Transition Systems and Implementations\n\nThis section presents transition systems and implementations among them, providing the mathematical foundation for proving that one transition system correctly implements another.\n\n\n\n2.1 Transition Systems\n\n\nDefinition 2.1 (Transition System).\n\n\nA transition system is a tuple T‚ÄãS=(C,c0,T)TS=(C,c_{0},T) where CC is an arbitrary set of configurations, c0‚ààCc_{0}\\in C is a designated initial configuration, and T‚äÜC√óCT\\subseteq C\\times C is a transition relation, with transitions written c‚Üíc‚Ä≤‚ààTc\\rightarrow c^{\\prime}\\in T.\n\n\nA transition c‚Üíc‚Ä≤‚ààTc\\rightarrow c^{\\prime}\\in T is enabled from configuration cc. A configuration cc is terminal if no transitions are enabled from cc. A computation is a (finite or infinite) sequence of configurations where for each two consecutive configurations (c,c‚Ä≤)(c,c^{\\prime}) in the sequence, c‚Üíc‚Ä≤‚ààTc\\rightarrow c^{\\prime}\\in T. We write c‚Üí‚àóc‚Ä≤c\\xrightarrow{*}c^{\\prime} to denote the existence of a computation (empty if c=c‚Ä≤c=c^{\\prime}) from cc to c‚Ä≤c^{\\prime}. A run is a computation starting from c0c_{0}, which is complete if it is infinite or ends in a terminal configuration. The outcome of a complete run is determined by a domain-specific function from complete runs to an outcome space.\n\n\n\nLiveness.\nThe framework we follow [shapiro2021multiagent] has an ela"
  },
  {
    "title": "When RL Meets Adaptive Speculative Training: A Unified Training-Serving System",
    "url": "https://arxiv.org/abs/2602.06932v1",
    "source": "arxiv",
    "summary": "Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag: (1) high time-to-serve, since a speculator must be trained offline for a considerable period before",
    "full_text": null
  },
  {
    "title": "Continuous-time reinforcement learning: ellipticity enables model-free value function approximation",
    "url": "https://arxiv.org/abs/2602.06930v1",
    "source": "arxiv",
    "summary": "We study off-policy reinforcement learning for controlling continuous-time Markov diffusion processes with discrete-time observations and actions. We consider model-free algorithms with function approximation that learn value and advantage functions directly from data, without unrealistic structural assumptions on the dynamics.\n  Leveraging the ellipticity of the diffusions, we establish a new cla",
    "full_text": null
  },
  {
    "title": "Robustness Beyond Known Groups with Low-rank Adaptation",
    "url": "https://arxiv.org/abs/2602.06924v1",
    "source": "arxiv",
    "summary": "Deep learning models trained to optimize average accuracy often exhibit systematic failures on particular subpopulations. In real world settings, the subpopulations most affected by such disparities are frequently unlabeled or unknown, thereby motivating the development of methods that are performant on sensitive subgroups without being pre-specified. However, existing group-robust methods typical",
    "full_text": null
  },
  {
    "title": "From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers",
    "url": "https://arxiv.org/abs/2602.06923v1",
    "source": "arxiv",
    "summary": "Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on \"world models\" -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous \"AI Physicist\" approaches have successfully recovered such laws, they typically rely on strong, domain-",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Inductive Bias 1: Spatial Smoothness\n\n2.1 Problem setup\n2.2 The emergent spatial map is poor\n2.3 Conditions and scaling laws for spatial map emergence\n\n\n\n3 Inductive Bias 2: Spatial Stability\n\n3.1 Regression: next state prediction\n3.2 Fair comparison: regression wins over classification\n\n\n4 Inductive Bias 3: Temporal Locality\n5 Conclusions and discussion\nA Related works\n\nB Training dynamics\n\nB.1 1D sine wave dataset\nB.2 Kepler as classification\nB.3 Kepler as regression\n\n\n\nC More probing results\n\nC.1 Interpolating between Kepler and Newton by varying context lengths\nC.2 Probing results across layers\n\n\n\n\n\n\n\nFrom Kepler to Newton: \nInductive Biases Guide Learned World Models in Transformers\n\n\nZiming Liu\n\n‚ÄÉ‚ÄÉ\nSophia Sanborn\n\n‚ÄÉ‚ÄÉ\nSurya Ganguli\n\n‚ÄÉ‚ÄÉ\nAndreas Tolias\n\n\n\nAbstract\nCan general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on ‚Äúworld models‚Äù‚Äîcausal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous ‚ÄúAI Physicist‚Äù approaches have successfully recovered such laws, they typically rely on strong, domain-specific priors that effectively ‚Äúbake in‚Äù the physics. Conversely, Vafa et¬†al. (2025) recently showed that generic Transformers fail to acquire these world models, achieving high predictive accuracy without capturing the underlying physical laws. We bridge this gap by systematically introducing three minimal inductive biases. We show that ensuring spatial smoothness (by formulating prediction as continuous regression) and stability (by training with noisy contexts to mitigate error accumulation) enables generic Transformers to surpass prior failures and learn a coherent Keplerian world model, successfully fitting ellipses to planetary trajectories. However, true physical insight requires a third bias: temporal locality. By restricting the attention window to the immediate past‚Äîimposing the simple assumption that future states depend only on the local state rather than a complex history‚Äîwe force the model to abandon curve-fitting and discover Newtonian force representations. Our results demonstrate that simple architectural choices determine whether an AI becomes a curve-fitter or a physicist, marking a critical step toward automated scientific discovery.\n\nMachine Learning, ICML\n\n\n\n1 Introduction\n\nGiven the broad skills and knowledge demonstrated by foundation models¬†(Brown et¬†al., 2020; Chowdhery et¬†al., 2023; Touvron et¬†al., 2023; Radford et¬†al., 2021; Alayrac et¬†al., 2022; Liu et¬†al., 2023; Zitkovich et¬†al., 2023; Kim et¬†al., 2024; Reed et¬†al., 2022), it is natural to expect that they possess robust internal ‚Äúworld models‚Äù‚Äîcausal abstractions that do not merely predict what happens next (e.g., Kepler‚Äôs geometric fits), but capture the simple physical mechanisms determining why it happens (e.g., Newton‚Äôs dynamical laws).\n\n\nThis expectation raises a central question: do world models truly emerge within foundation models? Answeing this question is a challenge. These models are highly complex, and the notion of a ‚Äúworld model‚Äù is often context-dependent or vaguely defined. Thus, it is useful to study world-model emergence in simple, controlled settings where the ground truth is well understood ‚Äì for instance, Newtonian physics, in which the governing ‚Äúworld model‚Äù reduces to a set of simple differential equations. In this vein,¬†Vafa et¬†al. (2025) used planetary motion as a testbed and found that although a transformer can make highly accurate predictions, gravitational forces fail to emerge in its internal representations, even when a GPT-2-scale transformer is trained on datasets as large as 20B tokens. However, the reason behind the failure remains unclear. The central research question of this paper is thus:\n\n\n\n\nResearch Question:\n\n\nWhy do transformers fail to learn the Newtonian world model for planetary motion, and how can we fix this problem?\n\n\n\nAnswering this is a critical litmus test for the vision of developing ‚ÄòAI Scientists‚Äô: if general-purpose architectures cannot recover the simple, known laws of classical mechanics, they are unlikely to be trusted to discover the unknown laws of novel phenomena.\n\n\nFigure 1: Visual abstract. Top left: The problem setup of¬†Vafa et¬†al. (2025): planetary motion prediction is formulated as next token(s) prediction. Bottom left: Inductive biases are key to learning Newtonian world models. Three inductive biases are identified and used to fix respective failure modes. Right: The context length controls the world model learned by transformers. Long context lengths lead to the Keplerian model (global, geometry-based), while small context lengths lead to the Newtonian model (local, force-based).\n\n\nWe can gain some insights from the success of ‚ÄúAI physicist‚Äù models¬†(Wu &amp; Tegmark, 2019; Brunton et¬†al., 2016; Cranmer et¬†al., 2020; Lemos et¬†al., 2023; Liu &amp; Tegmark, 2021; Liu et¬†al., 2022, 2024; Udrescu &amp; Tegmark, 2020), which not only make accurate predictions but also discover symbolic laws underlying the data ‚Äì i.e., they successfully recover ‚Äúworld models‚Äù ‚Äì often in settings more complex than planetary motion. The key for these AI physicist models to succeed is that they typically incorporate stronger inductive biases than transformers. We are thus motivated to study what inductive biases are lacking in transformers and how we can fix them. We find that simple and general inductive biases, like spatial smoothness, temporal continuity and temporal locality, are powerful enough to induce correct world models. The inductive biases do not need to know that much about the underlying law to be learned, but without them, it is impossible to learn.\n\n\nWe identify three key inductive biases required by a world model:\n\n\nInductive bias 1: spatial smoothness. Default tokenization discretizes continuous spatial coordinates r‚Üí=(x,y)\\vec{r}=(x,y) into bins (tokens), each represented by a randomly initialized, learnable embedding vector. This discretization breaks spatial smoothness, because two points that are close in physical space but fall into different bins are treated by the transformer as completely unrelated (at least prior to training). One might hope that the model could learn a good spatial map given enough compute and data, but the spatial map does not fully emerge in the setup of¬†Vafa et¬†al. (2025), even though their model size, data size and training compute are comparable to GPT-2‚Äìscale models. This spatial smoothness problem may be relevant for any training paradigm involving tokenization, which motivates us to study how the emergence of a spatial map depends on key hyperparameters, i.e., vocabulary size VV, training data size DD, and embedding dimension NN, which exhibit intriguing scaling behaviors detailed in Section¬†2.\n\n\nIf one insists on using tokenization, one must carefully choose V,D,NV,D,N to maximize spatial map emergence. Another solution, which is arguably simpler and more natural, is to use continuous coordinates without discretizing them. This, however, would lead to a stability problem stated below.\n\n\nFigure 2: Analyzing the embeddings of the transformer model used in¬†Vafa et¬†al. (2025).\n(a) Illustration of training dynamics of token embeddings: embeddings are randomly initialized (left), gradually gain spatial structure during training (middle), requiring substantial compute and data to reach true spatial map (right). (b) The learned embeddings exhibit poor locality: circular structures in the true coordinate space (left) fragment into four point clouds, losing fine-grained structure within each quadrant (right).\n(c) Learned embeddings show poor linear decodability to the true spatial map (left for xx, right for yy).\n\n\nInductive bias 2: spatial stability. It is known that auto-regressive models suffer severely from error accumulation when dealing with continuous variables¬†(Ren et¬†al., 2025). In addition,¬†Vafa et¬†al. (2025) reported that discretized coordinates trained with cross-entropy loss (classification) performed better than continuous coordinates trained with MSE loss (regression). However, as continuous coordinates naturally guarantee spatial smoothness, we believe they merit further investigation.\nIn fact, inference robustness can be significantly improved by injecting noise into the training contexts‚Äîa strategy known as noisy context learning¬†(Ren et¬†al., 2025). With this mitigation in place, we find that regression consistently outperforms classification across all data scales we evaluate. We elaborate on this regression-related failure mode and its remedy in Section¬†3.\n\n\nInductive bias 3: temporal locality. Newtonian mechanics has temporal locality since it is a second-order differential equation, i.e., when the time interval Œî‚Äãt\\Delta t is small enough, the next state r‚Üí‚Äã(t+Œî‚Äãt)\\vec{r}(t+\\Delta t) is solely dependent on the current state r‚Üí‚Äã(t)\\vec{r}(t) and the previous state r‚Üí‚Äã(t‚àíŒî‚Äãt)\\vec{r}(t-\\Delta t), but no states before that. This is different from a default transformer, which has a long context length (1k or longer). This inspires us to vary the context length to control temporal locality. Surprisingly, we find that: temporal locality induces the transformer to be a Newtonian world model, while lack of this knowledge induces a Keplerian world model‚Äîfitting elliptical equations based on all previous points and making predictions by continuing the curve. By contrast, a Newtonian world model would compute gravitational forces based on temporally local states and then make predictions by simulating the differential equation (see Figure¬†1 for an illustration). We elaborate on the two stories about Kepler versus Newton in Section¬†4.\n\n\nThe main findings and contributions in Section¬†2, ¬†3 and¬†4 are summarized in Figure¬†1. Conclusions and discussions are in Section¬†5. Codes are available at https://github.com/KindXiaoming/newton-kepler.\n\n\n\n\n2 Inductive Bias 1"
  },
  {
    "title": "Halluverse-M^3: A multitask multilingual benchmark for hallucination in LLMs",
    "url": "https://arxiv.org/abs/2602.06920v1",
    "source": "arxiv",
    "summary": "Hallucinations in large language models remain a persistent challenge, particularly in multilingual and generative settings where factual consistency is difficult to maintain. While recent models show strong performance on English-centric benchmarks, their behavior across languages, tasks, and hallucination types is not yet well understood. In this work, we introduce Halluverse-M^3, a dataset desi",
    "full_text": null
  },
  {
    "title": "Automatic Detection and Analysis of Singing Mistakes for Music Pedagogy",
    "url": "https://arxiv.org/abs/2602.06917v1",
    "source": "arxiv",
    "summary": "The advancement of machine learning in audio analysis has opened new possibilities for technology-enhanced music education. This paper introduces a framework for automatic singing mistake detection in the context of music pedagogy, supported by a newly curated dataset. The dataset comprises synchronized teacher learner vocal recordings, with annotations marking different types of mistakes made by ",
    "full_text": "\n\n\n\nI Introduction\n\nII Related Works\n\nII-A Computers for Music Evaluation\nII-B Computers for Music Education\nII-C Datasets for Music Analysis\n\n\n\nIII Dataset\n\nIII-A Recording Setup\nIII-B Dataset and Metadata\nIII-C Mistake Annotation\n\n\n\nIV Methodology\n\nIV-A Problem Setup\n\nIV-B Feature Representation\n\nIV-B1 Pitch Features\n\nIV-B2 Amplitude Features\n\nData Augmentation\n\n\n\n\n\nIV-C Models\n\nIV-C1 Baseline\n\nIV-C2 Deep Learning-Based models\n\nCNN Model\nCRNN Model\nTemporal Convolutional Network (TCN)\n\n\n\n\nIV-D Evaluation Metrics\n\n\n\nV Experiments\n\nV-A Studies on Data Split Scenarios\nV-B Cross-teacher Studies\n\n\n\nVI Results and Discussion\n\nVI-A Effect of Collar, Post-processing, and Data Augmentation\nVI-B Analysis of Data Split Scenarios\nVI-C Cross-Teacher Studies:\n\n\nVII Conclusion and Future Work\n\n\n\n\n\nAutomatic Detection and Analysis of Singing Mistakes for Music Pedagogy\n\n\nSumit Kumar‚Ä†, Suraj Jaiswal‚Ä†, Parampreet Singh‚Ä†, Vipul Arora¬ß\n‚Ä†Graduate Student Member, IEEE,‚ÄÉ¬ßSenior Member, IEEE\n‚Ä†¬ßIndian Institute of Technology, Kanpur\n¬ßDepartment of Electrical Engineering (ESAT), KU Leuven\nThis work is supported by IMPRINT-2C grant from DST-SERB and by Prasar Bharati.\n\n\nAbstract\nThe advancement of machine learning in audio analysis has opened new possibilities for technology-enhanced music education.\nThis paper introduces a framework for automatic singing mistake detection in the context of music pedagogy, supported by a newly curated dataset.\nThe dataset comprises synchronized teacher‚Äìlearner vocal recordings, with annotations marking different types of mistakes made by learners.\nUsing this dataset,\nwe develop different deep learning models for mistake detection and benchmark them.\nTo compare the efficacy of mistake\ndetection systems, a new evaluation methodology is proposed.\nExperiments indicate that the proposed learning-based methods are\nsuperior to rule-based methods.\nA systematic study of errors\nand a cross-teacher study reveal insights into music pedagogy that\ncan be utilised for various music applications.\nThis work sets out new directions of research in music pedagogy. The codes and dataset are publicly available.\n\n\n\n\nI Introduction\n\n\nThe proliferation of computer-assisted education methods across diverse fields has demonstrated their efficacy in enhancing learning outcomes¬†[Kalkanoƒülu_music_education_2024, 22, 42]. Within audio-based pedagogies, such as language and music teaching, significant research efforts are underway¬†[Kalkanoƒülu_music_education_2024, 35, 32]. The field of computer-assisted language learning and pronunciation training boasts a substantial body of literature and computational resources [29, 4].\nIn the case of music, although automated assessment methods have been developed for instrumental performance, such as violin and piano¬†[35, 32], analogous systems for vocal pedagogy remain in their early stages of development¬†[27].\n\n\nIndian Art Music (IAM) consists of long-established classical music traditions, including Hindustani and Carnatic music, characterized by raga and tala-based melodic and rhythmic frameworks and a strong emphasis on oral transmission. Learning is centered on imitation, memorization, and gradual refinement of pitch, rhythm, and stylistic expression through repeated listening and practice. IAM pedagogy is deeply rooted in the teacher‚Äìlearner (guru‚Äìshishya) tradition, where musical knowledge is transmitted primarily through direct, in-person interaction rather than written notation¬†[2].\nUnlike conventional classroom settings with regular instructions, music education typically involves only one or two weekly lessons, necessitating substantial independent practice between sessions¬†[9].\nIndependent practice typically relies on lesson recordings from class or on written instructions provided during the session.\nBut in the absence of immediate feedback, beginners may inadvertently entrench errors in pitch, rhythm, or expression during that independent practice.\nAlthough technology offers a promising avenue to bridge this learning gap by providing immediate feedback, tracking progress, and reinforcing correct habits [1, 50], systematic research into such intelligent tools specifically tailored for IAM remains limited.\n\n\nThis study develops an automated singing mistake detection system to support music learning. In this framework, learners attempt to replicate the teacher‚Äôs vocal performance within an imitation learning¬†[2] paradigm.\nTo enable this, we curate a dataset named M3111M3 (MADHAV Lab Mistake Detection for Music Teaching Database) available at https://zenodo.org/records/8332078 tailored for IAM vocal pedagogy. The dataset comprises synchronized teacher-learner singing recordings, where\nthe teachers annotate instances of pitch, amplitude, pronunciation, and rhythm errors in learners‚Äô singing corresponding to the teacher‚Äôs singing.\n\n\nUsing this dataset, we propose an automatic mistake detection framework\ncomprising a rule-based (RB) method,\nand deep learning models\nbased on CNN, CRNN, and TCN architectures.\nThis task is formulated as an audio event detection problem [30, 23], where the input consists of acoustic features derived from synchronized teacher and learner audio, and the target events are specific singing mistakes made by the learner. Our codes, dataset, pre-trained models, and demos are available on\nhttps://github.com/madhavlab/2023_narottam_engine.\n\n\nThe main contributions of this work are:\n\n\n‚Ä¢\n\nThe formulation of the task of automatic singing mistake detection, supported by both rule-based and deep learning approaches.\n\n\n\n‚Ä¢\n\nThe introduction of a novel dataset for mistake detection in Indian Art Music, consisting of synchronized teacher‚Äìlearner audio recordings annotated by expert teachers for pitch, amplitude, pronunciation, and rhythm-based mistakes.\n\n\n\n‚Ä¢\n\nThe development and benchmarking of deep learning based systems for detecting melodic and amplitude errors, aimed at providing detailed corrective feedback to learners.\n\n\n\n‚Ä¢\n\nThe development of a task-specific evaluation methodology\nand a systematic analysis of singing errors during the learning process.\n\n\n\n\n\n\n\nII Related Works\n\n\n\nII-A Computers for Music Evaluation\n\n\nResearch on computer-based singing evaluation began with karaoke-style systems, comparing a subject‚Äôs performance against a reference recording and producing an overall score [25, 46]. Early methods emphasized pitch-based alignment, starting with direct comparisons and later using techniques such as dynamic time warping [19, 7]. Subsequent works extended evaluation to other musical attributes, including rhythm and amplitude [46], and applied classical ML methods such as SVMs and HMMs for robustness in judging pitch intervals, vibrato, and pronunciation accuracy [33, 46, 47, 31].\n\n\nRecent approaches introduced regression and learned descriptors for instrument and voice assessments [53, 48, 15], as well as deep networks for predicting overall performance scores [36, 21, 28, 20]. Scalable assessment strategies include unsupervised clustering of large cohorts of singers by pitch, rhythm, and timbre similarity [14], while other works have addressed intelligibility in singing [43]. Gupta et al. [13] provides an overview of these singing voice evaluation methods. More recently, Hsieh et al. [18] proposed a tonality-based, accompaniment-guided framework that eliminates the need for reference vocals and correlates well with human judgments.\nA common tendency of these systems is to assign an overall score, overlooking details such as intonation, rhythm, or articulation, and thus offering limited feedback for music pedagogy.\n\n\n\n\nII-B Computers for Music Education\n\n\nComputers have been employed to support music pedagogy. Early efforts focused on real-time visualizations of learners‚Äô pitch contours and acoustics [16, 17, 51], which proved helpful at the basic level but are often inadequate for advanced and continuous patterns, especially in Indian classical music, where auditory learning is central [52, 3, 6]. Tools have also been developed for piano and keyboard pedagogy [11], but the lack of sheet-music traditions in IAM limits the transferability of such approaches [40].\nBeyond visualization, evaluation systems for education typically provide overall performance scores without detailed mistake feedback. Bozkurt et al. [8] integrate performance analysis into an online learning platform, while several piano tutoring systems compare learner recordings to reference MIDI or scores to assess accuracy [5, 10, 49, 39]. e-learning tools further support music theory and ear training [37].\n\n\n\n\nII-C Datasets for Music Analysis\n\n\nSaraga¬†[45], RRD¬†[12], CompMusic¬†[41], and Prasarbharti Indian Music (PIM-v1)¬†[44] are a few popular resources in IAM, which primarily focus on raga, tonic, and melody identification, emphasizing musical structure rather than learner performance.\nThe ROD¬†[24] dataset provides frame-wise ornamentation annotations for manually recorded IAM performances, while CoSIAN¬†[54] offers similar annotations for Japanese pop (J-POP) based on existing YouTube recordings.\nIn the domain of automatic singing quality assessment, datasets like DAMP and NUSnQ¬†[28] contain multiple renditions of popular songs annotated with listener-based quality scores, enabling the study of reference-free evaluation and rank-ordering of singers.\nOverall, while existing datasets address structural analysis, expert ornamentation, or holistic quality assessment, they do not capture learner-specific mistakes. Our dataset instead provides synchronized teacher‚Äìlearner recordings with frame-level mistake annotations, supporting fine-grained analysis for music pedagogy.\n\n\nMost prior works in music education and evaluation have focused on assigning holistic performance scores, offering little support for detailed mistake detection or targeted feedback. Existing systems are also developed mainly for Western music with discrete note structures, leaving IAM\nlargely unexplored. To address this, we in"
  },
  {
    "title": "PANC: Prior-Aware Normalized Cut for Object Segmentation",
    "url": "https://arxiv.org/abs/2602.06912v1",
    "source": "arxiv",
    "summary": "Fully unsupervised segmentation pipelines naively seek the most salient object, should this be present. As a result, most of the methods reported in the literature deliver non-deterministic partitions that are sensitive to initialization, seed order, and threshold heuristics.\n  We propose PANC, a weakly supervised spectral segmentation framework that uses a minimal set of annotated visual tokens t",
    "full_text": null
  },
  {
    "title": "TamperBench: Systematically Stress-Testing LLM Safety Under Fine-Tuning and Tampering",
    "url": "https://arxiv.org/abs/2602.06911v1",
    "source": "arxiv",
    "summary": "As increasingly capable open-weight large language models (LLMs) are deployed, improving their tamper resistance against unsafe modifications, whether accidental or intentional, becomes critical to minimize risks. However, there is no standard approach to evaluate tamper resistance. Varied data sets, metrics, and tampering configurations make it difficult to compare safety, utility, and robustness",
    "full_text": null
  },
  {
    "title": "Revisiting the Generic Transformer: Deconstructing a Strong Baseline for Time Series Foundation Models",
    "url": "https://arxiv.org/abs/2602.06909v1",
    "source": "arxiv",
    "summary": "The recent surge in Time Series Foundation Models has rapidly advanced the field, yet the heterogeneous training setups across studies make it difficult to attribute improvements to architectural innovations versus data engineering. In this work, we investigate the potential of a standard patch Transformer, demonstrating that this generic architecture achieves state-of-the-art zero-shot forecastin",
    "full_text": null
  },
  {
    "title": "A first realization of reinforcement learning-based closed-loop EEG-TMS",
    "url": "https://arxiv.org/abs/2602.06907v1",
    "source": "arxiv",
    "summary": "Background: Transcranial magnetic stimulation (TMS) is a powerful tool to investigate neurophysiology of the human brain and treat brain disorders. Traditionally, therapeutic TMS has been applied in a one-size-fits-all approach, disregarding inter- and intra-individual differences. Brain state-dependent EEG-TMS, such as coupling TMS with a pre-specified phase of the sensorimotor mu-rhythm, enables",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; cs &gt; arXiv:2602.06907v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Computer Science  Machine Learning\n    \n\n    \n      arXiv:2602.06907v1 (cs)\n    \n\n\n  \n    \n  [Submitted on 6 Feb 2026]\n    Title:A first realization of reinforcement learning-based closed-loop EEG-TMS\n    Authors:Dania Humaidan, Jiahua Xu, Jing Chen, Christoph Zrenner, David Emanuel Vetter, Laura Marzetti, Paolo Belardinelli, Timo Roine, Risto J. Ilmoniemi, Gian Luca Romani, Ulf Zieman            View a PDF of the paper titled A first realization of reinforcement learning-based closed-loop EEG-TMS, by Dania Humaidan and 10 other authors\n    View PDF\n\n\n\n    \n            Abstract:Background: Transcranial magnetic stimulation (TMS) is a powerful tool to investigate neurophysiology of the human brain and treat brain disorders. Traditionally, therapeutic TMS has been applied in a one-size-fits-all approach, disregarding inter- and intra-individual differences. Brain state-dependent EEG-TMS, such as coupling TMS with a pre-specified phase of the sensorimotor mu-rhythm, enables the induction of differential neuroplastic effects depending on the targeted phase. But this approach is still user-dependent as it requires defining an a-priori target phase. Objectives: To present a first realization of a machine-learning-based, closed-loop real-time EEG-TMS setup to identify user-independently the individual mu-rhythm phase associated with high- vs. low-corticospinal excitability states. Methods: We applied EEG-TMS to 25 participants targeting the supplementary motor area-primary motor cortex network and used a reinforcement learning algorithm to identify the mu-rhythm phase associated with high- vs. low corticospinal excitability. We employed linear mixed effects models and Bayesian analysis to determine effects of reinforced learning on corticospinal excitability indexed by motor evoked potential amplitude, and functional connectivity indexed by the imaginary part of resting-state EEG coherence. Results: Reinforcement learning effectively identified the mu-rhythm phase associated with high- vs. low-excitability states, and their repetitive stimulation resulted in long-term increases vs. decreases in functional connectivity in the stimulated sensorimotor network. Conclusions: We demonstrated for the first time the feasibility of closed-loop EEG-TMS in humans, a critical step towards individualized treatment of brain disorders.\n    \n\n    \n    \n      \n          Subjects:\n          \n            Machine Learning (cs.LG)\n        \n          Cite as:\n          arXiv:2602.06907 [cs.LG]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2602.06907v1 [cs.LG] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2602.06907\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Dania Humaidan [view email]          [v1]\n        Fri, 6 Feb 2026 17:58:26 UTC (1,791 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled A first realization of reinforcement learning-based closed-loop EEG-TMS, by Dania Humaidan and 10 other authorsView PDF\n      \n          \n          view license\n        \n    \n        \n    Current browse context: cs.LG\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-02\n  \n    Change to browse by:\n    \n        cs\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n                    \n            \n              \n                \n                \n                IArxiv recommender toggle\n              \n            \n            \n              IArxiv Recommender\n              (What is IArxiv?)\n            \n          \n\n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that al"
  },
  {
    "title": "Parameter-free Dynamic Regret: Time-varying Movement Costs, Delayed Feedback, and Memory",
    "url": "https://arxiv.org/abs/2602.06902v1",
    "source": "arxiv",
    "summary": "In this paper, we study dynamic regret in unconstrained online convex optimization (OCO) with movement costs. Specifically, we generalize the standard setting by allowing the movement cost coefficients $Œª_t$ to vary arbitrarily over time. Our main contribution is a novel algorithm that establishes the first comparator-adaptive dynamic regret bound for this setting, guaranteeing $\\widetilde{\\mathca",
    "full_text": "\n\n\n\n\n1 Introduction\n\n1.1 Contributions\n\n1.2 Related works\n\nOCO with movement costs.\nParameter-free online learning.\nDynamic regret.\nOCO with delayed feedback.\n\n\n\n\n\n2 Problem Setting\n\nGoal.\nOther notations.\n\n\n3 Parameter-free OCO with Movement Costs\n4 Improved Adaptivity to Movement Costs\n\n5 Applications\n\n5.1 Unconstrained OCO with Delayed Feedback\n5.2 Unconstrained OCO with Time-varying Memory\n\n\n6 Conclusion\nA Auxiliary Lemmas\nB Omitted Details from Section¬†3\nC Omitted Details from Section¬†4\n\nD Omitted Details from Section¬†5\n\nD.1 Unconstrained OCO with Delayed Feedback\nD.2 Unconstrained OCO with Time-varying Memory\n\n\n\n\n\n\n\nParameter-free Dynamic Regret: Time-varying Movement Costs, Delayed Feedback, and Memory\n\n\n\nEmmanuel Esposito\nUniversit√† degli Studi di Milano\nemmanuel@emmanuelesposito.it\nEqual contribution, in alphabetical order.\n‚ÄÉ‚ÄÉ\nAndrew Jacobsen‚Ä†‚Ä†footnotemark: \nUniversit√† degli Studi di Milano\n&amp; Politecnico di Milano\ncontact@andrew-jacobsen.com\n\n‚ÄÉ‚ÄÉ\nHao Qiu‚Ä†‚Ä†footnotemark: \nUniversit√† degli Studi di Milano\nqiuhaosai@gmail.com\n\n‚ÄÉ‚ÄÉ\nMengxiao Zhang‚Ä†‚Ä†footnotemark: \nUniversity of Iowa\nmengxiao-zhang@uiowa.edu\n\n\n\nAbstract\nIn this paper, we study dynamic regret in unconstrained online convex optimization (OCO) with movement costs.\nSpecifically, we generalize the standard setting by allowing the movement cost coefficients Œªt\\lambda_{t} to vary arbitrarily over time.\nOur main contribution is a novel algorithm that establishes the first comparator-adaptive dynamic regret bound for this setting, guaranteeing ùí™~‚Äã((1+PT)‚Äã(T+‚àëtŒªt))\\widetilde{\\mathcal{O}}(\\sqrt{(1+P_{T})(T+\\sum_{t}\\lambda_{t})}) regret, where PTP_{T} is the path length of the comparator sequence over TT rounds.\nThis recovers the optimal guarantees for both static and dynamic regret in standard OCO as a special case where Œªt=0\\lambda_{t}=0 for all rounds.\nTo demonstrate the versatility of our results, we consider two applications: OCO with delayed feedback and OCO with time-varying memory.\nWe show that both problems can be translated into time-varying movement costs, establishing a novel reduction specifically for the delayed feedback setting that is of independent interest.\nA crucial observation is that the first-order dependence on movement costs in our regret bound plays a key role in enabling optimal comparator-adaptive dynamic regret guarantees in both settings.\n\n\n\n1 Introduction\n\nOnline Convex Optimization (OCO) (Cesa-Bianchi and Lugosi, 2006; Hazan, 2016; Orabona, 2025) provides a robust framework for sequential decision-making under uncertainty. In the standard paradigm, a learner iteratively selects a decision and incurs a convex loss, aiming to minimize regret‚Äîthe difference between the learner‚Äôs cumulative loss and that of the best fixed decision in hindsight. However, in many practical systems, changing decisions is rarely cost-free. In domains such as optimal control (Goel et al., 2017; Goel and Wierman, 2019), video streaming (Joseph and de Veciana, 2012), and geographical load balancing (Lin et al., 2012), rapid fluctuations in strategy incur significant operational overhead, commonly referred to as switching or movement costs. Motivated by these challenges, we study a variation of online optimization in which the learner incurs an additional penalty proportional to the distance between consecutive decisions. Beyond its direct relevance to the aforementioned applications, the analysis of OCO with movement costs is instrumental in solving broader fundamental problems. A prime example is online learning with memory (Merhav et al., 2002; Anava et al., 2015), a framework designed to capture temporal dependencies in learning tasks. Reductions involving OCO with movement costs have proven essential for deriving state-of-the-art results in this domain (e.g., Anava et al. (2015); Agarwal et al. (2019); Foster and Simchowitz (2020); Zhao et al. (2023)).\n\n\nOn the other hand, modern online learning challenges are frequently characterized by unconstrained decision spaces and non-stationarity. A typical example is portfolio management with leverage and short-selling (McMahan and Streeter, 2012), where an agent allocates unbounded capital across assets and must adapt to shifting market regimes. In such environments, static benchmarks prove overly conservative, requiring the use of dynamic regret to track a moving target. Crucially, rebalancing incurs costs, such as transaction fees and market impact, that are not constant, but rather fluctuate with market liquidity and volatility. These factors motivate a unified framework that evaluates performance against an evolving benchmark while explicitly accounting for time-varying movement penalties.\n\n\nDespite this motivation, existing literature addresses these challenges only in isolation. While Zhang et al. (2022a, b) study unconstrained OCO with movement costs and Zhang et al. (2021) investigates dynamic regret with movement costs, the intersection of these two settings remains unexplored. Furthermore, all prior works assume fixed movement penalties, a restriction that fails to capture the temporal fluctuations described above. This raises the question:\nCan we design efficient algorithms that achieve near-optimal regret in unconstrained domains with time-varying movement costs?\n\n\n\n1.1 Contributions\n\nIn this paper, we answer this question affirmatively by developing the first parameter-free algorithm for unconstrained OCO that simultaneously handles dynamic regret and time-varying movement costs. Our primary result establishes a regret bound of\nùí™~‚Äã((M+PT)‚Äã‚àët=1T(‚Äñgt‚Äñ2+Œªt‚Äã‚Äñgt‚Äñ)‚Äã‚Äñut‚Äñ)\\widetilde{\\mathcal{O}}\\Big(\\sqrt{(M+P_{T})\\sum_{t=1}^{T}(\\|g_{t}\\|^{2}+\\lambda_{t}\\|g_{t}\\|)\\|u_{t}\\|}\\Big), where TT is the total horizon, gtg_{t} is the realized gradient at round tt, MM is the maximum norm of the comparator sequence, Œªt\\lambda_{t} and utu_{t} are the movement cost coefficient and the comparator at round tt, and PTP_{T} represents the comparator sequence path length. This guarantee exhibits three key layers of adaptivity: it scales with the comparator complexity, exploits favorable geometry through realized first-order information, and adjusts to arbitrary fluctuations in movement penalties.\n\n\nWe further demonstrate the versatility of our framework via reductions to two applications, showing that OCO with movement costs can serve as a primitive for other tasks.\nFirst, we show that OCO with delayed feedback reduces to time-varying movement costs by treating the number of missing gradients as the movement scale.\nThis reduction yields a parameter-free dynamic regret bound of ùí™~‚Äã((M2+M‚ÄãPT)‚Äã(T+dtot))\\widetilde{\\mathcal{O}}\\bigl(\\sqrt{\\left(M^{2}+MP_{T}\\right)\\left(T+d_{\\mathrm{tot}}\\right)}\\bigr), where dtotd_{\\mathrm{tot}} denotes the total delay.\nCompared with Wan et al. (2024), who establish a bound of ùí™~‚Äã((1+PT)‚Äã(T+dmax‚ÄãT))\\widetilde{\\mathcal{O}}\\bigl(\\sqrt{(1+P_{T})(T+d_{\\mathrm{max}}T)}\\bigr) for bounded domains (where dmaxd_{\\mathrm{max}} denotes the maximum delay) and only improve this to a dtotd_{\\mathrm{tot}} dependence under the restrictive assumption of in-order feedback, our result handles unbounded domains and achieves the tighter dtotd_{\\mathrm{tot}} dependence without assuming in-order arrival.\n\n\nSecond, under the assumption of coordinate-wise Lipschitz continuity, OCO with time-varying memory can be similarly reduced to our setting. This yields a ùí™~‚Äã((M2+M‚ÄãPT)‚Äã(H2‚ÄãT+G‚ÄãH‚Äã‚àëtbt2))\\widetilde{\\mathcal{O}}\\bigl(\\sqrt{(M^{2}+MP_{T})\\left(H^{2}T+GH\\sum_{t}b_{t}^{2}\\right)}\\bigr) regret bound, where GG is the coordinate-wise Lipschitz constant, HH bounds the gradient norm of the unary losses, and btb_{t} denotes the time-varying memory length. Compared with Zhao et al. (2023), who study dynamic regret for OCO with fixed memory length B‚â•1B\\geq 1 over bounded domains and establish a parameter-free bound of ùí™~‚Äã((1+PT)‚Äã(G‚ÄãH2‚ÄãB+G‚ÄãH‚ÄãB2)‚ÄãT)\\widetilde{\\mathcal{O}}\\Bigl(\\sqrt{(1+P_{T})\\bigl(\\sqrt{G}H^{2}B+GHB^{2}\\bigr)T}\\Bigr), our result applies to unconstrained domains and improves the dependence on the time-varying memory length.\n\n\n\n\n1.2 Related works\n\nOCO with movement costs.\n\nDue to its wide range of applications, OCO with movement costs, also known as smoothed OCO, has been extensively studied recently (Chen et al., 2018; Goel et al., 2019; Li et al., 2020). Closely related is the literature on online learning with switching costs, where the learner incurs an additional penalty, typically referred to as a switching cost, for changing decisions across rounds. This model has been investigated in a variety of settings, including prediction with expert advice (Cesa-Bianchi et al., 2013), multi-armed bandits (Dekel et al., 2014), and bandits with feedback graphs (Rangi and Franceschetti, 2019; Arora et al., 2019). Among these, the works most directly related to ours are Zhang et al. (2022b), which establishes the first guarantees for unconstrained static regret with movement costs, and Zhang et al. (2021), which develops the first optimal dynamic regret guarantees for bounded domains. Our work addresses the intersection of these two challenging settings by developing the first dynamic regret guarantees in unconstrained environments with movement costs. Another closely related line of work concerns OCO with memory (Merhav et al., 2002), where the loss at each round depends on a history of past decisions. Many algorithms in this setting enforce stability via reductions to OCO with movement costs (Anava et al., 2015). More recently, Wan et al. (2024) established dynamic regret guarantees for OCO with memory. While prior work focuses on constant memory length, our work provides the first dynamic-regret guarantees in unconstrained environments with time-varying memory.\n\n\n\nParameter-free online learning.\n\nOur work builds upon the recent line of work on comparator-adaptive (also known as parameter-free) methods in OCO. The unconstrained case was first studied by (McMahan and Streeter, 2012), in which a Œ©‚Äã(‚Äñu‚Äñ‚ÄãT‚Äãlog‚Å°(‚Äñu‚Äñ‚Äã"
  },
  {
    "title": "Supercharging Simulation-Based Inference for Bayesian Optimal Experimental Design",
    "url": "https://arxiv.org/abs/2602.06900v1",
    "source": "arxiv",
    "summary": "Bayesian optimal experimental design (BOED) seeks to maximize the expected information gain (EIG) of experiments. This requires a likelihood estimate, which in many settings is intractable. Simulation-based inference (SBI) provides powerful tools for this regime. However, existing work explicitly connecting SBI and BOED is restricted to a single contrastive EIG bound. We show that the EIG admits m",
    "full_text": "\n\n\n\n1 Introduction\n\n2 Background / Related Work\n\n2.1 Simulation based inference\n2.2 Bayesian optimal experiment design\n\n\n\n3 Methods\n\n3.1 Neural likelihood estimation\n3.2 Neural posterior estimation\n3.3 Neural ratio estimation\n3.4 Multiple parallel restart gradient ascent\n3.5 Sequential SBI\n\n\n\n4 Results\n\n4.1 Improving acquisition optimization\n4.2 Source finding in nn dimensions\n4.3 Pharmacokinetic model\n4.4 Constant elasticity of substitution\n\n\n5 Conclusion\nA Differentiable Simulators and Gradient Estimation\nB Direct EIG estimator with NLE\nC Acquisition optimization\n\nD Models\n\nD.1 Posterior model training\nD.2 Neural likelihood estimation\nD.3 Neural posterior estimation\nD.4 Neural ratio estimation\n\n\nE Timing information\n\nF Benchmark problems\n\n\nF.1 Source Finding Benchmark\n\nForward Model\nPrior Distribution\nExperimental Setup\n\n\n\nF.2 Pharmacokinetic Benchmark\n\nForward Model\nPrior Distribution\nExperimental Setup\nStatic baseline\n\n\n\nF.3 Constant Elasticity of Substitution (CES) Benchmark\n\nForward Model\nPrior Distribution\nExperimental Setup\n\n\n\n\nG Implementation and Software\n\n\n\n\n\nSupercharging Simulation-Based Inference\nfor Bayesian Optimal Experimental Design\n\n\nSamuel Klein\n\n‚ÄÉ‚ÄÉ\nWillie Neiswanger\n\n‚ÄÉ‚ÄÉ\nDaniel Ratner\n\n‚ÄÉ‚ÄÉ\nMichael Kagan\n\n‚ÄÉ‚ÄÉ\nSean Gasiorowski\n\n\n\nAbstract\nBayesian optimal experimental design (BOED) seeks to maximize the expected information gain (EIG) of experiments. This requires a likelihood estimate, which in many settings is intractable. Simulation-based inference (SBI) provides powerful tools for this regime. However, existing work explicitly connecting SBI and BOED is restricted to a single contrastive EIG bound. We show that the EIG admits multiple formulations which can directly leverage modern SBI density estimators, encompassing neural posterior, likelihood, and ratio estimation. Building on this perspective, we define a novel EIG estimator using neural likelihood estimation.\nFurther, we identify optimization as a key bottleneck of gradient based EIG maximization and show that a simple multi-start parallel gradient ascent procedure can substantially improve reliability and performance. With these innovations, our SBI-based BOED methods are able to match or outperform by up to 22%22\\% existing state-of-the-art approaches across standard BOED benchmarks.\n\nMachine Learning, ICML\n\n\n\n1 Introduction\n\nModern science experiments are often complex, high dimensional, and expensive.\nTo accomplish experimental goals, naive data collection approaches, such as grid or raster scans of spaces of interest, are often intractable, motivating more advanced methods for optimizing data acquisition.\nHere the focus is on cases where the scientific goal is to increase information about underlying system parameters, for which Bayesian Optimal Experimental Design (BOED)¬†(Rainforth et al., 2024) has emerged as the state-of-the-art.\nIn BOED, the objective is typically to design a sequence of experiments to maximize the expected information gain (EIG) about parameters of interest.\n\n\nThe fundamental object in BOED is the likelihood.\nWhile not all science cases make use of BOED for data acquisition, it is typical for this likelihood to be used in scientific analyses.\nOf particular interest for this work are contexts where explicit likelihoods are not available; in such cases, the likelihood is accessed indirectly via samples generated by a simulator.\nThis is common practice in domains such as particle physics¬†(Aad and others, 2025), astrophysics¬†(Alsing et al., 2019) and neuroscience¬†(Deistler et al., 2022), and significant effort has been invested to develop simulators of the underlying processes for each field.\nThe burgeoning field of simulation-based inference (SBI)¬†(Cranmer et al., 2020) has demonstrated particular success for scientific analysis without explicit likelihoods.\n\n\nFor both explicit and implicit likelihoods, BOED methods provide strategies for finding designs that maximize the EIG.\nThere are two main approaches that have emerged as promising candidates for optimizing the EIG in high dimensions¬†(Rainforth et al., 2024).\nPolicy-based approaches learn an amortized design policy, while per-trajectory approaches solve an EIG optimization after each measurement.\nIn a policy-based approach a network is trained to adapt to any realization of the parameters sampled from the prior.\nAt deployment, the policy samples designs without further optimization, enabling fast data acquisition.\nIn contrast, per-trajectory approaches run an EIG optimization procedure after every measurement, deriving solutions specific to each sequence of measurements performed.\nSurprisingly, prior work has found that per-trajectory optimization\nperforms poorly compared to policy-based strategies¬†(Ivanova et al., 2021; Zaballa and Hui, 2025),\ndespite the former customizing its design selection to the current set of observations.\n\n\nThis under-performance is especially problematic in settings where simulations are\nexpensive and training a policy is intractable, precisely where SBI methods\nare commonly employed¬†(Cranmer et al., 2020).\nFurther, while SBI has produced useful posteriors across diverse scientific domains, little work has directly connected these methods to BOED, with existing\nattempts reaching a significantly lower EIG than policy-based approaches¬†(Zaballa and Hui, 2025).\nIn the following we outline our contributions to this effort.\n\n\nComprehensive SBI-BOED framework. We provide an explicit connection between the three most widely-used SBI methods‚Äìneural posterior, likelihood, and ratio estimation‚Äìand variational bounds on the EIG.\nSpecifically, we use each of these SBI methods to directly compute variational approximations to the densities required for relevant formulations of the EIG bounds.\nThis affords practitioners the flexibility to choose the most appropriate method for their setting.\nAs a consequence of this connection, we define a new estimator for the EIG and analyze its performance and theoretical properties.\n\n\nImproved EIG optimization.\nWe identify that the underperformance of per-trajectory gradient-based EIG optimization is primarily due to convergence to local optima.\nWe propose multiple parallel restart gradient ascent (MPR-GA), a simple algorithm that significantly improves optimization performance, enabling SBI-based methods to match or exceed state-of-the-art policy-based approaches.\nThe increase in performance is significant, not an incremental improvement, revealing that the upper bound on performance is higher than previously thought.\nTo enable the MPR-GA technique, we identify and characterize challenges due to amortizing over designs.\n\n\nWe emphasize that, beyond our detailed contributions, there are important practical and conceptual connections between the fields of SBI and BOED.\nMany scientific domains have adopted SBI for posterior inference, leading to extensive development of specialized neural architectures and software tooling¬†(Boelts et al., 2025).\nModeling of densities is a dominant focus for SBI, with much effort devoted to flexibility, quality, and inductive biases¬†(Dax et al., 2021).\nBOED, which has historically used relatively simple variational models, has much to gain by leveraging this infrastructure.\nFurther, by explicitly connecting SBI posteriors to BOED, including describing how to sequentially update SBI posteriors, we expect that many existing scientific workflows may be translatable to data acquisition frameworks.\n\n\n\n\n2 Background / Related Work\n\nWhile there has been work on BOED for implicit models¬†(Kleinegesse and Gutmann, 2020; Ivanova et al., 2021; Kleinegesse and Gutmann, 2019; Zaballa and Hui, 2025), these approaches do not fully leverage or connect to modern SBI methods.\nThe one exception that makes explicit connections to SBI¬†(Zaballa and Hui, 2025) restricts itself to a single contrastive EIG bound. This leaves a broad range of SBI methodology unexploited for BOED.\n\n\n\n2.1 Simulation based inference\n\nIn many scientific domains, simulations provide an accurate model of the process that generated the data, with simulators encompassing all that is known about a system of interest.\nSimulators provide a way of sampling observations yy, given parameters of interest Œ∏\\theta and experimental designs Œæ\\xi, through a likelihood function p‚Äã(y|Œ∏,Œæ)p(y|\\theta,\\xi).\nThese likelihoods are often intractable, and SBI methods were developed to perform inference in these settings¬†(Cranmer et al., 2020).\nSBI methods provide ways of estimating posterior distributions p‚Äã(Œ∏|D)p(\\theta|D) where DD denotes previously observed data, using samples from a simulator.\nMany SBI methods focus on improving sample efficiency through adaptive simulation schemes¬†(Papamakarios and Murray, 2016; Lueckmann et al., 2017; Greenberg et al., 2019; Wiqvist et al., 2021; Griesemer et al., 2024; Papamakarios et al., 2019).\nThese schemes are often essential due to the high computational cost of running simulations in scientific contexts and the high dimensionality of the parameter space.\n\n\nThis work aims to pave the way for existing SBI infrastructure to be used directly for data acquisition using BOED.\nMany scientific workflows have already invested in SBI infrastructure for posterior inference.\nThis involves specialized simulators, training pipelines, and validation frameworks¬†(Hermans et al., 2022; Lueckmann et al., 2021).\nThese SBI systems often provide amortized posteriors that enable on-the-fly inference without retraining.\nIn this work we will assume that all simulators are differentiable. This makes gradient-based optimization of the EIG more straightforward, as gradients can be backpropagated through the simulator. Differentiable simulators are becoming more common in scientific contexts¬†(Kochkov et al., 2024; Gasiorowski et al., 2024; Heinrich and Kagan, 2023; Simpson and Heinrich, 2023) due to an increased understanding of automatic differentiation¬†(Baydin et al., 2018). We leave the case of non-differentiable simulators for"
  },
  {
    "title": "Sample Complexity of Causal Identification with Temporal Heterogeneity",
    "url": "https://arxiv.org/abs/2602.06899v1",
    "source": "arxiv",
    "summary": "Recovering a unique causal graph from observational data is an ill-posed problem because multiple generating mechanisms can lead to the same observational distribution. This problem becomes solvable only by exploiting specific structural or distributional assumptions. While recent work has separately utilized time-series dynamics or multi-environment heterogeneity to constrain this problem, we int",
    "full_text": null
  },
  {
    "title": "A Cycle-Consistent Graph Surrogate for Full-Cycle Left Ventricular Myocardial Biomechanics",
    "url": "https://arxiv.org/abs/2602.06884v1",
    "source": "arxiv",
    "summary": "Image-based patient-specific simulation of left ventricular (LV) mechanics is valuable for understanding cardiac function and supporting clinical intervention planning, but conventional finite-element analysis (FEA) is computationally intensive. Current graph-based surrogates do not have full-cycle prediction capabilities, and physics-informed neural networks often struggle to converge on complex ",
    "full_text": null
  },
  {
    "title": "Vision Transformer Finetuning Benefits from Non-Smooth Components",
    "url": "https://arxiv.org/abs/2602.06883v1",
    "source": "arxiv",
    "summary": "The smoothness of the transformer architecture has been extensively studied in the context of generalization, training stability, and adversarial robustness. However, its role in transfer learning remains poorly understood. In this paper, we analyze the ability of vision transformer components to adapt their outputs to changes in inputs, or, in other words, their plasticity. Defined as an average ",
    "full_text": "  class=\"with-cu-identity\"\n  \n  \n  \n    \n      Skip to main content\n      \n      \n        \n          \n        \n          We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.\n          Donate\n        \n      \n\n      \n\n  \n     &gt; cs &gt; arXiv:2602.06883v1\n  \n\n        \n        \n\n          \n    \n      \n        \n          \n          Help | Advanced Search\n        \n        \n          \n            \n              All fields\n              Title\n              Author\n              Abstract\n              Comments\n              Journal reference\n              ACM classification\n              MSC classification\n              Report number\n              arXiv identifier\n              DOI\n              ORCID\n              arXiv author ID\n              Help pages\n              Full text\n            \n          \n        \n        \n        Search\n      \n    \n  \n     \n\n      \n        \n          \n          \n            \n              \n              \n              \n            \n          \n          \n            open search\n            \n              \n                \n                  \n                  \n                  \n                  GO\n                \n              \n            \n\n            open navigation menu\n            \n              \n                quick links\n                \n                    Login\n                    Help Pages\n                    About\n                \n              \n            \n          \n        \n      \n    \n\n    \n      \n\n    \n    \n--\n\n  \n    \n      Computer Science  Machine Learning\n    \n\n    \n      arXiv:2602.06883v1 (cs)\n    \n\n\n  \n    \n  [Submitted on 6 Feb 2026]\n    Title:Vision Transformer Finetuning Benefits from Non-Smooth Components\n    Authors:Ambroise Odonnat, Laetitia Chapel, Romain Tavenard, Ievgen Redko            View a PDF of the paper titled Vision Transformer Finetuning Benefits from Non-Smooth Components, by Ambroise Odonnat and 3 other authors\n    View PDF\n\n\n\n    \n            Abstract:The smoothness of the transformer architecture has been extensively studied in the context of generalization, training stability, and adversarial robustness. However, its role in transfer learning remains poorly understood. In this paper, we analyze the ability of vision transformer components to adapt their outputs to changes in inputs, or, in other words, their plasticity. Defined as an average rate of change, it captures the sensitivity to input perturbation; in particular, a high plasticity implies low smoothness. We demonstrate through theoretical analysis and comprehensive experiments that this perspective provides principled guidance in choosing the components to prioritize during adaptation. A key takeaway for practitioners is that the high plasticity of the attention modules and feedforward layers consistently leads to better finetuning performance. Our findings depart from the prevailing assumption that smoothness is desirable, offering a novel perspective on the functional properties of transformers. The code is available at this https URL.\n    \n\n    \n    \n      \n          Subjects:\n          \n            Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)\n        \n          Cite as:\n          arXiv:2602.06883 [cs.LG]\n        \n        \n          &nbsp;\n          (or \n              arXiv:2602.06883v1 [cs.LG] for this version)\n          \n        \n        \n          &nbsp;\n                        https://doi.org/10.48550/arXiv.2602.06883\n              \n                \n                Focus to learn more\n              \n              \n              \n                                  arXiv-issued DOI via DataCite (pending registration)\n            \n          \n        \n    \n  \n\n    \n      Submission history From: Ambroise Odonnat [view email]          [v1]\n        Fri, 6 Feb 2026 17:12:22 UTC (1,704 KB)\n\n  \n  \n    \n      \n      Full-text links:\n      Access Paper:\n      \n  \nView a PDF of the paper titled Vision Transformer Finetuning Benefits from Non-Smooth Components, by Ambroise Odonnat and 3 other authorsView PDFTeX Source\n \n      \n          \n          view license\n        \n    \n        \n    Current browse context: cs.LG\n\n  \n\n      &lt;&nbsp;prev\n    \n    &nbsp; | &nbsp;    \n      next&nbsp;&gt;\n    \n  \n    new\n     | \n    recent\n     | 2026-02\n  \n    Change to browse by:\n    \n        cs\n        cs.CV\n        stat\n        stat.ML\n    \n  \n\n    \n      \n        References &amp; Citations\n        \n          NASA ADSGoogle Scholar\n          Semantic Scholar\n        \n        \n      \n\n\n    export BibTeX citation\n    Loading...\n\n\n\n    \n        \n            BibTeX formatted citation\n            &times;\n        \n        \n            loading...\n        \n        \n            Data provided by: \n            \n        \n    \n\n  Bookmark\n    \n  \n  \n    \n  \n  \n  \n\n\n  \n    Bibliographic Tools\n    \n      Bibliographic and Citation Tools\n      \n        \n          \n            \n              \n              \n              Bibliographic Explorer Toggle\n            \n          \n          \n            Bibliographic Explorer (What is the Explorer?)\n          \n        \n        \n          \n            \n              \n              \n              Connected Papers Toggle\n            \n          \n          \n            Connected Papers (What is Connected Papers?)\n          \n        \n          \n            \n              \n              \n              Litmaps Toggle\n            \n          \n          \n            Litmaps (What is Litmaps?)\n          \n        \n        \n          \n            \n              \n              \n              scite.ai Toggle\n            \n          \n          \n            scite Smart Citations (What are Smart Citations?)\n          \n        \n      \n        \n        \n        \n        \n    \n\n\n    \n    Code, Data, Media\n    \n      Code, Data and Media Associated with this Article\n      \n        \n          \n            \n              \n              \n              alphaXiv Toggle\n            \n          \n          \n            alphaXiv (What is alphaXiv?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            CatalyzeX Code Finder for Papers (What is CatalyzeX?)\n          \n        \n\n        \n          \n            \n              \n              \n              DagsHub Toggle\n            \n          \n          \n            DagsHub (What is DagsHub?)\n          \n        \n  \n        \n          \n            \n              \n              \n              GotitPub Toggle\n            \n          \n          \n            Gotit.pub (What is GotitPub?)\n          \n        \n\n        \n          \n            \n              \n              \n              Huggingface Toggle\n            \n          \n          \n            Hugging Face (What is Huggingface?)\n          \n        \n\n        \n          \n            \n              \n              \n              Links to Code Toggle\n            \n          \n          \n            Papers with Code (What is Papers with Code?)\n          \n        \n\n\n        \n          \n            \n              \n              \n              ScienceCast Toggle\n            \n          \n          \n            ScienceCast (What is ScienceCast?)\n          \n        \n      \n\n      \n      \n      \n      \n      \n      \n      \n      \n    \n\n\n      \n      Demos\n      \n        Demos\n        \n          \n            \n              \n                \n                \n                Replicate Toggle\n              \n            \n            \n              Replicate (What is Replicate?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              Hugging Face Spaces (What is Spaces?)\n            \n          \n          \n            \n              \n                \n                \n                Spaces Toggle\n              \n            \n            \n              TXYZ.AI (What is TXYZ.AI?)\n            \n          \n        \n        \n        \n        \n      \n      \n      Related Papers\n      \n        Recommenders and Search Tools\n        \n          \n            \n              \n                \n                \n                Link to Influence Flower\n              \n            \n            \n              Influence Flower (What are Influence Flowers?)\n            \n          \n          \n            \n              \n                \n                \n                Core recommender toggle\n              \n            \n            \n              CORE Recommender (What is CORE?)\n            \n                    \n            \n              \n                \n                \n                IArxiv recommender toggle\n              \n            \n            \n              IArxiv Recommender\n              (What is IArxiv?)\n            \n          \n\n        \n        \n          \n            Author\n            Venue\n            Institution\n            Topic\n          \n          \n            \n            \n            \n            \n          \n        \n        \n        \n      \n\n      \n      \n        About arXivLabs\n      \n      \n        \n          \n            arXivLabs: experimental projects with community collaborators\n            arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n            Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n            Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n          \n          \n            \n          \n        \n      \n\n    \n\n\n  \n    Which authors of this paper are endorsers? |\n    Disable MathJax (What is MathJax?)\n    \n  \n  mathjaxToggle();\n\n      \n    \n\n    \n      \n        \n  "
  },
  {
    "title": "Decoupling Variance and Scale-Invariant Updates in Adaptive Gradient Descent for Unified Vector and Matrix Optimization",
    "url": "https://arxiv.org/abs/2602.06880v1",
    "source": "arxiv",
    "summary": "Adaptive methods like Adam have become the $\\textit{de facto}$ standard for large-scale vector and Euclidean optimization due to their coordinate-wise adaptation with a second-order nature. More recently, matrix-based spectral optimizers like Muon (Jordan et al., 2024b) show the power of treating weight matrices as matrices rather than long vectors. Linking these is hard because many natural gener",
    "full_text": null
  }
]