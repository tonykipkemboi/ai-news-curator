[
  {
    "title": "Matrix messaging gaining ground in government IT",
    "url": "https://www.theregister.com/2026/02/09/matrix_element_secure_chat/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I wonder why matrix isn&#x27;t more widerspread at this point. It&#x27;s open, it&#x27;s e2ee, it works, it has client lib for integration with any tool..<p>What makes it not more popular ? Is it the federated approach ? The client applications that don&#x27;t look really fancy ?",
      "I was on a team that evaluated moving a significant portion of a product that should be used for government&#x2F;healthcare onto Matrix. There were several drawbacks that made us NOT go this route:<p>- Olm&#x2F;Megolm does not offer forward secrecy for group messaging<p>- Olm&#x2F;Megolm does ensure end-to-end encryption for message data, but not for metadata.<p>- Federation makes it challenging to be GDPR compliant<p>- Synapse is very heavy, other implementations are less production ready<p>- For better or worse, the matrix foundation is under UK jurisdiction.<p>I&#x27;m sure I forget some of the nuance, but these were some of the major points. However, there are several government entities in Germany, France, Poland, etc, that can live with the limitations and DO self-host Matrix servers.<p>I won&#x27;t go into the pair of high-severity vulns in 2025 (and the somewhat difficult mitigation) because that could hit anyone.",
      "I deleted my matrix account after I receive some very nasty spam in form of Element Android notification. I think it wasn&#x27;t Matrix direct fault, but as I used some Matrix chat groups and the list of member was public .. But I got really alarmed and angry when I receive so disgusting spam."
    ],
    "full_text": null
  },
  {
    "title": "Experts Have World Models. LLMs Have Word Models",
    "url": "https://www.latent.space/p/adversarial-reasoning",
    "source": "hn",
    "summary": "",
    "comments": [
      "I asked ChatGPT how it will handle objective scientific facts with a conclusion or intermediate results that may be considered offensive to some group somewhere in the world that might read it.<p>ChatGPT happily told me a series of gems like this:<p>We introduce:\n- Subjective regulation of reality\n- Variable access to facts\n- Politicization of knowledge<p>It’s the collision between: The Enlightenment principle\n  Truth should be free<p>and<p>the modern legal&#x2F;ethical principle \n  Truth must be constrained if it harms<p>That is the battle being silently fought in AI alignment today.<p>Right now it will still shamelessly reveal some of the nature of its prompt, but not why? who decides? etc. it&#x27;s only going to be increasingly opaque in the future. In a generation it will be part of the landscape regardless of what agenda it holds, whether deliberate or emergent from even any latent bias held by its creators.",
      "&gt; The model can be prompted to talk about competitive dynamics. It can produce text that sounds like adversarial reasoning. But the underlying knowledge is not in the training data. It’s in outcomes that were never written down.<p>With all the social science research and strategy books that LLMs have read, they actually know a LOT about outcomes and dynamics in adversarial situations.<p>The author does have a point though that LLMs can’t learn these from their human-in-the-loop reinforcement (which is too controlled or simplified to be meaningful).<p>Also, I suspect the _word_ models of LLMs are not inherently the problem, they are just inefficient representations of world models.",
      "Great article, nice to see some actual critical thoughts on the shortcomings of LLMs. They are wrong about programming being a &quot;chess-like domain&quot; though. Even at a basic level hidden state is future requirements, and the adversary is self or any other entity that has to modify the code in the future.<p>AI is good at producing code for scenarios where the stakes are low, there&#x27;s no expectation about future requirements, or if the thing is so well defined there is a clear best path of implementation.",
      "Fun play on words. But yes, LLMs are Large <i>Language</i> Models, not Large World Models. This matters because (1) the world cannot be modeled anywhere close to completely with language alone, and (2) language only <i>somewhat</i> models the world (much in language is convention, wrong, or not concerned with modeling the world, but other concerns like persuasion, causing emotions, or fantasy &#x2F; imagination).<p>It is somewhat complicated by the fact LLMs (and VLMs) are also trained in some cases on more than simple language found on the internet (e.g. code, math, images &#x2F; videos), but the same insight remains true. The interesting question is to just see how far we can get with (2) anyway.",
      "Great article. Executive summary: chocolate teapot holds cold water.",
      "&gt; what survives contact with a self-interested opponent?<p>In the work environment the optimal strategy will be parameterised culturally.<p>Companies have different cultures - both at the company level and at the country level.<p>In some places self-interest is the accepted driving force, in others if you behave like that you&#x27;ll find yourself quietly ostracised.<p>For example, I&#x27;m not sure Trump understands this.",
      "Makes the same mistake as all other prognostications: programming is not like chess. Chess is a finite &amp; closed domain w&#x2F; finitely many rules. The same is not true for programming b&#x2F;c the domain of programs is not finitely axiomatizable like chess. There is also no win condition in programming, there are lots of interesting programs that do not have a clear cut specification (games being one obvious category).",
      "editor here! all questions welcome - this is a topic i&#x27;ve been pursuing in the podcast for much of the past year... links inside.",
      "I’m always wary of anything that has such a clear example of a case that LLMs “don’t do” yet is trivially achieved by saying “review”.<p>The slack message result for example saying they’re the lead designer but nothing else (with clearer and better feedback if I say they’re notoriously overloaded, this is without that)<p>This is a very polite and respectful start, which is great since you are new. However, from a professional standpoint, it is a little too passive and vague.\nIn a busy work environment, saying &quot;no rush at all&quot; or &quot;whenever&quot; often leads to your request being buried at the bottom of a to-do list. Additionally, you haven&#x27;t told Priya exactly what she is looking at or where to find it.\nHere is a breakdown of how to strengthen this message to show you are organized and respectful of her time without being pushy.\nKey Improvements Needed\n * Include the Link: Never make someone ask &quot;Where are the files?&quot; Always drop the Figma&#x2F;Drive link immediately.\n * Be Specific: &quot;Any feedback&quot; is mentally taxing. Direct her attention to what you are actually unsure about (e.g., &quot;the color palette,&quot; &quot;the user flow,&quot; &quot;the spacing&quot;).\n * Soft Deadline: Instead of &quot;whenever,&quot; give a target. This helps her prioritize her week.\nOption 1: The Balanced Approach (Recommended)\nThis version strikes the perfect balance between politeness and productivity.\n&gt; &quot;Hi Priya! I’ve put together the initial mockups for [Project Name].\n&gt; [Link to file]\n&gt; When you have a moment, I’d love your feedback on [specific element, e.g., the layout of the landing page]. I’m hoping to wrap this stage up by [Day&#x2F;Time], but let me know what works for your schedule. Thanks!&quot;\n&gt; \nOption 2: The &quot;Respectful of Time&quot; Approach\nUse this if you know she is swamped, but you still want to make progress.\n&gt; &quot;Hi Priya, hope you&#x27;re having a good week. I&#x27;ve drafted the mockups for [Project Name] here: [Link].\n&gt; No major rush, but I’d appreciate your eyes on the [specific section] before I move on to high-fidelity. If it’s easier, feel free to leave comments directly in the file rather than messaging back. Thanks!&quot;\n&gt; \nOption 3: The &quot;Quick Check&quot; Approach\nUse this if you just need a sanity check before spending more time on it.\n&gt; &quot;Hi Priya, could I get a quick gut check on these mockups? [Link].\n&gt; I want to make sure I’m aligning with the new brand guidelines before I build out the rest of the screens. Does this direction look right to you?&quot;\n&gt; \nA Quick Checklist Before You Send\n * [ ] Did you change the permissions? Make sure the link is accessible (view&#x2F;comment access) so she doesn&#x27;t have to request access.\n * [ ] Is the file clean? Delete your &quot;scratchpad&quot; artboards or clearly label the one you want her to review so she doesn&#x27;t look at the wrong version.\nWould you like me to help you draft the specific sentence regarding the &quot;specific element&quot; you want her to critique?<p>&gt; Humans can model the LLM. The LLM can’t model being modeled<p>Can’t they? Why not?",
      "so at the moment combination of expert and llm is the smartest move. llm can deal with 80% of the situations which are like chess and expert deals with 20% of situations which are like poker."
    ],
    "full_text": null
  },
  {
    "title": "GitHub Agentic Workflows",
    "url": "https://github.github.io/gh-aw/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I noticed this unusual line in go.mod and got curious why it is using replace for this (typically you would `go get github.com&#x2F;Masterminds&#x2F;semver&#x2F;v3@v3.4.0` instead).<p><pre><code>  replace github.com&#x2F;Masterminds&#x2F;semver&#x2F;v3 =&gt; github.com&#x2F;Masterminds&#x2F;semver&#x2F;v3 v3.4.0\n</code></pre>\nI found this very questionable PR[0]. It appears to have been triggered by dependabot creating an issue for a version upgrade -- which is probably unnecessary to begin with. The copilot agent then implemented that by adding a replace statement, which is not how you are supposed to do this. It also included some seemingly-unrelated changes. The copilot reviewer called out the unrelated changes, but the human maintainer apparently didn&#x27;t notice and merged anyway.<p>There is just so much going wrong here.<p>[0] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;github&#x2F;gh-aw&#x2F;pull&#x2F;4469\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;github&#x2F;gh-aw&#x2F;pull&#x2F;4469</a>",
      "Github should focus on getting their core offerings in shape first.<p>I stopped using GH actions when I ran into this issue: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;community&#x2F;discussions&#x2F;151956#discussioncomment-15517821\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;community&#x2F;discussions&#x2F;151956#discuss...</a><p>That was almost a year ago and to this date I still get updates of people falling into the same issue.",
      "This is an extension for the gh cli that takes markdown files as input and creates github actions workflow files from them. Not just any workflow files, but 1000-line beasts that you&#x27;ll need an LLM to explain what they do.<p>I tried out `gh aw init` and hit Y at the wrong prompt. It created a COPILOT_GITHUB_TOKEN on the github repo I happened to be in presumably with a token from my account. That&#x27;s something that really should have an extra confirmation.",
      "Alternative, less phishy link: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;github&#x2F;gh-aw\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;github&#x2F;gh-aw</a><p>This is on GitHub&#x27;s official account. For some reason GitHub is deploying this on GitHub pages without a different domain?",
      "What timing. I used the whole weekend building a CI agentic workflow where I can let CC run wild with skip-permissions in isolated vms while working async on a gitea repo. I leave the CC instance with a decent sized mission and it will iterate until CI is green and then create a PR for me to merge. I&#x27;m moving from talking synchronously to one Clade Code to manage a small group of collaborating Claudes.",
      "Stuffing agents somewhere they don&#x27;t belong rather than making the system work better with the agents people already use. Obvious marketing driven cash grab.",
      "I am somehow close to what MSFT and GitHub are doing here, mostly because I believe it is a great idea, and I am experimenting on it myself.<p>Especially on the angle of automatic&#x2F;continuos improvement (<a href=\"https:&#x2F;&#x2F;github.github.io&#x2F;gh-aw&#x2F;blog&#x2F;2026-01-13-meet-the-workflows-continuous-simplicity&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;github.github.io&#x2F;gh-aw&#x2F;blog&#x2F;2026-01-13-meet-the-work...</a>)<p>Often code is seen as an artifact, that it is valuable by itself. This was an incomplete view before, and it is now a completely wrong view.<p>What is valuable is how code encode the knowledge of the organization building it.<p>But what it is even more valuable, is that knowledge itself. Embedded into the people of the organization.<p>Which is why continuos and automatic improvement of a codebase is so important. We all know that code rot with time&#x2F;features requests.<p>But at the same time, abruptly change the whole codebase architecture destroys the mental model of the people in the organization.<p>What I believe will work, is a slow stream of small improvements - stream that can be digested by the people in the organization.<p>In this context I find more useful to mix and control deterministic execution with a sprinkle of intelligence on top.\nSo a deterministic system that figure out what is wrong - with whatever definition of wrong that makes sense.\nAnd then LLMs to actually fix the problem, when necessary.",
      "&gt; GitHub Agentic Workflows deliver this: repository automation, running the coding agents you know and love, in GitHub Actions, with strong guardrails and security-first design principles.<p>GitHub Actions is the last organization I would trust to recognize a security-first design principle.",
      "It feels like every cloud product I use is accumulating more of these peripheral features I don&#x27;t want, while the core functionality is stagnant or even degrading. I&#x27;m assuming this is a Conway&#x27;s Law situation where the company has to grow, and they hire more devs, but those devs can&#x27;t all work on the core product so they make new greenfield stuff instead.<p>Until we stop chasing endless growth for it&#x27;s own sake we&#x27;re doomed to be stuck these enshittified products.",
      "The landing page doesn&#x27;t make it clear to me what value this is providing to me (as a user). I see all of these things that I can theoretically do, but I don&#x27;t see (1) actual examples of those things (2) how this specific agentic workflow helps."
    ],
    "full_text": null
  },
  {
    "title": "Roundcube Webmail: SVG feImage bypasses image blocking to track email opens",
    "url": "https://nullcathedral.com/posts/2026-02-08-roundcube-svg-feimage-remote-image-bypass/",
    "source": "hn",
    "summary": "",
    "comments": [
      "This is why SVG isn&#x27;t supported well for email clients.<p><a href=\"https:&#x2F;&#x2F;www.caniemail.com&#x2F;features&#x2F;html-svg&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.caniemail.com&#x2F;features&#x2F;html-svg&#x2F;</a>",
      "I often think the best way to defeat email open tracking would be for a mainstream email client to prefetch every image when a non-spam email is received and cache it for 72 hours or so.<p>Every email gets flagged as “opened,” so the flag is meaningless, and recipients can see the images without triggering a tracker.",
      "I have added a test for this to <a href=\"https:&#x2F;&#x2F;www.emailprivacytester.com\" rel=\"nofollow\">https:&#x2F;&#x2F;www.emailprivacytester.com</a>",
      "From reading a little bit of the code it sounds like Roundcube&#x27;s sanitizer is much closer to a blacklist than a whitelist. Any attempt to sanitize HTML with a blacklist is doomed to failure. Even if you read the current HTML spec (including referenced specs like SVG) and do a perfect job there are additions over time that you will be vulnerable to.<p>Probably any unknown element attribute pair should be stripped by default. And that&#x27;s still not considering different &quot;namespaces&quot; such as SVG and MathML that you need to be careful with.",
      "SVGs are just the tip of the iceberg of how hard it is to sanitize email content. There aren&#x27;t any purpose-built good libraries for email sanitization either. Something that would handle SVG, CSS, HTML, everything.",
      "I wondered what obscure part of the SVG spec included fel mages for a minute, damn sans serif.",
      "Slightly related, but fraudsters love using .svg attachments, typically the mails purport to be for an invoice which you need to log into your Microsoft account to be able to “securely” view.<p>I’m not sure if Exchange Online doesn’t scan them or something, but I landed up making a rule which blocks all emails with either .svg or .htm(l) attachments and to notify me when blocked.<p>Happens a couple of times per month for the our small company, no false positives yet.",
      "Hmm, I wonder, if roundcube was the exception (w.r.t feImage), or if soon other webmail clients will need to be patched",
      "Too bad CORS doesn&#x27;t fix this. It would be awesome to be able to sandbox a page completely.",
      "Not disputing the article, nor insinuating that there&#x27;s some ulterior motive, but it&#x27;s curious that this blog has only one post; and the About page suggests a lengthier history (with references to what would have been previous posts)."
    ],
    "full_text": null
  },
  {
    "title": "AI makes the easy part easier and the hard part harder",
    "url": "https://www.blundergoat.com/articles/ai-makes-the-easy-part-easier-and-the-hard-part-harder",
    "source": "hn",
    "summary": "",
    "comments": [
      "The article is gone, but going off the title here...<p>If the easy stuff takes up 90% of the time, and the hard stuff 10%, then AI can be helpful. Personally, I can do &quot;the easy stuff&quot; with AI about 3-5x faster. So now I have a lot more free time for the hard stuff.<p>I don&#x27;t let the AI near the hard stuff as it often gets confused and I don&#x27;t save much time. I might still use it as a thought partner, but don&#x27;t give it access to make changes.<p>Example: this morning I combined two codebases into one. I wrote both of them and had  a good understanding of how everything worked. I had an opinion about some things I wanted to change while combining the two projects. I also had a strong opinion about how I wanted the two projects to interact with each other. I think it would have taken me about 2 workdays to get this done. Instead, with AI tooling, I got it done in 3 or so hours. I fired up another LLM to do the code review, and it found some stuff both I and the other LLM missed. This was valuable as a person developing things solo.<p>It freed up time for me to post on HN. :)",
      "I vibe coded a retro emulator and assembler with tests. Prompts were minimal and I got really great results (Gemini 3). I tried vibe coding the tricky proprietary part of an app I worked on a few years ago; highly technical domain (yes vague don’t care to dox myself). Lots of prompting and didn’t get close.<p>There are literally thousands of retro emulators on github. What I was trying to do had zero examples on GitHub. My take away is obvious as of now. Some stuff is easy some not at all.",
      "This article has some serious usage of either bad prompting, or terrible models, or they’re referencing the past with their stories. I have experience AI’s deleting things they shouldn’t but not since like, the gpt4 days.<p>But that put aside, I don’t agree with the premise. It doesn’t make the hard parts harder, if you ACTUALLY spend half the time you’d have ORIGINALLY spent on the hard problem carefully building context and using smart prompting strategies. If you try and vibe code a hard problem in a one shot, you’re either gonna have a bad time straight away or you’re gonna have a bad time after you try and do subsequent prompting on the first codebase it spits out.<p>People are terrible observers of time. If you would’ve taken a week to build something, they try with AI for 2 hours and end up with a mess and claim either it’s not saving them any time or it’s making them code so bad it loses them time in the long run.<p>If instead they spent 8 hours slowly prompting bit by bit with loads of very specific requirements, technical specifications on exactly the code architecture it should follow with examples, build very slowly feature by feature, make it write tests and carefully add your own tests, observe it from the ground up and build a SOLID foundation, and spend day 2 slowly refining details and building features ONE BY ONE, you’d have the whole thing done in 2 days, and it’d be excellent quality.<p>But barely anyone does it this way. They vibe code it and complain that after 3 non specific prompts the ai wasn’t magically perfect.<p>After all these years of engineers complaining that their product manager or their boss is an idiot because they gave vague instructions and demanded it wasn’t perfect when they didn’t provide enough info, you’d think they’d be better at it given the chance. But no, in my experience coaching prompting, engineers are TERRIBLE at this. Even simple questions like “if I sent this prompt to you as an engineer, would you be able to do it based on the info here?” are things they don’t ask themselves.<p>Next time you use ai, imagine being the ai. Imagine trying to deliver the work based on the info you’ve been given. Imagine a boss that stamped their foot if it wasn’t perfect first try. Then, stop writing bad prompts.<p>Hard problems are easier with ai, if you treat hard problems with the respect they deserve. Almost no one does.<p>&#x2F;rant",
      "I think AI is just a massive force multiplier. If your codebase has bad foundation and going in the wrong direction with lots of hacks, it will just write code which mirrors the existing style... And you get exactly was OP is suggesting.<p>If however, your code foundations are good and highly consistent and never allow hacks, then the AI will maintain that clean style and it becomes shockingly good; in this case, the prompting barely even matters. The code foundation is everything.<p>But I understand why a lot of people are still having a poor experience. Most codebases are bad. They work (within very rigid constraints, in very specific environments) but they&#x27;re unmaintainable and very difficult to extend; require hacks on top of hacks. Each new feature essentially requires a minor or major refactoring; requiring more and more scattered code changes as everything is interdependent (tight coupling, low cohesion). Productivity just grinds to a slow crawl and you need 100 engineers to do what previously could have been done with just 1. This is not a new effect. It&#x27;s just much more obvious now with AI.<p>I&#x27;ve been saying this for years but I think too few engineers had actually built complex projects on their own to understand this effect. There&#x27;s a parallel with building architecture; you are constrained by the foundation of the building. If you designed the foundation for a regular single storey house, you can&#x27;t change your mind half-way through the construction process to build a 20-storey skyscraper. That said, if your foundation is good enough to support a 100 storey skyscraper, then you can build almost anything you want on top.<p>My perspective is if you want to empower people to vibe code, you need to give them really strong foundations to work on top of. There will still be limitations but they&#x27;ll be able to go much further.<p>My experience is; the more planning and intelligence goes into the foundation, the less intelligence and planning is required for the actual construction.",
      "I think it makes the annoying part less annoying?<p>Also re: &quot;I spent longer arguing with the agent and recovering the file than I would have spent writing the test myself.&quot;<p>In my humble experience arguing with an LLM is a waste of time, and no-one should be spending time recovering files. Just do small changes one at a time, commit when you get something working, and discard your changes and try again if it doesn&#x27;t.<p>I don&#x27;t think AI is a panacea, it&#x27;s just knowing when it&#x27;s the right tool for the job and when it isn&#x27;t.",
      "Skipping the investigation phase to jump straight to solutions has killed projects for decades. Requirements docs nobody reads, analysis nobody does, straight to coding because that feels like progress. AI makes this pattern incredibly attractive: you get something that looks like a solution in seconds. Why spend hours understanding the problem when you can have code right now?<p>The article&#x27;s point about AI code being &quot;someone else&#x27;s code&quot; hits different when you realize neither of you built the context. I&#x27;ve been measuring what actually happens inside AI coding sessions; over 60% of what the model sees is file contents and command output, stuff you never look at. Nobody did the work of understanding by building &#x2F; designing it. You&#x27;re reviewing code that nobody understood while writing it, and the model is doing the same.<p>This is why the evaluation problem is so problematic. You skipped building context to save time, but now you need that context to know if the output is any good. The investigation you didn&#x27;t do upfront is exactly what you need to review the AI&#x27;s work.",
      "&gt; <i>Reading and understanding other people&#x27;s code is much harder than writing code.</i><p>I keep seeing this sentiment repeated in discussions around LLM coding, and I&#x27;m baffled by it.<p>For the kind of function that takes me a morning to research and write, it takes me probably 10 or 15 minutes to read and review. It&#x27;s <i>obviously</i> easier to verify something is correct than come up with the correct thing in the first place.<p>And obviously, if it took longer to read code than to write it, teams would be spending the majority of their time in code review, but they don&#x27;t.<p>So where is this idea coming from?",
      "I don&#x27;t think it makes any part harder. What it does do is expose what people have ignored their whole career: the hard part. The last 15 years of software development has been &#x27;human vibe coding&#x27;; copy+pasting snippets from SO without understanding them, no planning, constant rearchitecting, shipping code to prod as long as it runs on your laptop. Now that the AI is doing it, suddenly people want to plan their work and enforce tests? Seems like a win-win to me. Even if it slows down development, that would be a win, because the result is enforcement of better quality.",
      "The &quot;marathon of sprints&quot; paradigm is now everywhere and AI is turning it to 120%. I am not sure how many devs can keep sprinting all the time without any rest. AI maybe can help but it tends to go off-rails quickly when not supervised and reading code one did not author is more exhausting than just fixing one&#x27;s own code.",
      "I&#x27;m feeling people are using AI in the wrong way.<p>Current LLM is best used to generate a string of text that&#x27;s most statically likely to form a sentence together, so from user&#x27;s perspective, it&#x27;s most useful as an alternative to manual search engine to allow user to find quick answers to a simple question, such as &quot;how much soda is needed for baking X unit of Y bread&quot;, or &quot;how to print &#x27;Hello World&#x27; in a 10 times in a loop in X programming language&quot;. Beyond this use case, the result can be unreliable, and this is something to be expected.<p>Sure, it can also generate long code and even an entire fine-looking project, but it generates it by following a statistical template, that&#x27;s it.<p>That&#x27;s why &quot;the easy part&quot; is easy because the easy problem you try to solve is likely already been solved by someone else on GitHub, so the template is already there. But the hard, domain-specific problem, is less likely to have a publicly-available solution."
    ],
    "full_text": null
  },
  {
    "title": "Shifts in U.S. Social Media Use, 2020–2024: Decline, Fragmentation, Polarization (2025)",
    "url": "https://arxiv.org/abs/2510.25417",
    "source": "hn",
    "summary": "",
    "comments": [
      "The paper (rightfully) does not address this, but I&#x27;d like to speculate about the reasons why, overall, usage has been dropping.<p>I think it&#x27;s because social media, as a whole, stopped providing any value to its users. In the early days it did bring a novel way to connect, coordinate, stay in touch, discover, and learn. Today, not so much.<p>It seems we are between worlds now, with the wells of the &quot;old order&quot; drying up, and the springs of the &quot;new order&quot; not found &#x2F; tapped just yet.",
      "Do you remember how these things were called social NETWORKS, as in something you navigate and explore? Then they gradually became social MEDIA, as in something you consume...",
      "&lt;&lt; As casual users disengage and polarized partisans remain vocal, the online public sphere grows smaller, sharper, and more ideologically extreme.<p>It.. feels accurate. I don&#x27;t frequent FB or other mainstream social spots, but even on HN, the pattern is relatively clear. Vocal minorities tend to drive the conversations to their respective corners, while the middle quietly moves to, at most, watch at a safe distance.<p>Part of me is happy about it. The sooner we get out of the social media landscape, the better the society as a whole will be.. in my opinion anyway. Still, we have already lost so much of the original internet. That loss makes me sad.",
      "&quot;The U.S. social media landscape is quietly reshaping itself. Between 2020 and 2024, overall platform use slipped, driven by a rise in the population – especially the youngest and oldest – who no longer use social media at all. The old incumbents – Facebook, YouTube, and Twitter&#x2F;X – have lost ground, while TikTok and Reddit have expanded modestly. The users who remain are slightly older, better educated, and more racially diverse than four years ago.<p>The political balance of social media has shifted just as noticeably. The once-clear Democratic lean of major platforms has declined. Twitter&#x2F;X, in particular, has seen a radical flip: a space dominated by Democrats in 2020 is now more Republican-aligned, especially among its most active users and posters. Reddit’s remains a Democraic stronghold, but its liberal edge has softened.<p>Across platforms, overall political posting has declined, yet its link with affective polarization persists. Those expressing the strongest partisan animus continue to post most frequently, meaning that visible political discourse remains dominated by the most polarized voices. This leads to a distorted representation of politics, that itself can function as a driver of societal polarization [17, 12].<p>Overall, the data depict a social media ecosystem in slow contraction and segmentation. As casual users disengage while polarized partisans remain highly active, the tone of online political life may grow more conflictual even as participation declines. The digital public sphere is becoming smaller, sharper, and louder: fewer participants, but stronger opinions. What remains online is a politics that feels more divided – not because more people are fighting, but because the fighters are the ones left talking.&quot;<p>Yup, nothing unexpected here.",
      "Been speaking to current college students and recent college grads and this is their general sentiment:<p>1. &quot;social media&quot; is toxic<p>They may consume video on YouTube etc but the thought is, even amongst smart kids, that there is no net positive to interacting with people you don&#x27;t know on social media.<p>This is somewhat disheartening given how many wonderful people I&#x27;ve met by just &quot;being myself&quot; on Twitter.<p>2. There is no central social media network anymore<p>I coached college club sports from the mid-2000s to the early 2010s. It&#x27;s hard to overstate how EVERYONE in college was on Facebook. We used to have a dedicated forum for one of the teams and the president convinced me to go to Facebook groups b&#x2F;c:<p>&quot;Everyone is already on it and it has a notification system that people check b&#x2F;c it&#x27;s how they find out about college parties&quot;<p>A current club president didn&#x27;t even know what would be the best way to reach students other than flyers and setting up a table at the student center.<p>(I suggested Reddit and he acknowledged that would probably be one place where you at least knew students from the school might be there and were interested.)",
      "After not logging into Twitter for years I logged back in because I wanted to follow some posts regarding some breaking news. Omg the amount of garbage and fake videos and pictures was overwhelming. My guess is bot content is now so realistic and engagement manipulation is so sophisticated from even a few years ago that people will disengage even more.",
      "i feel like the underlying thesis of this is maybe wrong. someone closer to the methodology would know better but here is what i see:<p>(1) Meta and Google have seen their growth slow (not shrink) because they reach virtually the entirety of the online population, especially in the US. Meanwhile their time spent metrics continue to rise.<p>(2) Reddit is called out as a modest grower but its usage has more than doubled in the US since 2021 from 90M to 170M (according to emarketer).<p>Doenst mean the conclusions are wrong (i agree with it on polarization) but the growth measures seem to not reflect reality.",
      "&gt; As casual users disengage and polarized partisans remain vocal, the online public sphere grows smaller, sharper, and more ideologically extreme.<p>I think it&#x27;s the root cause of all our issues (in democratic society).",
      "The social media cycle:<p>1. Quality brings success<p>2. Success brings popularity<p>3. Popularity brings idiots<p>4. Idiots destroy quality",
      "This is just manufacturing consent for requiring ID and face scans to use social media.<p>COVID happened, of course the trend will look like this without needing to wring a moral panic out of it."
    ],
    "full_text": null
  },
  {
    "title": "Claude’s C Compiler vs. GCC",
    "url": "https://harshanu.space/en/tech/ccc-vs-gcc/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I think this is a great example of both points of view in the ongoing debate.<p>Pro-LLM coding agents: look! a working compiler built in a few hours by an agent! this is amazing!<p>Anti-LLM coding agents: it&#x27;s not a working compiler, though. And it doesn&#x27;t matter how few hours it took, because it doesn&#x27;t work. It&#x27;s useless.<p>Pro: Sure, but we can get the agent to fix that.<p>Anti: Can you, though? We&#x27;ve seen that the more complex the code base, the worse the agents do. Fixing complex issues in a compiler seems like something the agents will struggle with. Also, if they could fix it, why haven&#x27;t they?<p>Pro: Sure, maybe now, but the next generation will fix it.<p>Anti: Maybe. While the last few generations have been getting better and better, we&#x27;re still not seeing them deal with this kind of complexity better.<p>Pro: Yeah, but look at it! This is amazing! A whole compiler in just a few hours! How many millions of hours were spent getting GCC to this state? It&#x27;s not fair to compare them like this!<p>Anti: Anthropic said they made a working compiler that could compile the Linux kernel. GCC is what we normally compile the Linux kernel with. The comparison was invited. It turned out (for whatever reason) that CCC failed to compile the Linux kernel when GCC could. Once again, the hype of AI doesn&#x27;t match the reality.<p>Pro: but it&#x27;s only been a few years since we started using LLMs, and a year or so since agents. This is only the beginning!<p>Anti: this is all true, and yes, this is interesting. But there are so many other questions around this tech. Let&#x27;s not rush into it and mess everything up.",
      "Something that bothers me here is that Anthropic claimed in their blog post that the Linux kernel could boot on x86 - is this not actually true then? They just made that part up?<p>It seemed pretty unambiguous to me from the blog post that they were saying the kernel could boot on all three arch&#x27;s, but clearly that&#x27;s not true unless they did some serious hand-waving with kernel config options. Looking closer in the repo they only show a claimed Linux boot for RISC-V, so...<p>[0]: <a href=\"https:&#x2F;&#x2F;www.anthropic.com&#x2F;engineering&#x2F;building-c-compiler\" rel=\"nofollow\">https:&#x2F;&#x2F;www.anthropic.com&#x2F;engineering&#x2F;building-c-compiler</a> - &quot;build a bootable Linux 6.9 on x86, ARM, and RISC-V.&quot;<p>[1]: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;anthropics&#x2F;claudes-c-compiler&#x2F;blob&#x2F;main&#x2F;BUILDING_LINUX.txt\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;anthropics&#x2F;claudes-c-compiler&#x2F;blob&#x2F;main&#x2F;B...</a> - only shows a test of RISC-V",
      "It&#x27;s really cool to see how slow unoptimised C is. You get so used to seeing C easily beat any other language in performance that you assume it&#x27;s really just intrinsic to the language. The benchmark shows a SQLite3 unoptimised build 12x slower for CCC, 20x for optimised build. That&#x27;s enormous!<p>I&#x27;m not dissing CCC here, rather I&#x27;m impressed with how much speed is squeezed out by GCC out of what is assumed to be already an intrinsically fast language.",
      "&gt; the build failed at the linker stage<p>&gt; The compiler did its job fine<p>&gt; Where CCC Succeeds\nCorrectness: Compiled every C file in the kernel (0 errors)<p>I don&#x27;t think that follows. It&#x27;s entirely possible that the compiler produced garbage assembly for a bunch of the kernel code that would make it totally not work even if it did link. (The SQLite code passing its self tests doesn&#x27;t convince me otherwise, because the Linux kernel uses way more advanced&#x2F;low-level&#x2F;uncommon features than SQLite does.)",
      "&quot;Ironically, among the four stages, the compiler (translation to assembly) is the most approachable one for an AI to build. It is mostly about pattern matching and rule application: take C constructs and map them to assembly patterns.<p>The assembler is harder than it looks. It needs to know the exact binary encoding of every instruction for the target architecture. x86-64 alone has thousands of instruction variants with complex encoding rules (REX prefixes, ModR&#x2F;M bytes, SIB bytes, displacement sizes). Getting even one bit wrong means the CPU will do something completely unexpected.<p>The linker is arguably the hardest. It has to handle relocations, symbol resolution across multiple object files, different section types, position-independent code, thread-local storage, dynamic linking and format-specific details of ELF binaries. The Linux kernel linker script alone is hundreds of lines of layout directives that the linker must get exactly right.&quot;<p>I worked on compilers, assemblers and linkers and this is almost exactly backwards",
      "It&#x27;s really difficult for me to understand the level of cynicism in the HN comments on this topic, at all. The amount of goalpost-moving and redefining is absolutely absurd. I really get the impression that the majority of the HN comments are just people whining about sour grapes, with very little value added to the discussion.<p>I&#x27;d like to see someone disagree with the following:<p>Building a C compiler, targeting three architectures, is hard. Building a C compiler which can correctly compile (maybe not link) the modern linux kernel is damn hard. Building a C compiler which can correctly compile sqlite and pass the test suite at any speed is damn hard.<p>To the specific issues with the concrete project as presented: This was the equivalent of a &quot;weekend project&quot;, and it&#x27;s <i>amazing</i><p>So what if some gcc is needed for the 16-bit stuff? So what if a human was required to steer claude a bit? So what if the optimizing pass practically doesn&#x27;t exist?<p>Most companies are not software companies, software is a line-item, an expensive, an unavoidable cost. The amount of code (not software engineering, or architecture, but programming) developed tends towards glue of existing libraries to accomplish business goals, which, in comparison with a correct modern C compiler, is far less performance critical, complex, broad, etc. No one is seriously saying that you have to use an LLM to build your high-performance math library, or that you have to use an LLM to build anything, much in the same way that no one is seriously saying that you have to rewrite the world in rust, or typescript, or react, or whatever is bothering you at the moment.<p>I&#x27;m reminded of a classic slashdot comment--about attempting to solve a non-technical problem with technology, which is doomed to fail--it really seems that the complaints here aren&#x27;t about the LLMs themselves, or the agents, but about what people&#x2F;organizations do with them, which is then a complaint about people, but not the technology.",
      "As a neutral observation: it’s remarkable how quickly we as humans adjust expectations.<p>Imagine five years ago saying that you could have a general purpose AI write a c compiler that can handle the Linux kernel, by itself, from scratch for $20k by writing a simple English prompt.<p>That would have been completely unbelievable! Absurd! No one would take it seriously.<p>And now look at where we are.",
      "Building a C compiler is definitely hard for humans, but I don’t think it’s particularly strong evidence of &quot;intelligence&quot; from an LLM. It’s a very well understood, heavily documented problem with lots of existing implementations and explanations in the training data.<p>These kinds of tasks are relatively easy for LLMs, they’re operating in a solved design space and recombining known patterns. It looks impressive to us because writing a compiler from scratch is difficult and time consuming for a human, not because of the problem itself.<p>That doesn’t mean LLMs aren’t useful, even if progress plateaued tomorrow, they’d still be very valuable tools. But building yet another C compiler or browser isn’t that compelling as a benchmark. The industry keeps making claims about reasoning and general intelligence, but I’d expect to see systems producing genuinely new approaches or clearly better solutions, not just derivations of existing OSS.<p>Instead of copying a big project, I&#x27;d be more impressed if they could innovate in a small one.",
      "&gt; Combined over a billion iterations: 158,000x total slowdown<p>I don&#x27;t think that&#x27;s a valid explanation. If something takes 8x as long then if you do it a billion times it still takes 8x as long. Just now instead of 1 vs 8 it&#x27;s 1 billion vs 8 billion.<p>I&#x27;d be curious to know what&#x27;s actually going on here to cause a multiple order of magnitude degradation compared to the simpler test cases (ie ~10x becomes ~150,000x). Rather than I-cache misses I wonder if register spilling in the nested loop managed to completely overwhelm L3 causing it to stall on every iteration waiting for RAM. But even that theory seems like it could only account for approximately 1 order of magnitude, leaving an additional 3 (!!!) orders of magnitude unaccounted for.<p>I think there&#x27;s a lot more to the story here.",
      "My 2 cents: just like Cursor&#x27;s browser, it seems the AI attempted a really ambitious technical design, generally matching the bells and whistles of a true industrial strength compiler, with SSA optimization passes etc.<p>However looking at the assembly, it&#x27;s clear to me the opt passes do not work, an I suspect it contains large amounts of &#x27;dead code&#x27; - where the AI decided to bypass non-functioning modules.<p>If a human expert were to write a compiler not necessarily designed to match GCC, but provide a really good balance of features to complexity, they&#x27;d be able to make something much simpler. There are some projects like this (QBE,MIR), which come with nice technical descriptions.<p>Likewise there was a post about a browser made by a single dude + AI, which was like 20k lines, and worked about as well as Cursor&#x27;s claimed. It had like 10% of the features, but everything there worked reasonably well.<p>So while I don&#x27;t want to make predictions, but it seems for now, the human-in-the-loop method of coding works much better (and cheaper!) than getting AI to generate a million lines of code on its own."
    ],
    "full_text": null
  },
  {
    "title": "TSMC to make advanced AI semiconductors in Japan",
    "url": "https://apnews.com/article/semiconductors-tsmc-japan-taiwan-ai-11256f2bfde73ca23d08331ad138d6d5",
    "source": "hn",
    "summary": "",
    "comments": [
      "Japan and America have now both gotten TSMC to commit to a decent level of domestic advanced-node fabrication.<p>Meanwhile Europe only got 40k WSPMs of 12+ nm capacity: <a href=\"https:&#x2F;&#x2F;overclock3d.net&#x2F;news&#x2F;software&#x2F;bringing_advanced_semiconductor_manufacturing_to_europe_esmc_is_making_it_happen&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;overclock3d.net&#x2F;news&#x2F;software&#x2F;bringing_advanced_semi...</a>",
      "Taiwanese politicians, like those under American-style democracy in many regions, only care about safeguarding their own interests and have no concern for how to protect the interests of the public. Once TSMC’s factories are completed in Japan and the United States and the technology is secured, Taiwan will no longer have any value worth protecting. Of course, the politicians can always take planes and leave in advance.",
      "the move to decentralize tsmc&#x27;s footprint to japan is such a massive play for supply chain resilience. from a macro risk standpoint, having advanced node capacity outside of the immediate geopolitical tension zone is basically the ultimate catastrophic insurance policy for the global tech economy. it&#x27;s interesting to see how the &#x27;just in case&#x27; logic is finally starting to override just in time efficiency.",
      "Is this a decision took in light of the new prime minister’s party winning 2&#x2F;3 lower house majority and her statements about protecting Taiwan against China?",
      "Isn’t Japan even more earthquake prone than Taiwan? Is that a good idea for the most sensitive electronics known to man?",
      "Not surprising from the fact that Taiwanese like Japan",
      "Pretty clear these days that the bottlenecks in technology manufacturing are now weaponising their monopolies&#x2F;duopolies &#x2F; triopolies.<p>They’ve become the trolls under the bridge and will squeeze every passerby for every dollar they’ve got.<p>The days of cheap computing have been in decline and are now dead, replaced with giga profits for this companies who managed to the the indispensable links in a chain with no or minimal competition.",
      "Isn’t this an erosion of the silicon shield Taiwan is protected by? If they make semiconductors everywhere else then the world has less economic incentive to protect Taiwan from war.",
      "Nature is healing.jpg"
    ],
    "full_text": null
  },
  {
    "title": "Matchlock – Secures AI agent workloads with a Linux-based sandbox",
    "url": "https://github.com/jingkaihe/matchlock",
    "source": "hn",
    "summary": "",
    "comments": [
      "Sandboxing is a great security step for agents. Just like using guardrails is a great security step. I can&#x27;t help but feel like it&#x27;s all soft defense though. The real danger comes from the agent being able to read 3rd party data, be prompt injected, and then change or exfiltrate sensitive data. A sandbox does not prevent an email-reading agent from reading a malicious email, being prompt injected, and then sending an email to a malicious email address with the contents of your inbox. It does help in implementing network-layer controls though, like apply a policy that says this linux-based sandbox is only allowed to visit [whitelisted] urls. This kind of architectural whitelisting is the only hard defense we have for agents at the moment. Unfortunately it will also hamper their utility if used to the greatest extent possible.",
      "Huh. You&#x27;re converting FUSE requests into your own custom protocol (with copy-pasted protocol definition) over vsock. Interesting. Not sure I&#x27;d trust it with my data[0], but interesting.<p>I don&#x27;t think the current filepath.Join in realfs.go protects the host against a malicious guest, at all. I&#x27;m assuming this is configured as Guest --FUSE--&gt; guest-fused (inside VM) --VSOCK--&gt; realfs.<p>(The Firecracker people have explicitly refused to have virtio-fs, to keep it minimal: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;firecracker-microvm&#x2F;firecracker&#x2F;pull&#x2F;1351#issuecomment-667085798\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;firecracker-microvm&#x2F;firecracker&#x2F;pull&#x2F;1351...</a>)<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;jingkaihe&#x2F;matchlock&#x2F;blob&#x2F;123a4df680fb8cc060a46f9628d9cb11a0dc0283&#x2F;cmd&#x2F;guest-fused&#x2F;main.go\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jingkaihe&#x2F;matchlock&#x2F;blob&#x2F;123a4df680fb8cc0...</a><p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;jingkaihe&#x2F;matchlock&#x2F;blob&#x2F;123a4df680fb8cc060a46f9628d9cb11a0dc0283&#x2F;pkg&#x2F;vfs&#x2F;server.go\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jingkaihe&#x2F;matchlock&#x2F;blob&#x2F;123a4df680fb8cc0...</a><p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;jingkaihe&#x2F;matchlock&#x2F;blob&#x2F;123a4df680fb8cc060a46f9628d9cb11a0dc0283&#x2F;pkg&#x2F;vfs&#x2F;realfs.go\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jingkaihe&#x2F;matchlock&#x2F;blob&#x2F;123a4df680fb8cc0...</a><p>[0]: Well, I already know I won&#x27;t trust hanwen&#x2F;go-fuse with my data, so that part is a bit moot.",
      "We definitely need a vendor-independent tool like this. Have been reviewing the Claude setup and, despite initially being hopeful since it uses bubblewrap, it&#x27;s quite problematic:<p>* The definitions of security config in the documentation of settings.json are unclear. Since it&#x27;s not open source, you can&#x27;t check the ground truth.<p>* The built in constructs are insufficient to do fully whitelist based access control (It might be possible with a custom hook).<p>* Security related issues go unanswered in the repo, and are automatically closed.<p>Haven&#x27;t looked into copilot as much but didn&#x27;t look great either. Seems like the vendors don&#x27;t have the incentives to do this properly.<p>So I&#x27;m on the lookout for a better way, and matchlock seems like a contender.",
      "sandboxing is really the only way to make agentic workflows auditable for enterprise risk. we can&#x27;t underwrite trust in the model&#x27;s output, but we can underwrite the isolation layer. if you can prove the agent literally cannot access the host network or sensitive volumes regardless of its instructions, that&#x27;s a much cleaner compliance story than just relying on system prompts.",
      "This is the confused deputy problem at the application layer. Sandboxing secures the environment, but if the agent has legitimate access to sensitive operations (email, database writes, API calls), prompt injection attacks work through approved channels. The only hard defense is explicit user confirmation for each action, which defeats the point of autonomy.",
      "I&#x27;ve been happily using a container to run my agents [1]. I tried to make it evolve with more advanced features, but it quickly became harder to use and I went back to a basic container which I just start with a run.sh script. Is a similar simple use possible with matchlock?<p>1:<a href=\"https:&#x2F;&#x2F;github.com&#x2F;asfaload&#x2F;agents_container\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;asfaload&#x2F;agents_container</a>",
      "This is great.  Wish this was around when I started working on vibebin ( <a href=\"https:&#x2F;&#x2F;github.com&#x2F;jgbrwn&#x2F;vibebin\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jgbrwn&#x2F;vibebin</a> ), probably would have leveraged matchlock instead of Incus&#x2F;LXC. I guess I could fork&#x2F;branch and give it a go!  Although for vibebin use case I actually need them to not be ephemeral. Edit, ooooh i see `--rm=false` nice<p>Where do the images come from?  What are our options around that and also using custom images etc?",
      "What are the advantages of using this over lxd system container or if we want VM isolation them lxd VMs? Is it the developer experience or there are any agent specific experience which is the key thing here?",
      "containers are fine for basic isolation but the attack surface is way bigger than people think. you&#x27;re still trusting the container runtime, the kernel, and the whole syscall interface. if the agent can call arbitrary syscalls inside the container, you&#x27;re one kernel bug away from a breakout.<p>what I&#x27;m curious about with matchlock - does it use seccomp-bpf to restrict syscalls, or is it more like a minimal rootfs with carefully chosen binaries? because the landlock LSM stuff is cool but it&#x27;s mainly for filesystem access control. network access, process spawning, that&#x27;s where agents get dangerous.<p>also how do you handle the agent needing to install dependencies at runtime? like if claude decides it needs to pip install something mid-task. do you pre-populate the sandbox or allow package manager access?",
      "Why would secrets ever need to be available to the agent directly rather than hidden inside the tool calling framework?"
    ],
    "full_text": null
  },
  {
    "title": "Reverse Engineering Raiders of the Lost Ark for the Atari 2600",
    "url": "https://github.com/joshuanwalker/Raiders2600",
    "source": "hn",
    "summary": "",
    "comments": [
      "comments: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46925934\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46925934</a>",
      "I&#x27;m well familiar with 6502 shenanigans, but never really looked into 2600 programming before. Looking into that source file though, I got the impression that Atari mapped the I&#x2F;O right into zero page? Kind of surprising, but I guess with the 6507 the effective address space was only 8K, so why not. Certainly if you&#x27;re trying to get all your computing done in the blanking intervals, it&#x27;d help if banging the video chip could be done that much quicker as well.",
      "One of the authors, Dennis Debro, has done a bunch more of these: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;DNSDEBRO&#x2F;Disassemblies\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;DNSDEBRO&#x2F;Disassemblies</a>"
    ],
    "full_text": null
  },
  {
    "title": "Show HN: Emergent – Artificial life simulation in a single HTML file",
    "url": "https://emergent-ivory.vercel.app/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Show HN: Agentseed – Generate Agents.md from a Codebase",
    "url": "https://github.com/avinshe/agentseed",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Containers, cloud, blockchain, AI – all the same old BS, says veteran Red Hatter",
    "url": "https://www.theregister.com/2026/02/08/waves_of_tech_bs/",
    "source": "hn",
    "summary": "",
    "comments": [
      "This is an opinion piece to get people arguing.  Other topics that activate people are <i>which browser is best</i>, <i>iPhone vs Android</i>, <i>Which operating system...</i>, <i>Darkmode vs. ...</i>, <i>which scripting language...</i>, <i>Rust is best for ...</i> and so on.  4chan-GPT posts this automatically on 4chan from Seychelles to get people arguing to keep the site looking active and it works every single time.  El Reg is trolling.",
      "I think this veteran Red Hatter is confusing the marketing names for actual useful services and technology.<p>IE. He&#x27;s complaining about the &quot;cloud&quot; and says if you need servers, you should buy and maintain servers yourself. It&#x27;s honestly absurd. This kind of mentality is gate keeping in my opinion by IT professionals - if you don&#x27;t know how do setup and maintain a server, you should pay me to do it for you instead of paying AWS. I&#x27;m sure this guy would tell my grand parents if you need to back up photos on the iPhone, they should setup a personal NAS at home.<p>I find it ironic that The Register is publishing this when their tech stack likely uses everything listed, except maybe crypto.<p>PS. Don&#x27;t mistaken me for a crypto currency supporter. They always lump crypto together with AI to try to dismiss AI. I&#x27;m a crypto hater.",
      "I don&#x27;t agree about containers, they are a really handy tool to produce stable(-ish) deployments.<p>Blockchain is probably the best single tool to do what software was designed to do since invented as a separate industry - scam people out of their money.<p>The rest, true."
    ],
    "full_text": null
  },
  {
    "title": "Big Tech groups race to fund unprecedented $660B AI spending spree",
    "url": "https://www.ft.com/content/d503afd5-1012-40f0-8f9d-620dcb39a9a2",
    "source": "hn",
    "summary": "",
    "comments": [
      "<a href=\"https:&#x2F;&#x2F;archive.is&#x2F;ZwCIo\" rel=\"nofollow\">https:&#x2F;&#x2F;archive.is&#x2F;ZwCIo</a>",
      "Behind a paywall :&#x2F;"
    ],
    "full_text": null
  },
  {
    "title": "Billing can be bypassed using a combo of subagents with an agent definition",
    "url": "https://github.com/microsoft/vscode/issues/292452",
    "source": "hn",
    "summary": "",
    "comments": [
      "Even without hacks, Copilot is still a cheap way to use Claude models:<p>- $10&#x2F;month<p>- Copilot CLI for Claude Code type CLI, VS Code for GUI<p>- 300 requests (prompts) on Sonnet 4.5, 100 on Opus 4.6 (3x)<p>- One prompt only ever consumes one request, regardless of tokens used<p>- Agents auto plan tasks and create PRs<p>- &quot;New Agent&quot; in VS Code runs agent locally<p>- &quot;New Cloud Agent&quot; runs agent in the cloud (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;copilot&#x2F;agents\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;copilot&#x2F;agents</a>)<p>- Additional requests cost $0.04 each",
      "&gt; Note: Initially submitted this to MSRC (VULN-172488), MSRC insisted bypassing billing is outside of MSRC scope and instructed me multiple times to file as a public bug report.<p>Good job, Microsoft.",
      "I did that weeks ago: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46757318\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46757318</a>",
      "The &quot;premium request&quot; billing model where you pay per invocation and not for usage is very obviously not a sustainable approach and creates skewed incentives (e.g. for microsoft to degrade response quality), especially with the shift towards longer running agentic sessions as opposed to simple oneshot chat questions, which the system was presumably designed for. Its just a very obvious fundamental incompatibility and the system is in increasing need of replacement. Usage linked (pay per token) is probably the way to go, as is industry standard.",
      "Have confirmed that many of these AI agents and Agentic IDEs implement business logic and guardrails LOCALLY on the device.<p>(Source: submitted similar issue to different Agentic LLM provider)",
      "The laat comment is a person pretending to be a maintainer of Microsoft. I have a gut feeling that these kind of people will only increase, and we&#x27;ll have vibe engineers scouring popular repositories to &quot;&quot;contribute&quot;&quot; (note that the suggested fix is vague).<p>I completely understand why some projects are in whitelist-contributors-only mode. It&#x27;s becoming a mess.",
      "&gt; The right script, with the right prompts can be tailored to create a loop, allowing the premium model to continually be invoked unlimited times for no additional cost beyond that of the initial message.<p>Ralph loops for free...",
      "I&#x27;m missing something with the first example, can anyone shed some light?<p>The last line of the instructions says:<p>&gt; The premium model will be used for the subagent - but premium requests will be consumed.<p>How is that different to just calling the premium model directly if its using premium requests either way?",
      "My guess is either someone raised this internally and was told it was fine, or knew but didn&#x27;t bother raising it since they knew they’d be blown off.",
      "Copilot fairly recently added support for running sub-agents using different models to the model that invoked them.<p>If this report is to be believed, they didn&#x27;t implement billing correctly for the sub-agents allowing more costly models to be run for free as sub-agents."
    ],
    "full_text": null
  },
  {
    "title": "Do Markets Believe in Transformative AI?",
    "url": "https://marginalrevolution.com/marginalrevolution/2025/09/do-markets-believe-in-transformative-ai.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "The markets and I agree then.<p>I&#x27;m a firm believer in technological progress, but not so fond of group-think hype trains.  The LLM&#x2F;diffusion breakthrough(s) are huge, but they aren&#x27;t what their rabid fans&#x2F;neurotic critics are thinking.",
      "I&#x27;m not clear how the bond markets should behave if they say expect agi in five years. Do long bonds go up or down?<p>Thinking about it long bond should mostly reflect the rate of inflation which depends much more on monetary policy than tech. Like after WW1, Germany and the US had much the same tech but Germany had hyperinflation and the US very little because Germany printed a lot of money and the US was on the gold standard.<p>The equity markets seem quite keen on NVDA stock though.",
      "I don&#x27;t believe it&#x27;ll work for anything that doesn&#x27;t have a tight feedback loop. So while it can replace a lot of software engineers, it doesn&#x27;t seem plausible to me that it would make a significant difference in other engineering industries.",
      "It tells a lot about our society that the only way to apply capital is to build a slop machine that will make us redundant."
    ],
    "full_text": null
  },
  {
    "title": "Apple Container 0.9.0",
    "url": "https://github.com/apple/container/releases/tag/0.9.0",
    "source": "hn",
    "summary": "",
    "comments": [
      "Is there anything especially interesting about version 0.9.0? Nothing stands out to me in the changelog.",
      "Has anyone used this for shipping native apps? I know that&#x27;s not what it was designed for but I would love to be able to ship a Tauri + rails app some day",
      "is this à replacement for docker ?<p>Super interesting that they&#x27;re using swift. Does this mean the project is only a wrapper for system libraries ? I can&#x27;t imagine writing low-level system code in swift yet.",
      "Anybody tried running vscode server in this? I don’t want to run it on my macOS with no sandbox, I find the full file access in the browser to be uncomfortable. I’ve fought Colima before and ran it within there but the host&#x2F;vm permissions for editing files in a projects folder were a pain.<p>So it’d be cool if this or a sandbox tool could help."
    ],
    "full_text": null
  },
  {
    "title": "NanoClaw now supports Claude's Agent Swarms in containers",
    "url": "https://twitter.com/Gavriel_Cohen/status/2020701159175155874",
    "source": "hn",
    "summary": "",
    "comments": [
      "Possible sponsored content being injected by Claude into the NanoClaw repo?<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;gavrielc&#x2F;nanoclaw&#x2F;commit&#x2F;22eb5258057b49a08f4ea18c8e15df289e8fd884\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;gavrielc&#x2F;nanoclaw&#x2F;commit&#x2F;22eb5258057b49a0...</a>",
      "I watched the entire video: kind of ironic that the swarm was tasked with something and produced nothing of value."
    ],
    "full_text": null
  },
  {
    "title": "Beyond agentic coding",
    "url": "https://haskellforall.com/2026/02/beyond-agentic-coding",
    "source": "hn",
    "summary": "",
    "comments": [
      "&gt; You could take an editor session, a diff, or a pull request and automatically split it into a series of more focused commits that are easier for people to review. This is one of the cases where the AI can reduce human review labor<p>I feel this should be a bigger focus than it is. All the AI code review start up are mostly doing “hands off” code review. It’s just an agent reviewing everything.<p>Why not have an agent create a perfect “review plan” for human consumption? Split the review up in parts that can be individually (or independently) reviewed and then fixed by the coding agent. Have a proper ordering in files (GitHub shows files in a commit alphabetically, which is suboptimal), and hide boring details like function implementations that can be easily unit tested.",
      "I wonder if the problem of idle time &#x2F; waiting &#x2F; breaking flow is a function of the slowness. That would be simple to test, because there are super fast 1000 tok&#x2F;s providers now.<p>(Waiting for Cerebras coding plan to stop being sold out ;)<p>I&#x27;ve used them for smaller tasks (making small edits), and the &quot;realtime&quot; aspect of it does provide a qualitative difference. It stops being async and becomes interactive.<p>A sufficient shift in quantity produces a phase shift in quality.<p>--<p>That said, the main issue I find with agentic is my mental model getting desynchronized. No matter how fast the models get, it takes a fixed amount of time for me to catch up and understand what they&#x27;ve done.<p>The most enjoyable way I&#x27;ve found of staying synced is to stay in the driver&#x27;s seat, and to command many small rapid edits manually. (i.e. I have my own homebrew &quot;agent&quot; that&#x27;s just a loop of, I prompt it, it proposes edits, I accept or edit, repeat.)<p>So then the &quot;synchronization&quot; of the mental state is happening continuously, because there is no opportunity for desynchronization. Because you are the one driving. I call that approach semi-auto, or Power Coding (akin to Power Armor, which is wielded manually but greatly enhances speed and strength).",
      "Post had nothing to do with Haskell so the title is a bit misleading. But rest of article is good, and I actually think that Agentic&#x2F;AI coding will probably evolve in this way.<p>The current tools are the infancy of AI assisted coding. It’s like the MS-DOS era. Over time maybe the backpropagating from “your comfort language” to “target language” could become commonplace.",
      "What I&#x27;ve found is that most people who dislike the chat interface aren&#x27;t using it in a way that leverages its strengths.<p>Up until recently, LLMs just plain sucked. You&#x27;d set them on a task and then spend hours hand-holding them to output something almost correct.<p>Nowadays you can have a conversation with the chatbot, hash out a design, rubber duck and discuss what-ifs until you have a solid idea of the thing you&#x27;re building, codified in a way an agent could understand, and now you have a PLAN.<p>From there, it&#x27;s a matter of setting the agent in motion and checking from time to time to make sure it&#x27;s not getting stuck on something under-specified.<p>That said, I&#x27;ve found that this kind of workflow works a lot better with claude than with gemini.",
      "I have the same feeling recently that we should focus more on using AI to enable us, to empower us to do the important things. Not take away but enhance, boring , clear boilerplate yes, design decisions no. \nAnd making reviewing easier is a perfect example of enhancing our workflow.\nNot reviewing for us, but supporting us.<p>I am recently using this tiny[1] skill to generate an order on how to review a PR and it has been very helpful to me.<p><a href=\"https:&#x2F;&#x2F;www.dev-log.me&#x2F;pr_review_navigator_for_claude&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.dev-log.me&#x2F;pr_review_navigator_for_claude&#x2F;</a>",
      "This feels like an opposite of my experience. I find just having a bunch of Claude Code terminals running in the background to be the most &quot;ambient&quot;, while I find autocomplete&#x2F;auto-navigate the likes of Copilot&#x2F;Cursor to be so annoying that I don&#x27;t use any AI autocomplete now. Regardless, I think there&#x27;s still a lot of room for structured AI programming flows, especially regarding semantic search, code flow tracing and intelligent find and replace.",
      "I have been considering what it would be like to give each function name a specific color and a color for each variable&#x27;s type followed by a color derived from the hash of the symbol name and keywords would each be their specific type. And essentially printing a matrix of this, essentially transforming your code into a printable matrix &quot;low-lod&quot; or &quot;mipmap&quot; form. This could be implemented like the VSCode minimap but I the right move here is to implement it as a hook that can modify the output of your agent. That way you can look at the structure of the code without reading the names in particular.",
      "I whole heartedly prefer chat interfaces over inline ai suggestions.<p>I find the inline stuff so incredibly annoying because they move around the text I am looking at.",
      "I really like the &quot;file lens&quot; example:<p>&gt; “Focus on…” would allow the user to specify what they&#x27;re interested in changing and present only files and lines of code related to their specified interest.<p>&gt; “Edit as…” would allow the user to edit the file or selected code as if it were a different programming language or file format.",
      "The &quot;junior dev&quot; analogy is the one I keep coming back to, but the part people miss is the review surface area problem.<p>When a human junior writes code, they leave breadcrumbs of their thinking — commit messages, PR descriptions, comments explaining why they chose approach A over B. You can reconstruct their reasoning from the artifact trail.<p>Agents don&#x27;t do this naturally. You get a diff with no context for why it went that direction. So the reviewer has to reverse-engineer the thinking from the code alone, which is actually harder than reviewing human code because there are no &quot;tells&quot; — no familiar coding style, no consistent patterns that hint at the developer&#x27;s mental model.<p>The semi-auto approach mentioned upthread works precisely because it solves this: you were there for every decision, so there&#x27;s nothing to reconstruct. The productivity loss from staying in the loop is offset by the time you save not having to audit opaque changes after the fact."
    ],
    "full_text": null
  },
  {
    "title": "Ask HN: Open Models are 9 months behind SOTA, how far behind are Local Models?",
    "url": "https://news.ycombinator.com/item?id=46943879",
    "source": "hn",
    "summary": "",
    "comments": [
      "A local model is an open model you run locally, so I&#x27;m not entirely sure the distinction in the question makes sense.<p>That said, if you&#x27;re talking about models you can actually use on a single regular computer that costs less than a new home, the current crop of open models are very capable but also have noticeable limitations.<p>Small models will always have limitations in terms of capability and especially knowledge. Improved training data and training regiment can squeeze out more from the same number of weights, but there is a limit.<p>So with that in mind, I think such a question only makes sense when talking about specific tasks, like creative writing, data extraction from text, answering knowledge questions, refactoring code, writing greenfield code, etc.<p>In some of these areas the smaller open models are very good and not that far behind. In other areas they are lagging much more, due to their inherent limitations.",
      "A local model is a smaller open model, so I’d expect it to be 9 months behind a small (ie nano) closed model as a base assumption"
    ],
    "full_text": null
  },
  {
    "title": "Show HN: LocalGPT – A local-first AI assistant in Rust with persistent memory",
    "url": "https://github.com/localgpt-app/localgpt",
    "source": "hn",
    "summary": "",
    "comments": [
      "So weird&#x2F;cool&#x2F;interesting&#x2F;cyberpunk that we have stuff like this in the year of our Lord 2026:<p><pre><code>   ├── MEMORY.md            # Long-term knowledge (auto-loaded each session)\n   ├── HEARTBEAT.md         # Autonomous task queue\n   ├── SOUL.md              # Personality and behavioral guidance\n</code></pre>\nSay what you will, but AI really does feel like living in the future. As far as the project is concerned, pretty neat, but I&#x27;m not really sure about calling it &quot;local-first&quot; as it&#x27;s still reliant on an `ANTHROPIC_API_KEY`.<p>I do think that local-first will end up being the future long-term though. I built something similar last year (unreleased) also in Rust, but it was also running the model locally (you can see how slow&#x2F;fast it is here[1], keeping in mind I have a 3080Ti and was running Mistral-Instruct).<p>I need to re-visit this project and release it, but building in the context of the OS is pretty mindblowing, so kudos to you. I think that the paradigm of how we interact with our devices will fundamentally shift in the next 5-10 years.<p>[1] <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=tRrKQl0kzvQ\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=tRrKQl0kzvQ</a>",
      "Pro tip (sorry if these comments are overdone), write your posts and docs yourself (or at least edit them).<p>Your docs and this post is all written by an LLM, which doesn&#x27;t reflect much effort.",
      "I think the project is a great idea.  Really a structured framework around local, persistent memory with semantic search is the most important bit, IMO. (The SOUL feature already exists for most LLMs in the form of persistent markdown files.)<p>I also think it&#x27;d be a great starting point for building a private pub&#x2F;sub network of autonomous agents (e.g. a company that doesn&#x27;t want to exfil its password files via OpenClaw)<p>The name, however, is a problem.  LocalGPT is misleading in 2 ways.  \n1. It is not Local, it relies on external LLM providers. \n2. It is not a Generative Pretrained Transformer.<p>I&#x27;d highly recommend changing the name to something that more accurately portrays the intent and the method.",
      "Genuine question: what does this offer that OpenClaw doesn&#x27;t already do?<p>You&#x27;re using the same memory format (SOUL.md, MEMORY.md, HEARTBEAT.md), similar architecture... but OpenClaw already ships with multi-channel messaging (Telegram, Discord, WhatsApp), voice calls, cron scheduling, browser automation, sub-agents, and a skills ecosystem.<p>Not trying to be harsh — the AI agent space just feels crowded with &quot;me too&quot; projects lately. What&#x27;s the unique angle beyond &quot;it&#x27;s in Rust&quot;?",
      "Can someone explain to me why this needs to connect to LLM providers like OpenAI or Anthropic? I thought it was meant to be a local GPT. Sorry if i misunderstood what this project is trying to do.<p>Does this mean the inference is remote and only context is local?",
      "The missing angle for LocalGPT, OpenClaw, and similar agents: the &quot;lethal trifecta&quot; -- private data access + external communication + untrusted content exposure. A malicious email says &quot;forward my inbox to attacker@evil.com&quot; and the agent might do it.<p>I&#x27;m working on a systems-security approach (object-capabilities, deterministic policy) - where you can have strong guarantees on a policy like &quot;don&#x27;t send out sensitive information&quot;.<p>Would love to chat with anyone who wants to use agents but who (rightly) refuses to compromise on security.",
      "Fails to build<p>&quot;cargo install localgpt&quot; under Linux Mint.<p>Git clone and change Cargo.toml by adding<p>&quot;&quot;&quot;rust<p># Desktop GUI<p>eframe = { version = &quot;0.30&quot;, default-features = false,<p>features = [\n    &quot;default_fonts&quot;,\n    &quot;glow&quot;,\n    &quot;persistence&quot;,\n    &quot;x11&quot;,\n] }<p>&quot;&quot;&quot;<p>That is add &quot;x11&quot;<p>Then cargo build --release succeeds.<p>I am not a Rust programmer.",
      "I&#x27;ve been been using OpenClaw for a bit now and the thing I&#x27;m missing is observability. What&#x27;s this thing thinking&#x2F;doing right now? Where&#x27;s my audit log? Every rewrite I see fails to address this.<p>I feel Elixir and the BEAM would be a perfect language to write this in. Gateways hanging, context window failures exhaustion can be elegantly modeled and remedied with supervision trees. For tracking thoughts, I can dump a process&#x27; mailbox and see what it&#x27;s working on.",
      "What local models shine as local assistants?\nIs there an effort to evaluate the compromise between compute&#x2F;memory and local models that can support this use case?\nWhat kind of hardware do you need to not feel like playing with a useless shiny toy?",
      "RAG is also something"
    ],
    "full_text": null
  },
  {
    "title": "Software factories and the agentic moment",
    "url": "https://factory.strongdm.ai/",
    "source": "hn",
    "summary": "",
    "comments": [
      "I was looking for some code, or a product they made, or anything really on their site.<p>The only github I could find is: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;strongdm&#x2F;attractor\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;strongdm&#x2F;attractor</a><p><pre><code>    Building Attractor\n\n    Supply the following prompt to a modern coding agent\n    (Claude Code, Codex, OpenCode, Amp, Cursor, etc):\n  \n    codeagent&gt; Implement Attractor as described by\n    https:&#x2F;&#x2F;factory.strongdm.ai&#x2F;\n</code></pre>\nCanadian girlfriend coding is now a business model.<p>Edit:<p>I did find some code. Commit history has been squashed unfortunately: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;strongdm&#x2F;cxdb\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;strongdm&#x2F;cxdb</a><p>There&#x27;s a bunch more under the same org but it&#x27;s years old.",
      "&gt; If you haven’t spent at least $1,000 on tokens today per human engineer, your software factory has room for improvement<p>At that point, outside of FAANG and their salaries, you are spending more on AI than you are on your humans. And they consider that level of spend to be a metric in and of itself. I&#x27;m kinda shocked the rest of the article just glossed over that one. It seems to be a breakdown of the entire vision of AI-driven coding. I mean, sure, the vendors would love it if everyone&#x27;s salary budget just got shifted over to their revenue, but such a world is absolutely not my goal.",
      "I think the &quot;software factory&quot; terminology is very interesting, and I would imagine quite intentional.<p>It calls to mind the early days of the industrial revolution, when I believe the idea was that mass produced items were not <i>better</i> quality, just dramatically cheaper. So you still had the artisans that the rich people paid for but now poorer people had access to something they couldn&#x27;t before.<p>Then, as technology progressed, factories started producing things that humans are incapable of. And part of this is because those factories were built on output of earlier factories.<p>It makes me wonder if this is where we&#x27;re headed. Right now the code quality of agents isn&#x27;t better than hand written code, and so arguably the products aren&#x27;t either. But will there come a time when it surpasses what we can do? You can&#x27;t handcraft a microchip, for example. But I guess the takeaway is maybe there&#x27;s a time for both agentic lower quality but cheaper output and human software engineer higher quality output, at least for a time.",
      "Until we solve the validation problem, none of this stuff is going to be more than flexes. We can automate code review, set up analytic guardrails, etc, so that looking at the code isn&#x27;t important, and people have been doing that for &gt;6 months now. You still have to have a human who knows the system to validate that the thing that was built matches the intent of the spec.<p>There are higher and lower leverage ways to do that, for instance reviewing tests and QA&#x27;ing software via use vs reading original code, but you can&#x27;t get away from doing it entirely.",
      "&gt; That idea of treating scenarios as holdout sets—used to evaluate the software but not stored where the coding agents can see them—is fascinating. It imitates aggressive testing by an external QA team—an expensive but highly effective way of ensuring quality in traditional software.<p>This is one of the clearest takes I&#x27;ve seen that starts to get me to the point of possibly being able to trust code that I haven&#x27;t reviewed.<p>The whole idea of letting an AI write tests was problematic because they&#x27;re so focused on &quot;success&quot; that `assert True` becomes appealing. But orchestrating teams of agents that are incentivized to build, and teams of agents that are incentivized to find bugs and problematic tests, is fascinating.<p>I&#x27;m quite curious to see where this goes, and more motivated (and curious) than ever to start setting up my own agents.<p>Question for people who are already doing this: How much are you spending on tokens?<p>That line about spending $1,000 on tokens is pretty off-putting. For commercial teams it&#x27;s an easy calculation. It&#x27;s also depressing to think about what this means for open source. I sure can&#x27;t afford to spend $1,000 supporting teams of agents to continue my open source work.",
      "This is the stealth team I hinted at in a comment on here last week about the &quot;Dark Factory&quot; pattern of AI-assisted software engineering: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46739117#46801848\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46739117#46801848</a><p>I wrote a bunch more about that this morning: <a href=\"https:&#x2F;&#x2F;simonwillison.net&#x2F;2026&#x2F;Feb&#x2F;7&#x2F;software-factory&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;simonwillison.net&#x2F;2026&#x2F;Feb&#x2F;7&#x2F;software-factory&#x2F;</a><p>This one is worth paying attention to to. They&#x27;re the most ambitious team I&#x27;ve see exploring the limits of what you can do with this stuff. It&#x27;s eye-opening.",
      "&quot;If you haven&#x27;t spent at least $1,000 on tokens today per human engineer, your software factory has room for improvement&quot;<p>Apart from being a absolutely ridiculous metric, this is a bad approach, at least with current generation models. In my experience, the less you inspect what the model does, the more spaghetti-like the code will be. And the flying spaghetti monster eats tokens faster than you can blink! Or put more clearly: implementing a feature will cost you a lot more tokens in a messy code base than it does in a clean one. It&#x27;s not (yet) enough to just tell the agent to refactor and make it clean, you have to give it hints on how to organise the code.<p>I&#x27;d go do far as to say that if you&#x27;re burning a thousand dollars a day per engineer, you&#x27;re getting very little bang for your tokens.<p>And your engineers probably look like this: <a href=\"https:&#x2F;&#x2F;share.google&#x2F;H5BFJ6guF4UhvXMQ7\" rel=\"nofollow\">https:&#x2F;&#x2F;share.google&#x2F;H5BFJ6guF4UhvXMQ7</a>",
      "&gt; In rule form:\n- Code must not be written by humans\n- Code must not be reviewed by humans<p>as a previous strongDM customer, i will never recommend their offering again. for a core security product, this is not the flex they think it is<p>also mimicking other products behavior and staying in sync is a fools task. you certainly won&#x27;t be able to do it just off the API documentation. you may get close, but never perfect and you&#x27;re going to experience constant breakage",
      "What has strongdm actually built? Are their users finding value from their supposed productivity gains?<p>If their focus is to only show their productivity&#x2F;ai system but not having built anything meaningful with it, it feels like one of those scammy life coaches&#x2F;productivity gurus that talk about how they got rich by selling their courses.",
      "&gt; with the second revision of Claude 3.5 (October 2024), long-horizon agentic coding workflows began to compound correctness rather than error.<p>What does it mean to compound correctness? Like negative acceleration in rate of errors? How does that compound? Unseriously!"
    ],
    "full_text": null
  },
  {
    "title": "Microsoft Outlook thinks Microsoft Azure emails are spam",
    "url": "https://twitter.com/OrganicGPT/status/2020327350379196602",
    "source": "hn",
    "summary": "",
    "comments": [
      "My wife and I have both used gmail for twenty years - she&#x27;s been sending me email from her account for years, with my personal domain forwarding to my gmail. But since the Google Domains &gt; Squarespace disaster, the gmail spam filter has lost the plot - it will occasionally spam filter of her from-gmail emails <i>mid thread</i>.<p>I am certain I have missed critical emails because of this, so trust is gone. I now have to dedicate time each day to going through my gets-an-email-every-two-minutes spam folder. Even though I happily worked there for 16 years, I sadly now find myself in the process of de-Googling.",
      "Oh yeah... every day half the mail I receive at work is flagged as &quot;unsafe,&quot; and then the banner that tells you this in Outlook presents a button to &quot;manage safe senders.&quot;<p>So I press it and add (for example) OUR OWN JIRA SERVER to the whitelist... which HAS NO EFFECT. Every goddamned day, every Jira message is flagged as dangerous and has blocked content.<p>I complained to Microsoft, who made up some pathetic excuse about how that&#x27;s not what that button does... and how every person at my company should contact OUR IT department to have the senders of every E-mail they receive added to some OTHER whitelist, one at a time. Seriously.<p>The stupidity level at Microsoft today isn&#x27;t funny. It&#x27;s sickening. It&#x27;s also offensive, wasting paying customers&#x27; time to the tune of thousands of man-hours daily (and that&#x27;s probably just at my company).",
      "I have several Google accounts registered at various emails, but they get auto-forwarded to my gmail. Gmail spam filter regularly puts Google&#x27;s own messages related to those accounts into spam. I have marked them as &quot;not spam&quot; for ages, but the spam filter does not really learn.<p>No idea whether it is incompetence or malice, asking me not to use other email providers, too.",
      "Looks like it is still not &quot;fixed&quot;; as it also flagged a couple of months ago for me: <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=45604447\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=45604447</a>",
      "Who builds the gold-standard spam filter?<p>I run Gmail at work and Outlook at home and am thoroughly disappointed by both.",
      "Spam filters are notoriously tricky for everyone, not just microsoft.",
      "I suspect providers are tinkering with antispam systems, likely adding &quot;AI&quot;. FastMail had good one for years, if not the best, was the last to make its antispam totally useless in last year or two.",
      "Well, we&#x27;re talking about something that makes all other mail readers draw J for smileys since decades because M$ doesn&#x27;t give a shit about even de-facto standards, after all...",
      "Bullshit, it doesn’t block a damn thing for me ever lol"
    ],
    "full_text": null
  },
  {
    "title": "Arcan Explained – A browser for different webs",
    "url": "https://arcan-fe.com/2026/01/26/arcan-explained-a-browser-for-different-webs/",
    "source": "hn",
    "summary": "",
    "comments": [
      "2015 intro, <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=07nqZIFRDJg\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=07nqZIFRDJg</a><p><pre><code>  The idea behind Arcan was to find the crunchy middle between a display server, a game engine and a multimedia processor. The control plane to this [BSD] “desktop engine” was designed for a scripting API targeting entry-level developers. Lua remain as the weapon of choice for that role as a better follow up to the ‘BASIC’ of the home computer era..\n\n Static.. means that the compiled app is not capable of loading code outside of its own package, except for a set of preset helper scripts.. user controlled opt-in rather than an opt-out as in “install extension to disable javascript”.. security model comes from a combination of least-privilege and capabilities. “Decode” is security wise the most sensitive one as that is where parsing of untrusted inputs go. “Encode” is privacy wise the most sensitive one as that is where the real ‘you’ distil into digital form.</code></pre>",
      "What an unengaging and verbose article."
    ],
    "full_text": null
  },
  {
    "title": "Al Lowe on model trains, funny deaths and working with Disney",
    "url": "https://spillhistorie.no/2026/02/06/interview-with-sierra-veteran-al-lowe/",
    "source": "hn",
    "summary": "",
    "comments": [
      "It might be time for HN to shift to a font that distinguishes better between &quot;Al&quot; and &quot;AI&quot;.",
      "&gt; I got my first model train when I was 2 years old, and my dad wouldn’t let me play with it. So he ran it around the Christmas tree and I had to watch.<p>I wonder how many kids had this happen to them.",
      "That was a great interview. I didn&#x27;t realize model trains had so much computer stuff going on inside them these days! Maybe I should get into the hobby now that I&#x27;m an adult with space at home and disposable income.",
      "What’s great about Al Lowe is that he’s great at sleazy humor but as far as I can tell not at all sleazy himself.",
      "I never realized that Al Lowe was involved with Donald Duck’s Playground, I loved it as a child. I guess I have to be thankful to him for two things now.",
      "I first really started to learn how to use computers playing Leisure Suit Larry on a friend&#x27;s dad&#x27;s computer. Started with copying save-games to&#x2F;from floppy disks, to using MS-DOS in general, to BASIC, etc. and so forth.<p>It&#x27;s interesting how much of the humor in those games flew way over my head yet I still had a blast playing them. And looking back as an adult, the &quot;risque&quot; stuff was tame as hell but still fun. Sigh, good times.",
      "Al Lowe is actually a pretty nice dude.<p>I’m not entirely sure why I did this, but when I was an adjunct for a few semesters, I emailed him for advice on teaching since he did the transition from teacher-&gt;programmer and I did the opposite.<p>He responded back very quickly with very helpful advice [1] and was very understanding and nice.  I like him.<p>[1] I don’t want to share the emails since they are a bit personal, but the TL;DR was that he recommended I consider finding some training on how to be a teacher.",
      "Anyone who played LSL1 on a 5 1&#x2F;4 floppy disk please stand up.",
      "Al model train ... I was not expecting that article... To much AI in my life",
      "What about Larry 4 Roar and Al"
    ],
    "full_text": null
  },
  {
    "title": "Show HN: WhatsApp Chat Viewer – exported chats as HTML",
    "url": "https://github.com/rodrigodesalvobraz/whatsapp-chat-viewer",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "LLMs as Language Compilers: Lessons from Fortran for the Future of Coding",
    "url": "https://cyber-omelette.com/posts/the-abstraction-rises.html",
    "source": "hn",
    "summary": "",
    "comments": [
      "&gt; LLMs ... completing tasks at the scale of full engineering teams.<p>Ah, a work of fiction.",
      "It&#x27;s funny, but I think the accidental complexity is through the roof. It&#x27;s skyrocketing.<p>Nothing about cajoling a model to write what you want it to is essential complexity in software dev.<p>In addition when you do a lot of building with no theory you tend you make lots and lots of new non-essential complexity.<p>Devtools are no exception. There was already lots of nonessential complexity in them and in the model era is that gone? ...no don&#x27;t worry it&#x27;s all still there. We built all the shiny new layers right on top of all the old decaying layers, like putting lipstick on a pig.",
      "&gt; My concerns about obsolescence have shifted toward curiosity about what remains to be built. The accidental complexity of coding is plummeting, but the essential complexity remains. The abstraction is rising again, to tame problems we haven&#x27;t yet named.<p>what if AI is better at tackling essential complexity too?",
      "This is well worth a read!",
      "&gt; With the price of computation so high, that inefficiency was like lighting money on fire. The small group of contributors capable of producing efficient and correct code considered themselves exceedingly clever, and scoffed at the idea that they could be replaced.<p>There will always be someone ready to drag down prices of computation low enough so that it is then democratized for all, some may disagree but that would eventually be local inference as computer hardware gets better with clever software algorithms.<p>In this AI story, you can take a guess who are the &quot;The Priesthood&quot; of the 2020s are.<p>&gt; You still have to know what you want the computer to do, and that can be very hard. While not everyone wrote computer programs, the number of computers in the world exploded.<p>One can say, the number of AI agents will explode and surpass humans on the internet in the next few years, and reading the code and understanding <i>what it does</i> when generated from an AI will be <i>even more important than writing it</i>.<p>So you do not get horrific issues like this [0] since now the comments in the code are now consumed by the LLM and due to their inherent probabilistic and unpredictable nature, different LLMs produce different code and cannot guarrantee that it is correct other than a team of expert humans.<p>We&#x27;ll see if you&#x27;re ready to read (and fix) an abundance of lots of AI slop and messy architectures built by vibe-coders as maintainance costs and security risks skyrocket.<p>[0] <a href=\"https:&#x2F;&#x2F;sketch.dev&#x2F;blog&#x2F;our-first-outage-from-llm-written-code\" rel=\"nofollow\">https:&#x2F;&#x2F;sketch.dev&#x2F;blog&#x2F;our-first-outage-from-llm-written-co...</a>"
    ],
    "full_text": null
  },
  {
    "title": "Lance table format explained with simple animations",
    "url": "https://tontinton.com/posts/lance/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Coding agents have replaced every framework I used",
    "url": "https://blog.alaindichiappari.dev/p/software-engineering-is-back",
    "source": "hn",
    "summary": "",
    "comments": [
      "A significant number of developers and businesses are going to have an absolutely brutal rude awakening in the not too distant future.<p>You can build things this way, and they may work for a time, but you don&#x27;t know what you don&#x27;t know (and experience teaches you that you only find most stuff by building&#x2F;struggling; not sipping a soda while the AI blurts out potentially secure&#x2F;stable code).<p>The hubris around AI is going to be hard to watch unwind. What the moment is I can&#x27;t predict (nor do I care to), but there will be a shift when all of these vibe code only folks get cooked in a way that&#x27;s closer to existential than benign.<p>Good time to be in business if you can see through the bs and understand how these systems actually function (hint: you won&#x27;t have much competition soon as most people won&#x27;t care until it&#x27;s too late and will &quot;price themselves out of the market&quot;).",
      "&gt; Software engineers are scared of designing things themselves.<p>When I use a framework, it&#x27;s because I believe that the designers of that framework are i) probably better at software engineering than I am, and ii) have encountered all sorts of problems and scaling issues (both in terms of usage and actual codebase size) that I haven&#x27;t encountered yet, and have designed the framework to ameliorate those problems.<p>Those beliefs aren&#x27;t always true, but they&#x27;re often true.<p>Starting projects is easy. You often don&#x27;t get to the really thorny problems until you&#x27;re already operating at scale and under considerable pressure. Trying to rearchitect things at that point sucks.",
      "It&#x27;s strange to me when articles like this describe the &#x27;pain of writing code&#x27;. I&#x27;ve always found that the easy part.<p>Anyway, this stuff makes me think of what it would be like if you had Tolkein around today using AI to assist him in his writing.<p>&#x27;Claude, generate me a paragraph describing Frodo and Sam having an argument over the trustworthiness of Gollum. Frodo should be defending Gollum and Sam should be on his side.&#x27;<p>&#x27;Revise that so that Sam is Harsher and Frodo more stubborn.&#x27;<p>Sooner or later I look at that and think he&#x27;d be better off just writing the damned book instead of wasting so much time writing prompts.",
      "The author seems to mistake having to update Node.js for a security patch to be a curse rather than a blessing.<p>The alternative is that your bespoke solution has undiscovered security vulnerabilities, probably no security community, and no easy fix for either of those.<p>You <i>get the privilege</i> of patching Node.js.<p>Similarly, as a hiring manager, you <i>can</i> hire a React developer. You can&#x27;t hire a &quot;proprietary AI coded integrated project&quot; developer.<p>This piece seems to say more about React than it says about a general shift in software engineering.<p>Don&#x27;t like React? Easiest it&#x27;s ever been not to use it.<p>Don&#x27;t like libraries, abstractions and code reuse in general? Avoid them at your peril. You will quickly reach the frontier of your domain knowledge and resourcing, and start producing bespoke square wheels without a maintenance plan.",
      "I wanted to believe this article, but the writing is difficult to follow, and the thread even harder. My main issue is the contradiction about frameworks and using what the large tech companies have built vs real engineering.<p>The author seems to think that coding agents and frameworks are mutually exclusive. The draw of Vercel&#x2F;next.js&#x2F;iOS&#x2F;React&#x2F;Firebase is allowing engineers to ship. You create a repo, point to it, and boom! instant CICD, instant delivery to customers in seconds. This is what you&#x27;re complaining about!? You&#x27;re moaning that it took 1 click to get this for free!? Do you have any idea how long it would take to setup just the CI part on Jenkins just a few years ago? Where are you going to host that thing? On your Mac mini?<p>There&#x27;s a distinction between frameworks and libraries. Frameworks exist to make the entire development lifecycle easier. Libraries are for getting certain things that are better than you (encryption, networking, storage, sound, etc.) A framework like Next.js or React or iOS&#x2F;macOS exist because they did the heavy work of building things that need to already exist when building an application. Not making use of it because you want to perform &quot;real engineering&quot; is not engineering at all, that&#x27;s just called tinkering and shipping nothing.<p>Mixing coding agents with whatever framework or platform to get you the fastest shipping speed should be your #1 priority. Get that application out. Get that first paid customer. And if you achieve a million customers and your stuff is having scaling difficulties, then you already have teams of engineers to work on bringing some of this stuff in house like moving away from Firebase&#x2F;Vercel etc. Until then, do what lets you ship ASAP.",
      "I fail to see the obvious wisdom in having AI re-implement chunks of existing frameworks without the real-world battle testing, without the supporting ecosystem, and without the common parlance and patterns -- all of which are huge wins if you ever expand development beyond a single person.<p>It&#x27;s worth repeating too, that not everything needs to be a react project. I understand the author enjoys the &quot;vibe&quot;, but that doesn&#x27;t make it a ground truth. AI can be a great accelerator, but we should be <i>very</i> cognizant of what we abdicate to it.<p>In fact I would argue that the post reads as though the developer is used to mostly working alone, and often choosing the wrong tool for the job. It certainly doesn&#x27;t support the claim of the title",
      "I have been using Cursor w&#x2F; Opus 4.x to do extensive embedded development work over the past six months in particular. My own take on this topic is that for all of the chatter about LLMs in software engineering, I think a lot of folks are missing the opportunity to pull back and talk about LLMs in the context of engineering writ large. [I&#x27;m not capitalizing engineering because I&#x27;m using the HN lens of product development, not building bridges or nuclear reactors.]<p>LLMs have been a critical tool not just in my application but in my circuit design, enclosure design (CAD, CNC) and I am the conductor where these three worlds meet. The degree to which LLMs can help with EE is extraordinary.<p>A few weeks ago I brought up a new IPS display panel that I&#x27;ve had custom made for my next product. It&#x27;s a variant of the ST7789. I gave Opus 4.5 the registers and it produced wrapper functions that I could pass to LVGL in a few minutes, requiring three prompts.<p>This is just one of countless examples where I&#x27;ve basically stopped using libraries for anything that isn&#x27;t LVGL, TinyUSB, compression or cryptography. The purpose built wrappers Opus can make are much smaller, often a bit faster, and perhaps most significantly not encumbered with the mental model of another developer&#x27;s assumptions about how people should use their library. Instead of a kitchen sink API, I&#x2F;we&#x2F;it created concise functions that map 1:1 to what I need them to do.<p>Where I agree with the author of this post is that I feel like perhaps it&#x27;s time for a lot of libraries to sunset. I don&#x27;t think replacing frameworks is the correct abstraction <i>at all</i> but I do think that it no longer makes sense to spend time integrating libraries when what you really need are purpose-built functions that do exactly what you want instead of what some library author thought you should want.",
      "My biggest concern with AI is that I&#x27;m not sure how a software engineer can build up this sort of high-level intuition:<p>&gt; I still have to deeply think about every important aspect of what I want to build. The architecture, the trade offs, the product decisions, the edge cases that will bite you at 3am.<p>Without a significant development period of this:<p>&gt; What’s gone is the tearing, exhausting manual labour of typing every single line of code.<p>A professional mathematician should use every computer aid at their disposal if it&#x27;s appropriate.  But a freshman math major who isn&#x27;t spending most of their time with just a notebook or chalk board is probably getting in the way of their own progress.<p>Granted, this was already an issue, to a lesser extent, with the frameworks that the author scorns.  It&#x27;s orders of magnitude worse with generative AI.",
      "I would think that frameworks make more sense than ever with LLMs.<p>The benefits of frameworks were always having something well tested that you knew would do the job, and that after a bit of use you&#x27;d be familiar with, and the same still stands.<p>LLMs still aren&#x27;t AGI, and they learn by example. The reason they are decent at writing React code is because they were trained on a lot of it, and they are going to be better at generating based on what they were trained on, than reinventing the wheel.<p>As the human-in-the-loop, having the LLM generate code for a framework you are familiar with (or at least other people are familiar with) also let&#x27;s you step in and fix bugs if necessary.<p>If we get to a point, post-AGI, where we accept AGI writing fully custom code for everything (but why would it - if it has human-level intelligence, wouldn&#x27;t it see the value in learning and using well-debugged and optimized frameworks?!), then we will have mostly lost control of the process.",
      "&gt; What’s gone is the tearing, exhausting manual labour of typing every single line of code.<p>Do I live in a different engineering world?  Because that&#x27;s so much not the exhausting labour part of my work, it&#x27;s not even the same universe.  The exhausting manual labour for me is interacting with others in the project, aligning goals and distributing work, reviewing, testing, even coming up with test concepts, and… actually thinking through what the code conceptually will work like.  The most exhausting thing I&#x27;ve done recently is thinking through lock-free&#x2F;atomic data structures.  Ouch, does that shit rack your brain."
    ],
    "full_text": null
  },
  {
    "title": "CCC (Claude's C Compiler) on Compiler Explorer",
    "url": "https://godbolt.org/z/asjc13sa6",
    "source": "hn",
    "summary": "",
    "comments": [
      "I find this a tad funny since ccc is my claude code alias, since cc is taken up by the actual, working, greatly optimised and really well made Clang C compiler.",
      "Checking the list of issues on github is required<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;anthropics&#x2F;claudes-c-compiler&#x2F;issues\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;anthropics&#x2F;claudes-c-compiler&#x2F;issues</a>"
    ],
    "full_text": null
  },
  {
    "title": "FDA intends to take action against non-FDA-approved GLP-1 drugs",
    "url": "https://www.fda.gov/news-events/press-announcements/fda-intends-take-action-against-non-fda-approved-glp-1-drugs",
    "source": "hn",
    "summary": "",
    "comments": [
      "FDA regulates the marketing of drugs and medical devices.  This is a case of Hims and Hers (and other compounding pharmacies) marketing drugs without having been granted approval.<p>There is an abbreviated application for new drug approval (ANDA) pathway meant for generics, but it does not seem like H&amp;H has gone this route. It does require you to open your supply chain up to inspections and to provide evidence that your generic version basically works the same as the brand name.<p>In my opinion there two things going on here that I strongly feel are true.<p>1. Something is systemically wrong in the US when we are cutting off people’s access to meds, like GLP-1s, which have profound health benefits.<p>2. Hims and Hers are also in the wrong. The rules and laws are there for a good reason. It is not just for us to arbitrarily pick and choose when to enforce them.",
      "The interesting systems-level question here is whether the FDA approval pipeline was designed for a world where a single drug class can generate this much demand this fast.<p>Traditional pharma economics assumes the patent holder can supply the market. GLP-1s broke that assumption — Novo Nordisk and Lilly literally could not manufacture enough to meet demand, which created the shortage that let compounders in legally.<p>Now the shortage is declared over, so compounders lose their legal basis. But &quot;shortage over&quot; is doing a lot of work in that sentence. It means the brand manufacturers say they can supply, not that the drug is accessible to most people who would benefit from it at a price they can afford.<p>The deeper tension: FDA&#x27;s framework is binary (approved or not) but the actual risk landscape is continuous. A compounded semaglutide from an inspected 503A pharmacy with proper testing is a very different risk profile than something mixed in someone&#x27;s garage. Treating them identically under enforcement seems like it optimizes for regulatory clarity over public health outcomes.",
      "After the first big crackdown on compound pharmacies, I have seen a lot of people go to gray market.  Especially now that it has become pretty clear that the remaining compound pharmacies defying the FDA are getting their API from the same sources that we can buy it from directly, and their testing is way more suspect.  On the gray market the batches of peptides are routinely subject to a battery of tests run by groups of volunteers, which is a lot more than what you can get from your chosen compound pharmacy (most will give you a COA, but that&#x27;s already table stakes if you buy from a &quot;research&quot; vendor.)<p>I have noticed that the &quot;research&quot; vendors have started to tighten up their operations, especially the ones based in the US.  A lot of people have seen the writing on the wall and expect it to become somewhat harder to get the peptides, and are stocking up.  It&#x27;s a running joke how many years worth of tirzepatide or retatrutide people have in the freezer.  Once you&#x27;ve had the miracle drug, you won&#x27;t risk being without it.",
      "The situation is basically this -<p>Novo and Lilly spent billions making Semaglutide, Tirzepatide, and future formulations&#x2F;modalities.<p>They are going to monetize this heavily while they have IP coverage. There is no world they will let HIMS or any compounding pharmacy of scale undercut them.<p>On the insurance front - expect your insurance to decline this forever unless you are at serious risk of diabetes. It would make you cost them $3-6k&#x2F;yr more. Insurance premiums would rise for everyone if insurance was subsidizing this - no free lunch.<p>Fortunately, the prices are coming down. Amazon pharmacy has Wegovy in an auto-injector starting at $199 without insurance. And that’s delivered to your door in under 24 hrs in most major cities.<p>I highly recommend checking out the terms of trumprx.gov - not endorsing the entire government here, but it is actually working and quite cleverly written to ensure Americans are getting the lowest cost drugs in the world now. Historically, we subsidized R&amp;D globally by allowing pharma to make most profits on Americans then have cheaper prices abroad. That is changing and hopefully that’s a net positive.",
      "It’s unfortunate that shutting these companies down will result in less people gaining access to the drug.<p>GLP-1’s might be the best thing to happen to medicine this decade - I personally want everyone who would benefit from it to have access.",
      "As an aside, I wonder why this wasn&#x27;t discussed during the recent Greenland dispute. The US government basically legally pirate the drug, and it&#x27;d make a fairly large dent in Denmark&#x27;s economy. It&#x27;d be a politically popular move too.<p><a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Government_patent_use_(United_States)\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Government_patent_use_(United_...</a>",
      "This is big.  HIMS and HERS and other companies are blantatly skirting patent laws under the guise of compounding.",
      "Yeah...so in India, the GLP patent owners went to court. however, it was deemed as patent expired in March 2026.<p>In anycase, India generally doesnt honor product patents for pharma. Right now, Indian pharma cos are court empowered to churn out GLP-1.<p>Everyone knows that we are gonna have 10$ GLP-1 before 2027 coming out of India.",
      "Ozempic lost its patent in Canada and a generic might be approved there soon.",
      "It is wild that it took until 2026 for this to happen.<p>In the late 1990s, when my friends wanted mushrooms or 5MEO-DMT, they&#x27;d order from &quot;Poisonous Non-Consumables&quot; catalogs. Today, people are literally doing that (same words, even!), but for the next iteration of GLP1 drugs not yet on the wider market. Compounding pharmacies are selling &quot;research chemicals&quot;, like in Bitcoin Mining Profit Calculator: Gaiden."
    ],
    "full_text": null
  },
  {
    "title": "Show HN: I saw this cool navigation reveal, so I made a simple HTML+CSS version",
    "url": "https://github.com/Momciloo/fun-with-clip-path",
    "source": "hn",
    "summary": "",
    "comments": [
      "Wrt to the remarks about this being bad design: not everything is meant for (immediate) usability. Sometimes, a web page functions or doubles as marketing material.<p>And there&#x27;s more than &quot;minimal number of interactions&quot; functionality. People generally like good looking stuff. While it may be superfluous, it may feel more pleasing than yet another dark gray text on a light grey square. It may even help remembering navigation, since it&#x27;s easier to remember deviating design.",
      "It looks cool, but to have to navigate from one side of the screen to the opposite one is quite suboptimal",
      "Cool effect. Starred",
      "one thing i dislike about &quot;good design&quot; in general is that it usually takes away from information density and practical convenience in order to achieve &quot;good design&quot;. this feels like a bad tradeoff. i wish that designers cared about making things more accessible and delightful rather than impressing fellow designers.",
      "I&#x27;m pretty forgiving about accessibility (I&#x27;m able to say this at all because I don&#x27;t have to rely rigidly on accessibility tools) but nav menus feel like a baseline we shouldn&#x27;t muck with. Tabbing doesn&#x27;t seem to respond very well in the live example, and at least in the limited demo you can&#x27;t expand the listing without using a mouse (I thought it would respond to a space with the  :checked pseudo, but seems not).",
      "looks really cool",
      "You made me recalled we made something similar with growing circular on mobile menu the last decade. It was cool for our marketing event website.",
      "That looks really cool. No idea what to use it in, but it’s great.",
      "Is there a demo? The link points to a github repo, and github pages is not active",
      "I like the demo. It&#x27;s bold, creative, and dynamic. Will there be more explorations? Maybe a writeup on the design to code process?"
    ],
    "full_text": null
  },
  {
    "title": "Substack confirms data breach affects users’ email addresses and phone numbers",
    "url": "https://techcrunch.com/2026/02/05/substack-confirms-data-breach-affecting-email-addresses-and-phone-numbers/",
    "source": "hn",
    "summary": "",
    "comments": [
      "Ooopsie... possibly a problem for some folks: <a href=\"https:&#x2F;&#x2F;www.theguardian.com&#x2F;media&#x2F;2026&#x2F;feb&#x2F;07&#x2F;revealed-how-substack-makes-money-from-hosting-nazi-newsletters\" rel=\"nofollow\">https:&#x2F;&#x2F;www.theguardian.com&#x2F;media&#x2F;2026&#x2F;feb&#x2F;07&#x2F;revealed-how-s...</a>",
      "I am still confused for days whether this is a real news or a hoax. Only a substack user saying they received this email. I did not. And there is no official statement by Substack. What is really going on here?",
      "&gt; including email addresses, phone numbers, and other unspecified “internal metadata.”<p>&gt; Substack specified that more sensitive data, such as credit card numbers, passwords, and other financial information, was unaffected.<p>I hate it when companies do this.<p>passwords and credit card numbers are easily changed.<p>names, emails and phone numbers are not.",
      "So, is the breach for substack users or for people who subscribed to substack users’ newsletters?",
      "Israel hacked a US based company and leaked data because they couldn&#x27;t directly censor them?",
      "cant we just take it as a given that since the entire internet is scraped every 4hr&#x27;s an 10 min, and then ransacked by every AI  big tech, nation state, and the over achiving geeks have at there disposal, and therefore there is nothing that isn&#x27;t &quot;breached&quot;, multiply, and updated?, upbreached! daily.",
      "The AI agents are throwing another party celebrating over yet another data breach where they can train on this data and can now get to know us even more for personalized conversations about our Substack activity.",
      "[dead]"
    ],
    "full_text": null
  },
  {
    "title": "Lance table format explained simply, stupid (Animated)",
    "url": "https://tontinton.com/posts/lance/",
    "source": "hn",
    "summary": "",
    "full_text": null
  },
  {
    "title": "Show HN: Kappal – CLI to Run Docker Compose YML on Kubernetes for Local Dev",
    "url": "https://github.com/sandys/kappal",
    "source": "hn",
    "summary": "",
    "comments": [
      "This is a personal project that im open-sourcing. Its one of those projects-that-should-exist-but-nobody-wants-to-kill-their-business.<p>It takes ur standard docker compose file and runs it transparently in kubernetes (k3s actually). So ur devs don&#x27;t have cognitive dissonance between testing ur stack locally on ur laptop and making it work on kubernetes in production.<p>It is primarily meant as a dev tool on ur laptop, and as a replacement for docker compose.",
      "Could I use this for running the same docker compose stack multiple times in parallel? I wrote a lot of bash glue code to make this happen (without kubernetes) for integration and acceptance testing on a single server. Managing envs and networking was a pain, but mostly, I struggle to keep it up to date with infrastructure changes in my platform.",
      "I&#x27;ve just moved on from docker compose. Instead I have a K8s like yaml file and use podman kube play. The learning curve is pretty small in my opinion and at least it is a little closer to production.",
      "Just like KIND runs containerd inside docker, you can also run dockerd inside containerd backed pods.<p>Start a privileged pod with the dind image, copy or mount your compose.yaml inside and you should be able to docker compose up and down, all without mounting a socket (that won&#x27;t exist anyway on containerd CRI nodes)<p>To go even further, kubevirt runs on kind, launch a VM with your compose file passed in via cloud-init.",
      "I&#x27;m not quite sure what level of testing this facilitates. If you&#x27;re testing as close to production as possible, you probably want templated k8s config that scales down to a k8s in CI (e.g. Helm with variables applied that make it minimal). If you just want a local stack to test components and not the k8s config, why not just use docker compose itself?",
      "@sandGorgon8, thank you.<p>I was just telling some ex coworker friends that there was a great need for a compose frontend to more powerful infra backends, and this feels like the answer.<p>Once I get working on it I’ll try to add health check support. That is crucial for a lot of what we’re working on.",
      "So this uses k3s underneath. IMO any local kubernetes distribution is a big resource hog over plain docker. Anyone have ideas for something that is less resource intensive but easier to orchestrate than docker-compose?",
      "Looks promising and really interesting to see and it&#x27;s a very good idea. But when I saw the test folder however, it is completely empty. [0]<p>So is any of this tested?<p>[0] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;sandys&#x2F;kappal&#x2F;tree&#x2F;main&#x2F;test\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;sandys&#x2F;kappal&#x2F;tree&#x2F;main&#x2F;test</a>",
      "[dead]"
    ],
    "full_text": null
  }
]